[{"authors":null,"categories":null,"content":"How to use these pages If you are new to EPOCH, start with the FAQ and the introductory information. Then read the basic examples. There\u0026rsquo;s quite a lot to learn in order to get started, so you should plan to read through all of this section. You will also need to refer to the input deck pages. Next, look at the code and have a play with some test problems. After that re-read the FAQ. This should be enough for testing simple problems. See below for more information on visualising the output files.\nFor specific information, see the index below or use the search function. Alternately, start with the FAQ and read through the pages in order by following the \u0026ldquo;Next section\u0026rdquo; links.\nBasic usage   The EPOCH FAQ list  Getting the code  The structure of the EPOCH codes  Library requirements for the EPOCH codes  Compiling EPOCH  Compiler flags and preprocessor defines  Running EPOCH and basic control of EPOCH  The input deck   The EPOCH input deck   The control block  The boundaries block  The species block  The laser block  The fields block  The window block  The output block  The output_global block  The dist_fn block  The probe block  The collisions block  The qed block  The subset block  The constant block  The injector block    Code details   The EPOCH maths parser  EPOCH use in practice  Using EPOCH in delta_f form  Basic examples of using EPOCH  Changes from previous versions of EPOCH  Visualising EPOCH output   Visualising SDF files using IDL or GNU Data Language (GDL)  Visualising SDF files using LLNL VisIt  Visualising SDF files using Python  Examples with EPOCH Example decks and output are available here:\n  Basic examples of using EPOCH from the manual  A link to submit your own examples will be provided soon\nThe EPOCH workshop The examples from the EPOCH workshop are in two parts: (part 1) (part 2)\nHelpful information  Acknowledging EPOCH The EPOCH Developer Manual is quite out of date at this point, so it contains some information which is no longer correct. However, the fundamental algorithms have not changed so it still contains plenty of useful and relevant information.\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1680612074,"objectID":"7ebcaaa360436ed18cc5fe3ced42705f","permalink":"/documentation.html","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/documentation.html","section":"documentation","summary":"How to use these pages If you are new to EPOCH, start with the FAQ and the introductory information. Then read the basic examples. There\u0026rsquo;s quite a lot to learn in order to get started, so you should plan to read through all of this section.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1689244278,"objectID":"bd355d2fd7172c06ce51b864057845ac","permalink":"/quickstart/basic_examples.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/quickstart/basic_examples.html","section":"quickstart","summary":"","tags":null,"title":"Basic examples","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"1f7de15fc154296a0810ece8d007eb3a","permalink":"/documentation/basic_usage.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage.html","section":"documentation","summary":"","tags":null,"title":"Basic usage","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"9f455340985649684a32d8c48dc6ec92","permalink":"/documentation/code_details.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details.html","section":"documentation","summary":"","tags":null,"title":"Code details","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH is designed so that it can fairly easily be extended while still being written in (more or less) standard Fortran90 and MPI1.2. This section details in increasing complexity what a programmer needs to know to develop the core systems of EPOCH, including the particle pusher, field solver, macro-particle weights and current solver.\nSpecifically, the core structure pages contain:\n  Basic structures - Some global and local variables, including physical constants, grid-properties, the time-step, and deck variables  Particles - How particles are stored in EPOCH, and the information contained in their data-structures  Linked lists - An explanation of the computer-science concept \u0026ldquo;linked lists\u0026rdquo;. These variable-length arrays are used to hold the EPOCH macro-particles.  Partlist - A description of the EPOCH subroutines used to create linked-lists for holding particles.  Field solver - Shows where the fields are evaluated on the EPOCH grid, and the equations solved.  Particle pusher - Describes how particle positions and velocities are updated in EPOCH.  Weighting functions - Explains how macro-particles are interpolated onto grid points, and vice versa.  Current solver - Explains how current densities are calculated within the code.  Boundary conditions - Details the different types of boundaries in an EPOCH simulation.  Parallelism - Discusses how parallelism is achieved in the code, and how the EPOCH load-balancer works.  Pre-compiler flags - How the pre-compiler flags in the Makefile work, and how to use them in the code.  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1680612074,"objectID":"9d57be75839024f18db110da383b5c90","permalink":"/developer/core_structure.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure.html","section":"developer","summary":"EPOCH is designed so that it can fairly easily be extended while still being written in (more or less) standard Fortran90 and MPI1.2. This section details in increasing complexity what a programmer needs to know to develop the core systems of EPOCH, including the particle pusher, field solver, macro-particle weights and current solver.","tags":null,"title":"Code Structure","type":"docs"},{"authors":null,"categories":null,"content":"This section of the manual is aimed at people who intend to edit the EPOCH source code to extend or modify existing features, add new diagnostics or develop new physics packages.\nEPOCH updates the electric and magnetic fields of the system by solving Maxwell\u0026rsquo;s equations, and these fields are used to update the positions of macro-particles using the Lorentz force law. The motion of charges gives the current densities in the system, which in turn are used to update the fields. Quantities are evaluated at different time-steps, and the order of opertations is given in this figure:\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1680612074,"objectID":"12d6fd5f7b29084bf695c665cfd9b216","permalink":"/developer.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer.html","section":"developer","summary":"This section of the manual is aimed at people who intend to edit the EPOCH source code to extend or modify existing features, add new diagnostics or develop new physics packages.","tags":null,"title":"EPOCH Developer Documentation","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"367e567d8f787d773400d890535b775e","permalink":"/documentation/examples.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples.html","section":"documentation","summary":"","tags":null,"title":"Examples","type":"docs"},{"authors":null,"categories":null,"content":"Exactly how to extend EPOCH depends heavily upon what you intend to add. The simplest things to add are new diagnostics, but other places where changes are likely to be include:\n The field solver - Changing the field solver to add new laser-like boundaries, add spatial smoothing to remove noise, add high order field solvers etc. The particle pusher - Change the basic physical model of EPOCH by modifying the particle pusher. The boundary routines - Add new boundary conditions or modify existing boundary conditions. The laser boundary routines - Add new features to the laser boundaries in this routine. Physics packages - EPOCH includes many existing physics packages, but the list is not complete. For example, the user may wish to add support for nuclear or particle physics processes, or electron-ion recombination. The main driver (epochnd.F90) - This is the routine where the main calling sequence of EPOCH is setup, and totally new extensions to EPOCH should be placed in here.  Changing the field solver, the particle pusher or boundary routines is fairly easy to accomplish by reading the section of this manual that details the relevant code. The general sequence for writing an extension would be:\n Add any new global variables needed to shared_data.F90. Add the meat of your change to the code. Test the changes to your code. Make absolutely sure that you can turn your change to the code off. Add controls for your extension to the input deck reader.  Examples The subpages here detail a few examples on how to make direct changes to the EPOCH source-code, without going through user-interaction interfaces. These include:\n  Input deck - Instructions on creating a new input deck block.  Maths parser - How to create a new function for the maths parser.  New module - If you already have the source-code for a new module or physics package, this will tell you how to add it to the EPOCH PIC loop.  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1680612074,"objectID":"35f326d0a76082a1ad6a89be523da98a","permalink":"/developer/extensions.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/extensions.html","section":"developer","summary":"Exactly how to extend EPOCH depends heavily upon what you intend to add. The simplest things to add are new diagnostics, but other places where changes are likely to be include:","tags":null,"title":"Extending EPOCH","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH initialises the simulation by reading the input.deck text file, and writes an output to SDF files. These subpages provide documentation on the string-handling in EPOCH, and give a description on how output scripts work. EPOCH also provides an interface to allow users to easily add new blocks for the input deck, or new functions for the maths parser, which will also be discussed here. These user-interface methods are appropriate for quick jobs, but any extensions intended for a general release should be properly added to the code.\nSpecifically, the pages contain:\n  Basic output - Provides a brief introduction to how the output routines work.  String-handling - Detailed documentation on the functions and subroutines which handle string reading.  Error-codes - Codes used in the EPOCH source-code to identify errors.  Adding outputs - How to output a new derived variable and particle variable. Note that this does not explain how to create a new particle variable, which is a more involved process.  Custom maths parser - How to use the user-interface to quickly create a new function or constant for the maths parser.  Custom deck blocks - How to use another user-interface to quickly add new blocks to the input deck.  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1680612074,"objectID":"c0ac8baf224e0a51db29ff94d7b38c57","permalink":"/developer/input_output.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/input_output.html","section":"developer","summary":"EPOCH initialises the simulation by reading the input.deck text file, and writes an output to SDF files. These subpages provide documentation on the string-handling in EPOCH, and give a description on how output scripts work.","tags":null,"title":"Input Output","type":"docs"},{"authors":null,"categories":null,"content":"Pre-requisites EPOCH is mostly a self-contained code. The code is intended to be run on a Linux-based operating system, and this section will be written for Linux machines. Experienced programmers may be able to adapt these instructions for Windows and Mac, or may choose to run EPOCH from a virtual Linux machine if they don\u0026rsquo;t have access to Linux.\nTo compile and run EPOCH, the system requires:\n A fortran compiler (e.g. GNU Fortran) An MPI library (e.g. Open MPI)  These packages can easily be installed by entering the commands\nsudo apt-get install gfortran sudo apt-get install openmpi-bin openmpi-common libopenmpi-dev libgtk2.0-dev  into a Linux terminal.\nInstalling EPOCH These instructions should work in your host institute if you have git. To install EPOCH, open a linux terminal and type into a command line:\ngit clone --recursive https://github.com/Warwick-Plasma/epoch.git  You will now have a directory called \u0026lsquo;epoch\u0026rsquo;. Inside this directory will be three EPOCH sub-directories epoch1d, epoch2d and epoch3d, an SDF directory and a few other files. EPOCH is split into 3 codes, one for each dimension - these must be built separately.\nIf you are unable to access git, you may download a compressed tar-file containing the code from the \u0026lsquo;Releases\u0026rsquo; section on the EPOCH GitHub webpage. Note that this will not include any bug-fixes since the last release, so it is strongly recommended to use the git installation.\nBuilding the code To build one of the EPOCH codes, navigate to either the epoch1d, epoch2d or epoch3d directories within a Linux terminal, and run:\nmake COMPILER=gfortran -j4  Here we assume you are compiling using mpif90, other compiler options are available. The -j4 key splits the compilation between 4 processors for a speed-up, the 4 can be replaced with a higher number if your system permits.\nThis command installs a basic version of EPOCH - some additional features like bremsstrahlung radiation or particle-ID require adjustments to the Makefile. The optional compilation flags are discussed here.\nRunning the code EPOCH simulations are specified using an input file called input.deck, which is read by the code. Example input decks are present in the example_decks sub-directory in the epoch1d, epoch2d and epoch3d directories. Whichever dimension you chose, ionisation.deck provides a small example simulation which can be run using the default EPOCH build.\nOnce you have a file called input.deck (either copied and renamed from ionisation.deck, or something you have written yourself), then you may run the code.\nTo run any EPOCH code, you must first navigate to the sub-directory of the code in a Linux terminal, such that the ls command shows the bin sub-directory. EPOCH expects you to be here when looking up physics tables. For example, the 2d code can be run by entering epoch2d and running:\nmpirun -np 4 ./bin/epoch2d  You will then be prompted to enter the path to the directory containing your input.deck file. This step may be skipped by piping in the path directly into the run command, using:\nmpirun -np 4 ./bin/epoch2d \u0026lt;\u0026lt;\u0026lt; /path/to/input/  where /path/to/input is the path to the directory containing the input.deck.\nVisualising the data The code generates data in the SDF format. The data is written to a self-describing file format called SDF. This has been developed for use by several codes maintained at the University of Warwick. There are routines for reading the data from within IDL, VisIt, MatLab and Python.\nMore complete documentation on visualisation routines is available here\nAs a quick summary:\n  MATLAB: To read data from the SDF file \u0026ldquo;0007.sdf\u0026rdquo;, run the command: data = GetDataSDF('0007.sdf');. The GetDataSDF function is present in the folder SDF/MATLAB.\n  Python: Data may be extracted and plotted using the sdf_helper library, which can be built using the Makefile. Data can then be read using:\n  import sdf_helper as sh data = sh.getdata(7)    IDL/GDL: The following commands are useful for listing the variables and reading the data: list_variables,7,'Data', data = getstruct(7,/varname), help,data,/struct, where /varname is the name of a variable output from the list. More detailed instructions are present here\n  VisIt: Consult the running instructions at this URL: here\n  Further examples Now the basics have been covered, you\u0026rsquo;re free to start running EPOCH. Documentation on writing input deck files is given here. There are also further examples from previous workshops we have run, which can be viewed in these pages:\n Basic examples\n Workshop\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1680612074,"objectID":"56c37f115652ad1cc402ca7af27fd77f","permalink":"/quickstart.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/quickstart.html","section":"quickstart","summary":"Pre-requisites EPOCH is mostly a self-contained code. The code is intended to be run on a Linux-based operating system, and this section will be written for Linux machines. Experienced programmers may be able to adapt these instructions for Windows and Mac, or may choose to run EPOCH from a virtual Linux machine if they don\u0026rsquo;t have access to Linux.","tags":null,"title":"Quick Start","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"12baaa8579fa05126afecf4f78d995a4","permalink":"/documentation/visualising_output.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output.html","section":"documentation","summary":"","tags":null,"title":"Visualising output","type":"docs"},{"authors":null,"categories":null,"content":"Antennae allow you to specify currents in the simulation domain that are added to the self consistent currents from the core solver. You can either specify the currents entirely manually or you can specify a frequency and a profile for each current component. You can have as many antennae as you want by specifying multiple antenna blocks.\nExample Deck begin:antenna jx = if (r_xy lt micron, 1.0e-5, 0.0) jy = if (r_xy lt micron, 1.0e-5, 0.0) jz = if (r_xy lt micron, 1.0e-5, 0.0) ranges = ((-micron, micron), (-micron, micron)) omega = 1.0e15 start_time = start stop_time = end end:antenna  Keys  jx - Profile for current in x direction. If you do not specify the omega key then you should include any time dependence manually. If the omega key is specified any time variation in jx will be multiplicatively combined with the sinusoidal variation from omega. Can be time and space varying. jy - Profile for current in y direction. If you do not specify the omega key then you should include any time dependence manually. If the omega key is specified any time variation in jy will be multiplicatively combined with the sinusoidal variation from omega. Can be time and space varying. jz - Profile for current in z direction. If you do not specify the omega key then you should include any time dependence manually. If the omega key is specified any time variation in jz will be multiplicatively combined with the sinusoidal variation from omega. Can be time and space varying. ranges - Array of (min,max) pairs for each dimension of your simulation (1 pair for EPOCH1d, 2 pairs for EPOCH2D and 3 pairs for EPOCH3D) showing the domain over which the antenna should operate. Describes the region of space over which the current from the antenna should be applied. The fields generated by that current will propagate everywhere in the simulation domain. If ranges is not present then the antenna will be applied to the whole domain. Performance of the antenna block will be highest if you set the smallest range possible. omega - Optional frequency for the antenna. If this key is set then the current will vary sinusoidally with the specified frequency. This is faster to run than specifying a sinusoidal profile in the jx, jy or jz keys but performs the same (for a frequency that doesn\u0026rsquo;t change in time, see Time variability section). Can be time varying, but not space varying start_time - Time after which to start applying the antenna currents. Can be \u0026ldquo;start\u0026rdquo; to apply from the start of the simulation. If key is not present antenna runs from the start of the simulation. stop_time - Time after which to cease applying the antenna currents. Can be \u0026ldquo;end\u0026rdquo; to apply until the end of the simulation. If key is not present antenna runs until the end of the simulation.  Time variability When you specify time variation for the jx, jy or jz keys this specifies the instantaneous current to be applied at each moment in time.\nWhen you specify time variation in the omega key this specifies the frequency at this time, but this is applied to the phase state of the antenna as an integral. So the sinusoid that is applied to the current is $\\sin\\Bigl(\\int_0^t\\omega(t')dt'\\Bigr)$. For constant $\\omega$ this reduces to $\\sin(\\omega t)$. This gives the correct behaviour for chirped antennae\nExample deck An example deck for this block can be found in example_decks/antenna.deck. The deck should take 5-20 seconds to run.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"707bde4b84117535d6dc281d83030b06","permalink":"/documentation/input_deck/input_deck_antenna.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_antenna.html","section":"documentation","summary":"Antennae allow you to specify currents in the simulation domain that are added to the self consistent currents from the core solver. You can either specify the currents entirely manually or you can specify a frequency and a profile for each current component.","tags":null,"title":"Antenna block","type":"docs"},{"authors":null,"categories":null,"content":"Is this manual up to date? Whenever a new milestone version of EPOCH is finalised, the version number is changed and this manual is updated accordingly. The version number of the manual should match the first two digits for that of the EPOCH source code. This version number is printed to screen when you run the code. The line looks something like the following:\n Welcome to EPOCH2D version 4.16.0 (commit v4.16.0-0-g69eb0fa6-clean)  Here, only the number \u0026ldquo;4.16\u0026rdquo; is important.\nSince version 3.1 of the manual, new additions and changes are mentioned in the appendix.\nWhat is EPOCH? EPOCH is a plasma physics simulation code which uses the Particle in Cell (PIC) method. In this method, collections of physical particles are represented using a smaller number of pseudoparticles, and the fields generated by the motion of these pseudoparticles are calculated using a finite difference time domain technique on an underlying grid of fixed spatial resolution. The forces on the pseudoparticles due to the calculated fields are then used to update the pseudoparticle velocities, and these velocities are then used to update the pseudoparticle positions. This leads to a scheme which can reproduce the full range of classical micro-scale behaviour of a collection of charged particles.\nFeatures of EPOCH   MPI parallelised, explicit, second-order, relativistic PIC code.\n  Dynamic load balancing option for making optimal use of all processors when run in parallel.\n  MPI-IO based output, allowing restart on an arbitrary number of processors.\n  Data analysis and visualisation options include ITT IDL, LLNL VisIt, Mathworks MatLab and matplotlib in Python.\n  Control of setup and runs of EPOCH through a customisable input deck.\n  The origins of the code The EPOCH family of PIC codes is based on the older PSC code written by Hartmut Ruhl and retains almost the same core algorithm for the field updates and particle push routines. EPOCH was written to add more modern features and to structure the code in such a way that future expansion of the code is made as easy as possible.\nHow do I obtain the code? The latest version of EPOCH can be found on GitHub at https://github.com/Warwick-Plasma/epoch\nA tarred and gzipped archive (commonly referred to as a tarball) of the latest release is always made available in the Releases section\nAlternately, using git the code can be cloned using the following command. Note that it is important to include the \u0026lsquo;\u0026lsquo;recursive\u0026rsquo;\u0026rsquo; flag in order to download the SDF submodules..\ngit clone \u0026ndash;recursive https://github.com/Warwick-Plasma/epoch.git\nWhat normalisations are used in EPOCH? Since the idea from the start was that EPOCH would be used by a large number of different users and that it should be as easy as possible to \u0026ldquo;plug in\u0026rdquo; different modules from different people into a given copy of the code, it was decided to write EPOCH in SI units. There are a few places in the code where some quantities are given in other units for convenience (for example charges are specified in multiples of the electron charge), but the entire core of the code is written in SI units.\nWhat are those _num things doing everywhere? Historically using the compiler auto-promotion of REAL to DOUBLE PRECISION was unreliable, so EPOCH uses \u0026ldquo;kind\u0026rdquo; tags to specify the precision of the code. The _num suffixes and the associated definition of REALs as REAL(num) are these \u0026ldquo;kind\u0026rdquo; tags in operation. The _num tags force numerical constants to match the precision of the code, preventing errors due to precision conversion. The important thing is that all numerical constants should be tagged with an _num tag and all REALs should be defined as REAL(num).\nWhat is an input deck? An input deck is text file which can be used to set simulation parameters for EPOCH without needing to edit or recompile the source code. It consists of a list of blocks which start as begin:blockname and end with end:blockname. Within the body of each block is a list of key/value pairs, one per line, with key and value separated by an equals sign. Most aspects of a simulation can be controlled using an input deck, such as the number of grid points in the simulation domain, the initial distribution of particles and initial electromagnetic field configuration. It is designed to be relatively easy to read and edit. For most projects it should be possible to set up a simulation without editing the source code at all. For more details, read the section titled \u0026ldquo;The EPOCH input deck\u0026rdquo;\nI just want to use the code as a black box, or I\u0026rsquo;m just starting. How do I do that? Begin by reading the basic examples. There\u0026rsquo;s quite a lot to learn in order to get started, so you should plan to read through all of this section. You will also need to refer to the input deck pages. Next, look at the code and have a play with some test problems. After that re-read this section. This should be enough for testing simple problems.\nWhat is the auto-loader? Throughout this document we will often refer to the \u0026ldquo;auto-loader\u0026rdquo; when setting up the initial particle distribution. In the input deck it is possible to specify a functional form for the density and temperature of a particle species. EPOCH will then place the particles to match the density function and set the velocities of the particles so that they match the Maxwellian thermal distribution for the temperature. The code which performs this particle set up is called the \u0026ldquo;auto-loader\u0026rdquo;.\nAt present, there is no way to specify a non-Maxwellian particle distribution from within the input deck. In such cases, it is necessary to edit and recompile the EPOCH source code. The recommended method for setting the initial particle properties is to use the \u0026ldquo;manual_load\u0026rdquo; function as described here.\nWhat is a maths parser? As previously mentioned, the behaviour of EPOCH is controlled using an input deck which contains a list of key/value pairs. The value part of the pair is not restricted to simple constants but can be a complex mathematical expression. It is evaluated at run time using a section of code called the \u0026ldquo;maths parser\u0026rdquo;. There is no need for the end user to know anything about this code. It is just there to enable the use of mathematical expressions in the input deck. Further information about this facility can be found here.\nI am an advanced user, but I want to set up the code so that less experienced users can use it. How do I do that? See here.\nI want to develop an addition to EPOCH. How do I do that? A slightly outdated developers manual exists which should be sufficient to cover most aspects of the code functionality. However, the code is written in a fairly modular and consistent manner, so reading through that is the best source of information. If you get stuck then you can post questions on the GitHub forums.\nI want to have a full understanding of how EPOCH works. How do I do that? If you really want to understand EPOCH in full, the only way is to read all of this manual and then read through the code. Most of it is commented.\nHow do I acknowledge use of the code? See here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"e17b74a6c4a52306539497a766fb1fff","permalink":"/documentation/basic_usage/faq.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/faq.html","section":"documentation","summary":"Is this manual up to date? Whenever a new milestone version of EPOCH is finalised, the version number is changed and this manual is updated accordingly. The version number of the manual should match the first two digits for that of the EPOCH source code.","tags":null,"title":"FAQs","type":"docs"},{"authors":null,"categories":null,"content":"It can sometimes be useful to restart an EPOCH simulation from an SDF file. Supercomputers may often place limits on job length, or systems may be prone to crashing, so code-restarts can help prevent CPU waste.\nUsing the EPOCH output block, the user is able to force the code to write restart-dumps. These differ from regular dumps, as they write all the particle and field properties required to restart the simulation. These will quite often be large and slow files to write, so there is a trade-off between simulation speed (no restarts) and safety (many restart dumps).\nIn this page we will simulate a basic laser injected into a vacuum, and run the simulation with and without restarts.\nSimulation set-up Here we provide the input deck for a basic 2D simulation where a plane wave enters the simulation window through the x_min boundary. This creates an SDF file containing the Ey field every 10 fs. This is a lightweight diagnostic, and is not sufficient to restart the whole simulation. A plot of the electric field from the 0010.sdf file is also present, along with the MATLAB script which created it (other post-processing tools are available). Instructions on running EPOCH input decks are provided here.\nbegin:control nx = 500 ny = 500 t_end = 100 * femto x_min = 0.0 x_max = 10.0e-6 y_min = -5.0e-6 y_max = 5.0e-6 stdout_frequency = 10 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = open bc_y_min = periodic bc_y_max = periodic end:boundaries begin:laser boundary = x_min intensity_w_cm2 = 1.0e15 lambda = 1.0e-6 profile = 1.0 t_profile = 1.0 end:laser begin:output dt_snapshot = 10.0e-15 ey = always end:output  This code took 3 seconds to run on a 4 core laptop. For the MATLAB post-processing, the contents of epoch/SDF/MATLAB were copied into the directory containing the SDF files and input.deck, and a plot was generated using this script:\n% Extract data data = GetDataSDF('0010.sdf'); % Format grid x_edges = data.Electric_Field.Ey.grid.x; y_edges = data.Electric_Field.Ey.grid.y; x_centres = 0.5*(x_edges(2:end) + x_edges(1:end-1)); y_centres = 0.5*(y_edges(2:end) + y_edges(1:end-1)); [x_plot, y_plot] = meshgrid(x_centres, y_centres); % Create and format plot surf(x_plot*1.0e6, y_plot*1.0e6, data.Electric_Field.Ey.data','EdgeColor','none'); view(2); xlabel('x [\\mum]'); ylabel('y [\\mum]'); cbar = colorbar; cbar.Label.String = 'Ey [V/m]'; ax = gca; ax.FontSize = 16; title(sprintf('%g fs',data.time*1.0e15));  Restarting from simulation end Now we have a basic script, let us run it in two simulations loading the second from a restart-dump. In our first run, we will reduce the run-time to 50 fs, and force the final dump to be restartable. We will start the second simulation from the 50 fs restart-dump, and run to completion.\nFor the first run, take the previous input.deck and make some changes. Firstly, change t_end in the control block from 100 * femto to 50 * femto. Next, add the following line to the output block:\nforce_final_to_be_restartable = T  When we run this simulation, we find that we generate output files from 0000.sdf to 0005.sdf. If we inspect the file-sizes, we\u0026rsquo;ll see that 0005.sdf has a size of 18 MB, while the rest have 2 MB - our restart-dump file is much larger.\nFor the restarted run, change t_end in the control block back to 100 * femto, and add the control block line:\nrestart_snapshot = 5  When running the restarted deck, EPOCH will print the lines:\n Loading snapshot for time 5.0012906556442301E-014 Input file contains 29 blocks Load from restart dump OK  if run successfully. You\u0026rsquo;ll see the SDF files continue from where they left off, and if we were to once again print the Ey field at 0010.sdf, we once again find what we had before:\nRestart checkpoints The previous example assumed you could split your simulation up into obvious chunks, but what if the nodes you run on have a tendency to crash? In this case, it would make more sense to make multiple restart dumps. While this could be achieved by replacing force_final_to_be_restartable with restart_dump_every to make multiple restart dumps, you may want to separate your restart dumps from your usual dumps. This can be done using multiple output blocks.\nThe previous example has been extended to produce two sets out output files, one labelled normal0000.sdf to normal0010.sdf, and the other labelled restart0000.sdf to restart0005.sdf.\nbegin:control nx = 500 ny = 500 t_end = 100 * femto x_min = 0.0 x_max = 10.0e-6 y_min = -5.0e-6 y_max = 5.0e-6 stdout_frequency = 10 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = open bc_y_min = periodic bc_y_max = periodic end:boundaries begin:laser boundary = x_min intensity_w_cm2 = 1.0e15 lambda = 1.0e-6 profile = 1.0 t_profile = 1.0 end:laser begin:output name = normal file_prefix = normal dt_snapshot = 10.0e-15 ey = always end:output begin:output name = restart file_prefix = restart restartable = T dt_snapshot = 20.0e-15 end:output  Once we have this, we can restart from any of the restart SDF files. Because these files now have a prefix, we must add a line like:\nrestart_snapshot = restart0004.sdf  to the control block, where we use the full file-name.\nRestart at end of the cluster job allocation The issue with regular checkpoints is that it may be overkill for your job, and any CPU time spent after the final checkpoint is wasted when you come to restart. Also, writing a restart dump at the end of a simulation is less useful when you run on supercomputers, as you don\u0026rsquo;t know where you\u0026rsquo;ll be at the end of your maximum job time!\nIn this case, you need a way to automatically stop the simulation as you near the end of your allotted time, and then write a restart dump so you can continue later. This can be achieved using the STOP file.\nWhile running, EPOCH continuously scans the directory containing input.deck for a file with a filename STOP. When this file appears, EPOCH completes the current time-step, writes a restart dump, ends the simulation, and deletes the STOP file.\nFor example, if you were to submit an EPOCH job on a super-computer with an allocated time of 5 hours, and you wanted the code to stop at 4 hours 30 mins (leaving you 30 minutes to write a restart dump), you could add the line:\n(sleep 16200; touch STOP) \u0026amp;  to your job-script just before EPOCH is run. This will create a background process which will wait 16200 seconds, then create the STOP file in the working directory of the original command. If this is the same directory as your input deck, this will stop the code with (hopefully) enough time to write the restart dump. You may want to check in advance how long a restart dump takes to write for your project.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689244278,"objectID":"ccf7f15e9e03c7348ceb1451eb6cb5eb","permalink":"/quickstart/basic_examples/restart_example.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/quickstart/basic_examples/restart_example.html","section":"quickstart","summary":"It can sometimes be useful to restart an EPOCH simulation from an SDF file. Supercomputers may often place limits on job length, or systems may be prone to crashing, so code-restarts can help prevent CPU waste.","tags":null,"title":"Restart from SDF dump","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the species of particles which are used in the code. Also details of how these are initialised. See EPOCH input deck for more information on the input deck.\nBasics The next section of the input deck describes the particle species used in the code. An example species block for any EPOCH code is given below. In this example, den_max is a parameter created by the user in a constant block.\nbegin:species name = Electron charge = -1.0 mass = 1.0 frac = 0.5 # npart = 2000 * 100 number_density = 1.e4 temp = 1e6 temp_x = 0.0 temp_y = temp_x(Electron) number_density_min = 0.1 * den_max number_density = if(abs(x) lt thick, den_max, 0.0) number_density = if((x gt -thick) and (abs(y) gt 2e-6), \\ 0.0, number_density(Electron)) end:species begin:species name = Carbon charge = 4.0 mass = 1836.0*12 frac = 0.5 number_density = 0.25*number_density(Electron) temp_x = temp_x(Electron) temp_y = temp_x(Electron) dumpmask = full end:species  Each species block accepts the following parameters:\n  name - This specifies the name of the particle species defined in the current block. This name can include any alphanumeric characters in the basic ASCII set. The name is used to identify the species in any consequent input block and is also used for labelling species data in any output dumps. It is a mandatory parameter. **NOTE: IT IS IMPOSSIBLE TO SET TWO SPECIES WITH THE SAME NAME! **\n  charge - This sets the charge of the species in multiples of the electron charge. Negative numbers are used for negatively charged particles. This is a mandatory parameter.\n  mass - This sets the mass of the species in multiples of the electron mass. Cannot be negative. This is a mandatory parameter.\n  npart - This specifies the number of pseudoparticles which should be loaded into the simulation domain for this species block. Using this parameter is the most convenient way of loading particles for simulations which contain multiple species with different number densities. If npart is specified in a species block then any value given for npart in the control block is ignored. npart should not be specified at the same time as frac within a species block.\n  frac - This specifies what fraction of npart (the global number of particles specified in the control block) should be assigned to the species.\n  **NOTE: frac should not be specified at the same time as npart for a given species. **\n npart_per_cell - Integer parameter which specifies the number of particles per cell to use for the initial particle loading. At a later stage this may be extended to allow \u0026ldquo;npart_per_cell\u0026rdquo; to be a spatially varying function.  If per-species weighting is used then the value of \u0026ldquo;npart_per_cell\u0026rdquo; will be the average number of particles per cell. If \u0026ldquo;npart\u0026rdquo; or \u0026ldquo;frac\u0026rdquo; have also been specified for a species, then they will be ignored.\nTo avoid confusion, there is no globally used \u0026ldquo;npart_per_species\u0026rdquo;. If you want to have a single value to change in the input deck then this can be achieved using a constant block.\n dumpmask - Determines which output dumps will include this particle species. The dumpmask has the same semantics as those used by variables in the output block. The actual dumpmask from the output block is applied first and then this one is applied afterwards. For example, if the species block contains \u0026ldquo;dumpmask = full\u0026rdquo; and the output block contains \u0026ldquo;vx = always\u0026rdquo; then the particle velocity will be only be dumped at full dumps for this particle species. The default dumpmask is \u0026ldquo;always\u0026rdquo;. dump - This logical flag is provided for backwards compatibility. If set to \u0026ldquo;F\u0026rdquo; it has the same meaning as \u0026ldquo;dumpmask = never\u0026rdquo;. If set to \u0026ldquo;T\u0026rdquo; it has the same meaning as \u0026ldquo;dumpmask = always\u0026rdquo;. zero_current - Logical flag switching the particle species into zero-current particles. Zero-current particles are enabled if the if the \u0026ldquo;NO_TRACER_PARTICLES\u0026rdquo; precompiler option has not been used and the \u0026ldquo;zero_current\u0026rdquo; flag is set to true for a given species. When set, the species will move correctly for its charge and mass, but contribute no current. This means that these particles are passive elements in the simulation. In all other respects they are designed to behave identically to ordinary particles, so they do take part in collisions by default. This can be prevented using the collision matrices. WARNING: Since the particles effectively have zero weight in terms of their numerical heating properties, they do not always behave in the same way that an ordinary particle with weight would behave and this can sometimes lead to unexpected behaviour. If the purpose is merely to track a subset of a particle species to use as output then a better mechanism to use is \u0026ldquo;persistent subsets\u0026rdquo; (see here). \u0026ldquo;tracer\u0026rdquo; is currently accepted as an alias but this will be removed in version 5.0. \u0026ldquo;zero_current = F\u0026rdquo; is the default value. identify - Used to identify the type of particle. Originally this was used for the QED routines, but it has since been adopted for other physics packages too. See here for details. immobile - Logical flag. If this parameter is set to \u0026ldquo;T\u0026rdquo; then the species will be ignored during the particle push. The default value is \u0026ldquo;F\u0026rdquo;. background_species - Logical flag. If set to \u0026ldquo;T\u0026rdquo; the species will be treated as a non evolving continuum background. No particles are loaded. Any particle-like specifications will be ignored. Background species are currently only used by the bremsstrahlung radiation model. See here for details. Default value is \u0026ldquo;F\u0026rdquo;. \u0026ldquo;background\u0026rdquo; is accepted as an alias.  The species blocks are also used for specifying initial conditions for the particle species. The initial conditions in EPOCH can be specified in various ways, but the easiest way is to specify the initial conditions in the input deck file. This allows any initial condition which can be specified everywhere in space by a number density and a drifting Maxwellian distribution function. These are built up using the normal maths expressions, by setting the density and temperature for each species which is then used by the autoloader to actually position the particles.\nThe elements of the species block used for setting initial conditions are:\n number_density - Particle number density in $m^{-3}$. As soon as a number_density= line has been read, the values are calculated for the whole domain and are available for reuse on the right hand side of an expression. This is seen in the above example in the first two lines for the Electron species, where the number density is first set and then corrected. If you wish0 to specify the number density in parts per cubic centimetre then you can divide by the \u0026ldquo;cc\u0026rdquo; constant (see here). This parameter is mandatory. \u0026ldquo;density\u0026rdquo; is accepted as an alias. number_density_min - Minimum particle number density in $m^{-3}$. When the number density in a cell falls below number_density_min the autoloader does not load any pseudoparticles into that cell to minimise the number of low weight, unimportant particles. If set to 0 then all cells are loaded with particles. This is the default. \u0026ldquo;density_min\u0026rdquo; is accepted as an alias. number_density_max - Maximum particle number density in $m^{-3}$. When the number density in a cell rises above number_density_max the autoloader clips the number_density to number_density_max allowing easy implementation of exponential rises to plateaus. If it is a negative value then no clipping is performed. This is the default. \u0026ldquo;density_max\u0026rdquo; is accepted as an alias. mass_density - Particle mass density in $kg,m^{-3}$. The same as \u0026ldquo;number_density\u0026rdquo; but multiplied by the particle mass. If you wish to use units of $g,cm^{-3}$ then append the appropriate multiplication factor. For example: \u0026ldquo;mass_density = 2 * 1e3 / cc\u0026rdquo;. temp_{x,y,z} - The temperature in each direction for a thermal distribution in Kelvin. temp - Sets an isotropic temperature distribution in Kelvin. If both temp and a specific temp_x, temp_y, temp_z parameter is specified then the last to appear in the deck has precedence. If neither are given then the species will have a default temperature of zero Kelvin. temp_{x,y,z}_ev, temp_ev - These are the same as the temperature parameters described above except the units are given in electronvolts rather than Kelvin, i.e. using 1ev = 11604.5K . drift_{x,y,z} - Specifies a momentum space offset in $kg\\ ms^{-1}$ to the distribution function for this species. By default, the drift is zero. offset - File offset. See below for details.  Loading data from a file It is also possible to set initial conditions for a particle species using an external file. Instead of specifying the initial conditions mathematically in the input deck, you specify in quotation marks the filename of a simple binary file containing the information required. For more information on what is meant by a \u0026ldquo;simple binary file\u0026rdquo;, see here.\nbegin:species name = Electron number_density = 'Data/ic.dat' offset = 80000 temp_x = 'Data/ic.dat' end:species  The sizes of the variables to be filled do not need to be provided: the code will continue reading until the given variable is filled. Note that ghost or guard cells should not be included in the file as they cannot be set this way.\nAn additional element is also introduced, the offset element. This is the offset in bytes from the start of the file to where the data should be read from. As a given line in the block executes, the file is opened, the file handle is moved to the point specified by the offset parameter, the data is read and the file is then closed. Therefore, unless the offset value is changed between data reading lines the same data will be read into all the variables. The data is read in as soon as a line is executed, and so it is perfectly possible to load data from a file and then modify the data using a mathematical expression. The example block above is for 10,000 values at double precision, i.e. 8-bytes each. The density data is the first 80,000 bytes of \u0026ldquo;ic.dat\u0026rdquo;. Bytes 80,000 to 160,000 are the temp_x data.\nThe file should be a simple binary file consisting of floating point numbers of the same precision as _num in the core EPOCH code. For multidimensional arrays, the data is assumed to be written according to FORTRAN array ordering rules (i.e. column-major order). NOTE: The files that are expected by this block are SIMPLE BINARY files, NOT FORTRAN unformatted files. It is possible to read FORTRAN unformatted files using the offset element, but care must be taken!\nDelta-f parameters The following entries are used for configuring the Delta-f method\n number_density_back drift_{x,y,z}_back temp_{x,y,z}_back temp_{x,y,z}_back_ev temp_back temp_back_ev  These all have the same meanings as the parameters listed above that don\u0026rsquo;t include the \u0026ldquo;_back\u0026rdquo; text, except that they specify the values to use for the background distribution function.\nParticle migration between species It is sometimes useful to separate particle species into separate energy bands and to migrate particles between species when they become more or less energetic. A method to achieve this functionality has been implemented. It is specified using two parameters to the \u0026ldquo;control\u0026rdquo; block:\n use_migration - Logical flag which determines whether or not to use particle migration. The default is \u0026ldquo;F\u0026rdquo;. migration_interval - The number of timesteps between each migration event. The default is 1 (migrate at every timestep). The following parameters are added to the \u0026ldquo;species\u0026rdquo; block: migrate - Logical flag which determines whether or not to consider this species for migration. The default is \u0026ldquo;F\u0026rdquo;. promote_to - The name of the species to promote particles to. demote_to - The name of the species to demote particles to. promote_multiplier - The particle is promoted when its energy is greater than \u0026ldquo;promote_multiplier\u0026rdquo; times the local average. The default value is 1. demote_multiplier - The particle is demoted when its energy is less than \u0026ldquo;demote_multiplier\u0026rdquo; times the local average. The default value is 1. promote_number_density - The particle is only considered for promotion when the local number density is less than \u0026ldquo;promote_number_density\u0026rdquo;. The default value is the largest floating point number. demote_number_density - The particle is only considered for demotion when the local number density is greater than \u0026ldquo;demote_number_density\u0026rdquo;. The default value is 0.  Ionisation EPOCH now includes both field and collisional ionisation, which can be activated by switching on keys in different blocks. Previous versions of EPOCH forced the user to specify ionisation energies for each ion charge state, but since EPOCH 4.19, these are set automatically using look-up tables.\nField and collisional ionisation must be switched on in the control block and collision block respectively, and species which are to be ionised must be specified in their species block. A basic example of using both ionisation mechanisms is given below, where non-relevant lines have been omitted.\nbegin:control use_multiphoton = T use_bsi = F field_ionisation = T physics_table_location = \u0026quot;/absolute/path/to/epoch/epoch2d/src/physics_packages/TABLES\u0026quot; end:control begin:collisions use_collisional_ionisation = T ci_n_step = 3 end:collisions begin:species name = Carbon charge = 0 atomic_no = 6 ionise = T ionise_limit = 3 unique_electron_species = T end:species begin:species name = Carbon4 charge = 4 atomic_no = 6 ionise = T ionisation_electron_species = (Electron4, Electron) end:species begin:species name = Electron identify:electron end:species  A full summary of the keys used in ionisation has been provided below:\n  field_ionisation - Switches on field ionisation.\n  use_collisional_ionisation - Switches on ionisation by collisional electron impact.\n  physics_table_location - If running the code from a non-standard directory, you will need to specify a path to the physics tables. This can be skipped if you run the code from the epoch1d, epoch2d, or epoch3d directories.\n  ci_n_step - Only performs the collisional ionisation calculation once every n steps, where n is set by this parameter. This is done to speed up the code, and the default is 1 (every step). When this is greater than 1, the assumed time-step for the collisional ionisation calculation is n*dt. Note that an ion may only be ionised once per calculation, so if n is too high, the number of ions will be underestimated.\n  atomic_no - Atomic number of the element. When combined with the charge, the code can deduce the element and charge-state of the ion, and may use the appropriate ionisation energy and shell binding energies.\n  ionise - Allows ionisation of this species, and generates additional particle species for each ion charge state. Here, Carbon will generate a Carbon1, Carbon2, and Carbon3 species. If you add a Carbon2 species block, it will be correctly linked to Carbon3. Only switch on ionise for the base state.\n  ionise_limit - This limits the number of additional particle species to be generated. In this example, ion macro-particles in the Carbon species can only be ionised 3 times - ionisation of Carbon3 will not be considered.\n  ionisation_electron_species - Name of the electron species to populate with ejected electrons. This can be specified as an array in the event that the user wishes some levels to have a different electron species which can be handy for monitoring ionisation at specific levels. electron and electron_species are accepted as synonyms. Either one species for all ionisation levels, or one species for each level should be specified. In the Carbon4 example, the user may have written ionisation_electron_species = Electron to use the Electron species for all ejected electrons.\n  unique_electron_species - If \u0026ldquo;T\u0026rdquo;, this generates a unique electron species to populate with ejected electrons from each ion charge state. The user must use this, or ionisation_electron_species.\n  identify - Collisional ionisation considers ionisation between every electron species and every species which can be ionised. To tell EPOCH which species are electrons, you must include the identify:electron key. EPOCH will also treat particles in any ejected-electron species as particles which can trigger collisional ionisation.\n  Ionised states are created automatically and are named according to the ionising species name with a number appended. For example, with the Carbon species block, the species named \u0026ldquo;Carbon1\u0026rdquo;, \u0026ldquo;Carbon2\u0026rdquo; and \u0026ldquo;Carbon3\u0026rdquo; are automatically created. Here the Carbon4 block is pre-ionised, and ends with its charge state. If a species name ends in its charge-state, EPOCH will recognise that the \u0026ldquo;base name\u0026rdquo; is Carbon, and so the Carbon4 block will create a \u0026ldquo;Carbon5\u0026rdquo; and \u0026ldquo;Carbon6\u0026rdquo; species. These species will also inherit the ``dump'' parameter from their parent species. This behaviour can be overridden by explicitly adding a species block of the same name with a differing dumpmask.\nField ionisation consists of three distinct regimes; multiphoton in which ionisation is best described as absorption of multiple photons, tunnelling in which deformation of the atomic Coulomb potential is the dominant factor, and barrier suppression ionisation in which the electric field is strong enough for an electron to escape classically. It is possible to turn off multiphoton or barrier suppression ionisation through the input deck using the following control block parameters:\n  use_multiphoton - Logical flag which turns on modelling ionisation by multiple photon absorption. This should be set to \u0026ldquo;F\u0026rdquo; if there is no laser attached to a boundary as it relies on laser frequency. The default is \u0026ldquo;T\u0026rdquo;.\n  use_bsi - Logical flag which turns on barrier suppression ionisation correction to the tunnelling ionisation model for high intensity lasers. The default is \u0026ldquo;T\u0026rdquo;.\n  When collisional ionisation is switched on, ionisation between all electron species and all species which may be ionised is considered - the collide parameter used in the collisions block has no effect on collisional ionisation. Species which may be ionised include any species with ionise=T set, and the ionised variants of this species up to the fully ionised state, or ionise_limit. For electrons, EPOCH will identify any species set as a destination for ejected electrons as an electron species, which can trigger further collisional ionisation. To mark other species as electrons for collisional ionisaiton, the identify key must be used. Any electron alias may be used for identify, including electrons created from pair production.\nSpecies Boundary Conditions  bc_x_min - Boundary condition to be applied to this species only on the lower x boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_x_max - Boundary condition to be applied to this species only on the upper x boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_y_min - Boundary condition to be applied to this species only on the lower y boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_y_max - Boundary condition to be applied to this species only on the upper y boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_z_min - Boundary condition to be applied to this species only on the lower z boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_z_max - Boundary condition to be applied to this species only on the upper z boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. meet_injectors - Logical flag determining whether the background plasma should be extended to meet the point where particle injectors operate from. This means that plasma is loaded one particle shape function length outside the boundary. This means that it is possible to use an injector to \u0026ldquo;continue\u0026rdquo; an existing drifting plasma. NOT COMPATIBLE WITH PERIODIC BOUNDARY CONDITIONS!  Maxwell Juttner distributions As of version 4.15, EPOCH allows the user to request a Maxwell-Jttner distribution rather than a Maxwellian distribution when sampling the particle momentum for a species.\nThis feature does not at present work with the delta_f loader and is not available for particle injectors. It does work correctly with the moving window.\n  use_maxwell_juttner - Logical flag determining whether to sample from the Maxwell-Jttner distribution when loading the particle species. If \u0026ldquo;T\u0026rdquo; then Maxwell-Jttner is used and if \u0026ldquo;F\u0026rdquo; Maxwellian is used. The default value is \u0026ldquo;F\u0026rdquo;.\n  fractional_tail_cutoff - The sampling is carried out using a rejection method with an arbitrary cut-off. This parameter takes a floating-point argument which specifies the fraction of maximum value at which the sampling should be cut off. Smaller values lead to distortion nearer the peak of the distribution but are faster to sample. Larger values lead to a better approximation of the distribution function but are slower to sample. The default value is 0.0001.\n  If drifts are specified with the Maxwell-Jttner distribution then the distribution is calculated in the rest frame and then Lorentz transformed to the specified drifting frame.\nArbitrary Distribution functions As of version 4.15, EPOCH also allows the user to request an arbitrary non-Maxwellian distribution function to use when sampling the particle momentum for a species. If combined with a specified drift then the distribution function is calculated first and the drift is applied to the resulting particles by Lorentz transform.\nThis feature does not at present work with the delta_f loader and is not available for particle injectors. It does work correctly with the moving window.\n dist_fn - Specifies the functional form of the distribution function, normalised to have a maximum value of 1. The variables \u0026ldquo;px\u0026rdquo;, \u0026ldquo;py\u0026rdquo; and \u0026ldquo;pz\u0026rdquo; should be used to parameterise the x, y and z components of momentum. This may freely vary in space but temporal variation will be ignored since this is only evaluated at the start of the simulation.   dist_fn_p{x,y,z}_range - Comma separated pair of numbers to specify the range of momentum for p_{x,y,z} in SI units. Should be of the form \u0026ldquo;\u0026lt;lower_range\u0026gt;, \u0026lt;upper_range\u0026gt;\u0026rdquo;  If a range for a momentum direction is not specified then that momentum is assumed to be zero. It is up to the user to ensure that the range is large enough to correctly capture their desired distribution function. Sampling is by a simple rejection sampling and may be much slower than the existing Maxwellian sampler. EPOCH will print a warning if a large number of samples are needed to complete the sampling. If this occurs then you might need to reduce the range of momentum over which sampling is considered.\nIf the \u0026ldquo;dist_fn\u0026rdquo; key is supplied then any supplied temperature keys are ignored. An example of setting up a truncated power law distribution in px would be\nbegin:constant dens = 10 v0 = 0.05 * c vmax = 0.5 * c p0 = v0 * me * (1.0 + 4.0 * x/x_max) pmax = vmax * me alpha = -2.0 end:constant begin:species name = Electron_pl charge = -1 mass = 1.0 frac = 0.5 number_density = dens #Truncated power law distribution in px dist_fn = exp(-p0/px) * (px/p0)^(alpha) dist_fn_px_range = (0, pmax) end:species  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687512826,"objectID":"cd349d1eac12f442231265345663d23c","permalink":"/documentation/input_deck/input_deck_species.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_species.html","section":"documentation","summary":"This block contains information about the species of particles which are used in the code. Also details of how these are initialised. See EPOCH input deck for more information on the input deck.","tags":null,"title":"Species block","type":"docs"},{"authors":null,"categories":null,"content":"When obtained, the EPOCH codes all have a similar structure. If the tarred and gzipped archive (commonly referred to as a tarball) is downloaded and unpacked into the user\u0026rsquo;s $HOME directory, then the extracted contents will consist of a directory named \u0026ldquo;$HOME/epoch-4.12.0\u0026rdquo; (with \u0026ldquo;4.12.0\u0026rdquo; substituted by the current version number) and the subdirectories and files listed below.\nAlternatively, if the code is checked out from the GitHub git repository with the command\ngit clone --recursive https://github.com/Warwick-Plasma/epoch.git\nthen the directory will be \u0026ldquo;$HOME/epoch\u0026rdquo;.\nOnce the code has been obtained, the top-level directory will contain the following 4 directories and several files\n epoch1d - Source code and other files required for the 1D version of EPOCH. epoch2d - Source code and other files required for the 2D version of EPOCH. epoch3d - Source code and other files required for the 3D version of EPOCH. SDF - Source code for the SDF file format which is used to generate output for EPOCH runs. This directory also includes various tools and readers for working with SDF files. CHANGELOG - A brief overview of the change history for each released version of EPOCH. CODING_STYLE - This document contains the conventions which must be used for any code being submitted for inclusion in the EPOCH project. LICENSE - A copy of the GPLv3 license which is used by the EPOCH project. README.md - A brief overview of obtaining and using the EPOCH code. make_tarball.sh - This is a shell script which is used for creating the tarred and gzipped archives of EPOCH which are posted to the GitHub server each time a new release is made. test_all.sh - A regression test script used when testing the code.  The three EPOCH subdirectories all have a similar structure. Inside each of the epoch{1,2,3}d directories, there are 3 sub-directories:\n src - The EPOCH source code. example_decks - A sample data directory containing example input deck files. Data - This is an empty directory to use for running simulations.  there are also 3 files:\n Makefile - A standard makefile. Start.pro - An IDL script which starts the IDL visualisation routines. Execute it using \u0026ldquo;idl Start\u0026rdquo;. unpack_source_from_restart - Restart dumps can be written to contain a copy of the input decks and source code used to generate them. This script can be used to unpack that information from a given restart dump. It is run from the command line and must be passed the name of the restart dump file.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"0be0ede1fad1b389d1892668595ddcd9","permalink":"/documentation/basic_usage/structure.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/structure.html","section":"documentation","summary":"When obtained, the EPOCH codes all have a similar structure. If the tarred and gzipped archive (commonly referred to as a tarball) is downloaded and unpacked into the user\u0026rsquo;s $HOME directory, then the extracted contents will consist of a directory named \u0026ldquo;$HOME/epoch-4.","tags":null,"title":"Code structure","type":"docs"},{"authors":null,"categories":null,"content":"To compile EPOCH in the supplied state, you must first change to the correct working directory. As explained in , the root directory for EPOCH contains several subdirectories, including separate directories for each of the 1D, 2D and 3D versions of the code. To compile the 2D version of the code, you first switch to the \u0026ldquo;epoch2d\u0026rdquo; directory using the command cd $HOME/epoch/epoch2d and then type make and the code will compile. There are certain options within the code which are controlled by compiler preprocessors and are described in the next section. When the code is compiled, it creates a new directory called \u0026ldquo;bin\u0026rdquo; containing the compiled binary which will be called epoch1d, epoch2d or epoch3d. To run the code, just execute the binary file by typing: ./bin/epoch2d or whatever the correct binary is for the dimensionality of the code that you have. You should be given a screen which begins with the EPOCH logo, and then reads:\nThe code was compiled with no compile time options Welcome to EPOCH2D version 4.12.0 (commit v4.12.0-0-gfd74a464-clean) Code is running on 1 processing elements Specify output directory  At this point, the user simply types in the name of the (already existing) output directory and the code will read the input deck files inside the specified directory and start running. To run the code in parallel, just use the normal mpirun or mpiexec scripts supplied by your MPI implementation. If you want the code to run unattended, then you will need to pipe in the output directory name to be used. The method for doing this varies between MPI implementations. For many MPI implementations (such as recent versions of OpenMPI) this can be achieved with the following: echo Data | mpirun -np 2 ./bin/epoch2d Some cluster setups accept the following instead: mpirun -np 2 ./bin/epoch2d \u0026lt; deck.file where \u0026ldquo;deck.file\u0026rdquo; is a file containing the name of the output directory. Some cluster queueing systems do not allow the use of input pipes to mpirun. In this case, there is usually a \u0026ldquo;-stdin\u0026rdquo; command line option to specify an input file. See your cluster documentation for more details.\nAs of version 4.2.12, EPOCH now checks for the existence of a file named \u0026ldquo;USE_DATA_DIRECTORY\u0026rdquo; in the current working directory before it prompts the user for a Data directory. If such a file exists, it reads it to obtain the name of the data directory to use and does not prompt the user. If no such file exists, it prompts for a data directory name as before. This is useful for cluster setups in which it is difficult or impossible to pipe in the directory name using a job script.\nThe \u0026ldquo;Makefile\u0026rdquo; contains configurations for fort, gfortran, pgi, g95, hector/archer and ibm (the compiler suite used on IBM\u0026rsquo;s BlueGene machines). In order to compile using one of the listed configurations, add the \u0026ldquo;COMPILER=\u0026rdquo; option to the \u0026ldquo;make\u0026rdquo; command. For example make COMPILER=gfortran will compile the code using the gfortran compiler and appropriate compiler flags. The options are\n COMPILER=gfortran - GNU Fortran COMPILER=intel - Intel ifort COMPILER=pgi - Portland group compiler COMPILER=g95 - G95 compiler COMPILER=ibm - IBM AIX Fortran compiler for BlueGene COMPILER=hector - Cray compiler as used on hector and archer  As of version 4.11, it is now possible for the build system to automatically detect the correct compiler to use. Typing make COMPILER=auto will cause the build system to guess which compiler is in use. Note that this might not always work, so it is better to use the correct value for COMPILER if it is already known.\nYou can also compile the code with debugging flags by adding \u0026ldquo;MODE=debug\u0026rdquo; and can compile using more than one processor by using \u0026ldquo;-j\u0026lt;n\u0026gt;\u0026rdquo;, where \u0026ldquo;\u0026lt;n\u0026gt;\u0026rdquo; is the number of processors to use. Note that this is just to speed up the compilation process; the resulting binary can be run on any number of processors.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"d50515e99eb5d4744eb8d368c13b3911","permalink":"/documentation/basic_usage/compiling.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/compiling.html","section":"documentation","summary":"To compile EPOCH in the supplied state, you must first change to the correct working directory. As explained in , the root directory for EPOCH contains several subdirectories, including separate directories for each of the 1D, 2D and 3D versions of the code.","tags":null,"title":"Compiling EPOCH","type":"docs"},{"authors":null,"categories":null,"content":"As already stated, some features of the code are controlled by compiler preprocessor directives. The flags for these preprocessor directives are specified in \u0026ldquo;Makefile\u0026rdquo; and are placed on lines which look like the following:\nDEFINES += $(D)PER_SPECIES_WEIGHT  On most machines $(D) just means -D but the variable is required to accommodate more exotic setups.\nMost of the flags provided in the \u0026ldquo;Makefile\u0026rdquo; are commented out by prepending them with a \u0026ldquo;#\u0026rdquo; symbol (the \u0026ldquo;make\u0026rdquo; system\u0026rsquo;s comment character). To turn on the effect controlled by a given preprocessor directive, just uncomment the appropriate \u0026ldquo;DEFINES\u0026rdquo; line by deleting this \u0026ldquo;#\u0026rdquo; symbol. The options currently controlled by the preprocessor are:\n  PER_SPECIES_WEIGHT - By default, each pseudoparticle in the code can represent a different number of real particles. Memory can be saved by disabling this feature and have all of the pseudoparticles in a species use the same particle weight. Many of the codes more advanced features require per-particle weighting so it is enabled by default. Use this flag to disable per- particle weighting if you need to save on memory, but it this option is recommended only for advanced users.\n  NO_TRACER_PARTICLES - This flag will disable the option to specify one or more species as zero-current particles. Zero-current particles move about as would a normal particle with the same charge and mass, but they do not generate any current and are therefore passive elements in the simulation. Zero-current particles should be included in collisions to ensure they move identically to ordinary particles. The implementation of zero-current particles requires an additional \u0026ldquo;IF\u0026rdquo; clause in the particle push, so it has a slight performance impact. If you do not require the feature then setting this flag will give a slight performance improvement. WARNING: Since the particles effectively have zero weight in terms of their numerical heating properties, they do not always behave in the same way that an ordinary particle with weight would behave and this can sometimes lead to unexpected behaviour. If the purpose is merely to track a subset of a particle species to use as output then a better mechanism to use is \u0026ldquo;persistent subsets\u0026rdquo; (see here). In version 5.0, this flag will be and replaced with \u0026ldquo;ZERO_CURRENT_PARTICLES\u0026rdquo;.\n  NO_PARTICLE_PROBES - For laser plasma interaction studies it can sometimes be useful to be able to record information about particles which cross a plane in the simulation. Since this requires the code to check whether each particles has crossed the plane in the particles pusher and also to store copies of particles until the next output dump, it is a heavyweight diagnostic. If you don\u0026rsquo;t require the diagnostic you can set this flag to disable it.\n  PROBE_TIME - Paticle probes also output the time particles pass the probe. Without this key, only the time of the SDF output dump will be available.\n  PARTICLE_SHAPE_TOPHAT - By default, the code uses a first order b-spline (triangle) shape function to represent particles giving third order particle weighting. Using this flag changes the particle representation to that of a top-hat function (0th order b-spline yielding a second order weighting).\n  PARTICLE_SHAPE_BSPLINE3 - This flag changes the particle representation to that of a 3rd order b-spline shape function (5th order weighting).\n  PARTICLE_ID - When this option is enabled, all particles are assigned a unique identification number when writing particle data to file. This number can then be used to track the progress of a particle during the simulation.\n  PARTICLE_ID4 - This does the same as the previous option except it uses a 4-byte integer instead of an 8-byte one. Whilst this saves storage space, care must be taken that the number does not overflow.\n  PHOTONS - This enables support for photon particle types in the code. These are a pre-requisite for modelling synchrotron emission, radiation reaction and pair production (see here).\n  TRIDENT_PHOTONS - This enables support for virtual photons which are used by the Trident process for pair production.\n  BREMSSTRAHLUNG - Similar to photons, but for modelling bremsstrahlung radiation instead of QED emission.\n  PREFETCH - This enables an Intel-specific code optimisation.\n  PARSER_DEBUG - The code outputs more detailed information whilst parsing the input deck. This is a debug mode for code development.\n  PARTICLE_DEBUG - Each particle is additionally tagged with information about which processor it is currently on, and which processor it started on. This is a debug mode for code development.\n  MPI_DEBUG - This option installs an error handler for MPI calls which should aid tracking down some MPI related errors.\n  SIMPLIFY_DEBUG - This option enables debugging code related to the deck parser simplification routine.\n  NO_IO - This option disables all file I/O which can be useful when doing benchmarking.\n  COLLISIONS_TEST - This enables some routines for debugging the collision routines. It completely alters the behaviour of the code. This flag should never be enabled by the end user.\n  PER_PARTICLE_CHARGE_MASS - By default, the particle charge and mass are specified on a per-species basis. With this flag enabled, charge and mass become a per-particle property. This is a legacy flag which will be removed soon.\n  PARSER_CHECKING - Setting this flag adds code which checks for valid values on evaluated deck expressions. This slows down the code but may be required if floating point exceptions are enabled.\n  WORK_DONE_INTEGRATED - This enables support for tracking the work done on each particle by the electric field. Note that this increases the size of each particle by 48 bytes. The information gathered can be output to file using the \u0026ldquo;work_{x,y,z}\u0026rdquo; and \u0026ldquo;work_{x,y,z}_total\u0026rdquo; dumpmasks. See here\n  DELTAF_METHOD - Compile the code to use the delta-f method to represent particles rather than standard PIC. Note that this completely changes the code behaviour and should not be enabled for normal use. See here.\n  DELTAF_DEBUG - Add debug code for the delta-f method.\n  HC_PUSH - Use the push from Higuera and Cary rather than the Boris push. This is slightly slower than the Boris push but gives the correct $\\mathbf{E} \\times \\mathbf{B}$ velocity, improving performance for highly relativistic simulations.\n  NO_USE_ISATTY - When printing the initial welcome message, EPOCH makes use of the C-library\u0026rsquo;s isatty function. This requires Fortran2003 features that might not be available on all platforms. The flag allows this functionality to be disabled on platforms that don\u0026rsquo;t support it.\n  NO_MPI3 - This compiler flag allows the user to disable MPI-3 features such as the \u0026ldquo;MPI_TYPE_SIZE_X\u0026rdquo; routine. This allows the code to be compiled against older versions of the MPI library. The flag should only be enabled if the code fails to compile without it.\n  Changing precompiler directives If a user has already compiled EPOCH, and would like to change the active compiler flags, then the user may comment and uncomment different flags in the Makefile (by adding or removing # at the start of the line), and recompiling the code using the commands:\nmake clean make COMPILER=gfortran -j4  Where in this example, the gfortran compiler has been chosen.\nErrors for unspecified precompiler directives If a user requests an option which the code has not been compiled to support then the code will give an error or warning message as follows:\n *** ERROR *** Unable to set \u0026quot;use_qed=T\u0026quot; in the \u0026quot;qed\u0026quot; block. Please recompile with the -DPHOTONS preprocessor flag.  Other Makefile flags It is also possible to pass other flags to the compiler. In \u0026ldquo;Makefile\u0026rdquo; there is a line which reads\nFFLAGS = -O3 -fast  The two commands to the right are compiler flags and are passed unaltered to the FORTRAN compiler. Change this line to add any additional flags required by your compiler.\nBy default, EPOCH will write a copy of the source code and input decks into each restart dump. This can be very useful since a restart dump contains an exact copy of the code which was used to generate it, ensuring that you can always regenerate the data or continue running from a restart. The output can be prevented by using \u0026ldquo;dump_source_code = F\u0026rdquo; and \u0026ldquo;dump_input_deck = F\u0026rdquo; in the output block. However, the functionality is difficult to build on some platforms so the Makefile contains a line for bypassing this section of the build process. Just below all the DEFINE flags there is the following line:\n#ENCODED_SOURCE = epoch_source_info_dummy.o  Just uncomment this line and source code in restart dumps will be permanently disabled.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677165867,"objectID":"5e0f22e4cea7007dfc4b8062fa2735f1","permalink":"/documentation/basic_usage/compiler_flags.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/compiler_flags.html","section":"documentation","summary":"As already stated, some features of the code are controlled by compiler preprocessor directives. The flags for these preprocessor directives are specified in \u0026ldquo;Makefile\u0026rdquo; and are placed on lines which look like the following:","tags":null,"title":"Compiler flags and preprocessor defines","type":"docs"},{"authors":null,"categories":null,"content":"When the code is run, the output is\n d########P d########b .######b d####### d##P d##P d########P d########### d########### .########## d##P d##P ---- ---- ---- ----- ---- ----- ---- -- P d########P d####,,,####P ####. .#### d###P d############P d########P d#########P #### .###P ####. d############P d##P d##P #### d#### ####. d##P d##P d########P d##P ###########P ##########P d##P d##P d########P d##P d######P #######P d##P d##P The code was compiled with no compile time options Welcome to EPOCH2D version 4.12.0 (commit v4.12.0-0-gfd74a464-clean) Code is running on 1 processing elements Specify output directory  At which point the end user should simply type in the name of the directory where the code output is to be placed. This directory must also include the file which controls the code setup, specifies how to set the initial conditions and controls the I/O. Writing an input deck for EPOCH is fairly time consuming and so the code is supplied with some example input decks which include all the necessary sections for the code to run. Alternately, the code checks for the Data directory in a file named \u0026ldquo;USE_DATA_DIRECTORY\u0026rdquo; before prompting at the command-line. This allows the code to be run without waiting for input at the command-line.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"0aadc5a22eae3b31c89ca7097c935699","permalink":"/documentation/basic_usage/running.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/running.html","section":"documentation","summary":"When the code is run, the output is\n d########P d########b .######b d####### d##P d##P d########P d########### d########### .########## d##P d##P ---- ---- ---- ----- ---- ----- ---- -- P d########P d####,,,####P ####.","tags":null,"title":"Running EPOCH and basic control of EPOCH","type":"docs"},{"authors":null,"categories":null,"content":"How do I acknowledge use of the code? There is a paper1 which details many aspects of the EPOCH implementation and also includes useful information on current PIC codes. This paper is OpenAccess so freely available to all. If using EPOCH in your research output please use this as the reference for EPOCH and ideally also acknowledge the UK grant which funded this work. The BibTeX entry for this paper is as follows.\n@article{Arber:2015hc, author = {Arber, T D and Bennett, K and Brady, C S and Lawrence-Douglas, A and Ramsay, M G and Sircombe, N J and Gillies, P and Evans, R G and Schmitz, H and Bell, A R and Ridgers, C P}, title = {{Contemporary particle-in-cell approach to laser-plasma modelling}}, journal = {Plasma Physics and Controlled Fusion}, year = {2015}, volume = {57}, number = {11}, pages = {1--26}, month = nov }  Acknowledgement: \u0026ldquo;This work was in part funded by the UK EPSRC grants EP/G054950/1, EP/G056803/1, EP/G055165/1 and EP/ M022463/1.\u0026rdquo;\nReferences   T D Arber, K Bennett, C S Brady, A Lawrence-Douglas, M G Ramsay, N J Sircombe, P Gillies, R G Evans, H Schmitz, A R Bell, \u0026ldquo;Contemporary particle-in-cell approach to laser-plasma modelling,\u0026rdquo; Plasma Physics and Controlled Fusion, 2015. link\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"82d332a3a356e7bb467541e5961ab09d","permalink":"/documentation/basic_usage/acknowledging_epoch.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/acknowledging_epoch.html","section":"documentation","summary":"How do I acknowledge use of the code? There is a paper1 which details many aspects of the EPOCH implementation and also includes useful information on current PIC codes. This paper is OpenAccess so freely available to all.","tags":null,"title":"Acknowledging EPOCH","type":"docs"},{"authors":null,"categories":null,"content":"Most of the control of EPOCH is through a text file called input.deck. The input deck file must be in the output directory which is passed to the code at runtime and contains all the basic information which is needed to set up the code, including the size and subdivision of the domain, the boundary conditions, the species of particles to simulate and the output settings for the code. For most users this will be capable of specifying all the initial conditions and output options they need. More complicated initial conditions will be handled in later sections.\nThe input deck is a structured file which is split into separate blocks, with each block containing several \u0026ldquo;parameter\u0026rdquo; = \u0026ldquo;value\u0026rdquo; pairs. The pairs can be present in any order, and not all possible pairs must be present in any given input deck. If a required pair is missing the code will exit with an error message. The blocks themselves can also appear in any order. The input deck is case sensitive, so true is always \u0026ldquo;T\u0026rdquo;, false is always \u0026ldquo;F\u0026rdquo; and the names of the parameters are always lower case. Parameter values are evaluated using a maths parser which is described in EPOCH maths parser. If the deck contains a \u0026ldquo;\\\u0026rdquo; character then the rest of the line is ignored and the next line becomes a continuation of the current one. Also, the comment character is \u0026ldquo;#\u0026quot;; if the \u0026ldquo;#\u0026rdquo; character is used anywhere on a line then the remainder of that line is ignored. There are three input deck directive commands, which are:\n begin:block - Begin the block named block. end:block - Ends the block named block. import:filename - Includes another file (called filename) into the input deck at the point where the directive is encountered. The input deck parser reads the included file exactly as if the contents of the included file were pasted directly at the position of the import directive.  Each block must be surrounded by valid begin: and end: directives or the input deck will fail. There are currently fourteen valid blocks hard coded into the input deck reader, but it is possible for end users to extend the input deck. The fourteen built in blocks are:\n control - Contains information about the general code setup. See here boundaries - Contains information about the boundary conditions for this run. See here species - Contains information about the species of particles which are used in the code. Also details of how these are initialised. See here laser - Contains information about laser boundary sources. See here. fields - Contains information about the EM fields specified at the start of the simulation. See here. particles_from_file - Contains information about files used to load particle data. See here. window - Contains information about the moving window if the code is used in that fashion. See here. output - Contains information about when and how to dump output files. See here. output_global - Contains parameters which should be applied to all output blocks. See here. dist_fn - Contains information about distribution functions that should be calculated for output. See here. probe - Contains information about particle probes used for output. See here. collisions - Contains information about particle collisions. See here. qed - Contains information about QED pair production. See here. subset - Contains configuration for filters which can be used to modify the data to be output. See here. constant - Contains information about user defined constants and expressions. These are designed to simplify the initial condition setup. See here.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"2c34596a53c5ed5a08c3369ce13fe03b","permalink":"/documentation/input_deck/input_deck.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck.html","section":"documentation","summary":"Most of the control of EPOCH is through a text file called input.deck. The input deck file must be in the output directory which is passed to the code at runtime and contains all the basic information which is needed to set up the code, including the size and subdivision of the domain, the boundary conditions, the species of particles to simulate and the output settings for the code.","tags":null,"title":"The EPOCH input deck","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about bremsstrahlung radiation. See EPOCH input deck for more information on the input deck.\nEPOCH is capable of simulating bremsstrahlung radiation using the teqhniques described by Morris et al 1 and Vyskoil et al 2. In order to run this module, the compiler flag -DBREMSSTRAHLUNG must be switched on in the Makefile. There should also be a corresponding \u0026ldquo;bremsstrahlung\u0026rdquo; block for the input deck which uses a similar format to the \u0026ldquo;qed\u0026rdquo; block. Bremsstrahlung cross sections may be calculated for both electrons and positrons. Photons may also undergo pair production according to the Bethe-Heitler model.\nAn example bremsstrahlung block is shown below:\nbegin:bremsstrahlung enable = T start_time = 0 produce_photons = T photon_energy_min = 1 * kev photon_weight = 1.0 photon_dynamics = F use_plasma_screening = F use_brem_scatter = T use_bethe_heitler = F use_positron_brem = F end:bremsstrahlung    enable - Logical flag to turn bremsstrahlung on or off. \u0026ldquo;use_bremsstrahlung\u0026rdquo; is accepted as an alias. The default is \u0026ldquo;F\u0026rdquo;.\n  start_time - Floating point value specifying the time after which bremsstrahlung radiation is modelled. The default is 0.\n  produce_photons - Logical flag to allow population of a photon species. If \u0026ldquo;F\u0026rdquo;, then only the energy loss of the electrons will be simulated. The photon species can be specified by including the line identify:brem_photon in the corresponding species block. If the compiler flag -DPHOTONS is active, QED and bremsstrahlung will both populate the first species with identify:photon if no brem_photon species is specified. The default is \u0026ldquo;F\u0026rdquo;.\n  photon_energy_min - Floating point value specifying the minimum energy of produced photons. Electron energy loss is still calculated for lower energy photon emissions, but these photons are not added to the photon species. The default is 0.\n  photon_weight - Floating point value which applies a multiplier to the weight of produced macro-photons, in order to increase the number of overall emissions and obtain better spectra. Must be less than or equal to 1 and greater than 0. For example, 0.1 would make emission 10 times more likely, but for macro-photons only 10% the weight of the generating macro-electrons. Electron recoil would be reduced accordingly. The default is 1. Note that only one emission is possible per macro-electron per timestep, so setting this too low will saturate emissions.\n  photon_dynamics - Logical flag to specify whether or not to push photons. If \u0026ldquo;F\u0026rdquo;, then the generated photons are immobilised at the point of emission. The default is \u0026ldquo;F\u0026rdquo;.\n  use_plasma_screening - Logical flag to specify whether a cross section enhancement due to heated ionised targets is considered, based on theory described by Wu et al3. It is expected that for high energy electrons passing through low density, ionised plasmas with electron temperatures over $\\sim$100 eV ($\\sim8\\times 10^{5}$ K), the bremsstrahlung emission rate could increase by a factor of 2-3. This has not been tested experimentally, and so the default value is set to \u0026ldquo;F\u0026rdquo;.\n  use_radiation_reaction - Logical flag to specify whether the electrons experience energy loss when emitting photons or not. \u0026ldquo;use_bremsstrahlung_recoil\u0026rdquo; is accepted as an alias. Debugging flag, default \u0026ldquo;T\u0026rdquo;.\n  table_location - String specifying the location of the emission look-up tables for bremsstrahlung. The default path is set to src/physics_packages/TABLES/br.\n  use_brem_scatter - Samples photon ejection angle from a differential cross section. Default is \u0026ldquo;F\u0026rdquo;, where photons are emitted in the direction of the incident particle (ultra-relativistic approximation).\n  use_bethe_heitler - Allows photons to undergo Bethe-Heitler pair production. Default is \u0026ldquo;F\u0026rdquo;. This requires both electron and positron species to be defined.\n  use_positron_brem - Samples bremsstrahlung radiation from positrons. Default is \u0026ldquo;F\u0026rdquo;. If \u0026ldquo;T\u0026rdquo;, electrons and positrons share the same parameter values set in the bremsstrahlung block.\n  Bremsstrahlung, like QED, requires the code to know which species are electrons and which are photons, so uses the same identify system (with identify:brem_photon for a bremsstrahlung-only photon species). Additionally, the atomic numbers of the atom/ion species are required in the species block. For example, atomic aluminium (charge = 0) could be specified as:\nbegin:species name = Aluminium atomic_number = 13 charge = 0 mass = 49218 number_density = 6.022e28 fraction = 0.5 dump = T end:species  If the atomic number is not specified then it will be assumed that the ion is fully ionised and the atomic number would be set to the charge (the nearest integer to the ion charge when expressed in units of elementary charge). If ionisation is considered, the atomic number must be specified once, and all child species will retain the same atomic number.\nIf Bethe-Heitler pair production is considered, the user may identify specific species to populate with Bethe-Heitler electrons and positrons using the identity aliases:\n  identify:bethe_heitler_electron - bh_electron is also accepted.\n  identify:bethe_heitler_positron - bh_positron is also accepted.\n  If these species are unspecified, EPOCH will populate the first electron and positron species present read in from the input deck. Additional identity aliases are provided in the QED section.\nReferences   Morris, S., Robinson, A., \u0026amp; Ridgers, C. (2021). Highly efficient conversion of laser energy to hard x-rays in high-intensity lasersolid simulations. Physics of Plasmas, 28(10), 103304. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n J. Vyskoil, O. Klimo, and S. Weber, Simulations of bremsstrahlung emission in ultra-intense laser interactions with foil targets, Plasma Physics and Controlled Fusion, vol. 60, no. 5, p. 054013, 2018. 2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Wu, D., He, X. T., Yu, W., \u0026amp; Fritzsche, S. (2018). Particle-in-cell simulations of laserplasma interactions at solid densities and relativistic intensities: the role of atomic processes. High Power Laser Science and Engineering, 6. 3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"7a1e156a99f2f3bc781ef5ca35a86040","permalink":"/documentation/input_deck/input_deck_bremsstrahlung.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_bremsstrahlung.html","section":"documentation","summary":"This block contains information about bremsstrahlung radiation. See EPOCH input deck for more information on the input deck.\nEPOCH is capable of simulating bremsstrahlung radiation using the teqhniques described by Morris et al 1 and Vyskoil et al 2.","tags":null,"title":"Bremsstrahlung block","type":"docs"},{"authors":null,"categories":null,"content":"The control block contains information about the general code setup. See EPOCH input deck for more information on the input deck.\nBasics The block sets up the basic code properties for the domain, the end time of the code, the load balancer and the types of initial conditions to use.\nThe control block of a valid input deck for EPOCH2D reads as follows:\nbegin:control # Global number of gridpoints nx = 512 # in x ny = 512 # in y # Global number of particles npart = 10 * nx * ny # Final time of simulation t_end = 1.0e-12 # nsteps = -1 # Size of domain x_min = -0.1e-6 x_max = 400.0e-6 y_min = -400.0e-6 y_max = 400.0e-6 # dt_multiplier = 0.95 # dlb_threshold = 0.8 # restart_snapshot = 98 # field_order = 2 # maxwell_solver = yee # stdout_frequency = 10 end:control  As illustrated in the above code block, the \u0026ldquo;#\u0026rdquo; symbol is treated as a comment character and the code ignores everything on a line following this character. The allowed entries are as follows:\n  nx, ny, nz - Number of grid points in the x,y,z direction. This parameter is mandatory.\n  npart - The global number of pseudoparticles in the simulation. This parameter does not need to be given if a specific number of particles is supplied for each particle species by using the \u0026ldquo;npart\u0026rdquo; directive in each species block. If both are given then the value in the control block will be ignored.\n  nsteps - The number of iterations of the core solver before the code terminates. Negative numbers instruct the code to only terminate at t_end. If nsteps is not specified then t_end must be given.\n  t_end - The final simulation time in simulation seconds before the code terminates. If t_end is not specified then nsteps must be given. If they are both specified then the first time restriction to be satisfied takes precedence. Sometimes it is more useful to specify the time in picoseconds or femtoseconds. To accomplish this, just append the appropriate multiplication factor. For example, \u0026ldquo;t_end = 3 * femto\u0026rdquo; specifies 3 femtoseconds. A list of multiplication factors is supplied here.\n  {x,y,z}_min - Minimum grid position of the domain in metres. These are required parameters. Can be negative. \u0026ldquo;{x,y,z}_start\u0026rdquo; is accepted as a synonym. In a similar manner to that described above, distances can be specified in microns using a multiplication constant. eg. \u0026ldquo;x_min = 4 * micron\u0026rdquo; specifies a distance of 4 m.\n  {x,y,z}_max - Maximum grid position of the domain in metres. These are required parameters. Must be greater than {x,y,z}_min. \u0026ldquo;{x,y,z}_end\u0026rdquo; is accepted as a synonym.\n  dt_multiplier - Factor by which the timestep is multiplied before it is applied in the code, i.e. a multiplying factor applied to the CFL condition on the timestep. Must be less than one. If no value is given then the default of 0.95 is used. If maxwell_solver is different from \u0026ldquo;yee\u0026rdquo; (the default) this parameter becomes increasingly relevant.\n  dlb_threshold - The minimum ratio of the load on the least loaded processor to that on the most loaded processor allowed before the code load balances. Set to 1 means always balance, set to 0 means never balance. If this parameter is not specified then the code will only be load balanced at initialisation time.\n  restart_snapshot - The number of a previously written restart dump to restart the code from. If not specified then the initial conditions from the input deck are used. Note that as of version 4.2.5, this parameter can now also accept a filename in place of a number. If you want to restart from \u0026ldquo;0012.sdf\u0026rdquo; then it can either be specified using \u0026ldquo;restart_snapshot = 12\u0026rdquo;, or alternatively it can be specified using \u0026ldquo;restart_snapshot = 0012.sdf\u0026rdquo;. This syntax is required if output file prefixes have been used (see the output block page).\n  field_order - Order of the finite difference scheme used for solving Maxwell\u0026rsquo;s equations. Can be 2, 4 or 6. If not specified, the default is to use a second order scheme.\n  maxwell_solver - Choose a Maxwell solver scheme with an extended stencil. This option is only active if field_order is set to 2. Possible options are \u0026ldquo;yee\u0026rdquo;, \u0026ldquo;lehe_{x,y,z}\u0026rdquo;, \u0026ldquo;pukhov\u0026rdquo;, \u0026ldquo;cowan\u0026rdquo; and since v4.12 \u0026ldquo;custom\u0026rdquo;. Note that not all options are available in 1d and 2d. The default is \u0026ldquo;yee\u0026rdquo; which is the default second order scheme.\n  stdout_frequency - If specified then the code will print a one line status message to stdout after every given number or timesteps. The default is to print nothing to screen (i.e. stdout_frequency = 0).\n  use_random_seed - The initial particle distribution is generated using a random number generator. By default, EPOCH uses a fixed value for the random generator seed so that results are repeatable. If this flag is set to \u0026ldquo;T\u0026rdquo; then the seed will be generated using the system clock.\n  nproc{x,y,z} - Number of processes in the x,y,z directions. By default, EPOCH will try to pick the best method of splitting the domain amongst the available processors but occasionally the user may wish to override this choice.\n  smooth_currents - This is a logical flag. If set to \u0026ldquo;T\u0026rdquo; then a smoothing function is applied to the current generated during the particle push. This can help to reduce noise and self-heating in a simulation. The smoothing function used is the same as that outlined in Buneman 1. The default value is \u0026ldquo;F\u0026rdquo;.\n  field_ionisation - Logical flag which turns on field ionisation. See here.\n  physics_table_location - EPOCH expects you to run the code from the epoch1d, epoch2d or epoch3d directories, so all paths are relative to this. If you can\u0026rsquo;t run the code from here, you must manually specify the location of the TABLES file by setting this key to something like: \u0026quot;/absolute/path/to/epoch/epoch2d/src/physics_packages/TABLES\u0026quot;\n  use_bsi - Logical flag which turns on barrier suppression ionisation correction to the tunnelling ionisation model for high intensity lasers. See here . This flag should always be enabled when using field ionisation and is only supplied for testing purposes. The default is \u0026ldquo;T\u0026rdquo;.\n  use_multiphoton - Logical flag which turns on modelling ionisation by multiple photon absorption. This should be set to \u0026ldquo;F\u0026rdquo; if there is no laser attached to a boundary as it relies on laser frequency. See here. This flag should always be enabled when using field ionisation and is only supplied for testing purposes. The default is \u0026ldquo;T\u0026rdquo;.\n  particle_tstart - Specifies the time at which to start pushing particles. This allows the field to evolve using the Maxwell solver for a specified time before beginning to move the particles.\n  use_exact_restart - Logical flag which makes a simulation restart as close as is numerically possible to if the simulation had not been stopped and restarted. Without this flag set to T then the simulation will still give a correct result after restart, it is simply not guaranteed to be identical to if the code had not been restarted. This flag is mainly intended for testing purposes and is not normally needed for physical simulations. If set to \u0026ldquo;T\u0026rdquo; then the domain split amongst processors will be identical along with the seeds for the random number generators. Note that the flag will be ignored if the number of processors does not match that used in the original run. The default value is \u0026ldquo;F\u0026rdquo;.\n  use_current_correction - Logical flag to specify whether EPOCH should correct for residual DC current in the initial conditions. If set to true, the DC current in the initial conditions is calculated and is subtracted from all subsequent current depositions.\n  allow_cpu_reduce - Logical flag which allows the number of CPUs used to be reduced from the number specified. In some situations it may not be possible to divide the simulation amongst all the processors requested. If this flag is set to \u0026ldquo;T\u0026rdquo; then EPOCH will continue to run and leave some of the requested CPUs idle. If set to \u0026ldquo;F\u0026rdquo; then code will exit if all CPUs cannot be utilised. The default value is \u0026ldquo;T\u0026rdquo;.\n  check_stop_file_frequency - Integer parameter controlling automatic halting of the code. The frequency is specified as number of simulation cycles. Refer to description later in this section. The default value is 10.\n  stop_at_walltime - Floating point parameter controlling automatic halting of the code. Refer to description later in this section. The default value is -1.0.\n  stop_at_walltime_file - String parameter controlling automatic halting of the code. See below. The default value is an empty string.\n  simplify_deck - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the deck parser will attempt to simplify the maths expressions encountered after the first pass. This can significantly improve the speed of evaluation for some input deck blocks. The default value is \u0026ldquo;F\u0026rdquo;.\n  print_constants - If this logical flag is set to \u0026ldquo;T\u0026rdquo;, deck constants are printed to the \u0026ldquo;deck.status\u0026rdquo; (and \u0026ldquo;const.status\u0026rdquo; after 4.11) file as they are parsed. The default value is \u0026ldquo;F\u0026rdquo;.\n  use_migration - Logical flag which determines whether or not to use particle migration. The default is \u0026ldquo;F\u0026rdquo;.\n  migration_interval - The number of timesteps between each migration event. The default is 1 (migrate at every timestep).\n  allow_missing_restart - Logical flag to allow code to run when a restart dump is absent. When \u0026ldquo;restart_snapshot\u0026rdquo; is specified then the simulation first checks that the specified restart dump is valid. If the restart dump exists and is valid then it is used to provide initial conditions for the simulation. However, if the restart dump does not exist or is not usable for some reason then by default the simulation will abort. If \u0026ldquo;allow_missing_restart\u0026rdquo; is set to \u0026ldquo;T\u0026rdquo; then the simulation will not abort but will continue to run and use the initial conditions contained in the input deck to initialise the simulation. The default value is \u0026ldquo;F\u0026rdquo;.\n   print_eta_string - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the current estimated time to completion will be appended to the status updates. The default value is \u0026ldquo;T\u0026rdquo;.\n   n_zeros - Integer flag which specifies the number of digits to use for the output file numbers. (eg. \u0026ldquo;0012.sdf\u0026rdquo;). By default, the code tries to calculate the number of digits required by dividing t_end by dt_snapshot. Note that the minimum number of digits is 4.\n  use_accurate_n_zeros - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the code performs a more rigorous test to determine the number of digits required to accommodate all outputs that are to be generated by a run. Since this can be time consuming and is overkill for most cases, it is disabled by default. The default value is \u0026ldquo;F\u0026rdquo;.\n  use_particle_count_update - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the code keeps global particle counts for each species on each processor. This information isn\u0026rsquo;t needed by the core algorithm, but can be useful for developing some types of additional physics packages. It does require one additional MPI_ALL_REDUCE per species per timestep, so it is not activated by default. The default value is \u0026ldquo;F\u0026rdquo;.\n  reset_walltime - When restarting from a dump file, the current walltime displayed will include the elapsed walltime recorded in the restart dump. The user can request that this time is ignored by setting the \u0026ldquo;reset_walltime\u0026rdquo; flag to \u0026ldquo;T\u0026rdquo;. The default value is \u0026ldquo;F\u0026rdquo;.\n  dlb_maximum_interval - This integer parameter determines the maximum number of timesteps to allow between load balancing checks. Each time that the load balancing sweep is unable to improve the load balance of the simulation, it doubles the number of steps before the next check will occur. It will keep increasing the check interval until it reaches the value given by dlb_maximum_interval. If the value of dlb_maximum_interval is negative then the check interval will increase indefinitely. When the load balancing sweep finds an improvement to the load balance of the simulation, the check interval is reset to one. The default value is 500.\n  dlb_force_interval - This integer parameter determines the maximum number of timesteps to allow between forcing a full load balance sweep. If the current load balance is greater than the value of dlb_threshold then the load balancer exits before attempting to improve the loading. If dlb_force_interval is greater than zero, then the full load balancer will be run at the requested interval of timesteps, regardless of the value of dlb_threshold. Note that the simulation will only be redistributed if this would result in an improved load balance. The default value is 2000.\n  balance_first - This logical flag determines whether a load balance will be attempted on the first call of the load balancer. The load balancer performs to functions: first it attempts to find a domain decomposition that balances the load evenly amongst processors. Next, it redistributes the domain and particles onto the new layout (if requred). This latter step is always required when setting up the simulation, so the load balancer is always called once during set-up. This flag controls whether or not a load balance is attempted during this call, regardless of the value of dlb_threshold. The default value is \u0026ldquo;T\u0026rdquo;.\n  use_pre_balance - This logical flag determines whether a load balance will be attempted before the particle load occurs. If this flag is set to \u0026ldquo;T\u0026rdquo; then the particle auto-loader will be called at setup time, but instead of creating particles it will just populate a particle-per-cell field array. This will then be used to calculate the optimal domain decomposition and all field arrays will be redistributed to use the new layout. Finally, after all of this has been done, the auto-loader will be called again and create just the particles that are present on their optimally load-balanced domains. In contrast, if the flag is set to \u0026ldquo;F\u0026rdquo; then the domain is just divided evenly amongst processors and the particles are loaded on this domain decomposition. Balancing is then carried out on to redistribute the work load. For heavily imbalanced problems, this can lead to situations in which there is insufficient memory to setup a simulation, despite there being sufficient resources for the final load-balanced conditions. The default value is \u0026ldquo;T\u0026rdquo;.\n  use_optimal_layout - This logical flag determines whether the load balancer attempts to find an optimal processor split before loading the particles. The initial domain split is chosen in such a way as to minimize the total surface area of the resulting domains in 3D, or edge lengths in 2D. For example, if a 2D square domain is run on 16 CPUs then the domain will be divided by 4 in the x-direction and 4 in the y-direction. The other possible splits (1x16, 2x8, 8x2, 16x1) are rejected because they all yield rectangular subdomains whose total edge length is greater than the 4x4 edge length. For some problems (eg. a density ramp or thin foil) this is a poor choice and a better load balance would be obtained by a less even split. It is always possible to specify such a split by using nproc{x,y,z} flags but enabling the use_optimal_layout flag will automatically determine the best split for you. Future versions of the code will also allow the split to be changed dynamically at run time. The default value is \u0026ldquo;T\u0026rdquo;.\n  use_more_setup_memory - This logical flag determines whether the extra memory will be used during the initial setup of particle species. If set to false then only one set of arrays will be used for storing temperature, density and drift during species loading. This can be a significant memory saving but omes at the expense of recalculating grid quantities multiple times. Setting the flag to true enables one set of arrays per species. The default value is \u0026ldquo;F\u0026rdquo;.\n  deck_warnings_fatal - This logical flag controls the behaviour of the deck parser when a warning is encountered. Usually the code will just print a warning message and continue running. Setting this flag to \u0026ldquo;T\u0026rdquo; will force the code to abort. The default value is \u0026ldquo;F\u0026rdquo;.\n  Maxwell Solvers With the default settings \u0026ldquo;field_order=2\u0026rdquo;, \u0026ldquo;maxwell_solver=yee\u0026rdquo; EPOCH will use the standard second order Yee scheme for solving Maxwell\u0026rsquo;s equations. This scheme has a grid dispersion relation with phase velocities smaller than $c$, especially for large spatial frequencies. Since EPOCH v4.11 it is possible to introduce extended stencils into the update step of the Maxwell-Faraday equation which will help improving the dispersion relation. All of the following extended stencils are only available when \u0026ldquo;field_order=2\u0026rdquo;. Please note that you will also need to choose an appropriate dt_multiplier, according to the selected scheme. A dt_multiplier equal to unity would result in using the largest time-step allowed by the CFL condition for any of the implemented schemes. This time-step is said to be marginally stable. While, in general, the marginally stable time-step has the best dispersion properties, simulations may suffer from numerical problems such as exponentially growing noise. Choosing smaller values for the dt_multiplier tend to improve on this, while adversely affecting the dispersion relation. The implemented solvers behave differently in this regard.\nDifferent options are available as follows:\n  maxwell_solver = lehe_{x,y,z} - This setting will enable an extended stencil proposed by Lehe et al 2. This stencil focusses on improving the dispersion relation on the $x$-axis, please take this into account when defining your laser input. It is available in EPOCH1D, EPOCH2D and EPOCH3D. While it is not technically required to use a dt_multiplier smaller than unity, the value proposed by Lehe et al 2 is \u0026ldquo;dt_multiplier=0.96\u0026rdquo;.\n  maxwell_solver = pukhov - This setting will enable an extended stencil proposed by Pukhov 3 under the name of NDFX. It is available in EPOCH2D and EPOCH3D. In EPOCH1D, setting maxwell_solver = pukhov will make the code fall back silently to Yee\u0026rsquo;s scheme. Pukhov\u0026rsquo;s NDFX scheme aims at improving the numerical dispersion relation by allowing to choose \u0026quot; dt_multiplier= 1.0\u0026quot;, while smaller values are also valid. The resulting dispersion relation is best along the axis with the smallest grid spacing.\n    maxwell_solver = cowan - This setting will enable en extended stencil proposed by Cowan et al 4. It is available only in EPOCH3D. In EPOCH1D and EPOCH2D, setting maxwell_solver = cowan will make the code fall back silently to Yee\u0026rsquo;s scheme. Cowan et al 4 proposes to numerically calculate a time step that has the correct group velocity for the input laser. Typically these time steps are only slightly below the CFL condition, e.g. \u0026quot; = 0.999\u0026quot;. When Cowan\u0026rsquo;s scheme is reduced to 2D it is the same as Pukhov\u0026rsquo;s scheme with dt_multiplier \u0026lt;1.0. The resulting dispersion relation is best along the axis with the smallest grid spacing.\n  maxwell_solver = custom - This setting will enable full user control over the extended stencil coefficients. This allows for the specification of optimised coefficients as outlined in 5. This option must be accompanied by a \u0026ldquo;stencil\u0026rdquo; block. See below.\n  Stencil Block The extended stencil Maxwell solvers described above all operate by including points in neighbouring cells with a carefully chosen weighting. These weightings are determined by adjusting the coefficients shown in the Figure. Full control over these coefficients can be achieved by specifying \u0026ldquo;custom\u0026rdquo; for the \u0026ldquo;maxwell_solver\u0026rdquo; parameter in the control block and then supplying a \u0026ldquo;stencil\u0026rdquo; block to provide the desired coefficient values.\nThis option allows the user to specify an extended stencil scheme that has been specifically optimised for the simulation grid spacing and timestep. See 5 for further details. or see 6 for stencil optimization code. Note that there is no option for changing the value of $\\alpha_{x,y,z}$ since these are calculated using the following equations: $$ \\begin{aligned} \\alpha_x \u0026amp;= 1 - 2\\beta_{xy} - 2\\beta{xz} - 3\\delta_x\\,, \\\\\\\n\\alpha_y \u0026amp;= 1 - 2\\beta_{yx} - 2\\beta{yz} - 3\\delta_y\\,, \\\\\\\n\\alpha_z \u0026amp;= 1 - 2\\beta_{zx} - 2\\beta{zy} - 3\\delta_z\\,. \\end{aligned} $$\n delta{x,y,z}, gamma{x,y,z}, beta{xy,xz,yx,yz,zx,zy} - The coefficients to use for the extended stencil points as shown in Figure[stencil]. See for further details. These coefficients are specified as floating point numbers. The default values are to set all coefficients to zero which results in $\\alpha_{x,y,z}$ having values of unity. This corresponds to the standard Yee scheme. dt - The timestep restriction to use for the field solver  Strided Current Filtering EPOCH 4.15 introduces strided multipass digital current filtering as described and benchmarked in the review by Vay and Godfrey. This can be tuned to substantially damp high frequencies in the currents and can be used to reduce the effect of numerical Cherenkov radiation. Once you turn on current filtering by specifying \u0026ldquo;smooth_currents=T\u0026rdquo; you can then set the following keys\n smooth_iterations - Integer number of iterations of the smoothing function to be performed. If not present defaults to one iteration. More iterations will produce smoother results but will be slower. smooth_compensation - Logical flag. If true then perform a compensation step (see Vay and Godfrey 6) after the smoothing steps are performed. Total number of iterations if true is smooth_iterations + 1. If not specified defaults to false smooth_strides - Either a comma separated list of integers or \u0026ldquo;auto\u0026rdquo; (without quote marks). This specifies the strides (in number of grid cells) to use when performing strided filtering. Specifying \u0026ldquo;1, 3\u0026rdquo; will smooth each point with the points immediately adjacent and with the points 3 cells away on each side of the current cell. Setting this key to \u0026ldquo;auto\u0026rdquo; uses a \u0026ldquo;1, 2, 3, 4\u0026rdquo; set of strides as a \u0026ldquo;good\u0026rdquo; starting point for strided filtering.  It should be stressed that there is no set of values that is guaranteed to give any given result from filtering while not affecting the physical correctness of your simulation. Current filtering should be tuned to match the problem that you want to work on and should always be carefully tested to ensure that it doesn\u0026rsquo;t produce unphysical results.\nDynamic Load Balancing \u0026ldquo;dlb\u0026rdquo; in the input deck stands for Dynamic Load Balancing and, when turned on, it allows the code to rearrange the internal domain boundaries to try and balance the workload on each processor. This rearrangement is an expensive operation, so it is only performed when the maximum load imbalance reaches a given critical point. This critical point is given by the parameter \u0026ldquo;dlb_threshold\u0026rdquo; which is the ratio of the workload on the least loaded processor to the most loaded processor. When the calculated load imbalance is less than \u0026ldquo;dlb_threshold\u0026rdquo; the code performs a re-balancing sweep, so if \u0026ldquo;dlb_threshold = 1.0\u0026rdquo; is set then the code will keep trying to re-balance the workload at almost every timestep. At present the workload on each processor is simply calculated from the number of particles on each processor, but this will probably change in future. If the \u0026ldquo;dlb_threshold\u0026rdquo; parameter is not specified then the code will only be load balanced at initialisation time.\nAutomatic halting of a simulation It is sometimes useful to be able to halt an EPOCH simulation midway through execution and generate a restart dump. Two methods have been implemented to enable this.\nThe first method is to check for the existence of a \u0026ldquo;STOP\u0026rdquo; file. Throughout execution, EPOCH will check for the existence of a file named either \u0026ldquo;STOP\u0026rdquo; or \u0026ldquo;STOP_NODUMP\u0026rdquo; in the simulation output directory. The check is performed at regular intervals and if such a file is found then the code exits immediately. If \u0026ldquo;STOP\u0026rdquo; is found then a restart dump is written before exiting. If \u0026ldquo;STOP_NODUMP\u0026rdquo; is found then no I/O is performed.\nThe interval between checks is controlled by the integer parameter \u0026ldquo;check_stop_frequency\u0026rdquo; which can be specified in the \u0026ldquo;control\u0026rdquo; block of the input deck. If it is less than or equal to zero then the check is never performed.\nThe next method for automatically halting the code is to stop execution after a given elapsed walltime. If a positive value for \u0026ldquo;stop_at_walltime\u0026rdquo; is specified in the control block of an input deck then the code will halt once this time is exceeded and write a restart dump. The parameter takes a real argument which is the time in seconds since the start of the simulation.\nAn alternative method of specifying this time is to write it into a separate text file. \u0026ldquo;stop_at_walltime_file\u0026rdquo; is the filename from which to read the value for \u0026ldquo;stop_at_walltime\u0026rdquo;. Since the walltime will often be found by querying the queueing system in a job script, it may be more convenient to pipe this value into a text file rather than modifying the input deck.\nRequesting output dumps at run time In addition to polling for the existence of a \u0026ldquo;STOP\u0026rdquo; file, EPOCH also periodically checks the output directory for a file named \u0026ldquo;DUMP\u0026rdquo;. If such a file is found then EPOCH will immediately create an output dump and remove the \u0026ldquo;DUMP\u0026rdquo; file. By default, the file written will be a restart dump but if the \u0026ldquo;DUMP\u0026rdquo; file contains the name of an output block then this will be used instead.\nReferences   O. Buneman, \u0026ldquo;TRISTAN: The 3-D Electromagnetic Particle Code.\u0026rdquo; in Computer Space Plasma Physics: Simulations Techniques and Software, 1993. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n R. Lehe, A. Lifschitz, C. Thaury, V. Malka, and X. Davoine, \u0026ldquo;Numerical growth of emittance in simulations of laser-wakefield acceleration,\u0026rdquo; Phys. Rev. Accel. Beams, vol. 16, no. 2, p.021301, 2013 2.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Pukhov, A., \u0026ldquo;Three-dimensional electromagnetic relativistic particle-in-cell code VLPL (Virtual Laser Plasma Lab)\u0026rdquo;, J. Plasma Phys., vol. 61, no. 3, p. 425, 1999 3.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n B. Cowan, D. Bruhwiler, J. Cary, E. Cormier-Michel, and C. Geddes, \u0026ldquo;Generalized algorithm for control of numerical dispersion in explicit time-domain electromagnetic simulations\u0026rdquo;, Phys. Rev. Accel. Beams, vol. 16, no. 4, p. 041303, 2013 4.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n A. Blinne, D. Schinkel, S. Kuschel, N. Elkina, S. G. Rykovanov, and M. Zepf, \u0026ldquo;A systematic approach to numerical dispersion in Maxwell solvers\u0026rdquo;, Computer Physics Communications, 00104655, 2017 5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n J. L. Vay and B. B. Godfrey, \u0026ldquo;Modeling of relativistic plasmas with the particle-in-cell method\u0026rdquo;, Comptes Rendus Mcanique, 2014 6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"22b02d7930309948ce443fa5cf2177ac","permalink":"/documentation/input_deck/input_deck_control.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_control.html","section":"documentation","summary":"The control block contains information about the general code setup. See EPOCH input deck for more information on the input deck.\nBasics The block sets up the basic code properties for the domain, the end time of the code, the load balancer and the types of initial conditions to use.","tags":null,"title":"Control block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the boundary conditions for this run. See EPOCH input deck for more information on the input deck.\nBasics The boundaries block sets the boundary conditions of each boundary of the domain. Some types of boundaries allow EM wave sources (lasers) to be attached to a boundary. Lasers are attached at the initial conditions stage.\nAn example boundary block for EPOCH2D is as follows:\nbegin:boundaries bc_x_min = simple_laser bc_x_max_field = simple_outflow bc_x_max_particle = simple_outflow bc_y_min = periodic bc_y_max = periodic end:boundaries  The boundaries block accepts the following parameters:\n bc_{x,y,z}_min - The condition for the lower boundary for both fields and particles. \u0026ldquo;xbc_left\u0026rdquo;, \u0026ldquo;ybc_down\u0026rdquo; and \u0026ldquo;zbc_back\u0026rdquo; are accepted as a synonyms. bc_{x,y,z}_min_{field,particle} - The condition for the lower boundary for {fields,particles}. \u0026ldquo;xbc_left_{field,particle}\u0026rdquo;, \u0026ldquo;ybc_down_{field,particle}\u0026rdquo; and \u0026ldquo;zbc_back_{field,particle}\u0026rdquo; are accepted as a synonyms. bc_{x,y,z}_max - The condition for the upper boundary for both fields and particles. \u0026ldquo;xbc_right\u0026rdquo;, \u0026ldquo;ybc_up\u0026rdquo; and \u0026ldquo;zbc_front\u0026rdquo; are accepted as a synonyms. bc_{x,y,z}_max_{field,particle} - The condition for the upper boundary for {fields,particles}. \u0026ldquo;xbc_right_{field,particle}\u0026rdquo;, \u0026ldquo;ybc_up_{field,particle}\u0026rdquo; and \u0026ldquo;zbc_front_{field,particle}\u0026rdquo; are accepted as a synonyms. cpml_thickness - The thickness of the CPML boundary in terms of the number of grid cells. The default value is 6. cpml_kappa_max - A tunable CPML parameter. cpml_a_max - A tunable CPML parameter. cpml_sigma_max - A tunable CPML parameter. There are ten boundary types in EPOCH and each boundary of the domain can have one and only one of these boundaries attached to it. These boundary types are: periodic - A simple periodic boundary condition. Fields and/or particles reaching one edge of the domain are wrapped round to the opposite boundary. If either boundary condition is set to periodic then the boundary condition on the matching boundary at the other side of the box is also assumed periodic. simple_laser - A characteristic based boundary condition to which one or more EM wave sources can be attached. EM waves impinging on a simple_laser boundary are transmitted with as little reflection as possible. Particles are fully transmitted. The field boundary condition works by allowing outflowing characteristics to propagate through the boundary while using the attached lasers to specify the inflowing characteristics. The particles are simply removed from the simulation when they reach the boundary. See laser blocks for details. simple_outflow - A simplified version of simple_laser which has the same properties of transmitting incident waves and particles, but which cannot have EM wave sources attached to it. These boundaries are about 5% more computationally efficient than simple_laser boundaries with no attached sources. This boundary condition again allows outflowing characteristics to flow unchanged, but this time the inflowing characteristics are set to zero. The particles are again simply removed from the simulation when they reach the boundary. reflect - This applies reflecting boundary conditions to particles. When specified for fields, all field components are clamped to zero. conduct - This applies perfectly conducting boundary conditions to the field. When specified for particles, the particles are reflected. open - When applied to fields, EM waves outflowing characteristics propagate through the boundary. Particles are transmitted through the boundary and removed from the system. cpml_laser - See #CPML boundary conditions. cpml_outflow - See #CPML boundary conditions. thermal - See #Thermal boundaries.  NOTE: If simple_laser, simple_outflow, cpml_laser, cpml_outflow or open are specified on one or more boundaries then the code will no longer necessarily conserve mass. Note also that it is possible for the user to specify contradictory, unphysical boundary conditions. It is the users responsibility that these flags are set correctly.\nCPML boundary conditions There are now Convolutional Perfectly Matched Layer boundary conditions in EPOCH. The implementation closely follows that outlined in the book \u0026ldquo;Computational Electrodynamics: The Finite-Difference Time-Domain Method\u0026rdquo; by Taflove and Hagness1. See also Roden and Gedney2.\nCPML boundaries are specified in the input deck by specifying either \u0026ldquo;cpml_outflow\u0026rdquo; or \u0026ldquo;cpml_laser\u0026rdquo; in the boundaries block. \u0026ldquo;cpml_outflow\u0026rdquo; specifies an absorbing boundary condition whereas \u0026ldquo;cpml_laser\u0026rdquo; is used to attach a laser to an otherwise absorbing boundary condition.\nThere are also four configurable parameters:\n cpml_thickness - The thickness of the CPML boundary in terms of the number of grid cells. The default value is 6. cpml_kappa_max, cpml_a_max, cpml_sigma_max - These are tunable parameters which affect the behaviour of the absorbing media. The notation follows that used in the two references quoted above. Note that the \u0026ldquo;cpml_sigma_max\u0026rdquo; parameter is normalised by $\\sigma_{\\rm opt}$ which is taken to be 3.2/dx (see Taflove and Hagness1 for details). These are real valued parameters which take the following default values: cpml_kappa_max=20, cpml_a_max=0.15, cpml_sigma_max=0.7 An example usage is as follows:   begin:boundaries cpml_thickness = 16 cpml_kappa_max = 20 cpml_a_max = 0.2 cpml_sigma_max = 0.7 bc_x_min = cpml_laser bc_x_max = cpml_outflow bc_y_min = cpml_outflow bc_y_max = cpml_outflow end:boundaries  Thermal boundaries Thermal boundary conditions have been added to the \u0026ldquo;boundaries\u0026rdquo; block. These simulate the existence of a \u0026ldquo;thermal bath\u0026rdquo; of particles in the domain adjacent to the boundary. When a particle leaves the simulation it is replace with an incoming particle sampled from a Maxwellian of a temperature corresponding to that of the initial conditions. It is requested using the keyword \u0026ldquo;thermal\u0026rdquo;. For example:\n begin:boundaries bc_x_min = laser bc_x_max = thermal end:boundaries  References   A. Taflove and S. C. Hagness, Computational Electrodynamics: The Finite-Difference Time-Domain Method. Artech House, 2000. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n J. Roden and S. Gedney, \u0026ldquo;Convolution pml (cpml): An efficient fdtd implementation of the cfs-pml for arbitrary media,\u0026rdquo; Microw. Opt. Technol. Lett., 2000. 2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"ee3d5051ae90afd95468545f66312741","permalink":"/documentation/input_deck/input_deck_boundaries.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_boundaries.html","section":"documentation","summary":"This block contains information about the boundary conditions for this run. See EPOCH input deck for more information on the input deck.\nBasics The boundaries block sets the boundary conditions of each boundary of the domain.","tags":null,"title":"Boundaries block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about laser boundary sources. See EPOCH input deck for more information on the input deck.\nLaser blocks attach an EM wave source to a boundary which is set as simple_laser.\nbegin:laser boundary = x_min id = 1 intensity_w_cm2 = 1.0e15 lambda = 1.06 * micron pol_angle = 0.0 phase = 0.0 t_profile = gauss(time, 40.0e-15, 40.0e-15) t_start = 0.0 t_end = 80.0e-15 end:laser  As already mentioned in the discussion of laser boundaries in the boundaries block, lasers are attached to compatible boundaries here in the initial conditions deck.\n boundary - The boundary on which to attach the laser. In 1D, the directions can be either x_min or x_max. \u0026ldquo;left\u0026rdquo; and \u0026ldquo;right\u0026rdquo; are accepted as a synonyms. In 2D, y_min and y_max may also be specified. These have synonyms of \u0026ldquo;down\u0026rdquo; and \u0026ldquo;up\u0026rdquo;. Finally, 3D adds z_min and z_max with synonyms of \u0026ldquo;back\u0026rdquo; and \u0026ldquo;front\u0026rdquo;. amp - The amplitude of the $E$ field of the laser in $V/m$. intensity - The intensity of the laser in $W/m^2$. There is no need to specify both intensity and amp and the last specified in the block is the value used. It is mandatory to specify at least one. The amplitude of the laser is calculated from intensity using the formula amp = sqrt(2*intensity/c/epsilon0). \u0026ldquo;irradiance\u0026rdquo; is accepted as a synonym. Note that spatial and temporal profiles are applied to the electromagnetic fields of the laser, not the intensity. For example, if a laser enters through a boundary in a cell where the profile is set to 0.5, the intensity would be reduced to 0.25 the value set here. intensity_w_cm2 - This is identical to the intensity parameter described above, except that the units are specified in $W/cm^2$. id - An id code for the laser. Used if you specify the laser time profile in the EPOCH source rather than in the input deck. Does not have to be unique, but all lasers with the same id will have the same time profile. This parameter is optional and is not used under normal conditions. omega - Angular frequency (rad/s not Hz) for the laser. frequency - Ordinary frequency (Hz not rad/s) for the laser. lambda - Wavelength in a vacuum for the laser specified in $m$. If you want to specify in $\\mu m$ then you can multiply by the constant \u0026ldquo;micron\u0026rdquo;. One of lambda or omega (or frequency) is a required parameter. pol_angle - Polarisation angle for the electric field of the laser in radians. This parameter is optional and has a value of zero by default. The angle is measured with respect to the right-hand triad of propagation direction, electric and magnetic fields. Although the 1D code has no $y$ or $z$ spatial axis, the fields still have $y$ and $z$ components. If the laser is on x_min then the default $E$ field is in the $y$-direction and the $B$ field is the $z$-direction. The polarisation angle is measured clockwise about the $x$-axis with zero along the $E_y$ direction. If the laser is on x_max then the angle is anti-clockwise. **Similarly, for propagation directions: **y_min - angle about $y$-axis, zero along $z$-axis **z_min - angle about $z$-axis, zero along $x$-axis **y_max - angle anti-clockwise about $y$-axis, zero along $z$-axis **z_max - angle anti-clockwise about $z$-axis, zero along $x$-axis pol - This is identical to pol_angle with the angle specified in degrees rather than radians. If both are specified then the last one is used. phase - The phase profile of the laser wavefront given in radians. Phase may be a function of both space and time. The laser is driven using ${\\rm{sin}}(\\omega t + \\phi)$ and phase is the $\\phi$ parameter. There is zero phase shift applied by default. profile - The spatial profile of the laser. This should be a spatial function not including any values in the direction normal to the boundary on which the laser is attached, and the expression will be evaluated at the boundary. It may also be time-dependant. The laser field is multiplied by the profile to give its final amplitude so the intention is to use a value between zero and one. By default it is a unit constant and therefore has no affect on the laser amplitude. This parameter is redundant in 1D and is only included for consistency with 2D and 3D versions of the code. t_profile - Used to specify the time profile for the laser amplitude. Like profile the laser field is multiplied by this parameter but it is only a function of time and not space. In a similar manner to profile, it is best to use a value between zero and one. Setting values greater than one is possible but will cause the maximum laser intensity to grow beyond amp. In previous versions of EPOCH, the profile parameter was only a function of space and this parameter was used to impose time-dependance. Since profile can now vary in time, t_profile is no longer needed but it has been kept to facilitate backwards compatibility. It can also make input decks clearer if the time dependance is given separately. The default value of t_profile is just the real constant value of 1.0. t_start - Start time for the laser in seconds. Can be set to the string \u0026ldquo;start\u0026rdquo; to start at the beginning of the simulation. This is the default value. When using this parameter, the laser start is hard. To get a soft start use the t_profile parameter to ramp the laser up to full strength. t_end - End time for the laser in seconds, can be set to the string \u0026ldquo;end\u0026rdquo; to end at the end of the simulation. This is the default value. When using this parameter, the laser end is clipped straight to zero at $t \u0026gt; t_end$. To get a soft end use the t_profile parameter to ramp the laser down to zero. If you add multiple laser blocks to the initial conditions file then the multiple lasers will be additively combined on the boundary.  In theory, any laser time profile required is possible, but the core FDTD solver for the EM fields in EPOCH produces spurious results if sudden changes in the field intensity occur. This is shown below. The pulse shown on the left used a constant t_profile and used t_end to stop the laser after 8fs. Since the stopping time was not an exact multiple of the period, the result was to introduce spurious oscillations behind the pulse. If the laser had a finite phase shift so that the amplitude did not start at zero, a similar effect would be observed on the front of the pulse.\nThe second figure instead used a Gaussian window function with a characteristic width of 8fs as well as using t_end to introduce a hard cutoff. It can clearly be seen that there are no spurious oscillations and the wave packet propagates correctly, showing only some dispersive features.\nThere is no hard and fast rule as to how rapid the rise or fall for a laser can be, and the best advice is to simply test the problem and see whether any problems occur. If they do then there are various solutions. Essentially, the timestep must be reduced to the point where the sharp change in amplitude can be accommodated. The best solution for this is to increase the spatial resolution (with a comparable increase in the number of pseudoparticles), thus causing the timestep to drop via the CFL condition.\nThis is computationally expensive, and so a cheaper option is simply to decrease the input.deck option dt_multiplier. This artificially decreases the timestep below the timestep calculated from the internal stability criteria and allows the resolution of sharp temporal gradients. This is an inferior solution since the FDTD scheme has increased error as the timestep is reduced from that for EM waves. EPOCH includes a high order field solver to attempt to reduce this.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"befe9ca9e484ba712671f4c88b18fad3","permalink":"/documentation/input_deck/input_deck_laser.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_laser.html","section":"documentation","summary":"This block contains information about laser boundary sources. See EPOCH input deck for more information on the input deck.\nLaser blocks attach an EM wave source to a boundary which is set as simple_laser.","tags":null,"title":"Laser block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the EM fields specified at the start of the simulation. See EPOCH input deck for more information on the input deck.\nThis block allows you to specify the electric and magnetic fields at any point in the domain. An example block is shown below:\nbegin:fields ex = sin(pi * x / length_x) ey = cos(pi * x / length_x) ez = 0 bx = 1.0 by = -1.0 bz = 0 end:fields  Once again, this is a very simple block needing only limited explanation. All field variables are accessible by name and can be read back using the appropriate commands from the maths parser (see here). The possible parameters are as follows:\n ex,ey,ez - The electric field vectors pointing in all three directions. The default value is zero. bx,by,bz - The magnetic field vectors pointing in all three directions. The default value is zero. offset - File offset. The field values may also be specified using a binary file in a similar way to that used for species variables. See the species block for more details. Any valid maths parser expression can be used to set up the fields, and no check is made to ensure that the $\\nabla.B = 0$ is satisfied.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"948cdf82cd0afd1c327065f74f60337d","permalink":"/documentation/input_deck/input_deck_fields.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_fields.html","section":"documentation","summary":"This block contains information about the EM fields specified at the start of the simulation. See EPOCH input deck for more information on the input deck.\nThis block allows you to specify the electric and magnetic fields at any point in the domain.","tags":null,"title":"Fields block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the moving window if the code is used in that fashion. See EPOCH input deck for more information on the input deck.\nEPOCH can include an optional block which causes the simulation domain to operate as a moving window. At present, it is only possible to have the window moving at a speed parallel to the x direction, although the window does not have to start moving at t = 0. When the window moves, the code removes particles from the left hand edge of the domain and introduces new particles at the right hand edge. The new particles are placed by re-evaluating the species density, temperature and drift using the new time and spatial coordinates. The block looks like:\nbegin:window move_window = T window_v_x = 3.0e8 window_start_time = 7.0e-13 bc_x_min_after_move = simple_outflow bc_x_max_after_move = simple_outflow end:window   move_window - Logical flag determining whether or not to move the window. If the window block is absent then this is the same as setting move_window to \u0026ldquo;F\u0026rdquo;. window_v_x - The speed in m/s of the window. window_start_time - The time in seconds at which the window should start moving. window_stop_time - The time in seconds at which the window should stop moving. bc_x_min_after_move - The boundary condition which should apply to the left boundary after the window has started moving. This is to allow the swapping of a laser boundary to a simple outflow boundary. Boundary codes are the same as when just specifying normal boundaries. If a boundary value isn\u0026rsquo;t specified then it is assumed that the boundary isn\u0026rsquo;t changed when the window starts moving. \u0026ldquo;xbc_left_after_move\u0026rdquo; is accepted as a synonym. bc_x_max_after_move - The boundary condition which should apply to the right boundary after the window has started moving. \u0026ldquo;xbc_right_after_move\u0026rdquo; is accepted as a synonym. bc_{y,z}_{min,max}_after_move - \u0026ldquo;y\u0026rdquo; and \u0026ldquo;z\u0026rdquo; versions of the previous two parameters. ybc_down_after_move, ybc_up_after_move, zbc_back_after_move and zbc_front_after_move are accepted as synonyms.  Compatibility Because of how the moving window must work, there are some compatibility issues with certain features. In particular:\n lasers attached to an X boundary which remain in place after the window moves, or attached to Y or Z boundaries:  The laser will behave as though it is attached to the window itself: for Y or Z boundaries with spatial variations this may not give the expected result For X boundaries, the moving emitter will result in a form of numerical Doppler shifting. In addition to this the boundary used to drive the field will shift discontinuously, yielding noisy and erratic changes in the electromagnetic field.   Injectors attached to an X boundary will not work. Those on a Y or Z boundary may appear to work, but the rates will be incorrect. CPML boundary conditions:  in X these cannot work as they rely on time-history which is simply missing. On Y or Z boundaries they will approximately work, but the history will be truncated and so they will generally require more tuning. We can\u0026rsquo;t help with this in general.   Load of particles from file is not supported since it can\u0026rsquo;t be made to work in general.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"6194dda40deb5e969b4a4b0d2aa0c379","permalink":"/documentation/input_deck/input_deck_window.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_window.html","section":"documentation","summary":"This block contains information about the moving window if the code is used in that fashion. See EPOCH input deck for more information on the input deck.\nEPOCH can include an optional block which causes the simulation domain to operate as a moving window.","tags":null,"title":"Window block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about when and how to dump output files. See EPOCH input deck for more information on the input deck.\nBasics Output in EPOCH is handled using the custom designed SDF file format (Self Describing Format). A detailed specification of this format is available elsewhere, although this is only of interest to developers wishing to write new libraries. EPOCH comes with readers for ITT IDL, LLNL VisIt, Mathworks MatLab and Python. The IDL reader is also compatible with the open source GDL tool.\nThere are two styles of output block supported by EPOCH. The first style, which will be referred to as the \u0026ldquo;traditional\u0026rdquo; style, is the method that has been supported by EPOCH since its inception. With this method, a single output block governs all the output dumps which are to be performed. There are a few levels of output which give some small amount of flexibility over what gets dumped but these do not allow for a very fine-grained control.\nIn version 4.0 of EPOCH, a new style was introduced in which multiple named output blocks may be specified allowing for much greater flexibility. The existence of a \u0026ldquo;name\u0026rdquo; parameter is what determines that an output block is the new style rather than the traditional style.\nMost of the parameters are shared by both styles. The following sections document the traditional style of output block and any differences between the two styles are described below .\nWhat the code should output and when it should output it is specified in the \u0026ldquo;output\u0026rdquo; block of the input deck. An example output block is shown below:\nbegin:output # If use_offset_grid is true then the code dumps a grid which # displays positions relative to the left hand edge of the window use_offset_grid = F # number of timesteps between output dumps dt_snapshot = 1.0e-14 # Number of dt_snapshot between full dumps full_dump_every = 10 restart_dump_every = -1 force_final_to_be_restartable = T # Properties at particle positions particles = never px = never py = never pz = never vx = never vy = never vz = never charge = never mass = never particle_weight = never # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always jy = always ekbar = always + species mass_density = never + species charge_density = always number_density = always + species temperature = always + species distribution_functions = always particle_probes = never end:output  There are three types of output dump in EPOCH which are used for different purposes. These types are:\n normal - The most frequent type of output dump in EPOCH is a normal dump. full - A full dump is usually written every 10 or so normal dumps. A full dump contains all the data that a normal dump contains and should also contain any information which is needed only infrequently, whether this is the full particle information or a large distribution function. It is possible to turn off full dumps completely. restart - A restart dump is a dump where the code guarantees to write enough data to allow the code to restart from the output. Output dumps are guaranteed to contain all the information in a normal dump and, if they coincide with the timing for a full dump, will also contain the full dump information.  Information will never be written into a file twice, even if two conditions for it being written are satisfied (i.e even if px should be dumped both because it is a full dump and a restart dump, px will only be written once).\nNote that these dump levels only really make sense for the traditional style of output block and are not really required when the new style is used.\nDumpmask When specifying which type of output dump to write a variable to there are eight options which can be specified for each variable and can be combined by addition. Some combinations make no sense but are formally valid. The first four options specify at which output types the variable is to be dumped:\n never - If the variable is not a required restart variable then it will never be written. If it is a required restart variable then it will be written only at restart dumps. full - This variable will be written at full dumps only. always - This variable will be written at full, normal and restart dumps. restart - This variable will be written at restart dumps only. Note that variables required for restarting the code are always written to restart dumps. This flag is to enable the writing of additional variables into such dump files. For grid variables derived from summing over particles (ie. \u0026ldquo;ekbar\u0026rdquo;, \u0026ldquo;mass_density\u0026rdquo;, \u0026ldquo;charge_density\u0026rdquo;, \u0026ldquo;number_density\u0026rdquo;, \u0026ldquo;temperature\u0026rdquo;) the following two parameters also apply. species - The derived variable should be output on a species by species basis. It is combined with a dumpmask code by addition as in: charge_density = always + species . no_sum - The output for this derived variable should not be summed over all species. By default, derived variables are summed over all species. If you don\u0026rsquo;t want to include this sum, you must use the \u0026ldquo;no_sum\u0026rdquo; flag. It is combined with a dumpmask code by addition as in: charge_density = always + species + no_sum . Most grid variables may be averaged over time. A more detailed description of this is given in #Data Averaging. Data averaging is specified using the following dumpmask parameters. average - The output for this variable should be averaged over time. The time span over which the variable will be averaged is controlled using flags described below. snapshot - By default, the \u0026ldquo;average\u0026rdquo; parameter replaces the variable with an averaged version of the data. Adding this flag specifies that the non-averaged variable should also be dumped to file. When applied to a variable, these codes are referred to as a dumpmask.  Directives The first set of options control the type and frequency of output dumps. They are used as follows\n disabled - Logical flag. If this is set to \u0026ldquo;T\u0026rdquo; then the block is ignored and never generates any output. The default value is \u0026ldquo;F\u0026rdquo;. dt_snapshot - Sets the interval between normal output dumps in simulation seconds. Setting zero or negative means that the code will not output based on this condition. The code does NOT guarantee that outputs will be exactly dt_snapshot apart, what is guaranteed is that the next output will be after the first iteration which takes the simulation to a time $\\ge$ dt_snapshot from the last output. As with other variables which specify a unit of time, it can be specified in more convenient unit by using a multiplication factor (see here). For example, \u0026ldquo;dt_snapshot = 5 * femto\u0026rdquo; will set it to be 5 femtoseconds. The default value is a large number which will never trigger an output. nstep_snapshot - Sets the number of timesteps between normal output dumps. Setting zero or negative means that the code will not output based on this condition. If dt_snapshot is also specified then both conditions are considered and output will be generated when either condition is met. The default value is a large integer which will never trigger an output. full_dump_every - The number of normal output dumps between full output dumps. Setting to zero makes every dump a full dump. Setting to a negative number stops the code from producing any full dumps. This is the default. restart_dump_every - The number of normal output dumps between restart dumps. Setting to zero makes every dump a restart dump. Setting to a negative number stops the code from producing any restart dumps. This is the default. force_first_to_be_restartable - Logical flag which determines whether the file written at time zero is a restart dump. The default value is \u0026ldquo;F\u0026rdquo;. force_last_to_be_restartable - Force the code to override other output settings and make the last output dump it writes be a restart dump. Any internal condition which causes the code to terminate will make the code write a restart dump, but code crashes or scheduler terminations will not cause the code to write a restart dump. \u0026ldquo;force_final_to_be_restartable\u0026rdquo; is accepted as a synonym. The default value is \u0026ldquo;T\u0026rdquo;. dump_first - Logical flag which determines whether to write an output file immediately after initialising the simulation. The default is \u0026ldquo;T\u0026rdquo;. dump_last - Logical flag which determines whether to write an output file just before ending the simulation. The default is \u0026ldquo;T\u0026rdquo; if an output block exists in the input deck and \u0026ldquo;F\u0026rdquo; otherwise. \u0026ldquo;dump_final\u0026rdquo; is accepted as a synonym. time_start - Floating point parameter which specifies the simulation time at which to start considering output for the block. Note that if \u0026ldquo;dump_first\u0026rdquo; or \u0026ldquo;dump_last\u0026rdquo; are set to true for this block then dumps will occur at the first or last timestep regardless of the value of the time_start parameter. This also applies to the three following parameters. The default value is 0. time_stop - Floating point parameter which specifies the simulation time at which to stop considering output for the block. The default value is the largest possible float. nstep_start - Integer parameter which specifies the step number at which to start considering output for the block. The default value is 0. nstep_stop - Integer parameter which specifies the step number at which to stop considering output for the block. The default value is the largest possible integer. walltime_start - Floating point parameter which specifies the elapsed walltime in seconds at which to start considering output for the block. Note that if dump_first or dump_last are set to true for this block then dumps will occur at the first or last timestep regardless of the value of the walltime_start parameter. The default value is 0. walltime_stop - Floating point parameter which specifies the elapsed walltime in seconds at which to stop considering output for the block. The default value is the largest possible float. dump_cycle - If this is set to a positive integer then the output file number will be reset to zero after the specified cycle number is reached. eg. if \u0026ldquo;dump_cycle = 2\u0026rdquo; then the sequence of output dumps will be 0000.sdf, 0001.sdf, 0002.sdf, 0000.sdf, 0001.sdf, etc. The default is 0, so dump cycling never occurs. dump_cycle_first_index - If this is set to a positive integer then the value is used as the first index to use when cycling output dumps due to the \u0026ldquo;dump_cycle\u0026rdquo; parameter. For example, if \u0026ldquo;dump_cycle = 2\u0026rdquo; and \u0026ldquo;dump_cycle_first_index = 1\u0026rdquo; then the sequence of output dumps will be 0000.sdf, 0001.sdf, 0002.sdf, 0001.sdf, 0002.sdf, 0001.sdf, etc. The default is 0. dump_source_code - EPOCH has the ability to write its own source code into restart dumps. This is generated at compile time and embedded into the binary and so is guaranteed to match that corresponding to the running code. EPOCH comes with a script called unpack_source_from_restart which can be used to unpack the source code from a restart dump. To use this script, just type unpack_source_from_restart \u0026lt;sdf_filename\u0026gt; at the command-line. If this logical flag is set to false then the feature will be disabled. The default value is \u0026ldquo;T\u0026rdquo;. dump_input_decks - If this logical flag is set to true then a copy of the input decks for the currently running simulation is written into the restart dumps. The default value is \u0026ldquo;T\u0026rdquo;. dt_average - When averaged variables are being output to file, this parameter specifies the simulation time period over which averaging is to occur. \u0026ldquo;averaging_period\u0026rdquo; is accepted as a synonym. nstep_average - When averaged variables are being output to file, this parameter specifies the number of time steps over which averaging is to occur. \u0026ldquo;min_cycles_per_average\u0026rdquo; is accepted as a synonym. If both dt_average and nstep_average are specified, the code will use the one which gives the longest simulation time-span. use_offset_grid - When using moving windows some visualisation programs (notably VisIt) show the motion of the window by moving the visualisation window rather than by changing the x-axis. Setting this option to \u0026ldquo;T\u0026rdquo; causes the code to write another grid which always gives the offset relative to the left hand edge of the window rather than the true origin. Performs no function when not using the moving window. The default value is \u0026ldquo;F\u0026rdquo;. filesystem - String parameter. Some filesystems can be unreliable when performing parallel I/O. Often this is fixable by prefixing the filename with \u0026lsquo;ufs\u0026rsquo; or \u0026lsquo;nfs\u0026rsquo;. This parameter supplies the prefix to be used. The default value is an empty string. file_prefix - Although this parameter is supported by the traditional style of output block, its primary purpose is for use with multiple output blocks so it is documented in . A few additional parameters have been added for use with the new style of output block. These are documented below.  Particle Variables The next set are per particle properties. If you wish to plot these according to their spatial positions, you must include the \u0026ldquo;particle_grid\u0026rdquo; in your output variables. All entries have a default dumpmask of \u0026ldquo;never\u0026rdquo;.\n particle_grid - Requests the output of particle positions. This is a restart variable. No particle variables can be plotted in VisIt unless this is dumped. If any particle variables are written then the \u0026ldquo;particle_grid\u0026rdquo; is automatically written unless \u0026ldquo;particle_grid = never\u0026rdquo; is specified. The synonym \u0026ldquo;particles\u0026rdquo; may also be used. px,py,pz - The dumpmasks for the particle momenta. Restart variable. vx,vy,vz - The dumpmasks for the particle velocities. charge - The dumpmask for the charge of a given particle. This has no effect if the code is not compiled with the flag \u0026ldquo;-DPER_PARTICLE_CHARGE_MASS\u0026rdquo; (see here ). mass - The dumpmask for the mass of a given particles. This has no effect if the code is not compiled with the flag \u0026ldquo;-DPER_PARTICLE_CHARGE_MASS\u0026rdquo; (see here). The synonym \u0026ldquo;rest_mass\u0026rdquo; may also be used. particle_weight - The dumpmask for the weighting function which describes how many real particles each pseudoparticle represents. Restart variable. The synonym \u0026ldquo;weight\u0026rdquo; may also be used. ejected_particles - If requested then all the particles which have left the simulation domain since the last output dump of this type are included in the output. The list of ejected particles is treated as if it were a separate species and the particle variables which get written are requested using the other particle variable flags (ie. \u0026ldquo;particle_grid\u0026rdquo;, etc). Once the data has been written, the ejected particle lists are reset and will accumulate particles until the next requested output dump. particle_energy - The dumpmask for per-particle kinetic energy. relativistic_mass - The dumpmask for per-particle relativistic mass (ie. not rest mass). gamma - The dumpmask for per-particle relativistic gamma (ie. $[1-(v/c)^2]^{-1/2}$). optical_depth - The dumpmask for per-particle optical depth. Restart variable. This option is only supplied for debugging purposes and should not be required by most users. trident_optical_depth - The dumpmask for per-particle optical depth used by the Trident model. Restart variable. This option is only supplied for debugging purposes and should not be required by most users. qed_energy - The dumpmask for per-particle QED-related particle energy. Restart variable. This option is only supplied for debugging purposes and should not be required by most users. work_{x,y,z} - The dumpmask for the work exerted by the fields on each particle during the last time step. The work is divided into its three spatial components. The output is in numbers of $mc^2$ corresponding to the particle\u0026rsquo;s $\\gamma$-factor. Requires compiler flag \u0026ldquo;WORK_DONE_INTEGRATED\u0026rdquo;. work_{x,y,z}_total - Same as above, but the work is integrated over the entire simulation duration. The sum of all three components equals the particle\u0026rsquo;s $\\gamma$-factor. Requires compiler flag \u0026ldquo;WORK_DONE_INTEGRATED\u0026rdquo;. id - Global particle ID. See below for details. Particle IDs are useful if you want to track the progress of each particle throughout the simulation. Since they increase the size of each particle data structure, they are disabled by default and must be enabled using a compiler flag. The \u0026ldquo;PARTICLE_ID\u0026rdquo; flag will use an 8-byte integer to represent the ID and \u0026ldquo;PARTICLE_ID4\u0026rdquo; uses a 4-byte integer. They are written to file using the \u0026ldquo;id\u0026rdquo; flag.  Note: In the current implementation, the particle IDs are passed between processors and written to file using REAL numbers. This means that in double precision the maximum particle ID is $2^{53} \\sim 10^{16}$. This should be ample for the foreseeable future. However, if the code is compiled for single precision then the maximum ID is $2^{24} = 16777216$. Probably not big enough.\nGrid Variables The next set of parameters specify properties which are defined on a regular cartesian mesh. All entries have a default dumpmask of \u0026ldquo;never\u0026rdquo;.\n grid - The dumpmask for the Cartesian grid which defines the locations of the grid variables. No grid variables can be plotted in VisIt unless this variable is output. If any grid variables are written then the \u0026ldquo;grid\u0026rdquo; is automatically written unless \u0026ldquo;grid = never\u0026rdquo; is specified. The synonym \u0026ldquo;field_grid\u0026rdquo; may also be used. ex,ey,ez - The electric field vectors pointing in all three directions. Restart variables. bx,by,bz - The magnetic field vectors pointing in all three directions. Restart variables. In 1D bx is a trivial variable because of the Solenoidal condition. It is included simply for symmetry with higher dimension codes. jx,jy,jz - The current densities pointing in all three directions. Restart variables. Can have species dumpmask.  Derived Variables The final set of parameters specify properties which are not variables used in the code but are derived from them. The first six variables are derived by summing properties of all the particles in each grid cell. The resulting quantities are defined on the regular cartesian mesh used for grid variables. All entries have a default dumpmask of \u0026ldquo;never\u0026rdquo;.\n ekbar - Mean kinetic energy on grid in $J$. Can have species dumpmask. ekflux - Mean kinetic energy flux in each direction on the grid in $W/m^2$. Can have species dumpmask. mass_density - Mass density on grid in $kg/m^3$. Can have species dumpmask. charge_density - Charge density on grid in $C/m^3$. Can have species dumpmask. number_density - Number density on grid in $m^{-3}$. Can have species dumpmask. particles per cell - Number of particles per cell. Can have species dumpmask. The synonym \u0026ldquo;ppc\u0026rdquo; may also be used. average weight - Average of weight of the particles in each cell. Can have species dumpmask. average_p{x,y,z} - Average momentum in each direction of the particles in each cell. Can have species dumpmask. temperature - Isotropic temperature on grid in $K$. Calculated from standard deviation of particle momenta, so in general matches mean kinetic energy only for isotropic plasma with no net drift. The synonym \u0026ldquo;temp\u0026rdquo; may also be used. Can have species dump mask. temperature_{x,y,z} - The temperature in each of the {x,y,z} directions, respectively, in $K$. The synonyms \u0026ldquo;temp_{x,y,z}\u0026rdquo; and \u0026ldquo;t{x,y,z}\u0026rdquo; may also be used. Can have species dumpmask. poynt_flux - Poynting flux in each direction in $W/m^2$. coulomb_logarithm - An estimate for the averaged Coulomb logarithm in each cell between the first listed species, and all other species. If the species dumpmask is given, then this calculation is repeated for the remaining particle species.  Other Variables  distribution_functions - Dumpmask for outputting distribution functions specified in the input deck. Each individual distribution function can have its own dumpmask and these will be applied after the value of \u0026ldquo;distribution_functions\u0026rdquo; has been considered. For example, if the output block contains \u0026ldquo;distribution_functions = full\u0026rdquo; and the dist_fn block (see here) contains \u0026ldquo;dumpmask = always\u0026rdquo; then the distribution function will only be output at full dumps. particle_probes - Dumpmask for outputting particle probes specified in the input deck. Each individual particle probe can have its own dumpmask and these will be applied after the value of \u0026ldquo;particle_probes\u0026rdquo; has been considered. For example, if the output block contains \u0026ldquo;particle_probes = always\u0026rdquo; and the dist_fn block contains \u0026ldquo;dumpmask = full\u0026rdquo; then the particle probe will only be output at full dumps. absorption - This is a two-valued output variable. It accepts a dumpmask in the same manner as other output variables. When selected, two numbers will be calculated and written to file:   \u0026ldquo;Absorption/Laser_enTotal\u0026rdquo; - The total amount of energy injected into the simulation by laser boundaries. \u0026ldquo;Absorption/Abs_frac\u0026rdquo; - The fraction of the total laser energy being absorbed by the open boundaries.   total_energy_sum - This is also a two-valued output variable. It accepts a dumpmask in the same manner as other output variables. When selected, the following two numbers will be calculated and written to file:   \u0026ldquo;Total Particle Energy in Simulation (J)\u0026rdquo; \u0026ldquo;Total Field Energy in Simulation (J)\u0026rdquo;  Data Averaging EPOCH can accumulate an average value for field variables to be written to output dumps. These may be requested by using the \u0026ldquo;average\u0026rdquo; keyword when specifying a dump variable. The non-averaged variable will still be written to restart dumps where required for restarting the code but not full or normal dumps. If you also want the non-averaged variable to be written then you can add the \u0026ldquo;snapshot\u0026rdquo; option.\nThe period of time over which averaging occurs can be specified using the \u0026ldquo;dt_average\u0026rdquo; keyword. Alternatively, you may specify the number of cycles over which to perform the averaging using the \u0026ldquo;nstep_average\u0026rdquo; keyword. If both \u0026ldquo;dt_average\u0026rdquo; and \u0026ldquo;nstep_average\u0026rdquo; are specified then the averaging will be performed over the longest of the two intervals.\nNote that previous versions of the code would alter the time step to ensure that there were enough cycles between output dumps to satisfy the \u0026ldquo;nstep_average\u0026rdquo; parameter. However, since it affects the accuracy of the result, this is no longer the case and only a warning message is issued.\nThe following shows an example use of averaging in the output block.\nbegin:output dt_snapshot = 1.0e-15 full_dump_every = 10 dt_average = 1.0e-17 charge_density = always + average + snapshot mass_density = full + average + snapshot ekbar = full + average end:output  With this configuration, \u0026ldquo;charge_density\u0026rdquo; will be written in both normal and averaged form at normal, full and restart dumps. \u0026ldquo;mass_density\u0026rdquo; will be written in both forms at full dumps. Only the average value of \u0026ldquo;ekbar\u0026rdquo; will be written at full dumps.\nOnly field and derived variables can be averaged currently in EPOCH. Particle properties, distribution functions and particle probes cannot currently be averaged.\nSingle-precision output By default, EPOCH is compiled and run using double precision arithmetic. This is the only method which has been fully tested and the method that we recommend to other users of the code. However, this also means that data files can get very large.\nTo avoid this problem, it is possible to run the code in double precision but convert the data to single precision when writing to disk. This is done by adding the \u0026ldquo;single\u0026rdquo; field the the dumpmask of an output variable. It can be specified on a per-variable basis.\nbegin:output dt_snapshot = 8 * femto grid = always ex = always ey = always + single end:output  In this example, the grid variable \u0026ldquo;ex\u0026rdquo; will be written as a double precision array and \u0026ldquo;ey\u0026rdquo; will be converted to single precision.\nDumping variable averages adds an extra field variable for each average requested. These take up memory during runtime but do not influence the simulation behaviour in any way. For this reason, if the average is to be written out in single precision then it may as well be stored in a single precision variable. This behaviour can be requested using the \u0026ldquo;average_single\u0026rdquo; dumpmask flag.\nMultiple output blocks In more recent versions of EPOCH, it is now possible to have multiple \u0026ldquo;output\u0026rdquo; blocks in the input deck, each with their own \u0026ldquo;dt_snapshot\u0026rdquo; or \u0026ldquo;nstep_snapshot\u0026rdquo; and their own set of output variables.\nThe syntax remains the same as the original \u0026ldquo;output\u0026rdquo; block syntax with the addition of \u0026ldquo;name\u0026rdquo; and \u0026ldquo;restartable\u0026rdquo; fields.\nThe \u0026ldquo;name\u0026rdquo; field specifies the file name to use for the output list. Each time EPOCH generates an output dump, it writes an entry into the file \u0026ldquo;\u0026lt;name\u0026gt;.visit\u0026rdquo;. This can be used to find all the output dumps of a specific output block. It is named with a \u0026ldquo;.visit\u0026rdquo; suffix to enable its use as a file grouping list in the VisIt data analysis tool, but it is just a plain text file so it can equally be used by any other program.\nIf two output blocks are written at the same time, the output will be combined into a single file.\nThe \u0026ldquo;restartable\u0026rdquo; field specifies that the output block should generate output dumps containing all the information necessary to restart a simulation.\nThe following parameters are supported by the new style of output block in addition to those for the traditional style:\n name - Identifies the output block with a name which is required when multiple output blocks are used. restartable - Specifies whether or not the output for this block is a restartable dump. dump_at_times - Floating point parameter which specifies a set of simulation times at which to write the current output block. This can only be used with named output blocks. The values are given as a comma separated list. eg. \u0026ldquo;dump_at_times = 0, 0.15, 1.1\u0026rdquo;. The name \u0026ldquo;times_dump\u0026rdquo; is accepted as a synonym. By default the list is empty. dump_at_nsteps - Integer parameter which specifies a set of step numbers at which to write the current output block. This can only be used with named output blocks. The values are given as a comma separated list. eg. \u0026ldquo;dump_at_nsteps = 5, 11, 15\u0026rdquo;. The name \u0026ldquo;nsteps_dump\u0026rdquo; is accepted as a synonym. By default the list is empty. dump_at_walltimes - Floating point parameter which specifies a set of elapsed walltimes at which to write the current output block. This can only be used with named output blocks. The values are given as a comma separated list. eg. \u0026ldquo;dump_at_walltimes = 10, 100.1, 250.5\u0026rdquo;. These times are the total elapsed time in seconds since the start of the simulation. Note that if the simulation has been restarted then the total elapsed time will include the accumulated walltime of all previous runs that were used to produce the restart dump. The name walltimes_dump is accepted as a synonym. By default the list is empty. walltime_interval - Floating point parameter which specifies the interval between output dumps in elapsed walltime seconds. Setting zero or negative means that the code will not output based on this condition. The default value is -1.0. file_prefix - String parameter. It is sometimes useful to distinguish between dumps generated by the different output blocks. This parameter allows the user to supply a file prefix to be prepended to all dumps generated by the current output block. See below for further details. The default value is an empty string. rolling_restart - Logical flag. If set to \u0026ldquo;T\u0026rdquo;, this sets the parameters required for performing rolling restarts on the current block. It is a shorthand for setting the following flags: \u0026ldquo;dump_cycle = 1\u0026rdquo;, \u0026ldquo;restartable = T\u0026rdquo; and \u0026ldquo;file_prefix = roll\u0026rdquo;. With rolling restarts enabled the first file will be named \u0026ldquo;roll0000.sdf\u0026rdquo; and the second will be \u0026ldquo;roll0001.sdf\u0026rdquo;. The third dump will again be named \u0026ldquo;roll0000.sdf\u0026rdquo;, overwriting the first one. In this way, restart dumps can be generated throughout the duration of the simulation whilst limiting the amount of disk space used.  The following parameters cannot be used in conjunction with the new style of output block:\n full_dump_every restart_dump_every force_first_to_be_restartable force_last_to_be_restartable use_offset_grid  The \u0026ldquo;file_prefix\u0026rdquo; parameter warrants some further discussion. This parameter prepends the given prefix to all files generated by the output block in which it is specified. For example, if \u0026ldquo;file_prefix = aa\u0026rdquo; is set then files generated by the output block will be named \u0026ldquo;aa0000.sdf\u0026rdquo;, etc. instead of just \u0026ldquo;0000.sdf\u0026rdquo;.\nThis also allows different variables to different files at the same time step. For example, here are two output blocks which do not use file prefixes:\nbegin:output name = o1 nstep_snapshot = 1 charge_density = always end:output begin:output name = o2 dump_at_nsteps = 10 restartable = T end:output  With this input deck, we want to have the \u0026ldquo;charge_density\u0026rdquo; derived variable at every snapshot and then periodically write a restart dump. The problem is that the dump file \u0026ldquo;0010.sdf\u0026rdquo; contains both the restart information and the \u0026ldquo;charge_density\u0026rdquo; variable. At the end of the run we can\u0026rsquo;t just delete the large restart dumps without losing the smaller variables at that time step.\nWith the new version we would add a prefix to one or both blocks:\nbegin:output name = o1 file_prefix = small nstep_snapshot = 1 charge_density = always end:output begin:output name = o2 nstep_snapshot = 10 restartable = T end:output  Now the \u0026ldquo;charge_density\u0026rdquo; will be written to \u0026ldquo;small0000.sdf\u0026rdquo;, etc. At step 10, two files will be written: \u0026ldquo;small0010.sdf\u0026rdquo; containing just the charge_density and \u0026ldquo;0000.sdf\u0026rdquo; containing all the restart variables.\nNote that some care must be taken, since if the same variable is in the output block for multiple file prefixes then multiple copies will be written to file. This obviously uses more disk space and is more time consuming than necessary.\nIt should also be noted that if multiple output blocks use the same file stem then their output will be combined. eg:\nbegin:output name = o1 file_prefix = a dump_at_nsteps = 2,4 ex = always end:output begin:output name = o2 file_prefix = a dump_at_nsteps = 3,4 ey = always end:output begin:output name = o3 file_prefix = b dump_at_nsteps = 4 ez = always end:output  In this example, at step 2 a0000.sdf contains ex, step 3 a0001.sdf contains ey, step 4 a0002.sdf contains ex, ey and b0000.sdf contains ez.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"f0702d60960854ae14766d0f653d2d33","permalink":"/documentation/input_deck/input_deck_output_block.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_output_block.html","section":"documentation","summary":"This block contains information about when and how to dump output files. See EPOCH input deck for more information on the input deck.\nBasics Output in EPOCH is handled using the custom designed SDF file format (Self Describing Format).","tags":null,"title":"Output block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains parameters which should be applied to all output blocks. See EPOCH input deck for more information on the input deck.\nWith the introduction of multiple output blocks, there are now a few parameters that only make sense to be applied globally across all output blocks. To accommodate this, a new block named \u0026ldquo;output_global\u0026rdquo; has been added. Most of the parameters accepted by this block have the same meaning as those in the \u0026ldquo;output\u0026rdquo; block except that they are applied to all \u0026ldquo;output\u0026rdquo; blocks.\nThe parameters that can be specified in the \u0026ldquo;output_global\u0026rdquo; block are as follows:\n force_first_to_be_restartable - Logical flag which determines whether the file written at time zero is a restart dump. The default value is \u0026ldquo;F\u0026rdquo;. force_last_to_be_restartable - Force the code to override other output settings and make the last output dump it writes be a restart dump. Any internal condition which causes the code to terminate will make the code write a restart dump, but code crashes or scheduler terminations will not cause the code to write a restart dump. \u0026ldquo;force_final_to_be_restartable\u0026rdquo; is accepted as a synonym. The default value is \u0026ldquo;T\u0026rdquo;. dump_first - Logical flag which determines whether to write an output file immediately after initialising the simulation. The default is \u0026ldquo;F\u0026rdquo;. dump_last - Logical flag which determines whether to write an output file just before ending the simulation. The default is \u0026ldquo;T\u0026rdquo; if an output block exists in the input deck and \u0026ldquo;F\u0026rdquo; otherwise. \u0026ldquo;dump_final\u0026rdquo; is accepted as a synonym. time_start - Floating point parameter which specifies the simulation time at which to start considering output for all output blocks. Note that if \u0026ldquo;dump_first\u0026rdquo; or \u0026ldquo;dump_last\u0026rdquo; are set to true for any block then dumps will occur at the first or last timestep regardless of the value of this parameter. This also applies to the three following parameters. The default value is 0. time_stop - Floating point parameter which specifies the simulation time at which to stop considering output for all output blocks. The default value is the largest possible float. nstep_start - Integer parameter which specifies the step number at which to start considering output for the block. The default value is 0. nstep_stop - Integer parameter which specifies the step number at which to stop considering output for the block. The default value is the largest possible integer. walltime_start - Floating point parameter which specifies the elapsed walltime in seconds at which to start considering output for all output blocks. Note that if dump_first or dump_last are set to true for any blocks then dumps will occur at the first or last timestep regardless of the value of the walltime_start parameter. The default value is 0. walltime_stop - Floating point parameter which specifies the elapsed walltime in seconds at which to stop considering output all output blocks. The default value is the largest possible float. sdf_buffer_size - Integer parameter. When writing particle data to an SDF file, the data is first transferred into an output buffer. The size of this buffer can have a big impact on the overall speed of writing dump files. This parameter allows the size of the buffer to be specified in bytes. The default value is 67108864 (64 MB). filesystem - String parameter. Some filesystems can be unreliable when performing parallel I/O. Often this is fixable by prefixing the filename with \u0026lsquo;ufs\u0026rsquo; or \u0026lsquo;nfs\u0026rsquo;. This parameter supplies the prefix to be used. The default value is an empty string. use_offset_grid - When using moving windows some visualisation programs (notably VisIt) show the motion of the window by moving the visualisation window rather than by changing the x-axis. Setting this option to \u0026ldquo;T\u0026rdquo; causes the code to write another grid which always gives the offset relative to the left hand edge of the window rather than the true origin. Performs no function when not using the moving window. The default value is \u0026ldquo;F\u0026rdquo;.  dump_first_after_restart - Logical flag to enable a dump to occur immediately after restart. In the past, a dump_first flag in the output block would cause an output dump immediately after restarting. Since this is rarely the desired behaviour, the flag is now ignored when restarting. To force a dump to occur immediately after restart, set dump_first_after_restart = T in the output block. The default value is \u0026ldquo;F\u0026rdquo;.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"cc3c5e8742026f2825fdc30f4e757f53","permalink":"/documentation/input_deck/input_deck_output_global.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_output_global.html","section":"documentation","summary":"This block contains parameters which should be applied to all output blocks. See EPOCH input deck for more information on the input deck.\nWith the introduction of multiple output blocks, there are now a few parameters that only make sense to be applied globally across all output blocks.","tags":null,"title":"Output_global block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about distribution functions that should be calculated for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to reconstruct part of the full phase space for one or more particle species. This functionality is provided through a dist_fn block. The distribution function is integrated over all dimensions which are not axes of the distribution function.\nCalculating distribution functions requires some degree of integration of data leading to various possible ways of normalising the resulting distribution function. In EPOCH, distribution functions are normalised so that the value at every point of the distribution function is the number of particles within that cell of the distribution function, ignoring all phase space directions which are not considered as an axis of the distribution function. Summing the distribution function should give the total number of real particles (as opposed to computational pseudoparticles) in the simulation.\nAn example dist_fn block is given below:\nbegin:dist_fn name = x_px ndims = 2 dumpmask = always direction1 = dir_x direction2 = dir_px # Range is ignored for spatial coordinates range1 = (1, 1) range2 = (-50.0e-20, 50.0e-20) # Resolution is ignored for spatial coordinates resolution1 = 1 resolution2 = 5000 restrict_py = (-3.0e-20, 3.0e-20) include_species:Electron include_species:Carbon end:dist_fn   name - The name of the distribution function when it is output. This name is appended with the name of each species for which the data is output and so, for example, when applied to a species named carbon the output is called x_px_Carbon. The Cartesian grid which describes the axes of the distribution function would then be called grid_x_px_Carbon. ndims - The number of dimensions in this phase space reconstruction. Due to difficulties in visualising data in more than three dimensions, this is restricted to being 1, 2 or 3. dumpmask - Determines which output dumps will include this distribution function. The dumpmask has the same semantics as those used by variables in the \u0026ldquo;output\u0026rdquo; block, described here. The dumpmask from \u0026ldquo;distribution_functions\u0026rdquo; in the output block is applied first and then this one is applied afterwards. For example, if the dist_fn block contains \u0026ldquo;dumpmask = full\u0026rdquo; and the output block contains \u0026ldquo;distribution_functions = always\u0026rdquo; then this distribution function will be only be dumped at full dumps. The default dumpmask is \u0026ldquo;always\u0026rdquo;. direction**n** - This is the phase space to sample along axis . This can be any one of: dir_x, dir_y, dir_z, dir_px, dir_py, dir_pz, dir_en, dir_gamma_m1, dir_xy_angle, dir_yz_angle, dir_zx_angle with spatial codes only being available in dimensionalities of the code which have that direction. Therefore dir_z does not exist in EPOCH1D or EPOCH2D and dir_y does not exist in EPOCH1D.  The flags \u0026ldquo;dir_xy_angle\u0026rdquo;, \u0026ldquo;dir_yz_angle\u0026rdquo; and \u0026ldquo;dir_zx_angle\u0026rdquo; calculate the distribution of particle momentum directions in the X-Y, Y-Z and Z-X planes. In general, \u0026ldquo;dir_ij_angle\u0026rdquo; collapses the particle momentum into the $ij$ plane, and quotes the momentum angle with respect to the positive $i$ unit vector. The angle is output in the range of $\\pi$ to $-\\pi$. Angles towards $+j$ are positive, and vice-versa for negative $j$.\n range**n** - The range between which this axis should run. This is in the form of (minimum, maximum). Any particle which exceeds the range is ignored. For momentum directions this parameter is specified in $kg\\ ms^{-1}$. If the range of a momentum direction is set so that the maximum and the minimum are equal then the code will automatically set the range to exactly span the range of particle momenta at the point of writing the dump. resolution**n** - The number of gridpoints in a given direction. This is ignored for spatial dimensions where the resolution is always the same as the resolution of the underlying simulation. include_species - Specifies a species which should be included in the output. This is useful since it is rare that momentum limits are appropriate for both electrons and ions, so usually for a given dist_fn block only electrons or ions are considered. It is possible to have two dist_fn blocks with the same name but different ranges and different include_species settings produce the effect of a single diagnostic for all species in the output file. output_deltaf - If set to \u0026ldquo;T\u0026rdquo;, the particle weights used in calculating the distribution function is adjusted by subtracting the Delta-f distribution function for the particle species. The default value is \u0026ldquo;F\u0026rdquo;. restrict_{x,y,z,px,py,pz} - Restrictions are specified in the same way as ranges, but have a subtly different behaviour. Ranges specify the range of a visible axis on the resulting distribution function, whereas restrictions allow you to specify minimum and maximum values for each spatial and momentum direction and use only particles which fall within this range when calculating the distribution function. Restrictions can be specified even for properties which are not being used as axes. It is possible to set a restriction that is more restrictive than the range applied. This is not trapped as an error and such parts of the distribution function are guaranteed to be empty. The available spatial restrictions depend on the dimensionality of the code. Therefore, attempting to set restrict_z in EPOCH1D will produce a warning. At present, the code to calculate the distribution functions has one limitation: it ignores particle shape functions when calculating properties on the spatial axis, meaning that the result is less smooth than normal properties from the code.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"79a34eda391ba8c8123f1f6a405c86a3","permalink":"/documentation/input_deck/input_deck_dist_fn.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_dist_fn.html","section":"documentation","summary":"This block contains information about distribution functions that should be calculated for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to reconstruct part of the full phase space for one or more particle species.","tags":null,"title":"Dist_fn block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about particle probes used for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to consider all the properties of particle which pass through a point/line/plane (depending on dimension) in the simulation. To allow this, it is possible to specify one or more Particle Probe blocks in the input deck. These record copies of all particles which cross a point/line/plane in a given direction which meet minimum and maximum kinetic energy criteria and output the particle properties into the normal output files. Each output file only contains properties for particles which have passed the probe since the previous output, and not all particles which have passed the probe since the start of the simulation.\nParticle probes record the positions, momenta and weight of all particles passing through the plane. If the code is compiled with -DPARTICLE_ID or -DPARTICLE_ID4, the code also outputs the ID of passing particles. If the code is compiled with -DPROBE_TIME, the time at which the particle touches the probe surface is also output.\nTo use particle probes, the code must not have been compiled with the -DNO_PARTICLE_PROBES compiler option. This is a fairly heavyweight diagnostic since each particle position must be tested from within the particle push. The code will run faster if it is not compiled in.\nThe probe is specified in terms of a point in the plane and the normal vector to the plane which is to be monitored. Particles are only recorded if they cross the plane in the direction given by the normal vector. If you want to record particles travelling in both directions then use two particle probes, one with an opposite signed normal vector to the other.\nbegin:probe name = electron_back_probe point = (50.0e-6, -50.0e-6) normal = (1.0, 0.0) ek_min = 0.0 ek_max = -1.0 include_species : s1 dumpmask = always end:probe   name - The name that the probe should have in output dumps. Output variables are then named this as a prefix. For example, the block shown above will result in the name electron_back_probe_px for the x momentum. The particle positions would just be called electron_back_probe. point - An arbitrary point in the plane of the probe. normal - A vector normal to the plane of the probe, in the direction of crossings you wish to monitor. include_species - The species to which this probe should be applied. To probe several species, use several probe blocks in the input deck. \u0026ldquo;probe_species\u0026rdquo; is accepted as a synonym. ek_min - The minimum kinetic energy of particles to store information about. Set to 0 for no minimum kinetic energy. ek_max - The maximum kinetic energy of particles to store information about. Set to -1 for no maximum kinetic energy. dumpmask - The dump code for this particle probe. This is the same as that for the main output controls in input.deck. Note that the code has to store copies of particles which pass through the probe until a dump occurs. This means that the code\u0026rsquo;s memory requirements can increase drastically if this code only dumps probe information infrequently. If this is set to never then the code effectively never uses the probe.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"db873f83b7b18276527943cb10c2f371","permalink":"/documentation/input_deck/input_deck_probe.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_probe.html","section":"documentation","summary":"This block contains information about particle probes used for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to consider all the properties of particle which pass through a point/line/plane (depending on dimension) in the simulation.","tags":null,"title":"Probe block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about particle collisions. See EPOCH input deck for more information on the input deck.\nEPOCH has a particle collision routine with scattering algorithms based on the model presented by Sentoku and Kemp1 or the model presented by Prez et al 2, which in turn was based on the work of Nanbu and Yonemura3. This adds a new output block named \u0026ldquo;collisions\u0026rdquo;, and since version 4.19, there are two possible collision modes: binary and background. Binary collisions pair particles together, and apply scatter to both particles. In the background mode, particle species are split into fast-background pairs, where only particles in the fast species are scattered. Originally, EPOCH could only run in the full binary-collisions mode, which accepts the following keys:\n  use_nanbu - This logical flag determines whether the scattering angle of Prez/Nanbu will be used. The default is \u0026ldquo;T\u0026rdquo;. If \u0026ldquo;F\u0026rdquo;, the Sentoku-Kemp algorithm will be used.\n  coulomb_log - This may either be set to a real value, specifying the Coulomb logarithm to use when scattering the particles or to the special value \u0026ldquo;auto\u0026rdquo;. If \u0026ldquo;auto\u0026rdquo; is used then the routine will calculate a value based on the local temperature and density of the particle species being scattered, along with the two particle charges. If omitted, the default value is \u0026ldquo;auto\u0026rdquo;.\n  collide - This sets up a symmetric square matrix of size $nspecies \\times nspecies$ containing the collision frequency factors to use between particle species. The element (s1,s2) gives the frequency factor used when colliding species s1 with species s2. If the factor is less than zero, no collisions are performed. If it is equal to one, collisions are performed normally. For any value between zero and one, the collisions are performed using a frequency multiplied by the given factor. If \u0026ldquo;collide\u0026rdquo; has a value of \u0026ldquo;all\u0026rdquo; then all elements of the matrix are set to one. If it has a value of \u0026ldquo;none\u0026rdquo; then all elements are set to minus one. If the syntax \u0026ldquo;species1 species2 value\u0026rdquo; is used, then the (species1,species2) element of the matrix is set to the factor \u0026ldquo;value\u0026rdquo;. This may either be a real number, or the special value \u0026ldquo;on\u0026rdquo; or \u0026ldquo;off\u0026rdquo;. value may also be set to \u0026ldquo;background\u0026rdquo; to specify a fast-background pair (see below). The \u0026ldquo;collide\u0026rdquo; parameter may be used multiple times. The default value is \u0026ldquo;all\u0026rdquo; (ie. all elements of the matrix are set to one, modelling physical collisions).\n  collisional_ionisation - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the collisional ionisation model is enabled. This process is independent of field_ionisation (see here). However, in order to set up collisional_ionisation you must also specify ionisation energies and electrons in a species block (see here). The default value is \u0026ldquo;F\u0026rdquo;.\n  coll_n_step - Number of time-steps, $n$, between collision calculations. This key speeds up the collisions routine by reducing the number of collision calculations performed. On steps which apply collisions, the calculation is performed using a time-step of $n$*dt, where dt is the simulation time-step. The default is 1 (calculate collisions every step).\n  ci_n_step - Only performs the collisional ionisation calculation once every $n$ steps, where $n$ is set by this parameter. This is done to speed up the code, and the default is 1 (every step). When this is greater than 1, the assumed time-step for the collisional ionisation calculation is $n$*dt. Note that an ion may only be ionised once per calculation, so if $n$ is too high, the number of ions will be underestimated.\n  An example deck using full binary collisions could be set up as follows.\nbegin:collisions use_collisions = T use_nanbu = T coulomb_log = auto collide = all collide = spec1 spec2 off collide = spec2 spec3 0.5 coll_n_step = 10 end:collisions  With this block, collisions are turned on, the Nanbu-Prez scattering algorithm is used and the Coulomb logarithm is automatically calculated. All values of the frequency array are set to one except (spec1,spec2) is set to minus one (and also (spec2,spec1)) and (spec2,spec3) is set to 0.5. Note: only a frequency value of 1 provides a physical scatter. Collisions are only calculated once every 10 steps, but using an inferred time-step of 10*dt.\nBackground collisions The background collisions mode offers a speed-up compared to the binary method when applicable. This mode assumes the particles in one species are considerably faster than the particles in a background species, so the relative velocity between fast and background particles is roughly the fast particle speed. This eliminates the need to pair particles together in a local cell, as in the binary-collision case. However, background particles will not experience scatter in this mode. This mode was originally intended for electron-ion collisions, where both species had temperatures on the order of keV. An example of fast-background collisions is given below:\nbegin:collisions use_collisions = T coulomb_log = 5 collide = none collide = Electron Ion1 background collide = Electron Ion2 background collide = Electron Electron on use_cold_correction = F rel_cutoff = 0.01 back_update_dt = 5.0e-15 end:collisions  The above example deactivates all collisions, then sets up two fast-background pairs, with the Electron providing the fast species in both pairs, and Ion1 and Ion2 taking the background roles. Full binary collisions are used for Electron-Electron collisions, as these do not satisfy the fast-background assumptions. Additional speed-up parameters are used which only apply to background collisions. These are:\n  use_cold_correction - The Nanbu-Prez collisions model has a low temperature correction factor, given in equation (20) of Prez2. In some cases, this only affects particles with energy on the order of eV, and may be ignored in hot plasma. If \u0026ldquo;F\u0026rdquo;, this calculation is skipped. The default is \u0026ldquo;T\u0026rdquo;, to perform the full calculation.\n  rel_cutoff - Collisions are calculated in the centre-of-mass frame between colliding fast and background particles. In practice, only the fast particle momentum is transformed. This parameter takes a number between 0 and 1, and if the fractional momentum change between frames is lower than this number, the frame transform is skipped. The default is 0, so frame transforms are always considered.\n  back_update_dt - If the background species number density varies slowly, we do not need to re-calculate each step. This parameter specifies the time-step of recalculation for the background number density, and also the Coulomb logarithm if coulomb_log is set to auto. The default is 0, so background variables are re-calculated each step.\n  References   Y. Sentoku and A. J. Kemp, \u0026ldquo;Numerical methods for particle simulations at extreme densities and temperatures: Weighted particles, relativistic collisions and reduced currents,\u0026rdquo; J. Comput. Phys., 2008. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n F. Prez et al, \u0026ldquo;Improved modeling of relativistic collisions and collisional ionization in particle-in-cell codes ,\u0026rdquo; Physics of Plasmas, 2012. 2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n K. Nanbu and S. Yonemura, \u0026ldquo;Weighted Particles in Coulomb Collision Simulations Based on the Theory of a Cumulative Scattering Angle,\u0026rdquo; J. Comput. Phys., 1998. 3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"bf398a887b1c1428719cde66e7fa46b2","permalink":"/documentation/input_deck/input_deck_collisions.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_collisions.html","section":"documentation","summary":"This block contains information about particle collisions. See EPOCH input deck for more information on the input deck.\nEPOCH has a particle collision routine with scattering algorithms based on the model presented by Sentoku and Kemp1 or the model presented by Prez et al 2, which in turn was based on the work of Nanbu and Yonemura3.","tags":null,"title":"Collisions block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about QED pair production. See EPOCH input deck for more information on the input deck.\nEPOCH can model QED pair production, synchrotron emission and radiation reaction as described in Duclous et al1 and Ridgers et al. 2 It is enabled using the compiler flag -DPHOTONS. Additionally, the Trident process is enabled using -DTRIDENT_PHOTONS.\nA new input deck block named \u0026ldquo;qed\u0026rdquo; has been added which accepts the following parameters:\n  use_qed - Logical flag which turns QED on or off. The default is \u0026ldquo;F\u0026rdquo;.\n  qed_start_time - Floating point value specifying the time after which QED effects should be turned on. The default is 0.\n  produce_photons - Logical flag which specifies whether to track the photons generated by synchrotron emission. If this is \u0026ldquo;F\u0026rdquo; then the radiation reaction force is calculated but the properties of the emitted photons are not tracked. The default is \u0026ldquo;F\u0026rdquo;.\n  photon_energy_min - Minimum energy of produced photons. Radiation reaction is calculated for photons of all energies, but photons with energy below this cutoff are not tracked. The default is 0.\n  photon_dynamics - Logical flag which specifies whether to push photons. If \u0026ldquo;F\u0026rdquo; then photons are generated, but their motion through the domain is not simulated and they stay where they were generated. The default is \u0026ldquo;F\u0026rdquo;.\n  produce_pairs - Logical flag which determines whether or not to simulate the process of pair generation from gamma ray photons. Both produce_photons and photon_dynamics must be \u0026ldquo;T\u0026rdquo; for this to work. The default is \u0026ldquo;F\u0026rdquo;.\n  qed_table_location - EPOCH\u0026rsquo;s QED routines use lookup tables to calculate gamma ray emission and pair production. If you want to use tables in a different location from the default, specify the new location using this parameter. The default is \u0026ldquo;src/physics_packages/TABLES\u0026rdquo;.\n  use_radiation_reaction - Logical flag which determines whether or not to calculate the radiation reaction force. If set to \u0026ldquo;F\u0026rdquo; then the force is not calculated. This should nearly always be enabled when using the QED model. It is only provided for testing purposes. The default value is \u0026ldquo;T\u0026rdquo;.\n  QED also requires that the code now know which species are electrons, positrons and photons. The species type is specified using a single \u0026ldquo;identify\u0026rdquo; tag in a species block. To specify an electron the block in the deck would look like\nbegin:species name = electron frac = 0.5 number_density = 7.7e29 identify:electron end:species  Once the identity of a species is set then the code automatically assigns mass and charge states for the species. Possible identities are:\n  electron - A normal electron species. All species of electrons in the simulation must be identified in this way or they will not generate photons.\n  positron - A normal positron species. All species of positron in the simulation must be identified in this way or they will not generate photons.\n  photon - A normal photon species. One species of this type is needed for photon production to work. If multiple species are present then generated photons will appear in the first species of this type.\n  bw_electron - The electron species for pair production by the Breit-Wheeler process. If a species of this type exists then electrons from the pair production module will be created in this species. If no species of this type is specified then pair electrons will be generated in the first electron species.\n  bw_positron - As above but for positrons.\n  trident_electron - The electron species for pair production by the Trident process. If a species of this type exists then electrons from the pair production module will be created in this species. If no species of this type is specified then pair electrons will be generated in the first electron species.\n  trident_positron - As above but for positrons.\n  proton - A normal proton species. This is for convenience only and is not required by the pair production routines. A species should be identified only once, so a \u0026ldquo;bw_electron\u0026rdquo; species does not need to also be identified as an \u0026ldquo;electron\u0026rdquo; species. If the code is running with \u0026ldquo;produce_photons=T\u0026rdquo; then a photon species must be created by the user and identified. If the code is running with \u0026ldquo;produce_pairs=T\u0026rdquo; then the code must specify at least one electron (or bw_electron) species and one positron (or bw_positron) species. These species will usually be defined with zero particles from the start of the simulation and will accumulate particles as the simulation progresses. The code will fail to run if the needed species are not specified.\n  brem_photon - A bremsstrahlung photon species. This is used by the bremsstrahlung radiation model. See the bremsstrahlung page.\n  bh_electron - An electron produced in a Bethe-Heitler pair. See the bremsstrahlung page for more details.\n  bh_positron - A positron produced in a Bethe-Heitler pair. See the bremsstrahlung page for more details.\n  The basic input deck has now been considered fully but it is possible for an end user to add new blocks to the input deck As a result, a version of the code which you have obtained from a source other than the GitHub server may include other input deck blocks. These should be described in additional documentation provided with the version of the code that you have.\nReferences   R. Duclous, J. G. Kirk, and A. R. Bell, \u0026ldquo;Monte carlo calculations of pair production in high-intensity laserplasma interactions,\u0026rdquo; Plasma Phys. Contr. F., vol. 53, no. 1, p. 015009, 2011 1.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n C. P. Ridgers, J. G. Kirk, R. Duclous, T. G. Blackburn, C. S. Brady, K. Bennett, T. D. Arber, A. R. Bell, \u0026ldquo;Modelling gamma-ray photon emission and pair production in high-intensity laser\u0026ndash;matter interactions,\u0026rdquo; J. Comp. Phys., vol. 260, p. 273-285, 2014 2.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"1dcd7aea32db34141ed6c90584a9d8b4","permalink":"/documentation/input_deck/input_deck_qed.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_qed.html","section":"documentation","summary":"This block contains information about QED pair production. See EPOCH input deck for more information on the input deck.\nEPOCH can model QED pair production, synchrotron emission and radiation reaction as described in Duclous et al1 and Ridgers et al.","tags":null,"title":"QED block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains configuration for filters which can be used to modify the data to be output. See EPOCH input deck for more information on the input deck.\nIt is possible to restrict the number of particles written to file according to various criteria. For example, you can now output the momentum of all particles which have a gamma lower than 1.8 or the positions of a randomly chosen subset of a given species.\nA new input deck block named \u0026ldquo;subset\u0026rdquo; is defined which accepts the following parameters:\n name - The name given to this subset. This is used to identify the subset in the output block and is also used when labelling the data in the SDF files. include_species - Add the given particle species to the set of particles that this subset applies to. By default, no particle species are included. dumpmask - The dumpmask to use when considering this subset in an output block. This takes the same form as the output block dumpmask. The default value is \u0026ldquo;always\u0026rdquo;. random_fraction - Select a random percentage of the particle species. This is a real value between zero and one. If 0 is specified, no particles are selected. If 1 is specified, all the particles are selected. If 0.2 is specified, 20% of the particles are selected. {px,py,pz,weight,charge,mass,gamma}_min - Select only the particles with momentum, weight, charge, mass or gamma which is greater than the given value. {px,py,pz,weight,charge,mass,gamma}_max - Select only the particles with momentum, weight, charge, mass or gamma which is less than the given value. {x,y,z}_min - Select only the particles whose position lies above the given value. {x,y,z}_max - Select only the particles whose position lies below the given value. id_min,max - Select only the particles whose \u0026ldquo;id\u0026rdquo; is greater than or less than the given values. The \u0026ldquo;id\u0026rdquo; field is explained below. skip,skip_{x,y,z} - Integer parameter for subsampling output. If set to a positive integer then all grid-based variables using the subset restriction will be reduced when being written to file. This is achieved by skipping by the specified number of cells in each of the specified directions. The \u0026ldquo;skip\u0026rdquo; parameter provides a quick method for setting the same number of cells to skip in all directions. This currently only applies to grid-based variables and is ignored for data averages. The default value is \u0026ldquo;0\u0026rdquo;.  Once a subset has been defined, the subset name can then be used in place of (or in addition to) the dumpmask in an \u0026ldquo;output\u0026rdquo; block (see also here). For example:\nbegin:subset name = background random_fraction = 0.1 include_species:electron include_species:proton end:subset begin:subset name = high_gamma gamma_min = 1.3 include_species:electron end:subset begin:output particles = background + high_gamma + always px = background + high_gamma py = background pz = always end:output  In this example, three \u0026ldquo;px\u0026rdquo; blocks will be written: \u0026ldquo;Particles/background/electron/Px\u0026rdquo;, \u0026ldquo;Particles/background/proton/Px\u0026rdquo; and \u0026ldquo;Particles/high_gamma/electron/Px\u0026rdquo;. The \u0026ldquo;background\u0026rdquo; blocks will contain 10% of the each species, randomly selected. The \u0026ldquo;high_gamma\u0026rdquo; block will contain all the electrons with a gamma greater than 1.3.\nThere will also be \u0026ldquo;Particles/background/electron/Py\u0026rdquo; and \u0026ldquo;Particles/background/proton/Py\u0026rdquo; block containing y-momentum for the same 10% random subset of particles. Finally, the \u0026ldquo;Particles/All/electron/Pz\u0026rdquo; and \u0026ldquo;Particles/All/proton/Pz\u0026rdquo; will contain the z-momentum for all particles.\nThe final selection criteria given in the list above is \u0026ldquo;id_min\u0026rdquo; and \u0026ldquo;id_max\u0026rdquo;. As of EPOCH version 4.0, the code can now assign a unique ID field to every particle in the simulation. This can be useful for tracking specific particles as they move through a simulation. As this field adds extra memory requirements to the particles, it is disabled by default and must be compiled in using the -DPARTICLE_ID compiler flag.\nParticle IDs can be written to file using the \u0026ldquo;id\u0026rdquo; variable name in the \u0026ldquo;output\u0026rdquo; block. Eg.\nbegin:output particles = always id = always end:output  Subsets of fields Subset blocks can be applied to per-species variables such as current and temperature. Only particles within the given momentum ranges and of the selected species are included in the calculations. In addition, subset blocks can now be applied to field or grid variables. This allows you to output spatial sections using the {x,y,z}_max,min restrictions. The output data will be trimmed to the selected ranges and a corresponding restricted grid included in the output. Note that specifying an empty range will lead to output of the entire domain. For example, the following snippet will output an ex_c_centre variable restricted to the centre 1/3rd of the domain with a corresponding grid grid_centre:\nbegin:subset name = centre x_min = x_min + (x_max - x_min) / 3.0 x_max = x_min + 2.0 * (x_max - x_min) / 3.0 end:subset begin:output ... ex = always + centre end:output  Persistent subsets Persistent subsets are subsets that capture a set of particles once, given a specified set of parameters, and then track those particles permanently. Persistent subsets use the same blocks as normal subsets and take the same parameters as normal subsets (except the skip parameters which only apply to fields). Subsets are marked as persistent by setting either\n persist_start_time - Time at which to record the list of particles to be tracked. Throughout the rest of the simulation this recorded list will be used whenever requesting output for this subset. \u0026ldquo;persist_after_time\u0026rdquo; is accepted as an alias. Set to 0 to record from the start of the simulation. persist_start_step - Similar to persist_start_time except this specifies a simulation step number to use instead of time. \u0026ldquo;persist_after_step\u0026rdquo; is accepted as an alias.  If the input deck is edited on restart to add a new persistent subset then it must be added after existing persistent subsets or problems may occur on restart.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"504f427eb73df0c879754da612a3c49f","permalink":"/documentation/input_deck/input_deck_subset.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_subset.html","section":"documentation","summary":"This block contains configuration for filters which can be used to modify the data to be output. See EPOCH input deck for more information on the input deck.\nIt is possible to restrict the number of particles written to file according to various criteria.","tags":null,"title":"Subset block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about user defined constants and expressions. These are designed to simplify the initial condition setup. See EPOCH input deck for more information on the input deck.\nThe constant block type helps to make the input deck more flexible and maintainable. It allows you to define constants and maths parser expressions (see EPOCH maths parser) which can be used by name later in the deck. Constants are simply maths parser expressions which are assigned to a name as shown above. When the name is used on the right hand side of a deck expression it is replaced by the expression it was assigned with. This expression may be a simple numerical constant, a mathematical expression or a function. Constants may contain spatially varying information without having to pre-calculate them at every location in the domain. To those familiar with FORTRAN codes which use statement functions, parameters appearing in the \u0026ldquo;constant\u0026rdquo; block are fairly similar. If a constant name is reused in a constant block then the old constant is deleted and replaced with the new one. This happens without warning.\nbegin:constant lambda = 1.06 * micron omega = 2.0 * pi * c / lambda den_crit = critical(omega) scale = 3.5 * micron den_max = 5.0 * den_crit thick = 300e-9 pplength = 6000e-9 widscale = 5.0e-6 t_wid = (10.0e-6) / c amax = 1.0 wy = 1e-6 y = 0.0 slope = exp(-2.0 * (y/wy)^2) blob = gauss(sqrt(x^2 + y^2), 0.0, 1.0e-6) end:constant  Using constants can be very helpful when dealing with long, complicated expressions since they allow the expression to be broken down into much simpler parts. They can also be used to get around the FORTRAN string length limitation built into many compilers which prevents deck lines being longer then 512 characters long. As a general rule, it is a good idea to break down complicated expressions using constants or by other means, in order to make the deck look more readable. Constants are persistent for the entire runtime of the code, allowing them to be used when specifying time profiles for lasers, and also allowing developers to use maths parser expressions for other internal parts of the code where needed. In the above example, several pre-defined constants have been used (pi and c) and also several functions (critical, exp, gauss and sqrt). These are described here and here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"840cdf10c04c4cf380220dcab1d5113e","permalink":"/documentation/input_deck/input_deck_constant.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_constant.html","section":"documentation","summary":"This block contains information about user defined constants and expressions. These are designed to simplify the initial condition setup. See EPOCH input deck for more information on the input deck.","tags":null,"title":"Constant block","type":"docs"},{"authors":null,"categories":null,"content":"The injector block specifies a particle source to be introduced through a simulation boundary. Each injector block specifies a source of a single species of particle defined by a density, centre of mass drift momentum, temperature and number of simulation particles per cell. Injectors may also be set-up to inject particles with properties and at times read from files created by the user. The current version of the injectors is incompatible with the -DPER_SPECIES_WEIGHT compiler flag, and attempting to use an injector with a version of EPOCH compiled with this flag will fail.\nConcepts EPOCH can inject particles through any of the simulation boundaries. This plasma is either a drifting Maxwellian corresponding to a collisionally thermalized beam or a \u0026ldquo;flux Maxwellian\u0026rdquo; corresponding to a Maxwellian source accelerated by an electrostatic accelerator. It can have any temporal or transverse spatial profile of density, temperature or drift that you wish to specify.\nEPOCH does not automatically make any assumption about the plasma that you wish to inject and does not correct for currents injected into the domain. Current due to an injected beam will be smoothly created as the particles enter the domain. If you wish to inject a neutral beam, you will have to use multiple injectors to inject electrons and ions so as to produce a neutral beam. Great care must be taken when introducing relativistic beams since the current due to a highly relativistic beam will not be the current due to the centre of mass velocity since EPOCH does not use the Maxwell-Jttner distribution for loading particles.\nThe user may over-ride this behaviour and inject particles with specific momenta, positions, weights and ID values, at specific simulation times. These particle parameters are read from files, and syntax for these is provided here.\nBoundary conditions The injectors only work properly with certain boundary conditions. For most purposes the \u0026ldquo;open\u0026rdquo; boundary condition is the only one that makes sense with injectors since particles are flowing freely through the boundary. Remember that in any version of EPOCH that supports injectors you can also use per species boundary conditions to allow you to have different boundary conditions for injected and bulk particles.\nMoving window Injectors and moving windows can be tricky to work with, so the default behaviour of EPOCH is to stop all injectors when the window starts to move. If you wish to override this behaviour then simply explicitly set t_end in the injector block to a value after the window starts to move. Setting\nt_end = t_end  will cause the injectors to continue running until the end of the simulation even with the moving window. You must take great care when specifying injectors for a moving window because you will likely get gaps or bunches in particles injected through the x boundary and there will probably be some shearing of particles introduced through y and z boundaries. It is in general recommended that you specify a velocity profile for the moving window that stops at times when particles are to be injected and then starts again once the injection is complete.\nKeys   boundary - specifies which boundary to attach the particle source too. Same specification as the laser block, so permitted values are x_min, x_max, y_min, y_max, z_min and z_max\n  species - specifies which species should be injected through the boundary. Just specify the name of the species required.\n  t_start - Time at which to start the injector\n  t_end - Time at which to end the injector\n  npart_per_cell - target pseudo-particle density for the injector.\nAverage number of particles injected will be this value or slightly higher if very few particles are specified\n  number_density - Number density of the particle source in $m^{-3}$. Can be space varying along the boundary to which the injector is attached and time varying\n  number_density_min - Minimum number density in $m^{-3}$ below which pseudo particles are not loaded. Use if the density has a profile to avoid injecting low weight particles in low density regions\n  number_density_max - Maximum particle number density in $m^{-3}$. When the number density in a cell rises above number_density_max the injector clips the density to number_density_max allowing easy implementation of exponential rises to plateaus for time-varying injectors. Note that the number of particles per cell is kept fixed and the number density adjustment is achieved by modifying the particle weight. This flag has no effect for particles with per-species weighting. If the flag has a negative value then no clipping is performed. This is the default.\n  temp_x - Temperature in x direction (K)\n  temp_y - Temperature in y direction (K)\n  temp_z - Temperature in z direction (K)\n  temp - Sets an isotropic temperature distribution in Kelvin. If both temp and a specific temp_x, temp_y, temp_z parameter is specified then the last to appear in the deck has precedence. If neither are given then the injector will have a default temperature of zero Kelvin.\n  temp_{x,y,z}_ev, temp_ev - These are the same as the temperature parameters described above except the units are given in electronvolts rather than Kelvin, i.e. using 1ev = 11604.5K .\n  drift_x - Momentum drift in x direction in $kg.m/s$\n  drift_y - Momentum drift in y direction in $kg.m/s$\n  drift_z - Momentum drift in z direction in $kg.m/s$\n  drift_{x,y,z} - Specifies a momentum space offset in $kg m/s$ to the distribution function for this injector. By default, the drift is zero.\n  use_flux_maxwellian - Logical flag to determine whether to use an accelerated flux Maxwellian rather than a drifting Maxwellian. This calculates the flux due to passing a Maxwellian source into an electrostatic accelerator instead of a drifting Maxwellian. If your particle source is a lab accelerator then you may want to set this to true.\n  Example Deck begin:injector boundary = x_min species = Electron number_density = dens temp_x = temp drift_x = drift_p npart_per_cell = 32 end:injector  Inject particles from file The plasma injectors may be over-written to allow the user to inject macro-particles with specific momenta, positions and weight, at given simulation times on given boundaries. Files containing injected particle properties must be formatted in a particular way. Each variable type (position, momentum, weight, time) must be stored in a separate file. Each line of a given file corresponds to a variable value for one particle, and particles must be arranged in chronological order.\nFor example, a user wants to inject 3 particles of weights 10, 20 and 30, at times 1.0e-15 s, 2.0e-15 s and 3.0e-15 s respectively, into a 1D simulation through the x_min boundary. The file containing injection time data (inject_t.txt) would contain:\n1.0e-15 2.0e-15 3.0e-15  and the weight data file (inject_w.txt) would contain:\n10 20 30  The user could create similar files to describe the $p_x$, $p_y$ and $p_z$ momentum components of each injected particle, where the first value in each file would be assigned to the 1.0e-15 macro-particle. In higher dimensions, injection position on the boundary must also be specified. Particle ID may be given if -DPARTICLE_ID or -DPARTICLE_ID4 are specified.\nThe user may have multiple file-injectors running simultaneously, by defining multiple file-injector blocks. An example block is provided below for a 2D simulation. In this example, all files are present in the same directory as the input deck.\nbegin:injector boundary = x_min species = Electron inject_from_file = T y_data = \u0026quot;inject_y.txt\u0026quot; px_data = \u0026quot;inject_px.txt\u0026quot; py_data = \u0026quot;inject_py.txt\u0026quot; w_data = \u0026quot;inject_w.txt\u0026quot; t_data = \u0026quot;inject_t.txt\u0026quot; end:injector    inject_from_file - If \u0026ldquo;T\u0026rdquo;, the code will ignore the flux-Maxwellian keys, and will instead inject particles based on the {\u0026hellip;}_data keys.\n  {x, y, z}_data - Files containing the positions of injected particles. These are not used in 1D simulations, but must be used in 2D and 3D. In this example, no $x$ file is given, as all particles are injected through x_min.\n  {px, py, pz}_data - Files containing the momenta of injected particles. These are optional parameters - if a momentum component file is missing, this component will be set to zero for all injected particles.\n  w_data - The file containing the weights of all injected particles. This data is mandatory.\n  t_data - The file containing the times each particle passes the boundary. Injected particles will be positioned outside the simulation window, such that they pass the boundary at the time specified in this file. This data is mandatory.\n  id_data - The file containing the ID values assigned to each injected particle. This is optional, and may only be used if the code is compiled with either -DPARTICLE_ID or -DPARTICLE_ID4.\n  Warnings Currently injectors are a beta feature of EPOCH. We believe them to work correctly, but unusual results must be considered suspect. If you get unexpected results, please contact the EPOCH development team.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"ff6d9373653b995c692b37b407217eb8","permalink":"/documentation/input_deck/input_deck_injector.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_injector.html","section":"documentation","summary":"The injector block specifies a particle source to be introduced through a simulation boundary. Each injector block specifies a source of a single species of particle defined by a density, centre of mass drift momentum, temperature and number of simulation particles per cell.","tags":null,"title":"Injector block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the block used to load particles from file. See EPOCH input deck for more information on the input deck.\nThe particles_from_file block is similar in function to the fields block, it allows the loading of custom particle data from raw binary data files. An example usage of the block is shown below\nbegin:particles_from_file species = \u0026quot;electron\u0026quot; # Load mandatory data for 3D simulation x_data = \u0026quot;xdata.dat\u0026quot; y_data = \u0026quot;ydata.dat\u0026quot; z_data = \u0026quot;ydata.dat\u0026quot; w_data = \u0026quot;ydata.dat\u0026quot; # Load particle ids in 4 byte int format, # ignoring first 8 bytes of file #offset = 8 #id4_data = \u0026quot;iddata.dat\u0026quot; end:particles_from_file  Specifying a particles_from_file block for a species causes EPOCH to load the per-particle data from the specified files. Data files are assumed to be in order such that the first variable in each file will be attributed to one particle, the second variable in each file to a second electron, and so on. A target species to load to, as well as particle position and weight data (unless has been set) must be supplied. With the exception of particle ID, any optional parameters which are left unspecified will be initialised to zero. If the code has been compiled with or then particle IDs may be loaded from a raw binary file of integers of either size 4 or size 8 regardless of the compile time flag choice. If no particle ID data is supplied, IDs will be generated sequentially from 1. All other data should be in the form of floating point numbers of the same precision as in the core code. A particles_from_file block accepts the following parameters:\n  species - Name of the species to which the particles will be loaded. This is a mandatory parameter and the corresponding species block must be defined.\n  {x,y,z}_data - File containing particle position data in $m$. This data must be supplied, up to the dimensionality of the simulation.\n  w_data - File containing pseudoparticle weight, this is the number of real particles the pseudoparticle represents. This data must be supplied.\n  {px,py,pz}_data - File containing particle momentum data in $kg,ms^{-1}$. The default value is zero.\n  id{4,8}_data - File containing particle IDs in either 4 or 8 byte unsigned integer representation.\n  offset - File offset. Number of bytes at the head of the file to be ignored, may be specified multiple times. see for more details of behaviour.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680770875,"objectID":"f32573fb9b55a393445eb0e956ad6d38","permalink":"/documentation/input_deck/input_deck_particle_file.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_particle_file.html","section":"documentation","summary":"This block contains information about the block used to load particles from file. See EPOCH input deck for more information on the input deck.\nThe particles_from_file block is similar in function to the fields block, it allows the loading of custom particle data from raw binary data files.","tags":null,"title":"Particles_from_file block","type":"docs"},{"authors":null,"categories":null,"content":"There are several input deck blocks which can read conditions directly from a user-specified file. These include the , and . In all such cases, the files specified must be in a simple binary format, often referred to as \u0026ldquo;raw\u0026rdquo; binary files.\nBinary files are machine readable, but not human readable. If you try opening a binary file in a text editor then you will see incomprehensible characters and some text editors might even crash. Most languages can write binary files, see \u0026ldquo;writeu\u0026rdquo; (in IDL/GDL), \u0026ldquo;fwrite\u0026rdquo; in MatLab, the \u0026ldquo;b\u0026rdquo; parameter to \u0026ldquo;open\u0026rdquo; in Python and \u0026ldquo;form=\u0026lsquo;UNFORMATTED\u0026rsquo; \u0026quot; in Fortran, so please see the documentation for those languages. Note that standard unformatted output in Fortran also writes some additional hidden output to the file that alters the offset of the actual binary array data within the file. It is therefore recommended that you always use the \u0026ldquo;access=\u0026lsquo;STREAM\u0026rsquo; \u0026quot; modifier whenever writing such files from Fortran programs.\nFor illustration purposes, here is a simple example of writing a 2D array to file using Fortran:\nPROGRAM output_array INTEGER :: iu, istat INTEGER, PARAMETER :: nx = 10, ny = 20 DOUBLE PRECISION :: array(nx,ny) CHARACTER(LEN=*), PARAMETER :: filename = array.dat array = 2.0d0 OPEN(newunit=iu, file=filename, status=NEW, form=UNFORMATTED, \u0026amp;amp; access=STREAM, iostat=istat) IF (istat == 0) THEN WRITE(iu) array CLOSE(iu, iostat=istat) ELSE PRINT*, ERROR: failed to open file ,  // filename // , \u0026amp;amp;  for writing END IF END PROGRAM output_array  In this example, there are 200 array elements written to file (10 * 20). Each element is a double-precision number which is 8 bytes. Therefore, the total file size will be 1600 bytes. Note that for Fortran, arrays are indexed using \u0026ldquo;column-major order\u0026rdquo;. This means that in the file, the first array element \u0026ldquo;array(1,1)\u0026rdquo; will be followed by \u0026ldquo;array(2,1)\u0026rdquo; and so on up to \u0026ldquo;array(10,1)\u0026rdquo;. After this, the second index will be incremented and the array element \u0026ldquo;array(1,2)\u0026rdquo; will be output, followed by \u0026ldquo;array(2,2)\u0026rdquo;, etc. In contrast, languages such as C and C++ use row-major order. For these languages the array output is transposed, so the array elements are output in the order: \u0026ldquo;array[0][0], array[0][1], .. array[0][19], array[1][0], ..\u0026rdquo;\nSimple binary files merely contain a long sequence of real numbers and do not contain any information about the shape of the arrays that have been written. This information must be supplied using the input deck. These should correspond to the values of \u0026ldquo;nx\u0026rdquo;, \u0026ldquo;ny\u0026rdquo;, etc. For example, to use the array generated by the Fortran code shown above, the input deck must specify \u0026ldquo;nx = 10\u0026rdquo; and \u0026ldquo;ny = 20\u0026rdquo;.\nIt is possible to write multiple arrays into the same binary file and use the \u0026ldquo;offset\u0026rdquo; comand in the input deck to specify where the next array in the file is to be located. This can be tricky to work with and it is therefore recommended to write each separate array to its own file.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"7d076699feafd5a7475a16628be5614f","permalink":"/documentation/input_deck/binary_files.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/binary_files.html","section":"documentation","summary":"There are several input deck blocks which can read conditions directly from a user-specified file. These include the , and . In all such cases, the files specified must be in a simple binary format, often referred to as \u0026ldquo;raw\u0026rdquo; binary files.","tags":null,"title":"Binary files","type":"docs"},{"authors":null,"categories":null,"content":"The makefile supplied with EPOCH is a standard GNU make makefile, which must be user modified to allow a developer to add new files to the code. EPOCH\u0026rsquo;s makefile is quite large, so an explanation of how to add new files and new directories is given below.\nAdding a new file to be compiled with EPOCH There are three things that must be done to cause EPOCH to compile a new file and link it into the final code. Assume that you\u0026rsquo;re adding a file called \u0026ldquo;newfile.F90\u0026rdquo;. First, find the line which sets the environment variable SRCFILES and add a new parameter which reads \u0026ldquo;newfile.F90\u0026rdquo;. This tells the makefile to compile the final code using your new file, the next thing to do is to add a line which tells the code about the dependencies for your file. Lower down in the makefile, you\u0026rsquo;ll find a section with lines which look like:\nbalance.o: balance.F90 boundary.o mpi_subtype_control.o partlist.o  Add a new line for describing all the FILES (NOT modules) which are used by your new file. If you USE shared_data, mpi_subtype_control and stack in your file then the line would look like:\nnewfile.o: newfile.F90 shared_data.o mpi_subtype_control.o stack.o  Note the structure of the line with ONLY the source file for the new file specified, all other used files specify the intermediate .o files. The remaining element of the makefile which needs to be modified is to add your new file as a dependency to all the files which USE modules contained in your new file. This is achieved very simply by adding \u0026ldquo;newfile.o\u0026rdquo; to the dependency list for those files which USE your modules. For example if you\u0026rsquo;ve written new boundary conditions and USE your modules in boundary.f90, you\u0026rsquo;d just change the line for boundary.f90 from:\nboundary.o: boundary.f90 deck_io_block.o particle_temperature.o partlist.o  to\nboundary.o: boundary.f90 deck_io_block.o particle_temperature.o partlist.o \\ newfile.o  Note that the backslash characters are line continuation marks in makefiles.\nAdding new directories to EPOCH\u0026rsquo;s makefile If you want to add an entire new directory to the EPOCH compile path then you need to add it to the definition of the variable VPATH. Remember to use the variable $(SRCDIR) rather than hard-coding src into the path.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"0fe306cac685aebe8a2f1653f0a5ccf3","permalink":"/developer/makefile.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/makefile.html","section":"developer","summary":"The makefile supplied with EPOCH is a standard GNU make makefile, which must be user modified to allow a developer to add new files to the code. EPOCH\u0026rsquo;s makefile is quite large, so an explanation of how to add new files and new directories is given below.","tags":null,"title":"EPOCH Makefile","type":"docs"},{"authors":null,"categories":null,"content":"A discussion of the input deck for EPOCH would not be complete without consideration of the maths parser. The maths parser is the code which reads the input decks. The parser makes it possible that any parameter taking a numerical value (integer or real) can be input as a mathematical expression rather than as a numerical constant. The maths parser is fairly extensive and includes a range of mathematical functions, physical and simulation constants and appropriately prioritised mathematical operators.\nConstants The maths parser in EPOCH has the following constants\n pi - The ratio of the circumference of a circle to its diameter. kb - Boltzmann\u0026rsquo;s constant. me - Mass of an electron. qe - Charge of an electron. c - Speed of light. epsilon0 - Permeability of free space. mu0 - Permittivity of free space. ev - Electronvolt. kev - Kilo-Electronvolt. mev - Mega-Electronvolt. micron - A convenience symbol for specifying wavelength in microns rather than metres. milli - $10^{-3}$ micro - $10^{-6}$ nano - $10^{-9}$ pico - $10^{-12}$ femto - $10^{-15}$ atto - $10^{-18}$ cc - A convenience symbol for converting from cubic metres to cubic centimetres (ie. $10^{-6}$) time - Initial simulation time. x,y,z - Grid coordinates in the x,y,z direction. ix,iy,iz - Grid index in the x,y,z direction. nx,ny,nz - Number of grid points in the x,y,z direction. dx,dy,dz - Grid spacing in the x,y,z direction. {x,y,z}_min - Grid coordinate of the minimum x,y,z boundary. {x,y,z}_max - Grid coordinate of the maximum x,y,z boundary. length_{x,y,z} - The length of the simulation box in the x,y,z direction. nproc_{x,y,z} - The number of processes in the x,y,z directions. nsteps - The number of timesteps requested. t_end - The end time of the simulation. p{x,y,z} - Momentum in the x, y, z directions. Used in specifying arbitrary distribution functions. EPOCH 4.15 or later required  It is also possible for an end user to specify custom constants both within the code and from the input deck. These topics are covered later in this subsection. An example of using a constant would be: length_x = pi\nFunctions The maths parser in EPOCH has the following functions\n abs(a) - Absolute value. floor(a) - Convert real to integer rounding down. ceil(a) - Convert real to integer rounding up. nint(a) - Convert real to integer rounding to nearest integer. sqrt(a) - Square root. sin(a) - Sine. cos(a) - Cosine. tan(a) - Tangent. asin(a) - Arcsine. acos(a) - Arccosine. atan(a) - Arctangent. atan2(Y,X) - Arctangent using the Fortran ATAN2 function. This computes the principal value of the argument function of the complex number $X + i Y$. This function can be used to transform from Cartesian into polar coordinates and allows to determine the angle in the correct quadrant. sinh(a) - Hyperbolic sine. cosh(a) - Hyperbolic cosine. tanh(a) - Hyperbolic tangent. exp(a) - Exponential. loge(a) - Natural logarithm. log10(a) - Base-10 logarithm. log_base(a,b) - Base-b logarithm. gauss($x,x_0,w$) - Calculate a Gaussian profile in variable x centred on $x_0$ with a characteristic width w. $f(x) = \\exp{(-((x-x_0)/w)^2)}$. In this expression the full width at half maximum is given by $fwhm = 2 w \\sqrt{\\ln{2}}$ supergauss($x,x_0,w,n$) - This is identical to \u0026ldquo;gauss\u0026rdquo; except it takes a fourth parameter, n, which is the power to raise the exponential argument to. semigauss($t,A,A_0,w$) - Calculate a semi Gaussian profile in variable $t$ with maximum amplitude $A$, amplitude at $t=0$ $A_0$ and width $w$. The parameter $A_0$ is used to calculate $t_0$, the point at which the Gaussian reaches its maximum value. For $t$ less than $t_0$ the profile is Gaussian and for $t$ greater than $t_0$ it is the constant $A$. $t_0 = w\\sqrt{-\\ln{(A_0/A)}}$f(t) =  \\begin{cases} A \\exp{(-((t-t_0)/w)^2)}, \u0026amp; t \u0026lt; t_0 \\\\ A, \u0026amp; \\mbox{otherwise} \\end{cases}\n interpolate(interp_var,.\u0026hellip;,n_pairs) - Linear interpolation function, explained later. if(a,b,c) - Conditional function. If a != 0 the function returns b, otherwise the function returns c. number_density(a) - Returns the number density for species a. temp_{x,y,z}(a) - Returns temperature in the x, y or z direction for species a. temp(a) - Returns the isotropic temperature for species a. e{x,y,z}(x,y,z) - Returns the x, y or z component of the electric field at the specified location. b{x,y,z}(x,y,z) - Returns the x, y or z component of the magnetic field at the specified location. critical($\\omega$) - Returns the critical density for the given frequency $\\omega$. ie. $n_{crit}(\\omega) = \\omega^2 m_0 \\epsilon_0 / e^2$  It is also possible for an end user to specify custom functions within the code. An example of using a function would be: length_x = exp(pi) The use of most of these functions is fairly simple, but \u0026ldquo;interpolate\u0026rdquo; requires some additional explanation. This function allows a user to specify a set of position,value pairs and have the code linearly interpolate the values between these control points. This function is mainly intended for ease of converting initial conditions from other existing PIC codes, and the same effect can usually be obtained more elegantly using the \u0026ldquo;if\u0026rdquo; command. The structure of the \u0026ldquo;interpolate\u0026rdquo; command is as follows: The first parameter is the variable which is to be used as the axis over which to interpolate the values. This can in general be any valid expression, but will normally just be a coordinate axis. The next 2n entries are the position,value pairs and the final parameter is the number of position,value pairs. The slightly clunky syntax of this command is unfortunately necessary to allow it to work with some fairly fundamental features of the maths parser used in EPOCH.\nOperators The maths parser in EPOCH allows the following operators\n a + b - Addition operator. a - b - Subtraction operator or unary negation operator (auto-detected). a * b - Multiplication operator. a / b - Division operator. a ^ b - Power raise operator. a e b - Power of ten operator (1.0e3 = 1000). a lt b - Less than operator. Returns 1 if a $\u0026lt;$ b, otherwise returns 0. Intended for use with if. a gt b - Greater than operator. Returns 1 if a $\u0026gt;$ b, otherwise returns 0. a eq b - Equality operator. Returns 1 if a == b, otherwise returns 0. a and b - Logical and operator. Returns 1 if a != 0 and b != 0, otherwise returns 0. a or b - Logical or operator. Returns 1 if a != 0 or b != 0, otherwise returns 0.  These follow the usual rules for operator precedence, although it is best to surround more complex expressions in parenthesis if the precedence is important. It is not possible at this time to specify custom operators without major changes to the code. An example of using an operator would be:\nlength_x = 10.0 + 12.0  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624406887,"objectID":"a0e05e75d55e7b546f0c9701cb7b8da6","permalink":"/documentation/code_details/maths_parser.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/maths_parser.html","section":"documentation","summary":"A discussion of the input deck for EPOCH would not be complete without consideration of the maths parser. The maths parser is the code which reads the input decks. The parser makes it possible that any parameter taking a numerical value (integer or real) can be input as a mathematical expression rather than as a numerical constant.","tags":null,"title":"Maths parser","type":"docs"},{"authors":null,"categories":null,"content":"The names of the source files in EPOCH are fairly self explanatory but, for clarity, they are explained here. Some files have the normal Fortran file extension .f90, while some have the slightly unusual .F90. The difference is that files with the .F90 extension are passed through the preprocessor before they are compiled allowing the use of precompiler directives (the #ifdef commands).\nDirectories All source files are contained in the src directory and its subdirectories. There is a stylistic reason for the layout of the files, which is explained here\n src - Files in this directory are the core files for the basic EPOCH code, such as the field solvers, the particle pusher, the boundary conditions and the lasers. src/deck - Files in this directory are responsible for dealing with the permanent input deck parser and include the core parts of the deck handler, and also the routines which deal with the blocks in the input deck files. src/housekeeping - Files in this directory deal with those parts of the code operation which are not physics; including the load balancer, the MPI setup routines and the moving window. src/include - This directory contains the shape function code fragments which are inserted into the particle push at compile time. src/io - The files involved in all I/O activities, including the distribution functions and the particle probes. src/parser - The files for the maths expression parser are in this directory, including both the core implementation of the shunting yard algorithm and the routines for implementing the permanent functions, constants and operators for the input deck. src/physics_packages - Contains routines which implement additional physics for the code. src/user_interaction - Contains any Fortran routines which a user has to modify to use the code with internal initial conditions, or to temporarily extend the maths parser or the input deck.  The files in src  boundary.F90 - Includes all boundary conditions except laser and transmissive boundaries; including field and particle MPI boundaries, and field and particle domain boundaries. constants.F90 - A collection of physical constants, and also integer flags for I/O, boundaries, and other variables. epoch1d.F90, epoch2d.F90, epoch3d.F90  - Main driver for the code. Reading this routine gives the basic layout of the code flow. fields.f90 - The Maxwell field solver. laser.f90 - Includes laser and transmissive boundary conditions for each boundary and also the housekeeping routines for the laser objects. particles.F90 - The particle pusher. shared_data.F90 - This file includes all the global variable and type definitions. Usually new variables should be defined in this file. gen_commit_string - This is a script used to generate an ID string when compiling the code. gen_src_module - This is a script which is used at build time to generate a Fortran module containing the source code. This is used for embedding the EPOCH source code into restart dumps.  The files in src/deck  deck.F90 - The main input deck routines. Deals with opening files, reading data and MPI distribution of the data to all processes. Also includes the routines which deal with calling the right reader routines to deal with a given block. deck_boundaries_block.f90 - Reader routine for the \u0026ldquo;boundaries\u0026rdquo; block of the input deck. deck_bremsstrahlung_block.f90 - Reader routine for the \u0026ldquo;bremsstrahlung\u0026rdquo; block of the input deck. deck_collision_block.f90 - Reader routine for \u0026ldquo;collision\u0026rdquo; blocks in the input deck. deck_constant_block.f90 - Reader routine for \u0026ldquo;constant\u0026rdquo; blocks in the input deck. deck_control_block.f90 - Reader routine for \u0026ldquo;control\u0026rdquo; block in the input deck. deck_dist_fn_block.f90 - Reader routine for \u0026ldquo;dist_fn\u0026rdquo; blocks in the input deck. deck_fields_block.f90 - Reader routine for \u0026ldquo;fields\u0026rdquo; blocks in the input deck. deck_io_block.F90 - Reader routine for the \u0026ldquo;io\u0026rdquo; block in the input deck. deck_io_global_block.F90 - Reader routine for the \u0026ldquo;io_global\u0026rdquo; block in the input deck. deck_laser_block.f90 - Reader routine for \u0026ldquo;laser\u0026rdquo; blocks in the input deck. deck_part_from_file_block.F90 - Reader routine for the \u0026ldquo;part_from_file\u0026rdquo; block in the input deck. deck_particle_probe_block.F90 - Reader routine for \u0026ldquo;particle_probe\u0026rdquo; blocks in the input deck. deck_species_block.F90 - Reader routine for \u0026ldquo;species\u0026rdquo; blocks in the input deck. This contains scripts which create the species_list array which holds the particle lists for each species. deck_stencil_block.F90 - Reader routine for \u0026ldquo;stencil\u0026rdquo; blocks in the input deck. deck_subset_block.F90 - Reader routine for \u0026ldquo;subset\u0026rdquo; blocks in the input deck. deck_window_block.f90 - Reader routine for the \u0026ldquo;window\u0026rdquo; block in the input deck. strings.f90 - Basic string handling routines such as \u0026ldquo;str_cmp\u0026rdquo; and routines for converting strings to numbers WITHOUT using the maths parser are covered in this routine. strings_advanced.f90 - The routines which pass maths along to the maths parser routines are here.  The files in src/housekeeping  balance.F90 - Contains the routines for the load balancer and related routines. current_smooth.F90 - Contains the current smoothing routines. epoch_source_info_dummy.f90 - A dummy module used when the code is being built without the ability to write the source code into restart dumps. finish.F90 - Deallocates fields, species, subsets and physics packages at the end of the simulation. mpi_routines.F90 - Contains the routines dealing with the setup of the MPI layer and the creation of the communicator. Also allocates all arrays for the first time before load balancing. mpi_subtype_control.f90 - Contains the routines that setup the mpi types required by the I/O subsystem. particle_id_hash.F90 - Stores scripts responsible for identifying particles in persistent subsets. particle_pointer_advance.f90 - Contains subroutines which walk through the lists of particles and species for I/O purposes. partlist.F90 - Contains the routines which deal with the particle lists which are used for inter-processor communication of particles. prefetch.F90 - Hold scripts for pre-fetching particles. This requires Intel compilation of the code, and can improve performance. random_generator.f90 - Contains the random number generator routines. redblack_module.f90 - Contains MPI routines used for the load-balancer. setup.F90 - Deals with the setup of the grids and domains and restarting from previous output dumps. shape_functions.F90 - Contains the particle shape functions used for calculating the particle weighting. split_particle.F90 - Is the implementation of a demonstration of particle splitting routines. terminal_controls.F90 - Makes the logo colourful on startup. timer.f90 - Tracks the run-time of the code. utilities.f90 - Contains growable arrays used by the species block parser. version_data.F90 - Contains version information for the current EPOCH code. welcome.F90 - The routine which prints the banner message and compiler options info. window.F90 - The routines which deal with the moving window.  The files in src/io  calc_df.F90 - Despite the slightly confusing name, this subroutine deals with derived functions like number density, charge density and mass density. diagnostics.F90 - Contains the routines which actually dump the data, decide what to dump and also the routine to calculate the timestep. dist_fn.F90 - Contains the routines to calculate the distribution functions, and also the routines handling the requests for distribution functions. iterators.F90 - Contains the iterator functions used to write particle data into SDF files. probes.F90 - Contains the routines which write the data from the particle probes. Also includes the routines which deal with user requests to add new particle probes. simple_io.f90 - Contains routines for performing the simple binary I/O required by species_external and fields_external blocks.  The files in src/parser  evaluate.f90 - Contains the routines which actually evaluate a tokenized expression. The core of this is a simple implementation of an RPN calculator. evaluator_blocks.f90 - Contains the routines which evaluate a given token into a numerical values. Actually implements the functions, constants and operators in EPOCH\u0026rsquo;s maths parser. shunt.F90 - EPOCH\u0026rsquo;s implementation of the \u0026ldquo;shunting yard\u0026rdquo; algorithm used to simultaneously tokenize the input and convert it from infix notation to RPN. stack.f90 - Deals with routines for pushing onto and popping off stacks. tokenizer_blocks.f90 - Deal with converting strings found in a string being tokenized into tokens. Essentially a large collection of \u0026ldquo;str_cmp\u0026rdquo; commands testing a string against a known name.  The files in src/physics_packages  TABLES - Subdirectory containing tables for QED emissions, bremsstrahlung radiation, and both collisional and field ionisation. background_collisions.F90 - Package handling particle collisions for special cases. Faster than the collisions.F90 model, but assumes a heavy species remains immobile during the collision. Appropriate for hot electron scatter through cold ions. bethe_heitler.F90 - Package sampling pair-production via the Bethe-Heitler process. This is run during the bremsstrahlung update. bremsstrahlung.F90 - Runs bremsstrahlung radiation of electrons and positrons, discussed in Appendix B of Morris et al. collision_ionise.F90 - Package sampling collisional ionisation triggered by incident electrons. See here for details. collisions.F90 - Package handling particle collisions. Estimates the number of binary Coulomb collisions over a simulation time-step, and samples a cumulative scatter angle. See here for details. file_injectors.F90 - Injects particles from user-written text files (ASCII). injectors.F90 - Package dealing with particle injection through a boundary. Currently this handles drifting and non-drifting Maxwellian and flux-Maxwellian distributions. ionise.F90 - Physics package dealing with field ionisation. Field ionisation consists of three distinct regimes; multiphoton in which ionisation is best described as absorption of multiple photons, tunnelling in which deformation of the atomic Coulomb potential is the dominant factor, and barrier suppression ionisation in which the electric field is strong enough for an electron to escape classically. It is possible to turn off multiphoton or barrier suppression ionisation through the input deck. numerics.f90 - Some additional numerics routines, primarily for the photons (QED) package. photons.F90 - Package for some QED effects. Models Breit-Wheeler pair production, synchrotron emission and radiation reaction as described in Duclous et al and Ridgers et al  The files in src/user_interaction  custom_deck.f90 - This file is where and end user can temporarily extend the input deck. custom_laser.f90 - The file where an end user specifies laser time profiles without using the input deck. custom_parser.f90 - The file where an end user can temporarily add new functions and constants to the input deck. deltaf_loader.F90 - Sets up parameters for the delta-f model. helper.F90 - This file contains all the internal workings of the autoloader. This is in user_interaction for historical reasons, since early versions of the code required the end user to modify some parts of the functions contained in this file. As the autoloader has increased in complexity, this has ceased to be the case, so it is likely that soon this file will be move to \u0026ldquo;housekeeping\u0026rdquo;. ic_module.f90 - This file is where the internal and manual initial conditions are set. particle_temperature.F90 - Contains the routines for thermally loading a particle species.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"38e2813c35199ee81493bb1d06c5a539","permalink":"/developer/source_code_files.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/source_code_files.html","section":"developer","summary":"The names of the source files in EPOCH are fairly self explanatory but, for clarity, they are explained here. Some files have the normal Fortran file extension .f90, while some have the slightly unusual .","tags":null,"title":"General layout of the EPOCH code","type":"docs"},{"authors":null,"categories":null,"content":"Specifying initial conditions for particles using the input deck If the initial conditions for the plasma you wish to model can be described by a number density and temperature profile on the underlying grid then EPOCH can create an appropriate particle distribution for you. The set of routines which accomplish this task are known as the autoloader. For many users, this functionality is sufficient to make use of the code and there is no need to deal with the internal representation of particles in EPOCH.\nThe autoloader randomly loads particles in space to reproduce the number density profile that was requested. It then sets the momentum components of the particles to approximate a Maxwell-Boltzmann distribution corresponding to the temperature profile. Sometimes this is not the desired behaviour, for example you may wish to model a bump-on-tail velocity distribution. It is currently not possible to specify these initial conditions from the input deck and the particles must be setup by modifying the source code.\nThere are two stages to the particle setup in EPOCH\n auto_load - This routine is called after reading and parsing the input deck. It takes care of allocating particles and setting up their initial positions and momenta using the initial conditions supplied in deck file. It is not necessary to recompile the code, or even have access to the source to change the initial conditions using this method. manual_load - Once particles have been allocated they can have their properties altered in this routine. By default it is an empty routine which does nothing.  Setting autoloader properties from the input deck To illustrate using the autoloader in practice, we present an example for setting up an isolated plasma block in 2D. This would look like:\nbegin:species name = s1 # First set number_density in the range 0 \u0026gt; 1 # Cut down number_density in x direction number_density = if ((x gt -1) and (x lt 1), 1.0, 0.2) # Cut down number_density in y direction number_density = if ((y gt -1) and (y lt 1), number_density(s1), 0.2) # Multiply number_density by real particle number_density number_density = number_density(s1) * 100.0 # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species begin:species # Just copy the number_density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species  An important point to notice is that the two parts of the logical expressions in the input deck are enclosed within their own brackets. This helps to remove some ambiguities in the functioning of the input deck parser. It is hoped that this will soon be fixed, but at present ALWAYS enclose logical expressions in brackets.\nManually overriding particle parameters set by the autoloader Since not all problems in plasma physics can be described in terms of an initial distribution of thermal plasma, it is also possible to manually control properties of each individual pseudoparticle for an initial condition. This takes place in the subroutine manual_load in the file user_interaction/ic_module.f90. Manual loading takes place after all the autoloader phase, to allow manual tweaking of autoloader specified initial conditions.\nEPOCH internal representation of particles Before we can go about manipulating particle properties in manual_load, we first need an overview of how the particles are defined in EPOCH. Inside the code, particles are represented by a Fortran90 TYPE called particle. The current definition of this type (in 1D) is:\nTYPE particle REAL(num), DIMENSION(3) :: part_p REAL(num) :: part_pos #if !defined(PER_SPECIES_WEIGHT) || defined(PHOTONS) REAL(num) :: weight #endif #ifdef DELTAF_METHOD REAL(num) :: pvol #endif #ifdef PER_PARTICLE_CHARGE_MASS REAL(num) :: charge REAL(num) :: mass #endif TYPE(particle), POINTER :: next, prev #ifdef PARTICLE_DEBUG INTEGER :: processor INTEGER :: processor_at_t0 #endif #ifdef PARTICLE_ID4 INTEGER :: id #elif PARTICLE_ID INTEGER(i8) :: id #endif #ifdef COLLISIONS_TEST INTEGER :: coll_count #endif #ifdef WORK_DONE_INTEGRATED REAL(num) :: work_x REAL(num) :: work_y REAL(num) :: work_z REAL(num) :: work_x_total REAL(num) :: work_y_total REAL(num) :: work_z_total #endif #ifdef PHOTONS REAL(num) :: optical_depth REAL(num) :: particle_energy #ifdef TRIDENT_PHOTONS REAL(num) :: optical_depth_tri #endif #endif END TYPE particle  Here, most of the preprocessing directives have been stripped out for clarity. We have left #ifdef PARTICLE_DEBUG as an example. Here, the \u0026ldquo;processor\u0026rdquo; and \u0026ldquo;processor_at_t0\u0026rdquo; variables only exist if the -DPARTICLE_DEBUG define was put in the makefile. If you want to access a property that does not seem to be present, check the preprocessor defines.\nThe \u0026ldquo;particle\u0026rdquo; properties can be explained as follows:\n part_p - The momentum in 3 dimensions for the particle. This is always of size 3. part_pos - The position of the particle in space. This is of the same size as the dimensionality of the code. weight - The weight of this particle. The number of real particles represented by this pseudoparticle. charge - The particle charge. If the code was compiled without per particle charge, then the code uses the charge property from TYPE(particle_species). mass - The particle rest mass. If the code was compiled without per particle mass, then the code uses the mass property from TYPE(particle_species). next, prev - The next and previous particle in the linked list which represents the particles in the current species. This will be explained in more detail later. processor - The rank of the processor which currently holds the particle. processor_at_t0 - The rank of the processor on which the particle started. id - Unique particle ID. coll_count - Used for debugging the collision routines. optical_depth - Optical depth used in the QED routines. particle_energy - Particle energy used in the QED routines. optical_depth_tri - Optical depth for the trident process in the QED routines.  Collections of particles are represented by another Fortran TYPE, called particle_list. This type represents all the properties of a collection of particles and is used behind the scenes to deal with inter-processor communication of particles. The definition of the type is:\nTYPE particle_list TYPE(particle), POINTER :: head TYPE(particle), POINTER :: tail INTEGER(i8) :: count INTEGER :: id_update ! Pointer is safe if the particles in it are all unambiguously linked LOGICAL :: safe ! Does this partlist hold copies of particles rather than originals LOGICAL :: holds_copies TYPE(particle_list), POINTER :: next, prev END TYPE particle_list   head - The first particle in the linked list. tail - The last particle in the linked list. count - The number of particles in the list. Note that this is NOT MPI aware, so reading count only gives you the number of particles on the local processor. safe - Any particle_list which a user should come across will be a safe particle_list. Don\u0026rsquo;t change this property. next, prev - For future expansion it is possible to attach particle_lists together in another linked list. This is not currently used anywhere in the code.  An entire species of particles is represented by another Fortran TYPE, this time called particle_species. This represents all the properties which are common to all particles in a species. The current definition is:\nTYPE particle_species ! Core properties CHARACTER(string_length) :: name TYPE(particle_species), POINTER :: next, prev INTEGER :: id INTEGER :: dumpmask INTEGER :: count_update_step REAL(num) :: charge REAL(num) :: mass REAL(num) :: weight INTEGER(i8) :: count TYPE(particle_list) :: attached_list LOGICAL :: immobile LOGICAL :: fill_ghosts ! Parameters for relativistic and arbitrary particle loader INTEGER :: ic_df_type REAL(num) :: fractional_tail_cutoff TYPE(primitive_stack) :: dist_fn TYPE(primitive_stack) :: dist_fn_range(3) #ifndef NO_TRACER_PARTICLES LOGICAL :: zero_current #endif ! ID code which identifies if a species is of a special type INTEGER :: species_type ! particle cell division INTEGER(i8) :: global_count LOGICAL :: split INTEGER(i8) :: npart_max ! Secondary list TYPE(particle_list), DIMENSION(:), POINTER :: secondary_list ! Injection of particles REAL(num) :: npart_per_cell TYPE(primitive_stack) :: density_function, temperature_function(3) TYPE(primitive_stack) :: drift_function(3) ! Thermal boundaries REAL(num), DIMENSION(:), POINTER :: ext_temp_x_min, ext_temp_x_max ! Species_ionisation LOGICAL :: electron LOGICAL :: ionise INTEGER :: ionise_to_species INTEGER :: release_species INTEGER :: n INTEGER :: l REAL(num) :: ionisation_energy ! Attached probes for this species #ifndef NO_PARTICLE_PROBES TYPE(particle_probe), POINTER :: attached_probes #endif ! Particle migration TYPE(particle_species_migration) :: migrate ! Initial conditions TYPE(initial_condition_block) :: initial_conditions ! Per-species boundary conditions INTEGER, DIMENSION(2*c_ndims) :: bc_particle END TYPE particle_species  This definition is for the 1D version of the code. The only difference for the other two versions is the number of dimensions in the arrays \u0026ldquo;secondary_list\u0026rdquo; and \u0026ldquo;ext_temp_*\u0026rdquo;. There are quite a lot of fields here, so we will just document some of the most important ones.\n name - The name of the particle species, used in the output dumps etc. next, prev - Particle species are also linked together in a linked list. This is used internally by the output dump routines, but should not be used by end users. id - The species number for this species. This is the same number as is used in the input deck to designate the species. dumpmask - Determine when to include this species in output dumps. Note that the flag is ignored for restart dumps. charge - The charge in Coulombs. Even if PER_PARTICLE_CHARGE_MASS is specified, this is still populated from the input deck, and now refers to the reference charge for the species. mass - The mass in kg. weight - The per-species particle weight. count - The global number of particles of this species (NOTE may not be accurate). This will only ever be the number of particles on this processor when running on a single processor. While this property will be accurate when setting up initial conditions, it is only guaranteed to be accurate for the rest of the code if the code is compiled with the correct preprocessor options. attached_list - The list of particles which belong to this species. immobile - If set to .TRUE. then the species is ignored during the particle push. zero_current - If set to .TRUE. then the current is not updated for this particle species.  Setting the particle properties The details of exactly what a linked list means in EPOCH requires a more in-depth study of the source code. For now, all we really need to know is that each species has a list of particles. A pointer to the first particle in the list is contained in species_list(ispecies)%attached_list%head. Once you have a pointer to a particle (eg. current), you advance to the next pointer in the list with current =\u0026gt; current%next. After all the descriptions of the types, actually setting the properties of the particles is fairly simple. The following is an example which positions the particles uniformly in 1D space, but doesn\u0026rsquo;t set any momentum.\nSUBROUTINE manual_load TYPE(particle), POINTER :: current INTEGER :: ispecies REAL(num) :: rpos, dx DO ispecies = 1, n_species current =\u0026gt; species_list(ispecies)%attached_list%head dx = length_x / species_list(ispecies)%attached_list%count rpos = x_min DO WHILE(ASSOCIATED(current)) current%part_pos = rpos current%weight = 1.0_num rpos = rpos + dx current =\u0026gt; current%next ENDDO ENDDO END SUBROUTINE manual_load  This will take the particles which have been placed at random positions by the autoloader and repositions them in a uniform manner. In order to adjust the particle positions, you need to know about the grid used in EPOCH. In this example we only required the length of the domain, \u0026ldquo;length_x\u0026rdquo; and the minimum value of x, \u0026ldquo;x_min\u0026rdquo;. A more exhaustive list is given in the following section. Note that I completely ignored the question of domain decomposition when setting up the particles. The code automatically moves the particles onto the correct processor without user interaction.\nIn the above example, note that particle momentum was not specified and particle weight was set to be a simple constant. Setting particle weight can be very simple if you can get the pseudoparticle distribution to match the real particle distribution, or quite tricky if this isn\u0026rsquo;t possible. The weight of a pseudoparticle is calculated such that the number of pseudoparticles in a cell multiplied by their weights equals the number of physical particles in that cell. This can be quite tricky to get right, so in more complicated cases it is probably better to use the autoloader than to manually set up the number density distribution.\nGrid coordinates used in EPOCH. When setting up initial conditions within the EPOCH source (rather than using the input deck) there are several constants that you may need to use. These constants are:\n nx - Number of gridpoints on the local processor in the x direction. ny - Number of gridpoints on the local processor in the y direction (2D and 3D). nz - Number of gridpoints on the local processor in the z direction (3D). length_{x,y,z} - Length of domain in the x, y, z directions. {x,y,z}_min - Minimum value of x, y, z for the whole domain. {x,y,z}_max - Maximum value of x, y, z for the whole domain. n_species - The number of species in the code.  There are also up to three arrays which are available for use.\n x(-2:nx+3) - Position of a given gridpoint in real units in the x direction. y(-2:ny+3) - Position of a given gridpoint in real units in the y direction (2D and 3D). z(-2:nz+3) - Position of a given gridpoint in read units in the z direction (3D).  Loading a separable non-thermal particle distribution. While the autoloader is capable of dealing with most required initial thermal distributions, you may want to set up non-thermal initial conditions. The code includes a helper function to select a point from an arbitrary distribution function which can be used to deal with most non-thermal distributions. To use the helper function, you need to define two 1D arrays which are the x and y axes for the distribution function. This approach is only possible if the distribution function can be represented as a set of 1D distribution functions in px, py and pz separately. If this is possible then this method is preferred since it is significantly faster than the arbitrary method detailed in the next section. An example of using the helper function is given below.\nSUBROUTINE manual_load TYPE(particle), POINTER :: current INTEGER, PARAMETER :: np_local = 1000 INTEGER :: ispecies, ip REAL(num) :: temperature, stdev2, tail_width, tail_height, tail_drift REAL(num) :: frac, tail_frac, min_p, max_p, dp_local, p2, tail_p2 REAL(num), DIMENSION(np_local) :: p_axis, distfn_axis temperature = 1e4_num tail_width = 0.05_num tail_height = 0.2_num tail_drift = 0.5_num DO ispecies = 1, n_species stdev2 = kb * temperature * species_list(ispecies)%mass frac = 1.0_num / (2.0_num * stdev2) tail_frac = 1.0_num / (2.0_num * stdev2 * tail_width) max_p = 5.0_num * SQRT(stdev2) min_p = -max_p dp_local = (max_p - min_p) / REAL(np_local-1, num) DO ip = 1, np_local p_axis(ip) = min_p + (ip - 1) * dp_local p2 = p_axis(ip)**2 tail_p2 = (p_axis(ip) - tail_drift * max_p)**2 distfn_axis(ip) = EXP(-p2 * frac) \u0026amp;amp; + tail_height * EXP(-tail_p2 * tail_frac) ENDDO current=\u0026gt;species_list(ispecies)%attached_list%head DO WHILE(ASSOCIATED(current)) current%part_p(1) = sample_dist_function(p_axis, distfn_axis) current=\u0026gt;current%next ENDDO ENDDO END SUBROUTINE manual_load  This example will set the particles to have a bump-on-tail velocity distribution, a setup which is not possible to do using only the input deck. It is not necessary to normalise the distribution function, as this is done automatically by the *sample_dist_function* function.\nLasers EPOCH has the ability to add EM wave sources such as lasers at boundaries. To use lasers, set the boundary that you wish to have a laser on to be of type simple_laser and then specify one or more lasers attached to that boundary. Lasers may be specified anywhere initial conditions are specified.\nLaser blocks in multiple dimensions. When running EPOCH in 2D or 3D, the laser can be modified spatially via the profile and phase parameters. These are briefly outlined here but in this section we will describe them in a little more depth.\n  profile - The spatial profile for the laser. This is essentially an array defined along the edge (or surface) that the laser is attached to. It is clear that the spatial profile is only meaningful perpendicular to the laser\u0026rsquo;s direction of travel and so it is just a single constant in 1D. The laser profile is evaluated as an initial condition and so cannot include any temporal information which must be encoded in t_profile. The spatial profile is evaluated at the boundary where the laser is attached and so only spatial information in the plane of the boundary is significant. This is most clearly explained through a couple of examples. In these examples the spatial profile of the laser is set to vary between a flat uniform profile (profile = 1) and a Gaussian profile in y (profile = gauss(y,0,2.5e-6)). The difference between these profiles is obvious but the important point is that a laser travelling parallel to the x-direction has a profile in the y direction. Similarly a laser propagating in the y-direction has a profile in the x direction. In 3D this is extended so that a laser propagating in a specified direction has a profile in both orthogonal directions. So a laser travelling parallel to the x axis in 3D would have a profile in y and z. Since 3D lasers are very similar to 2D lasers, they will not be considered here in greater detail, but in 3D, it is possible to freely specify the laser profile across the entire face where a laser is attached.   phase - Phase shift for the laser in radians. This is a spatial variable which is also defined across the whole of the boundary on which the laser is attached. This allows a user to add a laser travelling at an angle to a boundary as shown in Figure[angle]. The setup for this is not entirely straightforward and requires a little bit of explanation. Figure[wave] illustrates a laser being driven at an angle on the x_min boundary. Different wave fronts cross the $y$-axis at different places and this forms a sinusoidal profile along $y$ that represents the phase. The wavelength of this profile is given by $\\lambda_\\phi = \\lambda / \\sin\\theta$, where $\\lambda$ is the wavelength of the laser and $\\theta$ is the angle of the propagation direction with respect to the $x$-axis. The actual phase to use will be $\\phi(y) = -k_\\phi y = -2\\pi y / \\lambda_\\phi$. It is negative because the phase of the wave is propagating in the positive $y$ direction. It is also necessary to alter the wavelength of the driver since this is given in the direction perpendicular to the boundary. The new wavelength to use will be $\\lambda\\cos\\theta$. Figure[angle] shows the resulting $E_y$ field for a laser driven at an angle of $\\pi / 8$. Note that since the boundary conditions in the code are derived for propagation perpendicular to the boundary, there will be artefacts on the scale of the grid for lasers driven at an angle.\n  Using this technique it is also possible to focus a laser. This is done by using the same technique as above but making the angle of propagation, $\\theta$, a function of $y$ such that the laser is focused to a point along the $x$-axis. A simple example is given here.\nRestarting EPOCH from previous output dumps Another possible way of setting up initial conditions in EPOCH is to load in a previous output dump and use it to specify initial conditions for the code. The effect of this is to restart the code from the state that it was in when the dump was made. To do this, you just set the field \u0026ldquo;restart_snapshot\u0026rdquo; in the control block to the number of the output dump from which you want the code to restart. Because of the way in which the code is written you cannot guarantee that the code will successfully restart from any output dump. To restart properly, the following must have been dumped\n Particle positions. Particle momenta. Particle species. Particle weights. Relevant parts of the electric field (If for example it is known that ez == 0 then it is not needed). Relevant parts of the magnetic field.  It is possible to use the manual particle control part of the initial conditions to make changes to a restarted initial condition after the restart dump is loaded. The output files don\u0026rsquo;t include all of the information needed to restart the code fully since some of this information is contained in the input deck. However, a restart dump also contains a full copy of the input deck used and this can be unpacked before running the code. If specific \u0026ldquo;restart\u0026rdquo; dumps are specified in the input deck, or the \u0026ldquo;force_final_to_be_restartable\u0026rdquo; flag is set then in some cases the output is forced to contain enough information to output all the data. These restart dumps can be very large, and also override the \u0026ldquo;dumpmask\u0026rdquo; parameter specified for a species and output the data for that species anyway.\nParameterising input decks The simplest way to allow someone to use EPOCH as a black box is to give them the input.deck files that control the setup and initial conditions of the code. The input deck is simple enough that a quick read through of the relevant section of the manual should make it fairly easy for a new user to control those features of the code, but the initial conditions can be complex enough to be require significant work on the part of an unfamiliar user to understand. In this case, it can be helpful to use the ability to specify constants in an input deck to parameterise the file. So, to go back to a slight variation on an earlier example:\nbegin:species name = s1 # First set number_density in the range 0-\u0026amp;gt;1 # Cut down number_density in x direction number_density = if ((x gt -1) and (x lt 1), 1.0, 0.2) # Cut down number_density in y direction number_density = if ((y gt -1) and (y lt 1), number_density(s1), 0.2) # Multiply number_density by real particle number density number_density = number_density(s1) * 100.0 # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species begin:species name = s2 # Just copy the number_density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species  The particle number density (100.0) is hard coded into the deck file in several places. It would be easier if this was given to a new user as:\nbegin:constant particle_number_density = 100.0 # Particle number density end:constant begin:species name = s1 # First set number_density in the range 0-\u0026amp;gt;1 # Cut down number_density in x direction number_density = if ((x gt -1) and (x lt 1), 1.0, 0.2) # Cut down number_density in y direction number_density = if ((y gt -1) and (y lt 1), number_density(s1), 0.2) # Multiply number_density by real particle number density number_density = number_density(s1) * particle_number_density # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species begin:species name = s2 # Just copy the number density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species  It is also possible to parameterise other elements of initial conditions in a similar fashion. This is generally a good idea, since it makes the initial conditions easier to read an maintain.\nUsing spatially varying functions to further parameterise initial conditions Again, this is just a readability change to the normal input.deck file, but it also makes changing and understanding the initial conditions rather simpler. In this case, entire parts of the initial conditions are moved into a spatially varying constant in order to make changing them at a later date easier. For example:\nbegin:constant particle_number_density = 100.0 # Particle number density profile_x = if((x gt -1) and (x lt 1), 1.0, 0.2) profile_y = if((y gt -1) and (y lt 1), 1.0, 0.2) end:constant begin:species name = s1 # Multiply number_density by real particle number density number_density = particle_number_density * profile_x * profile_y # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species begin:species name = s2 # Just copy the number_density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species  This creates the same output as before. It is now trivial to modify the profiles later. For example:\nbegin:constant particle_number_density = 100.0 # Particle number density profile_x = gauss(x, 0.0, 1.0) profile_y = gauss(y, 0.0, 1.0) end:constant begin:species name = s1 # Multiply number_density by real particle number density number_density = particle_number_density * profile_x * profile_y # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species begin:species name = s2 # Just copy the number density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species  This changes the code to run with a Gaussian density profile rather then a step function. Again, this can be extended as far as required.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"6e24cc5c6c9e75395221d4d9df35cc7d","permalink":"/documentation/code_details/using_epoch_in_practice.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/using_epoch_in_practice.html","section":"documentation","summary":"Specifying initial conditions for particles using the input deck If the initial conditions for the plasma you wish to model can be described by a number density and temperature profile on the underlying grid then EPOCH can create an appropriate particle distribution for you.","tags":null,"title":"Using EPOCH in practice","type":"docs"},{"authors":null,"categories":null,"content":"To help reduce the impact of numerical noise in certain simulations, the delta-f method may be used in for specified particle species. The delta-f method effectively subtracts a background distribution $f_0$ when calculating currents due to the motion of markers; when the particle distribution function $f$ is close to $f_0$, this substantially reduces the statistical noise in the currents. Only current deposition is implemented differently, and the equations of motion of the markers are not modified in this delta-f approach.\nThe component of the currents associated with the background $f_0$ may be in principle be calculated analytically, but the delta-f implementation in EPOCH assumes (but does not check) that the total background current is zero.\nIn order to use the delta-f method EPOCH must be compiled with the #DELTAF_METHOD precompiler flag enabled. Standard input simulations are not affected by switching on this flag, but the user may then choose to treat certain species in the plasma using the delta-f method. To enable delta-f calculation for a species the background distribution function $f_0$ must be defined in the input block. $f_0$ is specified using variables similar to those used to specify $f$. The current implementation of delta-f allows only a spatially uniform drifting Maxwellian $f_0$, with temperatures $T_x$, $T_y$ and $T_z$ allowed to differ from each other. In 3D, for the case where the temperature in each direction is equal, we have $f_0 = n_0 (2 \\pi T)^{-3/2} \\exp\\left(\\frac{m (\\mathbf{v} - \\mathbf{v_d})^2}{2 k_B T } \\right).$\nThe parameters number_density_back, temp(x,y,z)_back and drift(x,y,z)_back in each species specification in the input deck set $f_0$. number_density_back=0 is the default and is equivalent to not using the delta-f method.\nFor example, the electron species component of an input deck solved using delta-f might be written:\nbegin:species name = electron charge = -1.0 mass = 1.0 frac = 0.3 temp = 1e8 temp_back = 1e8 number_density = 1e20 number_density_back = 1e20 end:species  Additional distribution function diagnostic options are supplied for the Delta-f version. Standard diagnostics work as usual based on the total distribution function $f$ but is is also possible to output the Delta-f component of the distribution functions by adding output_deltaf = T in dist_fn components of the input deck.\nAn example input deck is supplied in the 1D version as twostream_deltaf.deck. This uses the delta-f method to solve the weak-beam two stream instability. The bulk plasma species is solved using the delta-f method, since this evolve very little, and mostly supports the Lagnmuir waves that the weak beam interacts with. The relative change to the beam species is large, and the standard PIC method, rather than delta-f is used to model this species. A comparison of the electric field diagnostics between standard and delta-f simulations shows a substantial decrease in noise.\nFurther details of the method are provided in this pdf.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"db2bac938028317d0a415614391ad965","permalink":"/documentation/code_details/using_delta_f.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/using_delta_f.html","section":"documentation","summary":"To help reduce the impact of numerical noise in certain simulations, the delta-f method may be used in for specified particle species. The delta-f method effectively subtracts a background distribution $f_0$ when calculating currents due to the motion of markers; when the particle distribution function $f$ is close to $f_0$, this substantially reduces the statistical noise in the currents.","tags":null,"title":"Using delta f","type":"docs"},{"authors":null,"categories":null,"content":"Changes between version 3.1 and 4.0 Changes to the Makefile Some changes have been made to the Makefile. These are documented here. The following compile-time defines have been added to the Makefile:\n NO_IO PARTICLE_ID PARTICLE_ID4 COLLISIONS_TEST PHOTONS TRIDENT_PHOTONS PREFETCH  The following compile-time defines have been removed from the Makefile:\n COLLISIONS SPLIT_PARTICLES_AFTER_PUSH PARTICLE_IONISE  Major features and new blocks added to the input deck   CPML boundary conditions  Thermal boundary conditions  Collisions  QED  Subsets  Ionisation  Single-precision output  Multiple output blocks  Particle migration  Additional output block parameters The following parameters have also been added to the \u0026ldquo;output\u0026rdquo; block (see here):\n dump_first dump_last force_first_to_be_restartable ejected_particles absorption id name restartable  Other additions to the input deck   npart_per_cell  dir_{xy,yz,zx}_angle  particle_tstart  identify  Finally, the input deck now has a method for writing continuation lines. If the deck contains a \u0026ldquo;\u0026quot; character then the rest of the line is ignored and the next line becomes a continuation of the current one.\nChanges between version 4.0 and 4.3 Changes to the Makefile Some changes have been made to the Makefile. These are documented here . The following compile-time define has been added to the Makefile:\n MPI_DEBUG  The following compile-time define has been removed from the Makefile:\n FIELD_DEBUG  Additions to the input deck The following parameters have been added to the \u0026ldquo;control\u0026rdquo; block of the input deck:\n nproc{x,y,z} smooth_currents field_ionisation use_exact_restart allow_cpu_reduce check_stop_file_frequency stop_at_walltime stop_at_walltime_file simplify_deck print_constants The \u0026ldquo;restart_snapshot\u0026rdquo; parameter now accepts filenames  The following parameters have been added to the \u0026ldquo;output\u0026rdquo; block of the input deck:\n disabled time_start time_stop nstep_start nstep_stop dump_at_times dump_at_nsteps dump_cycle dump_cycle_first_index filesystem file_prefix rolling_restart particle_energy relativistic_mass gamma total_energy_sum optical_depth qed_energy trident_optical_depth The default value of \u0026ldquo;dump_first\u0026rdquo; is now \u0026ldquo;T\u0026rdquo;  The following parameter has been added to the \u0026ldquo;collisions\u0026rdquo; block of the input deck:\n collisional_ionisation  The following parameter has been added to the \u0026ldquo;qed\u0026rdquo; block of the input deck:\n use_radiation_reaction  The following parameter has been added to the \u0026ldquo;species\u0026rdquo; block of the input deck:\n immobile  The following parameters were changed in the \u0026ldquo;laser\u0026rdquo; block of the input deck:\n The \u0026ldquo;phase\u0026rdquo; parameter can now be time varying The \u0026ldquo;profile\u0026rdquo; parameter can now be time varying  The following parameters have been added to the list of pre-defined constants.\n nproc_{x,y,z} nsteps t_end cc  There has also been a new \u0026ldquo;output_global\u0026rdquo; block added to the input deck.\nChanges in behaviour which are not due to changes in the input deck  The species \u0026ldquo;drift\u0026rdquo; property is now applied to particles whilst the moving window model is active. In previous versions of the code, this property was ignored once the moving window began. Ionisation species now inherit their \u0026ldquo;dumpmask\u0026rdquo;. See here for details. Default values for ignorable directions were added. This change allows submitting 3D or 2D input decks to a 1D version of and 3D input decks to a 2D version of . Any references to y/z will be set equal to zero unless overridden by a deck constant. Other y/z values also assume sensible defaults, eg. 1 grid cell, 1 metre thick, etc. Automatic byte swapping is carried out by the SDF library. The library now checks the endianness of the SDF file and byte-swaps the data if required. \u0026ldquo;qed\u0026rdquo; blocks may now be present even if the code was not compiled using the \u0026ldquo;-DPHOTONS\u0026rdquo; flag. The code will only halt if \u0026ldquo;use_qed=T\u0026rdquo; inside the \u0026ldquo;qed\u0026rdquo; block. The code now checks for the Data directory in a file named \u0026ldquo;USE_DATA_DIRECTORY\u0026rdquo; before prompting at the command-line. This allows the code to be run without waiting for input at the command-line. The field and particle grids are now automatically written to SDF output files if they are needed. The Data directory may now contain a \u0026lsquo;/\u0026rsquo; character.  Changes between version 4.3 and 4.8 Changes to the Makefile Some changes have been made to the Makefile. These are documented here. The following compile-time define has been added to the Makefile:\n PER_SPECIES_WEIGHT NO_TRACER_PARTICLES NO_PARTICLE_PROBES PARSER_CHECKING  The following compile-time define has been removed from the Makefile:\n PER_PARTICLE_WEIGHT TRACER_PARTICLES PARTICLE_PROBES  Additions to the input deck The following parameters have been added to the \u0026ldquo;control\u0026rdquo; block of the input deck:\n allow_missing_restart print_eta_string n_zeros  The following parameters have been added to the \u0026ldquo;output\u0026rdquo; block of the input deck):\n weight (synonym for particle_weight)  The following parameters have been added to the \u0026ldquo;output_global\u0026rdquo; block of the input deck:\n dump_first_after_restart  The following parameters have been added to the \u0026ldquo;subset\u0026rdquo; block of the input deck:\n skip, skip_x,y,z  Changes between version 4.8 and 4.9 New capabilities Version 4.9 adds significant new capabilities as follows:\n delta-f version: particle distributions can be expressed as $f_0 + f_1$ where $f_0$ is a specified background plasma and all simulation particles are used to describe the $f_1$ component, documented in . selectable field solvers: 3 new solvers have been added for fields, fully documented in .  Changes to the Makefile Some changes have been made to the Makefile. These are documented in . The following compile-time define has been added to the Makefile:\n DELTAF_METHOD DELTAF_DEBUG USE_ISATTY  Additions to the input deck The following alterations were made to the input deck:\n ioniz* (with a \u0026ldquo;z\u0026rdquo;) aliases have been added for ionis* keywords. y and z parameters can now appear in the input deck in EPOCH 1D and 2D.  A new deck block has been added. The particles_from_file block allows loading of custom particle data from raw binary data files. See for details. This block accepts the following parameters:\n species {xyz}_data w_data {xyz}_data id{4,8}_data offset  The following parameters have been added to the \u0026ldquo;control\u0026rdquo; block of the input deck (see ):\n maxwell_solver use_current_correction  The following parameters have been added to the \u0026ldquo;species\u0026rdquo; block of the input deck (see ):\n maxwell_solver number_density_back drift_{x,y,z}_back temp_{x,y,z}_back temp_{x,y,z}_back_ev temp_back temp_back_ev  The following parameters have been added to the \u0026ldquo;dist_fn' block of the input deck (see ):\n dir may now take the value mod_p restrict_mod_p  Changes not resulting from changes to the deck  Lasers can be specified with time-varying frequency profile. The existing subset blocks can now be applied to field and derived grid variables. If spatial restrictions are used, subsections will be output, along with a corresponding grid. Note that these are not compatible with the \u0026ldquo;skip\u0026rdquo; parameter to subset blocks. The dist_fn block \u0026ldquo;range\u0026rdquo; keyword is now respected for spatial directions, allowing a spatial subset of the distribution function to be output directly. Some corrections were applied to calculation of thermal boundary conditions for particles. The load balancer may now be disabled by setting a 0 or negative threshold.  Changes between version 4.9 and 4.10 New capabilities Version 4.10 adds the following new capabilities:\n Time varying particle injectors. See here Per-species particle boundaries. You can now specify bc_x_min and bc_x_max to a species block. This overrides the global boundaries for that species. See here Added \u0026ldquo;particles_per_cell\u0026rdquo; output diagnostic. See here  Changes between version 4.10 and 4.11 New capabilities Version 4.11 adds the following new capabilities:\n Added time dependent moving window. No new input deck parameters have been added, but it is now possible to specify \u0026ldquo;window_v_x\u0026rdquo; to be a function that varies in time. See here If \u0026ldquo;print_constants=T\u0026rdquo; in the control block (see here) deck constants are now output to a separate file named \u0026ldquo;const.status\u0026rdquo;. This allows for easier post-processing. Added COMPILER=auto option to automatically detect compiler. See here  The following correction has been made:\n Fractional numbers of particles-per-cell now function as expected when used in conjunction with the moving window.  Changes between version 4.11 and 4.12 New capabilities Version 4.12 adds the following new capabilities:\n Added \u0026ldquo;average_weight\u0026rdquo; output diagnostic. See here Removed the \u0026ldquo;PARTICLE_COUNT_UPDATE\u0026rdquo; Makefile flag and replaced it with a \u0026ldquo;use_particle_count_update\u0026rdquo; parameter in the control block. See here Added \u0026ldquo;use_flux_maxwellian\u0026rdquo; option to the \u0026ldquo;injector\u0026rdquo; block. See here Added \u0026ldquo;lehe_{x,y,z}\u0026rdquo; flags to the \u0026ldquo;maxwell_solver\u0026rdquo; option in the control block. See here Added \u0026ldquo;use_accurate_n_zeros\u0026rdquo; control block parameter. See here Added \u0026ldquo;custom\u0026rdquo; flag to the \u0026ldquo;maxwell_solver\u0026rdquo; option in the control block. See here and here Added the \u0026ldquo;WORK_DONE_INTEGRATED\u0026rdquo; Makefile flag and corresponding dumpmask directives \u0026ldquo;work_{x,y,z}\u0026rdquo; and \u0026ldquo;work_{x,y,z}_total\u0026rdquo;. These add a diagnostic for the work done on a particle by the electric field. See here and here.  Changes between version 4.12 and 4.14 New capabilities Version 4.14 adds the following new capabilities:\n Added the \u0026ldquo;reset_walltime\u0026rdquo; flag to the control block. See here Changed the default value of \u0026ldquo;print_eta_string\u0026rdquo; to \u0026ldquo;T\u0026rdquo; in the control block. Added the ability to request an output dump at run time. See here Added the \u0026ldquo;window_stop_time\u0026rdquo; parameter to the window block. See here Added the \u0026ldquo;atan2\u0026rdquo; function to the maths parser. See here Added \u0026ldquo;dlb_maximum_interval\u0026rdquo; parameter to the control block. See here Added \u0026ldquo;dlb_force_interval\u0026rdquo; parameter to the control block. See here Added \u0026ldquo;balance_first\u0026rdquo; parameter to the control block. See here Added y and z versions of the \u0026ldquo;bc_x_min_after_move\u0026rdquo; and \u0026ldquo;bc_x_max_after_move\u0026rdquo; parameters to the window block. See here Added a \u0026ldquo;dump_at_walltimes\u0026rdquo; parameter to the output block. See here Added \u0026ldquo;walltime_start\u0026rdquo; and \u0026ldquo;walltime_stop\u0026rdquo; parameters to the output block and output_global block. See here and here Added \u0026ldquo;walltime_interval\u0026rdquo; parameter to the output block. See here Added the Higuera-Cary particle push. This can be enabled using the \u0026ldquo;HC_PUSH\u0026rdquo; Makefile flag. See here.  Changes between version 4.14 and 4.15  Added averaging of \u0026ldquo;poynt_flux\u0026rdquo; and \u0026ldquo;ekflux\u0026rdquo; variables. The initial problem setup can now be load-balanced before any particles are loaded. This enables some heavily imbalanced setups to be run that were not previously possible.  Added the \u0026ldquo;use_pre_balance\u0026rdquo; flag to the control block. See here   Allow the load balancer to adjust the processor topology  Added the \u0026ldquo;use_optimal_layout\u0026rdquo; flag to the control block. See here   Added control block option \u0026ldquo;use_more_setup_memory\u0026rdquo; for controlling the way that species are setup. See here Added strided multipass digital current filtering (See here). This adds the following flags to the control block.  smooth_iterations smooth_compensation smooth_strides   Added persistent subsets. See here. This adds the following flags to the subset block  persist_start_time persist_start_step   Added loading of relativistic particle species using the Maxwell-Jttner distribution. See here. This adds the following flags to the species block  use_maxwell_juttner fractional_tail_cutoff   Added loading of particle species using an arbitrary distribution function for sampling the momentum components. See here. This adds the following flags to the species block  dist_fn dist_fn_p{x,y,z}_range   Added \u0026ldquo;temperature_{x,y,z}\u0026rdquo; derived output variables to the output block. See here  Changes between version 4.15 and 4.16    Added \u0026ldquo;number_density\u0026rdquo; aliases for \u0026ldquo;density\u0026rdquo; in the species and injector blocks (see here and  here).  These aliases include:\n   number_density for density promote_number_density for promote_density demote_number_density for demote_density number_density_min for density_min number_density_max for density_max number_density_back for density_back    Replaced \u0026ldquo;USE_ISATTY\u0026rdquo; Makefile flag with \u0026ldquo;NO_USE_ISATTY\u0026rdquo;. See here.\n  Added \u0026ldquo;NO_MPI3\u0026rdquo; Makefile flag. See here.\n  Added a \u0026ldquo;zero_current\u0026rdquo; alias for \u0026ldquo;tracer\u0026rdquo; in the species blocks. See here. The use of \u0026ldquo;tracer\u0026rdquo; has now been deprecated and will be removed in version 5.0. At that time, the compiler flag will also be renamed.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"7a4fff90d083d4c470fb9cfca820451a","permalink":"/documentation/code_details/previous_versions.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/previous_versions.html","section":"documentation","summary":"Changes between version 3.1 and 4.0 Changes to the Makefile Some changes have been made to the Makefile. These are documented here. The following compile-time defines have been added to the Makefile:","tags":null,"title":"Previous versions","type":"docs"},{"authors":null,"categories":null,"content":"Using IDL to visualise data The EPOCH distribution comes with procedures for loading and inspecting SDF self-describing data files. The IDL routines are held in the SDF/IDL/ directory. There is also a procedure named Start.pro in each of the epoch\\*d/ directories which is used to set up the IDL environment.\nTo load data into IDL, navigate to one of the base directories (eg. epoch/epoch2d/ where epoch/ is the directory in which you have checked out the git repository) and type the following:\n$\u0026amp;gt; idl Start.pro IDL Version 8.1 (linux x86_64 m64). (c) 2011, ITT Visual Information Solutions Installation number: . +Licensed for use by: STAR404570-5University of Warwick . % Compiled module: TRACKEX_EVENT. % Compiled module: ISOPLOT. % Compiled module: READVAR. % Compiled module: LOADSDFFILE. % Compiled module: SDFHANDLEBLOCK. % Compiled module: SDFGETPLAINMESH. % Compiled module: SDFGETLAGRANMESH. % Compiled module: SDFGETPOINTMESH. % Compiled module: SDFGETPLAINVAR. % Compiled module: SDFGETPOINTVAR. % Compiled module: SDFGETCONSTANT. % Compiled module: SDFCHECKNAME. % Compiled module: INIT_SDFHELP. % Compiled module: GETDATA. % Compiled module: GETSTRUCT. % Compiled module: EXPLORE_DATA. % Compiled module: EXPLORE_STRUCT. % Compiled module: LIST_VARIABLES. % Compiled module: QUICK_VIEW. % Compiled module: GET_WKDIR. % Compiled module: SET_WKDIR. % Compiled module: INIT_STARTPIC. % Compiled module: INIT_WIDGET. % Compiled module: GENERATE_FILENAME. % Compiled module: COUNT_FILES. % Compiled module: LOAD_RAW. % Compiled module: GET_SDF_METATEXT. % Compiled module: VIEWER_EVENT_HANDLER. % Compiled module: EXPLORER_EVENT_HANDLER. % Compiled module: XLOADCT_CALLBACK. % Compiled module: LOAD_DATA. % Compiled module: DRAW_IMAGE. % Compiled module: LOAD_META_AND_POPULATE_SDF. % Compiled module: CLEAR_DRAW_SURFACE. % Compiled module: SDF_EXPLORER. % Compiled module: EXPLORER_LOAD_NEW_FILE. % Compiled module: CREATE_SDF_VISUALIZER. % Compiled module: VIEWER_LOAD_NEW_FILE. % LOADCT: Loading table RED TEMPERATURE IDL\u0026amp;gt;  This starts up the IDL interpreter and loads in all of the libraries for loading and inspecting SDF files.\nWe begin by inspecting SDF file contents and finding out what variables it contains. To do this we execute the list variables procedure call which is provided by the EPOCH IDL library.\nAt each timestep for which EPOCH is instructed to dump a set of variables a new data file is created. These files take the form 0000.sdf. For each new dump the number is incremented. The procedure call accepts up to two arguments. The first argument is mandatory and specifies the number of the SDF file to be read in. This argument can be any integer from 0 to 9999. It is padded with zeros and the suffix \u0026lsquo;.sdf\u0026rsquo; appended to the end to give the name of the data file. eg. 99  \u0026lsquo;0099.sdf\u0026rsquo;. The next arguments is optional. The keyword wkdir specifies the directory in which the data files are located. If this argument is omitted then the currently defined global default is used. Initially, this takes the value Data but this can be changed using the set_wkdir procedure and queried using the get_wkdir() function.\nIDL\u0026amp;gt; list_variables,0,\u0026amp;quot;Data\u0026amp;quot; Available elements are 1) EX (ELECTRIC_FIELD) : 2D Plain variable 2) EY (ELECTRIC_FIELD) : 2D Plain variable 3) EZ (ELECTRIC_FIELD) : 2D Plain variable 4) BX (MAGNETIC_FIELD) : 2D Plain variable 5) BY (MAGNETIC_FIELD) : 2D Plain variable 6) BZ (MAGNETIC_FIELD) : 2D Plain variable 7) JX (CURRENT) : 2D Plain variable 8) JY (CURRENT) : 2D Plain variable 9) JZ (CURRENT) : 2D Plain variable 10) WEIGHT_ELECTRON (PARTICLES) : 1D Point variable 11) WEIGHT_PROTON (PARTICLES) : 1D Point variable 12) PX_ELECTRON (PARTICLES) : 1D Point variable 13) PX_PROTON (PARTICLES) : 1D Point variable 14) GRID_ELECTRON (GRID) : 2D Point mesh 15) GRID_PROTON (GRID) : 2D Point mesh 16) EKBAR (DERIVED) : 2D Plain variable 17) EKBAR_ELECTRON (DERIVED) : 2D Plain variable 18) EKBAR_PROTON (DERIVED) : 2D Plain variable 19) CHARGE_DENSITY (DERIVED) : 2D Plain variable 20) NUMBER_DENSITY (DERIVED) : 2D Plain variable 21) NUMBER_DENSITY_ELECTRON (DERIVED) : 2D Plain variable 22) NUMBER_DENSITY_PROTON (DERIVED) : 2D Plain variable 23) GRID (GRID) : 2D Plain mesh 24) GRID_EN_ELECTRON (GRID) : 1D Plain mesh 25) EN_ELECTRON (DIST_FN) : 3D Plain variable 26) GRID_X_EN_ELECTRON (GRID) : 2D Plain mesh 27) X_EN_ELECTRON (DIST_FN) : 3D Plain variable 28) GRID_X_PX_ELECTRON (GRID) : 2D Plain mesh 29) X_PX_ELECTRON (DIST_FN) : 3D Plain variable IDL\u0026amp;gt;  Each variable in the SDF self-describing file format is assigned a name and a class as well as being defined by a given variable type. The \u0026ldquo;list_variables\u0026rdquo; procedure prints out the variable name followed by the variable\u0026rsquo;s class in parenthesis. Following the colon is a description of the variable type.\nTo retrieve the data, you must use the getdata() function call. The function must be passed a snapshot number, either as the first argument or as a keyword parameter \u0026ldquo;snapshot\u0026rdquo;. It also accepts the wkdir as either the second argument or the keyword parameter \u0026ldquo;wkdir\u0026rdquo;. If it is omitted altogether, the current global default is used. Finally, it accepts a list of variables or class of variables to load. Since it is a function, the result must be assigned to a variable. The object returned is an IDL data structure containing a list of named variables.\nTo load either a specific variable or a class of variables, specify the name prefixed by a forward slash. It should be noted here that the IDL scripting language is not case sensitive so $P_x$ can be specified as either \u0026ldquo;/Px\u0026rdquo; or \u0026ldquo;/px\u0026rdquo;.\nWe will now load and inspect the \u0026ldquo;Grid\u0026rdquo; class, this time omitting the optional \u0026ldquo;wkdir\u0026rdquo; parameter. This time we will load from the third dump file generated by the EPOCH run, which is found in the file 0002.sdf since the dump files are numbered starting from zero.\nInspecting Data IDL\u0026amp;gt; gridclass = getdata(1,/grid) IDL\u0026amp;gt; help,gridclass,/structures ** Structure \u0026amp;lt;22806408\u0026amp;gt;, 11 tags, length=536825024, data length=536825016, refs=1: FILENAME STRING 'Data/0001.sdf' TIMESTEP LONG 43 TIME DOUBLE 5.0705572e-15 GRID_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID_PROTON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] X DOUBLE Array[1024] Y DOUBLE Array[512] GRID_EN_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID_X_EN_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID_X_PX_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] IDL\u0026amp;gt; help,gridclass.grid,/structures ** Structure \u0026amp;lt;1701168\u0026amp;gt;, 5 tags, length=12376, data length=12376, refs=2: X DOUBLE Array[1025] Y DOUBLE Array[513] LABELS STRING Array[2] UNITS STRING Array[2] NPTS LONG Array[2]  Here we have used IDL\u0026rsquo;s built in \u0026ldquo;help\u0026rdquo; routine and passed the \u0026ldquo;/structures\u0026rdquo; keyword which prints information about a structure\u0026rsquo;s contents rather than just the structure itself.\nSince \u0026ldquo;Grid\u0026rdquo; is a class name, all variables of that class have been loaded into the returned data structure. It is a nested type so many of the variables returned are structures themselves and those variables may contain structures of their own.\nThe \u0026ldquo;Grid\u0026rdquo; variable itself contains x\u0026quot; and \u0026ldquo;y\u0026rdquo; arrays containing the $x$ and $y$ coordinates of the 2D cartesian grid. The other variables in \u0026ldquo;Grid\u0026rdquo; the structure are metadata used to identify the type and properties of the variable. In order to access the \u0026ldquo;Grid\u0026rdquo; variable contained within the \u0026ldquo;gridclass\u0026rdquo; data structure we have used the \u0026ldquo;.\u0026rdquo; operator. In a similar way, we would access the \u0026ldquo;x\u0026rdquo; array contained within the \u0026ldquo;Grid\u0026rdquo; variable using the identifier \u0026ldquo;gridclass.grid.x\u0026rdquo;.\nGetting Help in IDL IDL is a fairly sophisticated scripting environment with a large library of tools for manipulating data. Fortunately, it comes with a fairly comprehensive array of documentation. This can be accessed by typing ? at the IDL prompt.\nIDL\u0026amp;gt; ? % ONLINE_HELP: Starting the online help browser. IDL\u0026amp;gt;  The documentation is divided into books aimed at users or developers and is fully searchable and cross indexed.\nManipulating And Plotting Data Once the data has been loaded from the SDF file we will want to extract the specific data we wish to analyse, perhaps perform some mathematical operations on it and then plot the results.\nTo do this we must learn a few basic essentials about the IDL scripting language. Since we are all familiar with the basic concepts shared by all computer programming languages, I will just provide a brief overview of the essentials and leave other details to the excellent on-line documentation.\nIDL supports multidimensional arrays similar to those found in the FORTRAN programming language. Whole array operations are supported such as \u0026ldquo;5*array\u0026rdquo; to multiply every element of \u0026ldquo;array\u0026rdquo; by 5. Also matrix operations such as addition and multiplication are supported.\nThe preferred method for indexing arrays is to use brackets. It is possible to use parenthesis instead but this usage is deprecated. Column ordering is the same as that used by FORTRAN, so to access the $(i,j,k)$th element of an array you would use \u0026ldquo;array[i,j,k]\u0026rdquo;. IDL arrays also support ranges so \u0026ldquo;array[5:10,3,4]\u0026rdquo; will return a one dimensional array with five elements. \u0026ldquo;array[5:*]\u0026rdquo; specifies elements five to $n$ of an $n$ element array. \u0026ldquo;array[*,3]\u0026rdquo; picks out the third row of an array.\nThere are also a wide range of routines for querying and transforming arrays of data. For example, finding minimum and maximum values, performing FFTs, etc. These details can all be found by searching the on-line documentation.\nFinally, IDL is a full programming language so you can write your own functions and procedures for processing the data to suit your needs.\n1D Plotting in IDL The most commonly performed plot and perhaps the most useful data analysis tool is the 1D plot. In IDL, this is performed by issuing the command plot,x,y where \u0026ldquo;x\u0026rdquo; and \u0026ldquo;y\u0026rdquo; are one dimensional arrays of equal length. For each element \u0026ldquo;x[i]\u0026rdquo; plotted on the $x$-axis the corresponding value \u0026ldquo;y[i]\u0026rdquo; is plotted along the $y$-axis. As a simple example:\nIDL\u0026amp;gt; plot,[1,2,3],[2,2,5]  Gives rise to the following plot:\nAs a more concrete example, we will now take a one-dimensional slice through the 2D array \u0026ldquo;Number Density\u0026rdquo; read in from our SDF data file. In this example we will give the $x$ and $y$ axes labels by passing extra parameters to the \u0026ldquo;plot\u0026rdquo; routine. A full list of parameters can be found in the on-line documentation. In this example we also make use of the \u0026ldquo;$\u0026rdquo; symbol which is IDL\u0026rsquo;s line continuation character.\nIDL\u0026amp;gt; data = getdata(0) IDL\u0026amp;gt; plot,data.x,data.number_density[*,256],xtitle='x', $ IDL\u0026amp;gt; ytitle='number density'  This command generates the following plot:\nPostscript Plots The plots shown so far have just been screen-shots of the interactive IDL plotting window. These are fairly low quality and could included as figures in a paper.\nIn order to generate publication quality plots, we must output to the postscript device. IDL maintains a graphics context which is set using set plot the command. The two most commonly used output devices are \u0026ldquo;x\u0026rdquo; which denotes the X-server and \u0026ldquo;ps\u0026rdquo; which is the postscript device. Once the desired device has been selected, various attributes of its behaviour can be altered using the device procedure. For example, we can set the output file to use for the postscript plot. By default, a file with the name \u0026ldquo;idl.ps\u0026rdquo; is used.\nNote that this file is not fully written until the postscript device is closed using the device,/close command. When we have finished our plot we can resume plotting to screen by setting the device back to \u0026ldquo;x\u0026rdquo;.\nIDL\u0026amp;gt; set_plot,'ps' IDL\u0026amp;gt; device,filename='out.ps' IDL\u0026amp;gt; plot,data.x,data.number_density[*,256],xtitle='x', $ IDL\u0026amp;gt; ytitle='number density',charsize=1.5 IDL\u0026amp;gt; device,/close IDL\u0026amp;gt; set_plot,'x'  This set of commands results in the following plot being written to a file named \u0026ldquo;out.ps\u0026rdquo;.\nBy default, IDL draws its own set of fonts called \u0026ldquo;Hershey vector fonts\u0026rdquo;. Much better looking results can be obtained by using a postscript font instead. These options are passed as parameters to the device procedure. More details can be found in the on-line documentation under \u0026ldquo;Reference Guides $\\Rightarrow$ IDL Reference Guide $\\Rightarrow$ Appendices $\\Rightarrow$ Fonts\u0026rdquo;.\nContour Plots in IDL Whilst 1D plots are excellent tools for quantitive analysis of data, we can often get a better qualitative overview of the data using 2D or 3D plots.\nOne commonly used plot for 2D is the contour plot. The aptly named contour,z,x,y procedure takes a 2D array of data values, \u0026ldquo;z\u0026rdquo;, and plots them against $x$ and $y$ axes which are specified in the 1D \u0026ldquo;x\u0026rdquo; and \u0026ldquo;y\u0026rdquo; arrays. The number of contour lines to plot is specified by the \u0026ldquo;nlevels\u0026rdquo; parameter. If the \u0026ldquo;/fill\u0026rdquo; parameter is used then IDL will fill each contour level with a solid colour rather than just drawing a line at the contour value.\nThe example given below plots a huge number of levels so that a smooth looking plot is produced. \u0026ldquo;xstyle=1\u0026rdquo; requests that the $x$ axes drawn exactly matches the data in the variable rather than just using a nearby rounded value and similarly for \u0026ldquo;ystyle=1\u0026rdquo;.\nIDL\u0026amp;gt; n=100 IDL\u0026amp;gt; levels=max(data.number_density)*findgen(n)/(n-1) IDL\u0026amp;gt; colors=253.*findgen(n)/(n-1)+1 IDL\u0026amp;gt; contour,data.number_density,data.x,data.y,xstyle=1,ystyle=1, $ IDL\u0026amp;gt; levels=levels,/fill,c_colors=colors  Issuing these commands gives us the contour plot shown below. Note that the colour table used is not the default one but has been constructed to be similar to the one used by VisIt.\nShaded Surface Plots in IDL Another method for visualising 2D datasets is to produce a 3D plot in which the data is elevated in the $z$ direction by a height proportional to its value. IDL has two versions of the surface plot. surface produces a wireframe plot and shade surf produces a filled and shaded one. As we can see from the following example, many of IDL\u0026rsquo;s plotting routines accept the same parameters and keywords.\nThe first command shown here, loadct,3, asks IDL to load the third colour table which is\u0026quot;RED_TEMPERATURE\u0026quot;.\nIDL\u0026amp;gt; loadct,3 IDL\u0026amp;gt; shade_surf,data.number_density,data.x,data.y,xstyle=1, $ IDL\u0026amp;gt; ystyle=1,xtitle='x',ytitle='y',ztitle='number density',charsize=3  Interactive Plotting Finally, in recent versions of IDL (not GDL) it is now possible to perform all of these plot types in an interactive graphical user interface. The corresponding procedures are launched with the commands iplot, icontour and isurface.\nIDL\u0026amp;gt; iplot,data.x,data.number_density[*,256]  IDL is an extremely useful tool but it also comes with a fairly hefty price tag. If you are not part of an organisation that will buy it for you then you may wish to look into a free alternative. It is also a proprietary tool and you may not wish to work within the restrictions that this imposes.\nThere are a number of free tools available which offer similar functionality to that of IDL, occasionally producing superior results.\nFor a simple drop-in replacement, the GDL project aims to be fully compatible and works with the existing EPOCH IDL libraries after a couple of small changes. Other tools worth investigating are \u0026quot;yorick\u0026quot; and \u0026quot;python\u0026quot; with the \u0026quot;SciPy\u0026quot; libraries. The python SDF reader documentation will be added soon. At present there is no SDF reader for yorick but one may be developed if there is sufficient demand.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"d20659b75d861bc3da354bc2a944ea6b","permalink":"/documentation/visualising_output/visualising_sdf_files_with_idl_or_gdl.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output/visualising_sdf_files_with_idl_or_gdl.html","section":"documentation","summary":"Using IDL to visualise data The EPOCH distribution comes with procedures for loading and inspecting SDF self-describing data files. The IDL routines are held in the SDF/IDL/ directory. There is also a procedure named Start.","tags":null,"title":"IDL or GDL","type":"docs"},{"authors":null,"categories":null,"content":"Using VisIt to visualise data LLNL VisIt LLNL\u0026rsquo;s VisIt software is a parallel data visualisation package ( LLNL VisIt). EPOCH comes with source code for the plug-in needed to allow VisIt to load the SDF output files which are generated by EPOCH. There are full manuals for VisIt which can be downloaded from the above link so no further details will be given here. To build the plug-in, first ensure that the visit binary is in the $PATH environment variable. Then simply type \u0026ldquo;make visit\u0026rdquo; in one of the epoch{1,2,3}d directories. For more experienced users of VisIt, the xml file which is used to generate the plug-in is supplied in the VisIt subdirectory, called SDF2.xml.\nWhilst IDL is an excellent tool for visualising 1D and 2D datasets, it is extremely poor when it comes to dealing with 3D data. For this purpose, we recommend the use of the \u0026quot;VisIt\u0026quot; visualisation tool.\nThe other great advantage that VisIt has over IDL is the ability to render in parallel, enabling the visualisation of huge datasets which IDL would be incapable of dealing with.\n Initially developed by the Department of Energy (DOE) Advanced Simulation and Computing Initiative (ASCI) Now developed and maintained by the Lawrence Livermore National Laboratory along with a group of external contributors Written in C++ and supports python and Java interfaces Available for UNIX (Irix, Tru64, AIX, Linux, Solaris), Mac OS X (10.3 - Current), and Windows platforms Open source and freely available under the BSD license Plots, operators and database readers are implemented as plugins allowing the VisIt to be dynamically extended at run-time Powerful set of tools for manipulating, analysing and visualising 3D datasets Parallel and distributed architecture for visualising huge data sets  Obtaining And Installing VisIt Both the source code and pre-compiled binaries are available for download from the projects web page which is found at the URL https://wci.llnl.gov/simulation/computer-codes/visit\nThere are full instructions for compiling the project from source code along with build scripts written to help ease the process. However, this is not recommended as it is an extremely large tool and the compilation takes hours to complete. It is usually far easier to download a pre-compiled binary which matches your system architecture.\nHowever, occasionally compilation may be a necessary step. Linux in particular is a moving target and it is not always possible to find a binary which matches the particular combination of libraries installed on your system.\nThe easiest way to install the VisIt tool is to ask the system administrator to do it for you. However, this may not always be the best option. The system in question may be run by someone who is not concerned with your particular software needs or has insufficient skills to deal with the task. In any case, VisIt has a fairly rapid release schedule and you may find that some functionality you need is not present in the version installed on the machine.\nFortunately, for all these scenarios it is usually quite easy to install a copy in your own home directory. Just find a binary on the web page https://wci.llnl.gov/codes/visit/executables.html which closely matches your machine and download it. This can be unpacked into your home directory with the command tar xzf visit2_10_2.linux-x86_64-ubuntu14.tar.gz . The actual name of the file will vary depending on which version you downloaded. This will unpack the VisIt binary into a subdirectory named visit/. Now all that is necessary is to add this to your search path. e.g. export PATH=$HOME/visit/bin:$PATH\nThese instructions illustrate the steps required for installing your own copy of VisIt when you have no other choice. VisIt is an extremely large program, so if a version is already available then it is usually better to use the installed version.\nThe CSC machines at Warwick have a recent version of VisIt installed which is available via the system. To make use of it you must first issue the command module load visit.\nCompiling The Reader Plugin One piece of compilation which is almost always necessary is that of the SDF reader plugin. This is shipped as source code in a subdirectory of the repository. It is located in the SDF/VisIt subdirectory of the main epoch directory. The reader will work for any SDF file generated by any code which uses the SDF I/O routines. You do not need a separate reader for each version of EPOCH.\nTo compile, first navigate to one of the epoch*d directories in your repository. Just type \u0026ldquo;make visit\u0026rdquo; and the build scripts should take care of the rest. The SDF reader plugin will be installed into the $HOME/.visit/linux-intel/plugins/databases/ directory on your system. Note that the linux-intel component will vary depending on your machine operating system and architecture.\nEach time you install a new version of VisIt you must recompile the reader to match the new installation. It will also occasionally be necessary to recompile when changes occur to the SDF data format or the reader plugin itself. The developers will notify users if this is the case, although it does no harm to regularly recompile the reader as a matter of course.\nWe will see later that it is possible to do remote data visualisation with VisIt in which the GUI is launched and interacted with on one machine and the data files are located on a separate machine entirely. In this situation the reader must be installed on the remote machine and must match the setup there. The setup on the local machine is unimportant. In fact it is not even necessary to have the plugin installed on the local machine. This is particularly useful when using a Windows environment to analyse data located on a remote UNIX workstation.\nLoading Data Into VisIt The most straightforward method for loading data into VisIt is to start the application and then browse the filesystem for the dataset you are interested in. This is done by selecting \u0026ldquo;File  Open file\u0026rdquo; from the VisIt menu bar. A file selection dialogue will appear allowing you to browse directories along with the options to filter the results according to a given regular expression and grouping options. By default, VisIt will attempt to group all files containing the same suffix and some kind of numbering system into a sort of virtual database.\nThe right-hand pane of this window shows a list of selected files which will appear in the main VisIt window when you are finished.\nAn alternative method of specifying the data file to open is to pass a command line option when the tool is launched. An example of this method is visit -o Data/0000.sdf. When the file is specified in this manner the list of files shown in the VisIt window will also include the full list of files in the dataset\u0026rsquo;s subdirectory and all the files in the current working directory. The other SDF files will be grouped together in a virtual database.\nYet another method for selecting the dataset to use is by opening a previously saved session file. We will discuss this further in a later section.\nOnce an SDF file has been successfully loaded the \u0026ldquo;Add\u0026rdquo; menu item will become un-greyed and the cycle numbers for each file in the virtual database will be displayed. If we navigate to one of the plot types we are able to select the variable to plot from a drop-down list.\nContour Plots in VisIt We will now replicate each of the plots which we generated using IDL in earlier sections. For reasons which will soon become clear we begin with the contour plot and move on to the 1D plot in the next section.\nHaving opened the same dataset we were using in the IDL discussion we now select the \u0026ldquo;Add\u0026rdquo; menu item. Notice that many of the plot types listed here are greyed out and cannot be selected. This is because many of the plots are dependent on the type or dimensionality of the variable to be plotted. If our dataset contains no variables which match the required properties for a plot, the plot menu will be disabled.\nFor the current dataset there is no \u0026ldquo;Boundary\u0026rdquo; plot available since this requires multi-material data and none of our variables meet that criteria.\nThe list contains a menu item for a \u0026ldquo;Contour\u0026rdquo; plot. We are not going to select this item since it only generates a contour plot with lines indicating each contour level and not a filled version. Instead we choose \u0026ldquo;Add  Pseudocolor  Derived  Number Density\u0026rdquo; and then hit the \u0026ldquo;Draw\u0026rdquo; button.\nThere are many settings which can alter the visual appearance of plots generated by VisIt. The first point of call is usually to open up the \u0026ldquo;Plot Attributes\u0026rdquo; or \u0026ldquo;Operator Attributes\u0026rdquo; dialogue corresponding to the plot in question. A simpler method for accomplishing this task is to double-click on the plot in the main VisIt menu pane which will launch the corresponding \u0026ldquo;Plot Attributes\u0026rdquo; dialogue.\nIf it is the operator attributes you wish to change, click on the white arrow on the left hand side of the plot in the main VisIt menu pane. This will drop down to reveal a list containing the plot and all operators acting on it. Double-clicking on an operator will launch the corresponding \u0026ldquo;Operator Attributes\u0026rdquo; dialogue.\nAnother important tool for controlling the appearance of plots can be found in \u0026ldquo;Controls  Annotation\u0026rdquo; from the VisIt menu bar. This allows all of the plot annotations to be modified such as the legend, title, axis labels, etc.\n1D Plotting in VisIt A 1D plot in VisIt is called a \u0026ldquo;Curve\u0026rdquo; plot. We already mentioned that this was greyed out because we have no one dimensional variables in our data file.\nThe solution to this dilemma is the lineout operator which extracts a one dimensional array from a 2D or 3D variable. This operator is selected by pressing the button with red and blue lines located at the top of the plot window.\nOnce the button has been pressed, we can click and drag anywhere in the \u0026ldquo;Pseudocolor\u0026rdquo; plot window. When we release the mouse button a new plot window pops up containing a \u0026ldquo;Curve\u0026rdquo; plot of the data just selected.\nIn order to change the attributes for this plot, we must first select Active window\u0026quot; number 2 in the main VisIt pane.\nShaded Surface Plots in VisIt Again, we will confusingly refuse to pick the obvious plot type for this task. There is \u0026ldquo;Surface\u0026rdquo; plot listed in the menu. However, most of the time the \u0026ldquo;Elevator\u0026rdquo; operator does what we want and also gives us more flexibility.\nThe first step is to do a \u0026ldquo;Pseudocolor\u0026rdquo; plot of \u0026ldquo;Number Density\u0026rdquo; as we did before. Next select the \u0026ldquo;Operator Attributes  Transforms  Elevate\u0026rdquo; menu item. In the pop up dialogue click on the \u0026ldquo;Elevation height relative to XY limits?\u0026rdquo; and then \u0026ldquo;Apply\u0026rdquo;. Click \u0026ldquo;Yes\u0026rdquo; when the warning dialogue pops up.\nTo make this plot look similar to the one generated by IDL, we have changed the colour table using \u0026ldquo;Controls  Color table\u0026rdquo;. We also changed the axis appearance with the annotations menu discussed earlier and changed the height of the elevation using the min and max operator attributes.\nCreating User-Defined Expressions VisIt comes with an extremely powerful method of manipulating data before visualising the results. The basic idea is that an array is transformed by applying a set of mathematical functions on all its elements and then the result is defined as a new variable. Once defined, this variable behaves in exactly the same way as any of the variables read from the data file.\nAs an example, we can combine the three components of electric field to generate a single electric field vector.\nNow when we return to the \u0026ldquo;Add\u0026rdquo; menu we see that the \u0026ldquo;Vector\u0026rdquo; and \u0026ldquo;Streamline\u0026rdquo; and plot types now have an entry for our newly defined vector.\nCreating Movies A compelling visualisation of numerically generated data is often made by combining a series of images into a movie. This can be an invaluable method for illustrating the basic behaviour of a system as it changes over time. Alternatively rotating around a 3D scene can sometimes give a much better idea of the structure in the model being presented. There can also be much to gain by constructing visual fly-throughs of a scene, dynamically slicing through sets of data or combinations of all these techniques.\nVisIt provides several facilities for generating movies from your data. The simplest of these is to select the \u0026ldquo;File  Save movie\u0026rdquo; menu item. This pops up a movie wizard which will walk you through the process of generating a simple linear movie based on the time-advancing snapshots represented by your virtual database of files. Alternatively you can select one of the pre-defined movie templates which manipulate the currently selected plot and create a movie from that.\nCreating a simple time advancing movie is as simple as walking through the wizard dialogue and selecting from the self-explanatory options presented to you.\nFor many uses, the wizard will give exactly the desired results. However it is occasionally useful to have a little more control over how the movie is created. In such cases it can be useful to specify an image format such as \u0026ldquo;PNG\u0026rdquo; to save to rather than \u0026ldquo;MPEG\u0026rdquo;. VisIt will then generate one image per frame and number them consecutively. At the end of the process the images can be converted into a movie using whatever tool best accomplishes the task.\nAnother useful tip is to select the \u0026ldquo;Later, tell me the command to run\u0026rdquo; radio button. This will output a long command which can run from a UNIX terminal screen. The advantage is that no X session is required so the command can be run in the background. It also becomes a simple task to interrupt the job at any point and resume it from where it left off at a later date. In a similar manner it is easy to resume a job which crashes half way through for any reason.\nMore complex movies can be created by using VisIt\u0026rsquo;s keyframing facility which allows you to change animation attributes such as view or plot attributes as the animation progresses. Further information about this somewhat complex task can be found in the on-line help.\nFinally, you can use VisIt\u0026rsquo;s python scripting interface to programmatically describe the details of each frame as the movie progresses. This approach offers far more flexibility in what can be achieved but is also much more involved and time consuming than the previous two methods. Again, further information on this subject can be found in the on-line help system.\nRemote Visualisation It was mentioned earlier that it is possible to perform remote visualisation using VisIt. This is a process in which the data files being interrogated reside on a different machine to the one on which the VisIt GUI runs and where the results are plotted.\nThis method of working can be extremely useful when the data is generated on a powerful machine located in an external environment such as a large cluster. Another common use is when EPOCH is executed on a UNIX machine and the desktop used for visualisation is running Windows.\nIt is sometimes possible to run a graphical tool on the remote machine and tunnel the X-server session through to the local machine but this can be quite slow and unstable. When connecting to a remote VisIt instance the only data which needs to be sent between machines is the pre-rendered image and a few simple plotting commands. Naturally, this can be a much faster approach.\nAlso, as mentioned before, it is possible to use a machine on which the reader plugin is difficult or impossible to compile for and connect to a machine on which the reader is already installed.\nIn order to use the remote visualisation facility, you must first set up a \u0026ldquo;Host profile\u0026rdquo; for the remote machine using the \u0026ldquo;Options  Host profiles\u0026rdquo; menu item. The pre-compiled binaries are shipped with a long list of pre-defined host profiles. These are unnecessary for anyone not affiliated and can safely be removed by deleting the directory $HOME/visit/current/.visit (assuming you have unpacked the VisIt tarball into your home directory).\nCreate a new profile by clicking on the \u0026ldquo;New Host\u0026rdquo; button and filling out some of the form fields. The important ones to change are \u0026ldquo;Host nickname\u0026rdquo;, \u0026ldquo;Remote host name\u0026rdquo;, \u0026ldquo;Host name aliases\u0026rdquo; and \u0026ldquo;Username\u0026rdquo;. If the visit binary is not in your default search path on the remote machine then you must specify its location by filling in the \u0026ldquo;Path to VisIt installation\u0026rdquo; field.\nNow click \u0026ldquo;Apply\u0026rdquo; and \u0026ldquo;Dismiss\u0026rdquo; followed by the \u0026ldquo;Options  Save Settings\u0026rdquo; menu item to ensure that the profile is saved for future sessions.\nData on the remote machine can now be loaded by selecting and picking the desired host profile from the drop down list of \u0026ldquo;Hosts\u0026rdquo;. VisIt will wait for the remote process to launch and then continue with the file selection procedure but now displaying files located on the remote machine rather than the local one. From this point on everything should work as before except you should see the name of the remote machine in the \u0026ldquo;Selected files\u0026rdquo; dialogue.\nParallel Visualisation Parallel visualisation is performed in almost exactly the same manner as remote visualisation. Again, you must create a host profile for the purpose except this time you need to set up a parallel launch profile in the \u0026ldquo;Launch Profiles\u0026rdquo; tab pane. Click the \u0026ldquo;New Profile\u0026rdquo; button, give the profile a name and then set the required options in the \u0026ldquo;Parallel\u0026rdquo; tab on the bottom section of the page. Selecting the \u0026ldquo;Launch parallel engine\u0026rdquo; radio button will allow you to set the various launch options which relate to the cluster on which the job will run.\nThe major difference now is due to the fact that VisIt must be launched by an external job script which fits in with the queueing system used by the parallel machine. Usually you will need to consult with the system administrator of the cluster to confirm which launch method and arguments to use.\nThe details of job launch can be better understood by reading through the \u0026ldquo;User documentation\u0026rdquo; section provided at 1 . Of particular help here is the \u0026ldquo;Getting VisIt to run in parallel\u0026rdquo; section and the \u0026ldquo;How VisIt Launching works\u0026rdquo; entry in the \u0026ldquo;Developer documentation\u0026rdquo; section.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"7d3774268a06227509196710f0882fd9","permalink":"/documentation/visualising_output/visualising_sdf_files_with_llnl_visit.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output/visualising_sdf_files_with_llnl_visit.html","section":"documentation","summary":"Using VisIt to visualise data LLNL VisIt LLNL\u0026rsquo;s VisIt software is a parallel data visualisation package ( LLNL VisIt). EPOCH comes with source code for the plug-in needed to allow VisIt to load the SDF output files which are generated by EPOCH.","tags":null,"title":"LLNL VisIt","type":"docs"},{"authors":null,"categories":null,"content":"Installing the python sdf readers To install the python sdf readers you need to have an installation of python (2 or 3) with the numpy library. The automated plotting library requires the matplotlib library. Both numpy and matplotlib are available through most system package managers or are installable through pip.\nOnce you have a working python install, just go into one of the epoch directories (epoch1d, epoch2d or epoch3d) and type\nmake sdfutils\nThis will build the SDF python library and install the sdf_helper wrapper and utility layer.\nUsing the sdf_helper wrapper layer The low level python SDF library is not user friendly, so a wrapper layer called sdf_helper has been written. This wrapper layer simplifies loading SDF files and provides simple plotting routines using matplotlib.\nImporting sdf_helper Importing sdf_helper is as simple as\nimport sdf_helper  In these examples, the numpy and matplotlib libraries are usually loaded too, and an alias is created for sdf_helper, so the boilerplate code looks like\nimport sdf_helper as sh import numpy as np import matplotlib.pyplot as plt  Loading an sdf file using sdf_helper To load a file, use the getdata function. This function takes either a string which it loads as a filename, so to load the file Data/0010.df you would run\nimport sdf_helper as sh data=sh.getdata('Data/0010.sdf')  or it takes a number which is the dump number, and optionally a second parameter which is the directory name as a string, so you would run\nimport sdf_helper as sh data=sh.getdata(10, 'Data')  Because memory is only allocated when needed in the SDF python reader there is no way of specifying which variables to load using getdata. All variables are available when the file is first loaded, and memory is allocated when the variable is first used.\nListing the available variables in an sdf file To see what variables are available use the list_variables method\nimport sdf_helper as sh data=sh.getdata('Data/0010.sdf') sh.list_variables(data)  This produces an output that looks something like\nCPUs_Current_rank \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [0] CPUs_Original_rank \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [2] Current_Jx \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Charge_Density \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Number_Density \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Number_Density_Left \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Number_Density_Right \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Electric_Field_Ex \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Grid_CPUs_Original_rank \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [3] Grid_CPUs_Original_rank_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [2] Grid_Grid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [401] Grid_Grid_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [400] Grid_x_px_Left \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [400, 200] Grid_x_px_Left_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [399, 199] Grid_x_px_Right \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [400, 200] Grid_x_px_Right_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [399, 199] Wall_time \u0026lt;class 'sdf.BlockConstant'\u0026gt; [1] dist_fn_x_px_Left \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400, 200] dist_fn_x_px_Right \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400, 200]  These are the names of the variables in the data structure. This example is taken from the supplied two_stream.deck example in 1D.\nWorking with the data in an SDF file You can access the underlying data using the names obtained from list_variables\nvariable = data.Electric_Field_Ex  This returns an instance of either sdf.BlockPlainVariable or sdf.BlockPointVariable depending on whether you have requested a grid variable (such as Ex, Ey or a distribution function) or a particle variable (such as particle momentum or weight). The raw contents of the variable is a numpy array. It is then available using the data element of these objects.\nimport numpy as np variable = data.Electric_Field_Ex raw = variable.data print(type(raw)) print(np.mean(raw))  produces the output\n\u0026lt;type 'numpy.ndarray'\u0026gt; -1.27980874427008e-06  Plotting using sdf_helper The sdf_helper wrapper script comes with some plotting routines. They are incomplete currently, but aim to provide as close as possible to press ready figures in a single command. You need the matplotlib library to use these routines, and they are only available for 1D and 2D data at present. To plot data, simply provide an sdf.BlockPlainVariable object to the routine plot_auto. An example of plotting a 1D variable, using the two_stream.deck example deck to generate the figures would be\nimport sdf_helper as sh import matplotlib.pyplot as plt plt.ion() data=sh.getdata('Data/0010.sdf') sh.plot_auto(data.Current_Jx)  This will produce a window similar to the image shown here, with slight difference depending on your version of matplotlib and your operating system. The code plt.ion() sets matplotlib to interactive mode, so control will be returned to you as soon as the plot has finished drawing.\n Example 1D plot generated by sdf_helper.plot_auto\nPlotting a 2D function is the same basic idea, and the code\nimport sdf_helper as sh import matplotlib.pyplot as plt plt.ion() data=sh.getdata('Data/0010.sdf') sh.plot_auto(data.dist_fn_x_px_Right, iso=0)  will produce the figure on the right. The procedure for variables from EPOCH2D data is exactly the same.\nChanging colour tables The easiest solution to changing colour tables is to set the global colour table. This is done by\nimport matplotlib.pyplot as plt plt.set_cmap(tablename)  where tablename is a string describing the colour table to be used. The available strings are given here\nSome bugs in matplotlib There are some bugs in matplotlib which can mean that sometimes the 2D images don\u0026rsquo;t render properly. If you get incorrect rendering, please try updating matplotlib to the latest version for your platform. If that doesn\u0026rsquo;t work then pass the parameter compatibility=True to the plot_auto routine. This may make the plot slightly less pretty, but tends to work on more platforms.\nCore Python library The SDF python reader allows you to read any SDF file and access any information within the file. It has very few user friendly features to assist working with the files. Some of the methods listed in the section on sdf_helper (notably list_variables) are not available when using the core library. Loading an sdf file with the core library has the following syntax\nimport sdf data=sdf.read(filename)  where filename is a string containing the name of the file to be loaded. This returns an sdf.BlockList object\nThe sdf.BlockList object The list_variables routine is added by the sdf_helper wrapper, but you can check what elements are in the file by simply typing\ndata.__dict__  Which will produce an output like the following example from EPOCH2D\n{'Header': {'filename': '/Users/phsiav/dev/epoch/epoch2d/Data/0005.sdf', 'file_version': 1, 'file_revision': 4, 'code_name': 'Epoch2d', 'step': 53, 'time': 2.5293132385759517e-14, 'jobid1': 1552896563, 'jobid2': 376, 'code_io_version': 1, 'restart_flag': False, 'other_domains': False, 'station_file': False}, 'Wall_time': \u0026lt;sdf.BlockConstant object at 0x11a012318\u0026gt;, 'Electric_Field_Ex': \u0026lt;sdf.BlockPlainVariable object at 0x11a012220\u0026gt;, 'Electric_Field_Ey': \u0026lt;sdf.BlockPlainVariable object at 0x11a012128\u0026gt;, 'Electric_Field_Ez': \u0026lt;sdf.BlockPlainVariable object at 0x11a012030\u0026gt;, 'Magnetic_Field_Bx': \u0026lt;sdf.BlockPlainVariable object at 0x117b2ceb8\u0026gt;, 'Magnetic_Field_By': \u0026lt;sdf.BlockPlainVariable object at 0x117b2cdc0\u0026gt;, 'Magnetic_Field_Bz': \u0026lt;sdf.BlockPlainVariable object at 0x117b2ccc8\u0026gt;, 'Grid_Grid': \u0026lt;sdf.BlockPlainMesh object at 0x117b2cbd0\u0026gt;, 'Grid_Grid_mid': \u0026lt;sdf.BlockPlainMesh object at 0x117b2cad8\u0026gt;, 'Grid_CPUs_Original_rank': \u0026lt;sdf.BlockPlainMesh object at 0x117b2c9e0\u0026gt;, 'Grid_CPUs_Original_rank_mid': \u0026lt;sdf.BlockPlainMesh object at 0x117b2c8e8\u0026gt;, 'CPUs_Original_rank': \u0026lt;sdf.BlockPlainVariable object at 0x117b2c7f0\u0026gt;, 'CPUs_Current_rank': \u0026lt;sdf.BlockPlainVariable object at 0x11a015128\u0026gt;}\nThe sdf.BlockPlainVariable object These objects represent the variables in the SDF file. It does not fully implement the dict property, so to inspect it\u0026rsquo;s contents you must use\ndir(data.Electric_Field_Ey)  which produces an output like\n['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'blocklist', 'data', 'data_length', 'datatype', 'dims', 'grid', 'grid_id', 'grid_mid', 'id', 'mult', 'name', 'stagger', 'units']\nThe key elements are data which contains the raw data for the variable stored as a numpy array, dims which is an array containing the number of elements in each dimension of the array and grid and grid_mid which refer to sdf.BlockPlainMesh objects that represent the grid axes that the variable is to be plotted against. Grid and grid_mid do similar but different things. Grid is an array of points corresponding to the edges of the computational cells, grid_mid to the midpoints. This means that all of the arrays in grid are one element longer than the arrays in grid_mid. To identify whether to use grid or grid_mid you must compare the sizes of the variable dims array to the sizes of the grid and grid_mid sizes and for each axis use the element of grid or grid_mid that has the same number of elements.\nImportant note! - 2D SDF data is loaded into Python rotated by 90 degrees compared to the original Fortran code that generated it.\nThe sdf.BlockPlainMesh object Once again you have to use the dir command to output the information about an sdf.BlockPlainMesh object, for example in EPOCH\ndir(data.Grid_Grid)  Which produces output like\n['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'blocklist', 'data', 'data_length', 'datatype', 'dims', 'extents', 'geometry', 'id', 'labels', 'mult', 'name', 'units']\nThe important element of this block is data which is a tuple of 1D numpy arrays corresponding to each coordinate axis of the grid.\nPlotting a variable using raw SDF and raw matplotlib  Warning - This is not our recommended suggestion for plotting. We recommend using our helper routines in sdf_helper*  import matplotlib.pyplot as plt import sdf data=sdf.read('Data/0005.sdf') ey = data.Electric_Field_Ey plt.pcolormesh(ey.grid_mid.data[0], ey.grid_mid.data[1], ey.data.T) plt.show()  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"a05a00db2d4350293a64a7343919d8df","permalink":"/documentation/visualising_output/python.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output/python.html","section":"documentation","summary":"Installing the python sdf readers To install the python sdf readers you need to have an installation of python (2 or 3) with the numpy library. The automated plotting library requires the matplotlib library.","tags":null,"title":"Python","type":"docs"},{"authors":null,"categories":null,"content":"In this section we outline a few worked examples of setting up problems using the EPOCH input deck.\nElectron two stream instability An obvious simple test problem to do with EPOCH is the electron two stream instability. An example of a nice dramatic two stream instability can be obtained using EPOCH1D by setting the code with the following input deck file:\nbegin:control nx = 400 # Size of domain x_min = 0 x_max = 5.0e5 # Final time of simulation t_end = 1.5e-1 stdout_frequency = 400 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:constant drift_p = 2.5e-24 temp = 273 dens = 10 end:constant begin:species # Rightwards travelling electrons name = Right charge = -1 mass = 1.0 temp = temp drift_x = drift_p number_density = dens npart = 4 * nx end:species begin:species # Leftwards travelling electrons name = Left charge = -1 mass = 1.0 temp = temp drift_x = -drift_p number_density = dens npart = 4 * nx end:species begin:output # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties at particle positions particles = always px = always # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always ekbar = always mass_density = never + species charge_density = always number_density = always + species temperature = always + species end:output  In this example, the constant block sets up constants for the momentum space drift, the temperature and the electron number density. The two species blocks set up the two drifting Maxwellian distributions and the constant density profile. The final output from this simulation is shown in the figure.\nStructured density profile in EPOCH2D A simple but useful example for EPOCH2D is to have a highly structured initial condition to show that this is still easy to implement in EPOCH. A good example initial condition would be:\nbegin:control nx = 500 ny = nx x_min = -10 * micron x_max = -x_min y_min = x_min y_max = x_max nsteps = 0 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic bc_y_min = periodic bc_y_max = periodic end:boundaries begin:constant den_peak = 1.0e19 end:constant begin:species name = Electron number_density = den_peak * (sin(4.0 * pi * x / length_x + pi / 4)) \\ * (sin(8.0 * pi * y / length_y) + 1) number_density_min = 0.1 * den_peak charge = -1.0 mass = 1.0 npart = 20 * nx * ny end:species begin:species name = Proton number_density = number_density(Electron) charge = 1.0 mass = 1836.2 npart = 20 * nx * ny end:species begin:output number_density = always + species end:output  The species block for Electron is specified first, setting up the electron density to be a structured 2D sinusoidal profile. The species block for Proton is then set to match the density of Electron, enforcing charge neutrality. On its own this initial condition does nothing and so only needs to run for 0 timesteps (nsteps = 0 in input.deck). The resulting electron number density should look like the figure.\nA hollow cone in 3D A more useful example of an initial condition is to create a hollow cone. This is easy to do in both 2D and 3D, but is presented here in 3D form.\nbegin:control nx = 250 ny = nx nz = nx x_min = -10 * micron x_max = -x_min y_min = x_min y_max = x_max z_min = x_min z_max = x_max nsteps = 0 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = simple_outflow bc_y_min = periodic bc_y_max = periodic bc_z_min = periodic bc_z_max = periodic end:boundaries begin:output number_density = always + species end:output begin:constant den_cone = 1.0e22 ri = abs(x - 5.0e-6) - 0.5e-6 ro = abs(x - 5.0e-6) + 0.5e-6 xi = 3.0e-6 - 0.5e-6 xo = 3.0e-6 + 0.5e-6 r = sqrt(y^2 + z^2) end:constant begin:species name = proton charge = 1.0 mass = 1836.2 number_density = if((r gt ri) and (r lt ro), den_cone, 0.0) number_density = if((x gt xi) and (x lt xo) and (r lt ri), \\ den_cone, number_density(proton)) number_density = if(x gt xo, 0.0, number_density(proton)) npart = nx * ny * nz end:species begin:species name = electron charge = -1.0 mass = 1.0 number_density = number_density(proton) npart = nx * ny * nz end:species  Cone initial conditions in 3D Cone initial conditions in 2D To convert this to 2D, simply replace the line r = sqrt(y^2+z^2) with the line r = abs(y). The actual work in these initial conditions is done by the three lines inside the block for the Proton species. Each of these lines performs a very specific function:\n Creates the outer cone. Simply tests whether r is within the range of radii which corresponds to the thickness of the cone and if so fills it with the given density. Since the inner radius is x dependent this produces a cone rather than a cylinder. On its own, this line produces a pair of cones joined at the tip. Creates the solid tip of the cone. This line just tests whether the point in space is within the outer radius of the cone and within a given range in x, and fills it with the given density if true. Cuts off all of the cone beyond the solid tip. Simply tests if x is greater than the end of the cone tip and sets the density to zero if so.  This deck produces an initial condition as in the Figures in 3D and 2D respectively.\nFocussing a Gaussian Beam A laser can be driven on the boundary so that it focusses on a given spot. Basic details of how to do this are here. To summarise, using the paraxial approximation, the electric fields for a $x$-propagating, $y$-polarised Gaussian beam take the form:\n$\\pmb{E}(r,x) = E_0 \\frac{w_0}{w(x)} e^{-r^2/w(x)^2} e^{-i(kx + k\\frac{r^2}{2R_c(x)}-\\psi(x))} \\hat{\\pmb{y}}$\nwhere\n $r$ is the radial distance from the laser propagation axis $x$ is axial distance along the wave, with $x=0$ at the focus $E_0$ is the peak electric field amplitude at the focus $w(x)$ is the beam-waist at $x$ (radial distance where field strength drops by $e^{-1}$) $w_0$ is $w(x=0)$ $k$ is the laser wave-vector $R_c(x)$ is the radius of curvature at $x$ $\\psi(x)$ is the Gouy phase correction  If the fields on the simulation boundary are of this form, then the fields will propagate according to this equation, and a focal spot will be formed. Note that this propagation is only expected provided the paraxial approximation is satisfied. This implies that, for vacuum propagation, the laser wavelength, $\\lambda$ is much smaller than the beam-waist: $\\lambda \u0026laquo; w_0$.\nThe following deck gives an example for a laser attached to x_min. Two constant blocks are provided: the first gives the user control over the focused laser properties, and the second derives variables to be used in the laser block. The user only needs to touch the first, which sets the intensity full-width-at-half-maximum (related to beam-waist), the peak, cycle-averaged intensity, the laser wave-length and the distance from the $x_{min}$ boundary to the focal point.\nbegin:control nx = 2400 ny = 1200 t_end = 100e-15 x_min = 0 x_max = 20e-6 y_min = -5e-6 y_max = 5e-6 stdout_frequency = 100 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = open bc_y_min = open bc_y_max = open end:boundaries begin:constant I_fwhm = 2.0e-6 # FWHM of laser intensity I_peak_Wcm2 = 1.0e15 # 0.5 * eps0 * c * E_peak^2 las_lambda = 1.0e-6 # Laser wavelength foc_dist = 5.0e-6 # Boundary to focal point distance end:constant begin:constant las_k = 2.0 * pi / las_lambda w0 = I_fwhm / sqrt(2.0 * loge(2.0)) # Beam Waist ray_rang = pi * w0^2 / las_lambda # Rayleigh range w_boundary = w0 * sqrt(1.0 + (foc_dist/ray_rang)^2) # Waist on boundary I_boundary = I_peak_Wcm2 * (w0 / w_boundary)^2 # Intens. on boundary rad_curve = foc_dist * (1.0 + (ray_rang/foc_dist)^2) # Boundary curv. rad. gouy = atan(-foc_dist/rad_curve) # Boundary Gouy shift end:constant begin:laser boundary = x_min intensity_w_cm2 = I_boundary lambda = las_lambda phase = las_k * y^2 / (2.0 * rad_curve) - gouy profile = gauss(y, 0, w_boundary) end:laser begin:output name = o1 dt_snapshot = 10 * femto poynt_flux = always end:output  In this example, EPOCH correctly reproduces the focal point position, laser wavelength, and radial FWHM at the focus - however, the peak intensity is only $0.88\\times 10^{15} \\text{ Wcm}^{-2}$. This intensity reduction from target is due to the tight focal spot, with $w_0\\approx 1.7$ m being close to $\\lambda = 1.0$ m.\nThe deck is based on the laser test deck supplied with EPOCH, with a modified laser and longer runtime. Other classes of beam (Bessel etc) can be created similarly.\nInjecting the laser at an angle By setting up a phase shift as a function of space, it is possible to force wavefronts to arrive at different points on the boundary at different times (for 2D and 3D simulations). This allows the user to inject lasers with an angle to the boundary normal.\nAngled incident laser profile The setup for this is not entirely straightforward and requires a little bit of explanation. The above figure illustrates a laser being driven at an angle on the $x_{min}$ boundary. Different wave fronts cross the $y$-axis at different places and this forms a sinusoidal profile along $y$ that represents the phase. The wavelength of this profile is given by $\\lambda_\\phi = \\lambda / \\sin\\theta$, where $\\lambda$ is the wavelength of the laser and $\\theta$ is the angle of the propagation direction with respect to the $x$-axis. The actual phase to use will be $\\phi(y) = -k_\\phi y = -2\\pi y / \\lambda_\\phi$. It is negative because the phase of the wave is propagating in the positive $y$ direction. It is also necessary to alter the wavelength of the driver since this is given in the direction perpendicular to the boundary. The new wavelength to use will be $\\lambda\\cos\\theta$. The figure shows the resulting $E_y$ field for a laser driven at an angle of $\\pi / 6$. Note that since the boundary conditions in the code are derived for propagation perpendicular to the boundary, there will be artefacts on the scale of the grid for lasers driven at an angle.\nThe input deck used to generate this figure is given below:\nbegin:control nx = 2000 ny = 2000 t_end = 50.e-15 x_min = -10.0e-6 x_max = 10.0e-6 y_min = -10.0e-6 y_max = 10.0e-6 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = simple_outflow bc_y_min = simple_outflow bc_y_max = simple_outflow end:boundaries begin:constant laser_angle = pi / 6 # Set angle of laser w.r.t positive x unit vector laser_fwhm = 2.0e-6 # Size of gaussian profile for laser electric field laser_wavelength = 1.0e-6 laser_k = 2 * pi / laser_wavelength end:constant begin:laser boundary = x_min intensity_w_cm2 = 1.0e15 profile = gauss(y, 0, laser_fwhm / (2.0 * sqrt(loge(2.0)))) t_profile = 1 phase = -y * laser_k * sin(laser_angle) # Vary wave-front position in space lambda = laser_wavelength * cos(laser_angle) # Space wave-fronts apart # correctly along k end:laser begin:output dt_snapshot = 10.e-15 grid = always ey = always end:output  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674130882,"objectID":"d3bcb35000c59ee992f06b02811a9323","permalink":"/documentation/examples/basic_examples.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples/basic_examples.html","section":"documentation","summary":"In this section we outline a few worked examples of setting up problems using the EPOCH input deck.\nElectron two stream instability An obvious simple test problem to do with EPOCH is the electron two stream instability.","tags":null,"title":"Basic examples","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH workshop overview The aims of the Workshop are:\n After the workshop you should be able to setup and run EPOCH on a problem of real importance to your research. You should also be in a position to use and understand the manual. You should learn about PIC codes in general. You should understand more about the pitfalls of trying to do LPI studies with PIC. Advice on how to run EPOCH and setup software on your home computers. Give advice to the EPOCH team on new features for the code.  Warwick EPOCH Personnel:\n Tony Arber \u0026ndash; PI on EPOCH project at Warwick. Keith Bennett \u0026ndash; PDRA and senior EPOCH developer. Chris Brady \u0026ndash; Original EPOCH developer and head of RSE at Warwick Heather Ratcliffe - EPOCH user and developer Tom Goffrey \u0026ndash; PDRA and developer on other non-EPOCH codes Alexander Seaton - Final year PhD student with extensive experience of using EPOCH  Resources:\n All machines, and exercises, are linux based. EPOCH is a Fortran90 program which uses MPI for parallelization. You will always need both F90 and MPI to compile and run the code even on one processor. MPI on a Windows computer is not easy. Use linux or a Mac.  Workstation usage You can use the workstations for simple 1D tests and looking at the code.\nUltra-simple getting EPOCH guide! These instructions should work in your host institute if you have git.\n Login to workstation using guest account. Open a terminal. Type the following command at the prompt: git clone --recursive https://github.com/Warwick-Plasma/epoch.git  You will now have a directory called \u0026lsquo;epoch\u0026rsquo;. Inside this directory will be three EPOCH sub-directories epoch1d, epoch2d and epoch3d, an SDF directory and a few other files. Change directory into the epoch1d directory and start working through the \u0026lsquo;Getting Started with EPOCH\u0026rsquo; guide.\nRunning the codes Single core job: \u0026gt; echo Data | mpiexec -n 1 bin/epoch1d Four core parallel job: \u0026gt; echo Data | mpiexec -n 4 bin/epoch2d\nNote: If you don\u0026rsquo;t have git on your home computer you can always download a tar file of epoch when you return to your lab. This you get from the \u0026lsquo;Releases\u0026rsquo; section on the EPOCH GitHub webpage. However I recommend you get, and learn, git and join the 21st century.\nGetting Started with EPOCH Compiling the code The first thing you must do is to compile the code. This is done using the UNIX \u0026ldquo;make\u0026rdquo; command. This command reads a file called Makefile and uses the instructions in this file to generate all the steps required for compiling the code. Most of this is done automatically and the only part which typically needs changing are the instructions for which compiler to use and what compiler flags it accepts. The Makefiles supplied as part of the EPOCH source code contain sections for most commonly used compilers so it is usually unnecessary to actually edit these files. Usually you can compile just by passing the name of the compiler on the command line.\nTo compile the 1D version of the code, first change to the correct directory by typing cd epoch/epoch1d. The compiler used on most desktop machines is gfortran, so you can compile the code by typing make COMPILER=gfortran. Alternatively, if you type make COMPILER=gfortran -j4 then the code will be compiled in parallel using 4 processors. If you wish, you can save yourself a bit of typing by editing your ~/.bashrc file and adding the line export COMPILER=gfortran at the top of the file. Then the command would just be make -j4.\nThe most commonly used compiler on clusters these days is the Intel FORTRAN compiler. You can compile by typing make COMPILER=intel or edit your ~/.bashrc file to add the line export COMPILER=intel at the top.\nYou should rarely need to edit the Makefile more than this. Occasionally, you may need to change fundamental behavior of the code by changing the list of flags in the \u0026ldquo;DEFINES\u0026rdquo; entry. This is documented in the User manual.\nRunning the code Once you have built the version of EPOCH that you want (1D, 2D or 3D) you simply run it by typing ./bin/epoch1d, ./bin/epoch2d, or ./bin/epoch3d. That will then show you the EPOCH splash page, which prints the logo, lists any compile time options that you specified and then asks you to specify the output directory. It will look in this directory for a file with the name \u0026ldquo;input.deck\u0026rdquo; containing the problem setup. Any output performed by the code will also be written into this directory. To work through the examples, you must download an input deck from the section below to the directory you want EPOCH to use and rename the file \u0026ldquo;input.deck\u0026rdquo;. Throughout this guide we will assume that you use the directory named \u0026ldquo;Data\u0026rdquo;.\nGetting the example decks for this workshop The example input decks used in this workshop can be downloaded using the following links. Create a directory \u0026ldquo;~/EXAMPLES\u0026rdquo; to put them in:\ncd . mkdir EXAMPLES  then download the .zip to this folder (either click the link and then copy the file, or right-click and select the save-as option). All decks as a .zip\n 01-1d_laser.deck - A simple laser\n 02-2d_laser.deck - A simple 2d laser\n 03-1d_two_stream.deck - A simple two-stream instability\n 04-1d_two_stream_io.deck - The same two-stream instability with extended output\n 05-2d_moving_window.deck - Simple moving-window problem with density jump and laser\n 06-2d_ramp.deck - Gaussian laser into a density ramp\n 07-1d_heating.deck - Demonstration of numerical heating\nA Basic EM-Field Simulation Our first example problem will be a simple 1D domain with a laser. This should give you a simple introduction to the input deck and visualization of 1D datasets.\nBegin by copying the \u0026ldquo;01-1d_laser.deck\u0026rdquo; file from the EXAMPLES directory into the \u0026ldquo;Data\u0026rdquo; directory using the command: cp ~/EXAMPLES/01-1d_laser.deck Data/input.deck\n Or click to expand and copy this text into a file \"input.deck\" in your Data directory. begin:control nx = 200 # Size of domain x_min = -4 * micron x_max = -x_min # Final time of simulation t_end = 50 * femto #stdout_frequency = 10 end:control begin:boundaries bc_x_min = open #bc_x_min = simple_laser bc_x_max = open end:boundaries #begin:laser # boundary = x_min # intensity_w_cm2 = 1.0e15 # lambda = 1 * micron # phase = pi / 2 # t_profile = gauss(time, 2*micron/c, 1*micron/c) # t_end = 4 * micron / c #end:laser # # #begin:output # dt_snapshot = 1 * micron / c # # # Properties on grid # grid = always # ey = always #end:output   Open the input deck with an editor to view its contents. Eg. \u0026ldquo;gedit Data/input.deck\u0026rdquo;\nThis is the simplest possible input deck. The file is divided into blocks which are surrounded by \u0026ldquo;begin:blocktype\u0026rdquo; and \u0026ldquo;end:blocktype\u0026rdquo; lines. There are currently ten different blocktypes. The most basic input deck requires only two.\nThe first block is the \u0026ldquo;control\u0026rdquo; block. This is used for specifying the domain size and resolution and the length of time to run the simulation. There are also some global simulation parameters that can be specified in this block which will be introduced later. Within the block, each parameter is specified as a \u0026ldquo;name = value\u0026rdquo; pair.\nThe parameters are as follows. \u0026ldquo;nx\u0026rdquo; specifies the number of grid points in the x-direction (since this is a 1D code, the grid is only defined in the x-direction). \u0026ldquo;x_min\u0026rdquo; and \u0026ldquo;x_max\u0026rdquo; give the minimum and maximum grid locations measured in meters. Since most plasma simulations are measured in microns, there is a \u0026ldquo;micron\u0026rdquo; multiplication factor for convenience. There are also multiplication factors for \u0026ldquo;milli\u0026rdquo; through to \u0026ldquo;atto\u0026rdquo;. Finally, the simulation time is specified using \u0026ldquo;t_end\u0026rdquo; measured in seconds.\nThere are also commented lines in the deck. Any text following the \u0026ldquo;#\u0026rdquo; character is ignored. The character may appear anywhere on a line, so in the following example: t_end = 50 #* femto The value of \u0026ldquo;t_end\u0026rdquo; will be set to 50 seconds, since \u0026ldquo;#* femto\u0026rdquo; is ignored.\nThe other required block is the \u0026ldquo;boundaries\u0026rdquo; block. This contains one entry for each boundary, specifying what boundary condition to apply. For the 1D code there are two boundaries: \u0026ldquo;bc_x_min\u0026rdquo; and \u0026ldquo;bc_x_max\u0026rdquo;. The deck currently has both of these set to use open boundary conditions.\nTo run the code type: echo Data | mpiexec -n 4 ./bin/epoch1d\nThis will run epoch1d in parallel using 4 processors. It will use the directory named \u0026ldquo;Data\u0026rdquo; for all its output and will read the file \u0026ldquo;Data/input.deck\u0026rdquo; to obtain the simulation setup.\nThis simulation is rather dull. It is just a grid with zero electromagnetic field and it generates no data files. After running the program, two files are generated in the \u0026ldquo;Data\u0026rdquo; directory. The \u0026ldquo;deck.status\u0026rdquo; file contains the results from the deck parsing routines and is only useful for debugging. The \u0026ldquo;epoch1d.dat\u0026rdquo; file contains a terse one line header with the code name, version information and time the job started followed by a list of output dumps generated during the run.\nStatus information about the running job can be requested by uncommenting the \u0026ldquo;stdout_frequency\u0026rdquo; line in the \u0026ldquo;control\u0026rdquo; block. This is achieved by using a text editor to remove the \u0026ldquo;#\u0026rdquo; character and saving the file.\nAdding a laser We will now edit this input deck to add a laser source to the left hand boundary and dump some output files.\n Open the \u0026ldquo;Data/input.deck\u0026rdquo; file with an editor. Add a \u0026ldquo;#\u0026rdquo; comment character to the beginning of the first \u0026ldquo;bc_x_min\u0026rdquo; line in the \u0026ldquo;boundaries\u0026rdquo; block. Uncomment the line \u0026ldquo;bc_x_min = simple_laser\u0026rdquo; Uncomment the remaining lines in the file.  The change to the \u0026ldquo;boundaries\u0026rdquo; block instructs the code to add a laser source to the left-hand boundary.\nThe Laser Block We then require a new block, named \u0026ldquo;laser\u0026rdquo;, to set up the laser source. The parameters in this block do the following:\n boundary \u0026ndash; Specifies the boundary on which to attach this laser source intensity_w_cm2 \u0026ndash; Specifies the intensity of the laser in Watts / cm^2 lambda \u0026ndash; Gives the wavelength of the laser in meters. We have used the multiplication factor \u0026ldquo;micron\u0026rdquo; for readability phase \u0026ndash; Specifies the phase shift of the laser. t_profile \u0026ndash; This parameter is used to modify the amplitude of the laser over time. It is usually used to ramp a laser up or down gradually. The left-hand side will be a function of time, usually ranging between zero and one. t_end \u0026ndash; The time at which to switch off the laser.  These parameters are mostly self-explanatory. The \u0026ldquo;t_profile\u0026rdquo; parameter is best explained using an example. The figure above shows the result of using a gaussian time profile. The red line shows the value of \u0026ldquo;t_profile\u0026rdquo; over time. This starts at a value close to zero, ramps up to one and then ramps back down to zero. The green line shows the amplitude of the laser when \u0026ldquo;t_profile\u0026rdquo; has not been specified. Note that the function would normally be a sine wave, but this has been shifted by pi/2 because the \u0026ldquo;phase\u0026rdquo; parameter was used. The blue line shows the laser amplitude generated when the \u0026ldquo;t_profile\u0026rdquo; gaussian profile is applied.\nThe Output Block The final addition is the \u0026ldquo;output\u0026rdquo; block. We will cover this in more detail later. For now, it is sufficient to know that this is the block which controls the generation of data output. The parameters used in this case are:\n dt_snapshot \u0026ndash; This specifies the simulation time between each output dump grid \u0026ndash; This controls when to dump the simulation grid. The value of \u0026ldquo;always\u0026rdquo; means that the grid will be output whenever there is a new output dump generated. ey \u0026ndash; The controls when to dump the y-component of the electric field.  Visualising the data Now that we have generated some data we need to plot it. The data is written to a self-describing file format called SDF. This has been developed for use by several codes maintained at the University of Warwick. There are routines for reading the data from within IDL, VisIt, MatLab and Python.\nMore complete documentation on visualisation routines is available here\nLoading the data into IDL/GDL First, we will load the data into IDL/GDL. The desktop machines have GDL installed \u0026ndash; the GNU Data Language, which is a free implementation of IDL. It doesn\u0026rsquo;t have all the feature of IDL but the core routines and syntax are identical. Type gdl Start.pro and GDL will start up and load the SDF reading library. To view the data contained in a file, type list_variables,7,'Data' Here, \u0026ldquo;7\u0026rdquo; is the snapshot number. It can be any number between 0 and 9999. The second parameter specifies the directory which holds the data files. If it is omitted then the directory named \u0026ldquo;Data\u0026rdquo; is used by default.\nTo load the data and assign the result to a structure named \u0026ldquo;data\u0026rdquo;, just issue the following command: data = getstruct(7,/varname) Here, \u0026ldquo;/varname\u0026rdquo; is any of the variables listed by the previous command. This will just read the \u0026ldquo;varname\u0026rdquo; variable into the data structure. However, it is usually easiest just to omit the \u0026ldquo;/varname\u0026rdquo; flag. If it is omitted then the entire contents of the file is read.\nThe \u0026ldquo;getstruct\u0026rdquo; command returns a hierarchical data structure. The contents of this structure can be viewed with the following command: help,data,/struct For the current example the result of this command is the following:\n GDL\u0026gt; help,data,/struct ** Structure \u0026lt;Anonymous\u0026gt;, 8 tags, data length=5552: FILENAME STRING 'Data/0007.sdf' TIMESTEP LONG 185 TIME DOUBLE 2.3449556e-14 HEADER STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] ELAPSED_TIME STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] EY STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] GRID STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] X DOUBLE Array[200]  The first few entries are fairly self-explanatory. The seventh item is a 1D array containing the cell-centred grid positions. The fiftth item is a structure containing a 1D array of Ey at these positions. This structure can be queried in the same way as \u0026ldquo;data\u0026rdquo; :\n GDL\u0026gt; help,data.ey,/struct ** Structure \u0026lt;Anonymous\u0026gt;, 2 tags, data length=1728: METADATA STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] DATA DOUBLE Array[200]  The raw data is contained in the \u0026ldquo;data\u0026rdquo; entry. The sixth entry, \u0026ldquo;GRID\u0026rdquo; is a structure which contains :\nGDL\u0026gt; help,data.grid,/struct ** Structure \u0026lt;Anonymous\u0026gt;, 5 tags, data length=1824: METADATA STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] X DOUBLE Array[201] LABELS STRING Array[1] UNITS STRING Array[1] NPTS LONG Array[1]  This is the node-centred grid along with its metadata. The cell-centred array shown previously is derived from this. Finally, the HEADER entry contains metadata about the code and runtime information.\nThe above plot can be generated by issuing the following command: plot,data.x,data.ey.data There are more examples on using idl/gdl in the manual.\nLoading the data into Python EPOCH also ships with a module for reading SDF data into python. To build this module, change directory to epoch/epoch1d (or 2d,3d) and type \u0026ldquo;make sdfutils\u0026rdquo;. This will build the python reader and install it locally. It also installs a helper module which adds a few user-friendly routines. To simplify discussion, we will just focus on using this helper routine.\nOpen a python interpreter by typing \u0026ldquo;python\u0026rdquo;, or preferably \u0026ldquo;ipython\u0026rdquo; if you have it installed.\nOn the desktops, the sdf and sdf_helper modules will be imported for you, as sdf and sdf_helper respectively. On other machines, to load the SDF module, type the command:\nimport sdf_helper as sh  You can now load a data file by typing:\ndata = sh.getdata(7)  or\ndata = sdf_helper.getdata(7)  This returns a data structure which can be inspected using\ndata.__dict__  It also imports the contents of data arrays and prints a summary of what has been imported.\nFor example:\nfrom sdf_helper import * data = getdata(7) #\u0026gt;\u0026gt;Reading file Data/0007.sdf t() = time ey(200,) = ey x(201,) = grid xc(200,) = grid_mid  If you have matplotlib installed then you can load the module using\nfrom matplotlib.pyplot import *  Turn on interactive plotting with\nion()  You can now plot the data with the command:\nplot(xc,ey)  The helper module has a \u0026ldquo;plot_auto\u0026rdquo; command which automatically adds axis labels. To use this type:\nplot_auto(data.Electric_Field_Ey)  Loading the data into VisIt EPOCH comes with an SDF reader plugin for the VisIt parallel visualization tool. In order to use it, you must first compile the reader to match the version of VisIt installed on your system. To do this, first ensure that the \u0026ldquo;visit\u0026rdquo; command is in your path. This is the case if typing \u0026ldquo;visit\u0026rdquo; on the command line launches the VisIt application. Once you have this setup, you should be able to type \u0026ldquo;make visit\u0026rdquo; from one of the epoch{1,2,3}d directories. You will need to re-do this each time a new version of VisIt is installed on your system.\nLaunch the VisIt application by typing \u0026ldquo;visit\u0026rdquo; on the command line. A useful shortcut is to type visit -o Data/0000.sdf. This will launch VisIt and open the specified data file on startup. Alternatively, you can browse for the file to open using the \u0026ldquo;Open\u0026rdquo; button. All the SDF files in a directory will be grouped together with a green \u0026ldquo;DB\u0026rdquo; icon and the name \u0026ldquo;*.sdf database\u0026rdquo;.\nYou can then plot a quantity by pressing the \u0026ldquo;Add\u0026rdquo; button, selecting the type of plot and the variable to use for the plot. When the plot has been selected, press the \u0026ldquo;Draw\u0026rdquo; button to render it to screen. The plot above was generated by selecting \u0026ldquo;Add-\u0026gt;Curve-\u0026gt;Electric Field-\u0026gt;Ey\u0026rdquo;. Some of the plot properties were adjusted to make it look nicer.\nMore details on using VisIt are here. We recommend that you learn VisIt \u0026ndash; it\u0026rsquo;s free and powerful.\nLoading data into MatLab The EPOCH distribution also comes with a set of reader routines for the MatLab plotting utility. The routines themselves are contained in the \u0026ldquo;Epoch/Matlab\u0026rdquo; directory. It is first necessary to add this directory to your search path. One simple way of doing this is to use the menu item \u0026ldquo;File-\u0026gt;Set Path\u0026rdquo; and then \u0026ldquo;Add Folder\u0026rdquo; to select the location of the \u0026ldquo;Matlab\u0026rdquo; folder. To make this change permanent you have to use the \u0026ldquo;Save\u0026rdquo; button. Unfortunately, on many systems this will not work as it tries to change global settings which will not be permitted on a multi-user setup. On Unix systems (including OS X), the change can be made permanent by using the \u0026ldquo;$MATLABPATH\u0026rdquo; environment variable. For example in bash this would be \u0026lsquo;export MATLABPATH=\u0026ldquo;Epoch/Matlab\u0026rdquo; ' which you can add to your .bashrc file.\nTo load the data from an SDF file, type the following at the MatLab prompt:\ndata=GetDataSDF('Data/0007.sdf');  The \u0026ldquo;data\u0026rdquo; variable will now contain a data structure similar to that obtained with the IDL reader. You can explore the contents of the structure using MatLab\u0026rsquo;s built-in variable editor. To plot Ey, you can browse to \u0026ldquo;data.Electric_Field.Ey\u0026rdquo;. The structure member \u0026ldquo;data.Electric_Field.Ey.data\u0026rdquo; contains the 1D array with Ey values. Right-clicking on it gives a range of options, including \u0026ldquo;plot\u0026rdquo;. Alternatively, from the command prompt you can type\nx=data.Electric_Field.Ey.grid.x; xc=(x(1:end-1) + x(2:end))/2; plot(xc,data.Electric_Field.Ey.data);  The first two lines set up a cell-centred grid using the node-centred grid data. In the future, this work will be automatically done by the reader.\nA 2D laser Next, we will take a look at the 2-dimensional version of the code.\n Change to the epoch2d directory: cd ~/Epoch/epoch2d Type make -j4 to compile the code. Copy the next example input deck into the Data directory: cp ~/EXAMPLES/02-2d_laser.deck Data/input.deck or save the text below into Data/input.deck Run with echo Data | mpirun -np 4 ./bin/epoch2d   Click to expand begin:control nx = 500 ny = nx # Size of domain x_min = -10 * micron x_max = -x_min y_min = x_min y_max = x_max # Final time of simulation t_end = 50 * femto stdout_frequency = 10 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = open bc_y_min = periodic bc_y_max = periodic end:boundaries begin:constant lambda0 = 1 * micron theta = pi / 8.0 end:constant begin:laser boundary = x_min intensity_w_cm2 = 1.0e15 lambda = lambda0 * cos(theta) profile = gauss(y, 0, 4*micron) #phase = -2.0 * pi * y * tan(theta) / lambda0 #t_profile = gauss(time, 2*micron/c, 1*micron/c) end:laser begin:output dt_snapshot = 1 * micron / c # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always end:output   This deck is very similar to the 1D version that we have just looked at. It contains the necessary modifications for adding a new dimension and some additions to the laser block for driving a laser at an angle.\nThe \u0026ldquo;control\u0026rdquo; block now contains \u0026ldquo;ny\u0026rdquo; which specifies the number of grid points in the y-direction. Notice that we are using the value \u0026ldquo;nx\u0026rdquo; to set \u0026ldquo;ny\u0026rdquo;. As soon as \u0026ldquo;nx\u0026rdquo; has been assigned it becomes available as a constant for use as part of a value. We must also provide the minimum and maximum grid positions in the y-direction using \u0026ldquo;y_min\u0026rdquo;, \u0026ldquo;y_max\u0026rdquo;. Like \u0026ldquo;nx\u0026rdquo;, the values \u0026ldquo;x_min\u0026rdquo; and \u0026ldquo;x_max\u0026rdquo; are available for use once they have been assigned.\nIn the \u0026ldquo;boundaries\u0026rdquo; block we must include boundary conditions for the lower and upper boundaries in the y-direction, \u0026ldquo;bc_y_min\u0026rdquo;, \u0026ldquo;bc_y_max\u0026rdquo;. These have both been set to \u0026ldquo;periodic\u0026rdquo; so that the field at the top of the domain wraps around to the bottom of the domain.\nNext, we introduce a new block type, \u0026ldquo;constant\u0026rdquo;. This block defines named variables which can be arbitrary mathematical expressions. Once defined, these can be used on the left-hand side of name-value pairs in the same way we used \u0026ldquo;nx\u0026rdquo;, \u0026ldquo;x_min\u0026rdquo;, etc. in the \u0026ldquo;control\u0026rdquo; block. This facility can greatly aid the construction and maintenance of complex input decks.\nThe \u0026ldquo;laser\u0026rdquo; block is similar to that given in the 1D version except that there is now a \u0026ldquo;profile\u0026rdquo; parameter. In a similar manner to \u0026ldquo;t_profile\u0026rdquo; this is a function ranging between 0 and 1 which is multiplied by the wave amplitude to give a modified laser profile. The only difference is that this is a function of space rather than time. When applied to a laser attached to \u0026ldquo;x_min\u0026rdquo; or \u0026ldquo;x_max\u0026rdquo; it is a function of Y, defined at all points along the boundary. When the laser is attached to \u0026ldquo;y_min\u0026rdquo; or \u0026ldquo;y_max\u0026rdquo;, it is a function of X.\nFinally, the output block has been modified so that it outputs all electromagnetic field components.\nThe result of plotting \u0026ldquo;Add-\u0026gt;Pseudocolor-\u0026gt;Electric Field-\u0026gt;Ey\u0026rdquo; in VisIt is shown above. The laser block also contains a commented-out \u0026ldquo;phase\u0026rdquo; entry. Unlike in the 1D version seen previously, this is a function of Y, like the \u0026ldquo;profile\u0026rdquo; parameter. Uncommenting this line and re-running the deck will generate a laser driven at an angle to the boundary. The mathematical details explaining why this works are explained in more detail in the User Manual. By making the value of \u0026ldquo;theta\u0026rdquo; a function of Y, it is also possible to produce a focused laser. This is left as an exercise for the reader!\nThe above plot can also be generated using matplotlib using the command plot2d(data.Electric_Field_Ey)\nSpecifying particle species In this example we will finally introduce some particles into the PIC code! The deck is for the 1D version of the code, so change back to the epoch1d directory and copy ~/EXAMPLES/03-1d_two_stream.deck to Data/input.deck (or copy the deck below) and run the code.\n Click to expand begin:control nx = 400 # Size of domain x_min = 0 x_max = 5.0e5 # Final time of simulation t_end = 1.5e-1 stdout_frequency = 400 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:constant drift_p = 2.5e-24 temp = 273 dens = 10 end:constant begin:species # Rightwards travelling electrons name = Right charge = -1 mass = 1.0 temp = temp drift_x = drift_p number_density = dens npart = 4 * nx end:species begin:species # Leftwards travelling electrons name = Left charge = -1 mass = 1.0 temp = temp drift_x = -drift_p number_density = dens npart = 4 * nx end:species begin:output # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties at particle positions particles = always px = always # Properties on grid grid = always ey = always end:output   The control block has one new parameter. \u0026ldquo;npart\u0026rdquo; gives the total number of PIC particles to use in the simulation.\nThe input deck contains a new block type, \u0026ldquo;species\u0026rdquo;, which is used for populating the domain with particles. Every species block must contain a \u0026ldquo;name\u0026rdquo; parameter. This is used to identify the particle species in other sections of the input deck and is also used for naming variables in the output dumps. The next parameter is \u0026ldquo;charge\u0026rdquo; which gives the charge on each particle in terms of elementary charge units. \u0026ldquo;mass\u0026rdquo; is specified in units of electron mass. \u0026ldquo;frac\u0026rdquo; is the fraction of the total number of PIC particles (npart) to assign to this species. Both of the blocks in this deck use \u0026ldquo;frac = 0.5\u0026rdquo;, so there will be 1600 particles of each species. The next parameter, \u0026ldquo;temp\u0026rdquo;, sets the average temperature of the particle species in Kelvin. Alternatively, you can use \u0026ldquo;temp_ev\u0026rdquo; to specify the temperature in electronvolts. Particles are assigned an initial momentum corresponding to a Maxwell-Boltzmann distribution for this temperature. It is defined across the entire problem domain, so in 1D it is a function of X, in 2D a function of X and Y, and in 3D a function of X, Y and Z. \u0026ldquo;number_density\u0026rdquo; sets the number density across the problem domain. The code is set to use per-particle weights in the default Makefile. With this option, the pseudoparticles are distributed evenly across the domain. Then the weight of each pseudoparticle is adjusted so that it matches the number density specified in the \u0026ldquo;number_density\u0026rdquo; parameter. The alternative option is to disable per-particle weighting. In this case, the weight of each pseudoparticle is the same and the particles are placed on the grid so that they match the number density at the start of the simulation. Finally, we have a \u0026ldquo;drift_x\u0026rdquo; parameter. This is also defined across the entire problem domain and is used to give the particles an average momentum drift in the x-direction. There are similar \u0026ldquo;drift_y\u0026rdquo; and \u0026ldquo;drift_z\u0026rdquo; parameters.\nThis deck has been designed to simulate a two-stream instability, so it has two groups of particles which are identical in every respect except that one set is drifting in the opposite direction to the other. In the output block we have added a couple of parameters for outputting particle data. The first parameter, \u0026ldquo;particles\u0026rdquo;, outputs the grid on which the particles are defined. There are two different types of variable in EPOCH: particle variables and grid-based variables. The grid-based variables are like the electromagnetic field components we have seen previously. The domain is divided into a regular Cartesian mesh and the grid-based variables are defined at either a node or cell-centre of each point in this mesh. Particle variables, on the other hand, are associated with each of the pseudoparticles. These PIC particles move independently of the Cartesian mesh and can be located anywhere in the problem domain. The \u0026ldquo;particles\u0026rdquo; parameter requests that the coordinates of each particle are written to file. This information is required in order to plot any of the particle variables. The next parameter is \u0026ldquo;px\u0026rdquo; which writes the momentum of each particle.\nTo plot this using python and matplotlib, type the following:\ndata = getdata(30) plot1d(data.Particles_Px_Left,'r.',ms=2,yscale=1) oplot1d(data.Particles_Px_Right,'b.',ms=2,yscale=1) ylim([-6e-24,6e-24])  To plot with GDL, type the following:\ngdl Start.pro data=getstruct(30) plot,data.grid_right.x,data.px_right.data,psym=3,$ yrange=[-6e-24,6e-24],ystyle=1 oplot,data.grid_left.x,data.px_left.data,psym=3,color=150  Above we have plotted the x-component of particle momentum as a function of x-position at a time when the instability is just starting to form. The \u0026ldquo;psym=3\u0026rdquo; option to the plot routine tells GDL to plot each data point as a dot and not to join the dots up.\nThe Output Block The contents of the output block can be much more complicated than the examples shown so far. Here, we will cover the options in a little more depth.\nEPOCH currently has three different types of output dump. So far, we have only been using the \u0026ldquo;normal\u0026rdquo; dump type. The next type of dump is the \u0026ldquo;full\u0026rdquo; dump. To request this type of dump, you add the parameter \u0026ldquo;full_dump_every\u0026rdquo; which is set to an integer. If this was set equal to \u0026ldquo;10\u0026rdquo; then after every 9 dump files written, the 10th dump would be a \u0026ldquo;full\u0026rdquo; dump. This hierarchy exists so that some variables can be written at frequent intervals whilst large variables such as particle data are written only occasionally. The third dump type is the \u0026ldquo;restart\u0026rdquo; dump. This contains all the variables required in order to restart a simulation, which includes all the field variables along with particle positions, weights and momentum components. In a similar manner to full dumps, the output frequency is specified using the \u0026ldquo;restart_dump_every\u0026rdquo; parameter.\nSo far, we have given all the variable parameters a value of \u0026ldquo;always\u0026rdquo; so that they will always be dumped to file. There are three other values which can be used to specify when a dump will occur. \u0026ldquo;never\u0026rdquo; indicates that a variable should never be dumped to file. This is the default used for all output variables which are not specified in the output block. The value of \u0026ldquo;full\u0026rdquo; indicates that a variable should be written at full dumps. \u0026ldquo;restart\u0026rdquo; means it is written into restart dumps.\nThere are a few output variables which are grid-based quantities derived by summing over properties for all the particles contained within each cell on the mesh. These are \u0026ldquo;ekbar\u0026rdquo;, \u0026ldquo;mass_density\u0026rdquo;, \u0026ldquo;charge_density\u0026rdquo;, \u0026ldquo;number_density\u0026rdquo; and \u0026ldquo;temperature\u0026rdquo;. To find more details about these variables, consult the output block section of the user manual.\nOther Laser-Plasma example decks  Continue the examples\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"1d41a763e549cd5ac4399b5a8e67d90c","permalink":"/documentation/examples/workshop_examples.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples/workshop_examples.html","section":"documentation","summary":"EPOCH workshop overview The aims of the Workshop are:\n After the workshop you should be able to setup and run EPOCH on a problem of real importance to your research.","tags":null,"title":"Workshop examples","type":"docs"},{"authors":null,"categories":null,"content":"Other Laser-Plasma example decks Now that you have a basic understanding of how the input decks work, you should be able to work through the remaining example decks by referring to the User manual for a description of any new parameters used. Several experienced users of the code will be available throughout the duration of the workshop, so if you want help with anything please don\u0026rsquo;t hesitate to ask. The decks are:\n 01-1d_laser.deck Described in notes above (here) 02-2d_laser.deck Described in notes above (here) 03-1d_two_stream.deck Described in notes above (here) 04-1d_two_stream_io.deck This is the same as the previous deck but with the addition of more sophisticated output diagnostics 05-2d_moving_window.deck This deck contains an example of firing a laser into a plasma and then using the moving window facility to track the wave front as it moves beyond the edge of the original domain. 06-2d_ramp.deck This deck contains an example of firing a laser at a plasma with a ramped density profile. 07-1d_heating.deck This deck contains a setup for investigating the anomalous heating of a plasma that occurs for purely resolved systems.  Other things to try  Landau damping predicts collisionless damping of electrostatic waves. Setup a 1D problem with an electrostatic wave and check for a range of wavelengths. Points to note:  Does the answer depend on whether the initial condition is a travelling wave or standing wave? How are these setup? Look for trapping in the Langmuir wave Check the damping rate against published formulae. Try for a range of $k\\lambda_D$ as the most commonly reported formulae assume $k_D1$ The answer is more accurate, assuming you have enough grid-points and particles to get a good answer, if you ignore the first maxima or two \u0026ndash; why?   A more realistic instability than the two cold beams tested above is the bump-on-tail instability. Setup a 1D bump-on-tail distribution and check that the simple formula for the growth-rates is correctly reproduced. The main problem with the initial conditions is how to setup a suitable initial distribution. Try setting up the initial conditions for a problem of direct relevance to your research. This may be too computationally demanding to run on the workshop computers but it is a good exercise as you can get some help on trickier input decks and diagnostic planning than the simple exercises so far. Check that EPOCH works as expected on your host institution computer. If not we may be able to help before you leave.  Copies of the decks The decks can be downloaded here and viewed or copied from here:\n 04-1d_two_stream_io.deck (click to expand) begin:control nx = 400 # Size of domain x_min = 0 x_max = 5.0e5 # Final time of simulation t_end = 1.5e-1 stdout_frequency = 400 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:constant drift_p = 2.5e-24 temp = 273 dens = 10 end:constant begin:species # Rightwards travelling electrons name = Right charge = -1 mass = 1.0 temp = temp drift_x = drift_p number_density = dens npart = 4 * nx end:species begin:species # Leftwards travelling electrons name = Left charge = -1 mass = 1.0 temp = temp drift_x = -drift_p number_density = dens npart = 4 * nx end:species begin:output name = normal # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties at particle positions particles = always px = always # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always ekbar = always mass_density = never + species charge_density = always number_density = always + species temperature = always + species distribution_functions = always end:output begin:output name = restart # Number of timesteps between output dumps dt_snapshot = 0.15 restartable = T end:output begin:dist_fn name = x_px ndims = 2 direction1 = dir_x direction2 = dir_px # Range is ignored for spatial coordinates range1 = (1, 1) range2 = (-5e-24, 5e-24) # Resolution is ignored for spatial coordinates resolution1 = 1 resolution2 = 200 include_species:Left include_species:Right end:dist_fn    05-2d_moving_window.deck (click to expand) begin:constant x0 = 20 * micron lambda = 10 * micron t_laser = 120 * femto sigma_t = t_laser / 2 / sqrt(loge(2)) w0_laser = 30 * micron sigma_w0 = w0_laser / 2 / sqrt(loge(2)) den_peak = 5.0e19 * 1.0e6 win_start = 340 * femto end:constant begin:control nx = 1550 / 8 ny = 600 / 8 npart = (60e6) / 8 # Size of domain x_min = 0 x_max = 155 * micron y_min = -30 * micron y_max = -y_min # Final time of simulation t_end = 1600 * femto stdout_frequency = 1 print_eta_string = T end:control begin:boundaries bc_x_min = simple_laser bc_x_max = simple_outflow bc_y_min = simple_outflow bc_y_max = simple_outflow end:boundaries begin:species name = electron charge = -1.0 mass = 1.0 number_density = if((x lt x0), 0.0, den_peak) frac = 0.5 end:species begin:species name = proton charge = 1.0 mass = 1836.2 number_density = number_density(electron) frac = 0.5 end:species begin:output name = normal dt_snapshot = 50 * femto grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always jy = always ekbar = always mass_density = never + species charge_density = always number_density = always + species temperature = always + species end:output begin:output name = large dt_snapshot = 500 * femto particles = always particle_weight = always end:output begin:laser boundary = x_min intensity_w_cm2 = 1.9e18 lambda = lambda t_profile = gauss(time, 2*sigma_t, sigma_t) profile = gauss(y, 0, sigma_w0) end:laser begin:window move_window = T window_v_x = c * 0.87 window_start_time = win_start bc_x_min_after_move = simple_outflow bc_x_max_after_move = simple_outflow end:window    06-2d_ramp.deck (click to expand) begin:constant # Particles per cell part = 32 las_lambda = 1 * micron las_omega = 2.0 * pi * c / las_lambda las_time = 2.0 * pi / las_omega n_crit = critical(las_omega) max_dens = 0.8 * n_crit scale_x = 20 * micron las_scale_y = 8 * micron xmin = -4 * micron # Gaussian Beam stuff w0 = las_scale_y rayleigh_range = pi * w0^2 / las_lambda wz = w0 * sqrt(1 + (x_start / rayleigh_range)^2) radius_of_curvature = x_start * (1.0 + (rayleigh_range / x_start)^2) end:constant begin:control nx = 1024 / 4 ny = 512 / 4 # Final time of simulation t_end = 0.4 * pico # Size of domain x_min = xmin x_end = scale_x + 20 * micron y_min = -20 * micron y_max = -y_min stdout_frequency = 10 end:control begin:laser boundary = x_min intensity_w_cm2 = 1.0e16 omega = las_omega t_profile = if (time lt 2*las_time, gauss(time, 2*las_time, 2*las_time), 1) profile = (1.0 + 0.05 * sin(32.0*pi*y/lengthy)) * gauss(y, 0, las_scale_y) end:laser begin:boundaries bc_x_min = simple_laser bc_x_max = simple_outflow bc_y_min = periodic bc_y_max = periodic end:boundaries begin:species # Electron name = electron charge = -1.0 mass = 1.0 npart = nx * ny * part number_density = max_dens * (exp(x/scale_x) - 1) / (exp(1) - 1) number_density = if(x lt 0, 0.0, number_density(electron)) number_density = if(number_density(electron) gt max_dens, max_dens, \\ number_density(electron)) number_density = if(x gt 75*micron, 0.0, number_density(electron)) #number_density = number_density(electron) \\ * (0.8 + 0.2 * gauss(y, 0, 0.5*las_scale_y)) number_density_min = 0.0001 * n_crit number_density_max = n_crit temp_ev = 10^3 end:species begin:species # Protons name = proton charge = 1.0 mass = 1836.2 npart = nx * ny * part number_density = number_density(electron) number_density_min = 0.0001 * n_crit number_density_max = 1.2 * n_crit temp_ev = 40 end:species begin:output name = normal # Number of timesteps between output dumps dt_snapshot = 5 * femto # Properties at particle positions particles = always px = always particle_weight = always # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always jy = always jz = always ekbar = always + species mass_density = never + species charge_density = always # + average + snapshot number_density = always + species temperature = never + species # Extended io distribution_functions = always end:output begin:dist_fn name = en ndims = 1 direction1 = dir_en range1 = (0, 15*kev) resolution1 = 5000 include_species:electron end:dist_fn begin:dist_fn name = x_en ndims = 2 direction1 = dir_x direction2 = dir_en # Range is ignored for spatial coordinates #range1 = (1, 1) range2 = (0, 15*kev) # Resolution is ignored for spatial coordinates #resolution1 = 1 resolution2 = 1500 include_species:electron end:dist_fn begin:dist_fn name = x_px ndims = 2 direction1 = dir_x direction2 = dir_px # Range is ignored for spatial coordinates #range1 = (1, 1) range2 = (-5e-23, 5e-23) # Resolution is ignored for spatial coordinates #resolution1 = 1 resolution2 = 1500 include_species:electron end:dist_fn begin:probe name = electron_probe point = (0.5 * (x_max + x_min), y_min) normal = (1, 0) include_species:electron include_species:proton end:probe    07-1d_heating.deck (click to expand) begin:constant dl = 74.33942 * micron end:constant begin:control nx = 10 # Size of domain x_min = 0 x_max = 14000 * dl # Final time of simulation t_end = 1.5e-2 stdout_frequency = 10000 print_eta_string = T end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:species name = electron charge = -1 mass = 1.0 temp_x_ev = 1 number_density = 1e16 npart = nx * 5 end:species begin:output name = normal # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties on grid grid = always ekbar = always temperature = always end:output begin:output name = large # Number of timesteps between output dumps dt_snapshot = 75e-3 # Properties at particle positions particles = always px = always py = always pz = always end:output   Remote Visualisation with VisIt If the local workstation you are using isn\u0026rsquo;t big enough for your test problems you may also use a your host institutes HPC cluster.\nRemote Visualisation with VisIt Most large simulations are carried out on a remotely located machine. Often this machine is located many miles away, perhaps even in a different country. Viewing data on remote systems can be awkward and poor network speeds can often make it nearly impossible. The VisIt visualisation tool solves this problem by using a client-server model. The program which reads, processes and renders the data is completely separated from the program which displays the results on the screen. It is therefore possible to run VisIt on your local machine and look at data located on a different machine. The method of setting this up varies depending on the configuration of the remote machine so we will not go into details here. However, the desktop machines have been setup to be able to view data located on remote clusters so you can try it out.\nIn the VisIt control window, click the \u0026ldquo;Open\u0026rdquo; button which launches a file browser window. The first entry is called \u0026ldquo;Host\u0026rdquo; and contains a drop-down list of all configure remote machines.\nIf you want to know more about how to set up remote visualisation in VisIt, you can ask one of the Warwick staff members.\nWhen viewing data across a slow network connection, there is one more useful thing to know. VisIt has two methods of drawing plots generated on a remote machine. The first method is to construct the polygons used in drawing the plot on the remote machine and send them across the network. The local machine then turns these into a plot image. This makes manipulating the figure very fast (zooming, rotating, etc), since all the polygons that generate the image are on the local machine. However, if there are a lot of polygons then they can be slow to transfer across the network. They can also use up a lot of memory. For these cases, the alternative is to render the image on the remote machine and just transfer the image across the network. The downside of this approach is that whenever you manipulate the plot, it must be re-drawn on the remote machine and then transferred across the network again. The options controlling this behaviour are to be found under \u0026ldquo;Options-\u0026gt;Rendering\u0026rdquo; in the \u0026ldquo;Advanced\u0026rdquo; tab. The feature is called \u0026ldquo;scalable rendering\u0026rdquo;.\nCollisions in EPOCH EPOCH now contains a collision routine based on the technique outlined in Sentoku \u0026amp; Kemp1\nCollisions are enabled using the output block named collisions which accepts the following three parameters.\n use_collisions \u0026ndash; This is a logical flag which determines whether or not to call the collision routine. If omitted, the default is \u0026ldquo;true\u0026rdquo; if any of the frequency factors are non-zero (see below) and \u0026ldquo;false\u0026rdquo; otherwise.   coulomb_log \u0026ndash; This may either be set to a real value, specifying the Coulomb logarithm to use when scattering the particles or to the special value \u0026ldquo;auto\u0026rdquo;. If \u0026ldquo;auto\u0026rdquo; is used then the routine will calculate a value based on the properties of the two species being scattered. If omitted, the default value is \u0026ldquo;auto\u0026rdquo;.   collide \u0026ndash; This sets up a symmetric square matrix of size nspecies*nspecies containing the collision frequency factors to use between particle species. The element (s1,s2) gives the frequency factor used when colliding species s1 with species s2. If the factor is less than zero, no collisions are performed. If it is equal to one, collisions are performed normally. For any value between zero and one, the collisions are performed using a frequency multiplied by the given factor. If \u0026ldquo;collide\u0026rdquo; has a value of \u0026ldquo;all\u0026rdquo; then all elements of the matrix are set to one. If it has a value of \u0026ldquo;none\u0026rdquo; then all elements are set to minus one. If the syntax \u0026ldquo;species1 species2 \u0026rdquo; is used, then the (species1,species2) element of the matrix is set to the factor \u0026ldquo;\u0026rdquo;. This may either be a real number, or the special value \u0026ldquo;on\u0026rdquo; or \u0026ldquo;off\u0026rdquo;. The \u0026ldquo;collide\u0026rdquo; parameter may be used multiple times. The default value is \u0026ldquo;all\u0026rdquo; (ie. all elements of the matrix are set to one).  For example:\nbegin:collisions use_collisions = T coulomb_log = auto collide = all collide = spec1 spec2 off collide = spec2 spec3 0.1 end:collisions  With this block, collisions are turned on and the Coulomb logarithm is automatically calculated. All values of the frequency array are set to one except (spec1,spec2) is set to minus one (and also (spec2,spec1)) and (spec2,spec3) is set to 0.1\nIonisation in EPOCH EPOCH includes field ionization which can be activated by defining \u0026ldquo;field_ionisation = T\u0026rdquo; in the control block along with ionisation energies and an electron for the ionising species in one of the species blocks. This is done via the species block in the \u0026ldquo;ionisation_energies\u0026rdquo; and \u0026ldquo;electron_species\u0026rdquo; parameter respectively. \u0026ldquo;ionisation_energies\u0026rdquo; should be given as a list in joules, and \u0026ldquo;electron_species\u0026rdquo; should be the name of the species to be used as the electron species. For example, ionising carbon species might appear in the input deck as:\nbegin:species charge = 0.0 mass = 1837.2 name = carbon ionisation_energies = \\ (11.26*ev, 24.38*ev, 47.89*ev, 64.49*ev, 392.1*ev, 490.0*ev) electron_species = electron number_density = den_gas end:species begin:species charge = -1.0 mass = 1.0 name = electron number_density = 0.0 end:species  It is possible to define different electron species for each ionisation level, which is particularly useful in monitoring specific ionisation levels. If we wished to monitor the fourth ionisation level of carbon in the above example, the above example might appear:\nbegin:species charge = 0.0 mass = 1837.2 name = carbon ionisation_energies = \\ (11.26*ev, 24.38*ev, 47.89*ev, 64.49*ev, 392.1*ev, 490.0*ev) electron_species = (electron, electron, electron, fourth, electron, electron) number_density = den_gas end:species begin:species charge = -1.0 mass = 1.0 name = electron number_density = 0.0 end:species begin:species charge = -1.0 mass = 1.0 name = fourth number_density = 0.0 end:species  Field ionisation consists of three distinct regimes; multiphoton in which ionisation is best described as absorption of multiple photons, tunneling in which deformation of the atomic coulomb potential is the dominant factor, and barrier suppression ionisation in which the electric field is strong enough for an electron to escape classically. It is possible to turn off multiphoton or barrier suppression ionisation through the input deck by adding \u0026ldquo;use_multiphoton=F\u0026rdquo; and/or \u0026ldquo;use_bsi=F\u0026rdquo; to the control block.\nQED Effects in EPOCH EPOCH has recently been extended to include some quantum electrodynamic effects that are important for high intensity (\u0026gt;) lasers. The two processes that are included are\n Gamma ray production by QED corrected synchrotron emission (Also called magnetic bremsstrahlung or nonlinear Compton scattering). Electron positron pair production by the Breit-Wheeler process from these gamma ray photons.  For more information on the theory see Duclous et al. 2\nSimulating the QED effects increases EPOCH\u0026rsquo;s memory requirements and so the code has to be compiled with the correct compilation options to turn the module on. To turn the module on, open \u0026ldquo;Makefile\u0026rdquo; in an editor and find the commented out line #DEFINES += $(D)PHOTONS. Uncomment this line, then type \u0026ldquo;make clean\u0026rdquo; and then \u0026ldquo;make\u0026rdquo; (remember to include the COMPILER= if you haven\u0026rsquo;t specified the environment variable) to rebuild the code with QED support.\nOnce the code is built with QED support, actually turning on QED for a specific simulation requires the addition of a new block into the input deck. This block is simply called qed and starts with the usual \u0026ldquo;begin:qed\u0026rdquo; and \u0026ldquo;end:qed\u0026rdquo; markers of the other blocks. The parameters which can go into the block are:\n use_qed - Turns QED on or off. If you don\u0026rsquo;t want QED effects at all then compile the code without the \u0026ldquo;-DPHOTONS\u0026rdquo; lines in the makefile. qed_start_time - Specifies the time after which QED effects should be turned on. For example you can turn off the routines until a laser has crossed the vacuum region in front of the target. produce_photons - Specifies whether you\u0026rsquo;re interested in the photons generated by synchrotron emission. If this is F then the radiation reaction force is calculated but the properties of the emitted photons are not tracked. photon_energy_min - Minimum energy of produced photons. Radiation reaction is calculated for photons of all energies, but photons with energy below this cutoff are not tracked. photon_dynamics - If F then photons are generated, but their motion through the domain is not simulated and they stay where they were generated. Photon motion is often less interesting than photon generation unless you want to simulate pair production. In these cases set this to F. produce_pairs - Whether or not to simulate the process of pair generation from gamma ray photons. Both produce_photons and photon_dynamics must be T for this to work. qed_table_location - EPOCH\u0026rsquo;s QED routines use lookup tables to calculate gamma ray emission and pair production. If you want to use tables in a different location from the default put the location in this parameter.  QED also requires that the code now know which species are electrons, positrons and photons. Rather than try to do this automatically the user has to specify the type of a species. This is done by using a single \u0026ldquo;identify\u0026rdquo; tag in a species block. To specify an electron the block in the deck would look like\nbegin:species name = electron frac = 0.5 number_density = 7.7e29 identify:electron end:species  Once the identity of a species is set then the code automatically assigns mass and charge states for the species. At present, the user cannot override these. Possible identities are\n electron : A normal electron species. All species of electrons in the simulation must be identified in this way or they will not generate photons. positron : A normal positron species. All species of positron in the simulation must be identified in this way or they will not generate photons. photon : A normal photon species. One species of this type is needed for photon production to work. If multiple species are present then generated photons will appear in the first species of this type. bw_electron : The electron species for pair production. If a species of this type exists then electrons from the pair production module will be created in this species. If no species of this type is specified then pair electrons will be generated in the first electron species. bw_positron : The positron species for pair production. If a species of this type exists then positrons from the pair production module will be created in this species. If no species of this type is specified then pair positrons will be generated in the first positron species.  A species should be identified only once, so a \u0026ldquo;bw_electron\u0026rdquo; species does not need to also be identified as an \u0026ldquo;electron\u0026rdquo; species. If the code is running with \u0026ldquo;produce_photons=T\u0026rdquo; then a photon species must be created by user and identified. If the code is running with \u0026ldquo;produce_pairs=T\u0026rdquo; then the code must specify at least one electron (or bw_electron) species and one positron (or bw_positron) species. The code will fail to run if the needed species are not specified.\nOther Useful Info Bug reports, feature requests and questions All questions and requests after the workshop should be posted on the GitHub EPOCH project web page\nThe VisIt programme The VisIt programme is free. It can be downloaded from https://wci.llnl.gov/simulation/computer-codes/visit/ There are many pre-compiled binaries so this ought to be easy. If you have any problems post a question on the GitHub EPOCH project.\nGDL not IDL If you don\u0026rsquo;t have IDL, or don\u0026rsquo;t want to pay for it!, then the free GDL is available from http://gnudatalanguage.sourceforge.net/\nUpdating EPOCH To update to the latest version of EPOCH simple cd into your Epoch directory and enter \u0026lsquo;git pull\u0026rsquo;. This will work fine provided you haven\u0026rsquo;t edited any of the Fortran source code. If you have edited the source code then you need to learn git.\nGetting Old Copies of EPOCH You can also checkout an old version of EPOCH, you may want to get the version used 18 months ago to reproduce some previous simulations exactly for example. In this case it is best to checkout a new branch in the EPOCH repository. If you wanted the version from 10 February 2010 for example you would first enter git log --before=2010-02-11 This will give you the log of commits in reverse order, starting on the 11th of February. Identify the commit you want and copy the commit hash (the long string of numbers and letters following the word \u0026ldquo;commit\u0026rdquo;). To checkout a copy of this version of the code, type git checkout -b old-code  After this your repository will reflect the state of the code at that point in time. To get back to the current version, just type git checkout master\nReferences   Y. Sentoku and A. J. Kemp, \u0026ldquo;Numerical methods for particle simulations at extreme densities and temperatures: Weighted particles, relativistic collisions and reduced currents,\u0026rdquo; J. Comput. Phys., 2008. link\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n R. Duclous, J. G. Kirk, and A. R. Bell, \u0026ldquo;Monte carlo calculations of pair production in high-intensity laser plasma interactions,\u0026rdquo; Plasma Phys. Contr. F., vol. 53, no. 1, p. 015009, 2011 1.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"c445cc87f1f7e004fbe4f077cd397e16","permalink":"/documentation/examples/workshop_examples_continued.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples/workshop_examples_continued.html","section":"documentation","summary":"Other Laser-Plasma example decks Now that you have a basic understanding of how the input decks work, you should be able to work through the remaining example decks by referring to the User manual for a description of any new parameters used.","tags":null,"title":"Workshop examples continued","type":"docs"},{"authors":null,"categories":null,"content":"Adding a derived variable Derived variables are variables which are defined on the Cartesian spatial grid but are not directly updated by the solver. They are calculated when needed for output or for use in other physics packages. The final form of a derived variable is an array on each processor with the same size as the field arrays. Examples include number_density, ekbar and poynting_flux.\nA derived variable is defined on the same grid as the main simulation variables and must be written to disk in such a way as to stitch the parts of the grid from each processor together. This is achieved using the routine:\nCALL sdf_write_plain_variable(sdf_handle, id, name, units, dims, stagger, \u0026amp; grid_id, variable, subtype_field, subarray_field)  The parameters have the following types and meanings:\n block_id - The id name of the variable. This character string is a unique identifier for the variable in the file enabling a program to retrieve it later. Once defined it should not change so that newer versions of EPOCH can still identify variables generated by older versions. name - The display name of the variable. This character string is the name that is used by external programs to display an identifying name for the variable. If it contains \u0026lsquo;/\u0026rsquo; characters then these are used by VisIt to group the variables. units - The units of the variable. This character string is used when displaying the data units. For most variables in EPOCH these are SI units. dims - An nD integer array containing the GLOBAL length of the variable across all processors. In EPOCH a variable actually called \u0026ldquo;dims\u0026rdquo; exists for variables which are the same size as the default field variables. stagger - An integer constant containing the stagger of a variable from the cell centre of a cell. This property lets external programs know the position of a variable on the grid. grid_id - The id name of the grid to which the variable is attached. In EPOCH, the main grid is just called \u0026ldquo;grid\u0026rdquo;. Note that this property is case sensitive. variable - The actual variable to be written to disk. subtype_field - This is an MPI type representing the layout of the data across the processors. For a standard field variable, there is an automatically created type called \u0026ldquo;subtype_field\u0026rdquo; which should be used here. subarray_field - This is an MPI type representing the section of the \u0026ldquo;variable\u0026rdquo; parameter to be written. For a standard field variable, there is an automatically created type called \u0026ldquo;subarray_field\u0026rdquo; which should be used here.  It\u0026rsquo;s probably easiest to read the diagnostics.F90 file and see how the code implements the output of simple variables like ex or ey for an example of how this works. Once the appropriate sdf_write call has been added to the code, there is no further work to be done. The IDL, MatLab and VisIt routines will all read the existence of the variable from the metadata in the SDF file, and it will now be available to view in all SDF reading packages.\nThere is a working variable called array which is large enough to store a derived variable. It is therefore recommended that to calculate derived variables a new subroutine should be created which populates array with the required variable and then writes it to disk. An example would look like:\nIF (IAND(dumpmask(c_dump_myvar), code)) THEN CALL calc_my_variable(array) CALL sdf_write_plain_variable(sdf_handle, 'my_var', 'Mine/variable', 'unit', dims, c_stagger_cell_centre, 'grid', array, subtype_field, subarray_field) ENDIF  where calc_my_variable is a function which calculates the variable which you wish to write. The form of this function depends on the type of variable to be calculated and is given in the next section.\nAdding a particle variable The next simplest type of output to add is a new property for all particles. To add new particle variables to the output dump, two things are needed: a call to the SDF command to write the data and an iterator function to iterate through all the particles. NOTE: This section only deals with new outputs for existing particle variables. Creation of a new particle variable is more involved, and requires modifying MPI routines.\nThe iterators are stored in the file iterators.F90. An example iterator is:\n! iterator for particle momenta FUNCTION iterate_px(array, n_points, start) REAL(num) :: iterate_px REAL(num), DIMENSION(:), INTENT(OUT) :: array INTEGER, INTENT(INOUT) :: n_points LOGICAL, INTENT(IN) :: start TYPE(particle), POINTER, SAVE :: cur TYPE(particle_list), POINTER, SAVE :: current_list INTEGER :: part_count IF (start) THEN CALL start_particle_list(current_species, current_list, cur) ENDIF part_count = 0 DO WHILE (ASSOCIATED(current_list) .AND. (part_count .LT. n_points)) DO WHILE (ASSOCIATED(cur) .AND. (part_count .LT. n_points)) part_count = part_count + 1 array(part_count) = cur%part_p(1) cur=\u0026gt;cur%next ENDDO ! If the current partlist is exhausted, switch to the next one IF (.NOT. ASSOCIATED(cur)) CALL advance_particle_list(current_list, cur) ENDDO n_points = part_count iterate_px = 0 END FUNCTION iterate_px  This is a fairly complicated routine which includes code for dealing with the possibility of particle species not being dumped, and other complicated book keeping. Luckily, there is only one line in the routine which needs to change to output a new variable. This being:\narray(part_count) = cur%part_p(1)  To write a new iterator, you just have to copy the skeleton of an existing iterator and change this line to copy your particle property into the \u0026ldquo;array\u0026rdquo; array. The details of the particle structure\u0026rsquo;s contents is explained here. Once your new iterator has been written and added into the iterators.F90 file, it\u0026rsquo;s time to add the SDF routine to actually write the data. The routine is:\nCALL write_particle_variable(c_dump_id, code, name, iterator)  The parameters this time are\n c_dump_id - The index into the dumpmask for this variable. code - The dump code for the current output dump. name - The display name to use for this variable. iterator - The name of the iterator function that you created in the previous step. Note that this is not a string but simply the name of the function.  Once again, looking at how this is implemented for one of the existing variables (e.g. px) is probably the most enlightening way to see how it works. As for the fluid variables, the new variable will appear in IDL, MatLab and VisIt.\nAt this point it is possible to write any property which is similar to the default field variables or the default particle properties. It becomes slightly more challenging if you want to write other types of variable into an output file.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"21846de36394f9dfa3448aebcdd731bc","permalink":"/developer/input_output/adding_outputs.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/input_output/adding_outputs.html","section":"developer","summary":"Adding a derived variable Derived variables are variables which are defined on the Cartesian spatial grid but are not directly updated by the solver. They are calculated when needed for output or for use in other physics packages.","tags":null,"title":"Adding Outputs","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH uses a file format called SDF which was custom developed for use with codes developed by CFSA at the University of Warwick. However, it isn\u0026rsquo;t necessary to have a full understanding of the file format to add the output of new variables to EPOCH. To add a new variable to EPOCH\u0026rsquo;s output, you simply have to use the supplied subroutines of the SDF library which is part of EPOCH. The file output from EPOCH takes place in diagnostics.F90, so to add new variables to the output you must add additional code there. Looking through the listings, you will see two lines:\nCALL sdf_open(sdf_handle, filename, rank, comm, c_sdf_write) CALL sdf_close(sdf_handle)  These, as may be expected, are the commands which open and close the SDF file. It is perfectly possible to create new SDF files containing only your own data. There are various commands in-between which actually write the data into the file. These commands start with sdf_ to ensure that the don\u0026rsquo;t conflict with any other subroutine names in the code. Some more complex areas of I/O, such as the particle probes and the distribution function routines call other subroutines in their respective source files, but these too make use of the SDF routines to actually write data. A user should never try to write data directly to the output file, since this will cause problems with internal parts of the SDF format and generate a nonsensical file.\nThe dumpmask Looking through diagnostics.F90 there are many lines with commands which begin sdf_, but are all prepended with a command which looks like:\nIF (IAND(dumpmask(c_dump_id), code) .NE. 0) THEN  This is the method by which EPOCH allows the end user to specify whether a variable should be dumped, and whether it should only be dumped at full/partial/restart dumps. dumpmask is an integer array, the length of which is defined by the variable num_vars_to_dump in shared_data.F90 and contains the bitmask representing all the types of output which should be written for the associated variable. The possible values in the bitmask are:\n c_io_never - Never dump this variable. c_io_always - Dump this variable at every output dump. c_io_full - Dump this variable at full dumps. c_io_restartable - Dump this variable for restart dumps. c_io_species - If meaningful for this variable, write information for each species rather than integrated over all species. c_io_no_sum - If meaningful for this variable, do not write information integrated over all species. c_io_averaged - If meaningful for this variable, write this variable averaged over time. c_io_snapshot - If meaningful for this variable, write the non-averaged value of the variable.  The c_dump_id entry is a constant defined in shared_data.F90 which identifies the variable\u0026rsquo;s index within this dumpmask.\nWhen adding a new variable to be written to disk, the value of num_vars_to_dump should be increased to match the number of new written variables. Next, open the file src/deck/deck_io_block.F90 and find the line:\nCHARACTER(LEN=entry_length), DIMENSION(io_block_elements) :: \u0026amp; io_block_name = ...  Simply add new strings for your new variables to the end of the definitions along with its c_dump_id value. These new variable names should then be placed in your input decks in the same place as the existing I/O information and take the same parameters.\nPrecompiler directives and the input deck In theory, it is possible for someone to request a feature of the code in the input deck which this version hasn\u0026rsquo;t been compiled with. In this case, there is a special error code c_err_pp_options_wrong which causes the input deck parser to give a meaningful error. You should also set the string extended_error_string to be the define command for the missing preprocessor directive i.e extended_error_string = \u0026quot;-DMY_PRECOMPILER_DIRECTIVE\u0026quot;\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"e074fc7bc024c0233b45487b6e01711b","permalink":"/developer/input_output/basic_output.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/input_output/basic_output.html","section":"developer","summary":"EPOCH uses a file format called SDF which was custom developed for use with codes developed by CFSA at the University of Warwick. However, it isn\u0026rsquo;t necessary to have a full understanding of the file format to add the output of new variables to EPOCH.","tags":null,"title":"Basic Output","type":"docs"},{"authors":null,"categories":null,"content":"This page details a few basic background components of EPOCH. Here we introduce the global shared data modules and its physical constants, variables used to define the cell grid, and the functions used to load macro-particles onto the grid.\nPhysical constants In order to ensure that different parts of the code run at the same precision common physical constants are defined in constants.F90 and any new physical constants required by extensions to the code should be placed in the same location. The constants available in the code are\n pi - Ratio of a circle\u0026rsquo;s circumference to its diameter. q0 - Charge on electron. m0 - Rest mass of electron. c - Speed of light in vacuum. kb - Boltzmann\u0026rsquo;s constant. mu0 - Permeability of free space. epsilon0 - Permittivity of free space. h_planck - Planck\u0026rsquo;s constant. ev - The value of an electron volt. h_bar - Planck\u0026rsquo;s constant divided by $2\\pi$ . a0 - The Bohr radius. hartree - Double the Rydberg energy. alpha - Fine structure constant. atomic_time - Time in atomic units (h_bar / hartree). atomic_electric_field - Electric field in atomic units (hatree / q0 / a0). mc0 - Electron mass * speed of light. m0c2 - Electron rest mass energy.  Further constants are used in the QED (photons) physics package and the bremsstrahlnug package.\nAny new constants required should be specified in the same place in constants.F90.\nShape and size variables As well as the physical constants, there are some important variables which you will have to use to do any development with EPOCH. As a general note, since EPOCH is written with separate 1D, 2D and 3D versions, definitions will be given for the 3D version of the code and irrelevant dimensions should just be left out.\n  INTEGER :: nx, ny, nz - The number of gridpoints on the current processor in each direction. This may change when the load balancer activates, so always use these variables rather than local copies.\n  INTEGER :: nx_global, ny_global, nz_global - The number of gridpoints in each direction of the whole domain. These numbers will never change and will be the numbers read in from the input deck.\n  INTEGER(KIND=8) :: npart_global - The global number of particles specified in the input deck. This is not updated as particles leave the domain through boundaries etc. so it is not guaranteed to be accurate.\n  INTEGER :: n_species - The number of species of particles specified.\n  INTEGER :: nsteps - The maximum number of steps that the core solver should take.\n  INTEGER, DIMENSION(1:nproc{x,y,z}), ALLOCATABLE :: cell_{x,y,z}_min, cell_{x,y,z}_max - The variables cell_{x,y,z}_min and cell_{x,y,z}_max represent the part of a global array which is held by the current processor. Since EPOCH is an MPI code, there doesn\u0026rsquo;t exist a single copy of any of the global arrays anywhere, but if there did then each processor would be responsible for the slice which runs (cell_x_min(rank):cell_x_max(rank), cell_y_min(rank):cell_y_max(rank)) in 2D. These variables are used internally in the load balancer, where it is updated, but is also used when calculating distribution functions. Here it is used to define the extents of the MPI type which is used to write the distribution function to disk.\n  -Useful global parameters exist for tracking the position and size of the fields stored by each MPI rank. The variables:\n  INTERGER :: {x,y,z}_grid_min_local - These give the position of the cell-centre which has indices (1,1,1) on the current MPI rank. The grids on each rank only contain a fraction of the total simulation cells.\n  LOGICAL :: {x,y,z}_{min,max}_boundary - Logical flags to determine whether the current rank is on the simulation edge. If x_min_boundary is true, then the current MPI rank has no neighbouring ranks on the low-$x$ edge.\n  The timestep The timestep is calculated in the subroutine set_dt in the file src/housekeeping/setup.F90. All that the subroutine has to do is set the variable dt to set the timestep for the whole code. Any additional timestep constraints should be coded into this subroutine. This should be implemented after the existing dt= lines but before the line dt = dt_multiplier * dt. Such a modification should be set so that it only changes the timestep if the timestep is MORE restrictive than that calculated from the core code. An example would be:\ndt = dx * dy / SQRT(dx**2 + dy**2) / c dt = MIN(dt, my_new_dt)  In the core EPOCH code the timestep can be calculated identically on each processor, so there is no requirement to synchronise the timestep across multiple processors. If your new timestep restriction uses information local to each processor then some additional lines must be added to the set_dt routine after the timestep has been calculated which should read:\nREAL(num) :: dt_global . . . CALL MPI_ALLREDUCE(dt_global, dt, 1, mpireal, MPI_MIN, comm, errcode) dt = dt_global  This uses another MPI command to determine the most restrictive timestep across all processors. EPOCH is not written in a way that permits operation with different timesteps on different processors, and the behaviour of the code is undefined (and likely wrong) if the code runs with different timesteps on different processors.\nInput deck variables  CHARACTER(LEN=entry_length) :: blank - A special string which the input deck parser uses to indicate that it\u0026rsquo;s passing a blank string rather than a string read from the deck which just happens to be blank. INTEGER :: deck_state - An integer determining the current sweep of the input deck by the deck parser. INTEGER, PARAMETER :: num_vars_to_dump - A variable describing the number of variables which should be selectable in the input deck as possible variables to dump. CHARACTER(LEN=entry_length) :: extended_error_string - String used by some error codes in the deck parser to give more user friendly error messages. INTEGER :: data_dir_max_length - The maximum number of characters in the name of the output directory. INTEGER :: n_zeros - The number of leading zeros in the output filenames from EPOCH.  Initial conditions (autoloader) variables Initial conditions for the autoloader for a given species are described in EPOCH by the Fortran TYPE initial_conditions_block. The definition (in 3D) is:\nTYPE initial_condition_block REAL(num), DIMENSION(:,:,:), POINTER :: density REAL(num), DIMENSION(:,:,:,:), POINTER :: temp REAL(num), DIMENSION(:,:,:,:), POINTER :: drift REAL(num) :: density_min REAL(num) :: density_max END TYPE initial_condition_block  In 2D, the arrays have one fewer index, and in 1D they have two fewer.\n REAL(num) :: density - Number density for the particles in the species. When defined runs (-2:nx+3,-2:ny+3,-2:nz+3). REAL(num) :: temp - Temperature in Kelvin of the species in space. When defined runs (-2:nx+3,-2:ny+3,-2:nz+3,1:3). The final index of the array is a direction index, used to give anisotropic thermal distributions. REAL(num) :: drift - Velocity drift in $m/s$ of the species in space. When defined runs (-2:nx+3,-2:ny+3,-2:nz+3,1:3). The final index of the array is the velocity direction component. density_min - The minimum density below which the autoloader should not load particles. density_max - The maximum density above which the autoloader should clip the density function.  The initial conditions themselves are in the variable\nTYPE(initial_condition_block), DIMENSION(:), ALLOCATABLE :: initial_conditions  which is allocated to an array of size 1:n_species.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"ffcd6d002d6b444b4ff92a515f98d340","permalink":"/developer/core_structure/basic_structures.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/basic_structures.html","section":"developer","summary":"This page details a few basic background components of EPOCH. Here we introduce the global shared data modules and its physical constants, variables used to define the cell grid, and the functions used to load macro-particles onto the grid.","tags":null,"title":"Basic Structures","type":"docs"},{"authors":null,"categories":null,"content":"Boundary conditions in EPOCH are split into three types\n Simple field boundaries. Laser and outflow boundaries. Particle boundaries.  These boundaries can be combined in different ways to give different effects. From the end user perspective there are 4 boundaries which can be applied to each edge of the simulation domain. These are\n Periodic  Particles periodic Fields periodic Lasers off   Other  Particles reflect Fields clamped zero Lasers off   Simple Laser  Particles transmissive Fields clamped zero Lasers applied at half timestep for $B$ field   Simple outflow  Particles transmissive Fields clamped zero No lasers applied at half timestep, but outflow conditions applied to $B$ field at half timestep    The boundary conditions are applied in too many places in the code to give a full description of them, but the laser boundaries are only applied in src/fields.f90. The boundaries requested by the user are converted into the conditions on the fields and particles in the routine setup_particle_boundaries in src/boundaries.F90. For each of the six possible boundaries (x_min, x_max, y_min, y_max, z_min, z_max) there is a variable which will be named something like bc_x_min_particle or bc_y_max_field which controls the boundary condition which will be applied to either the field or the particles.\nSimple field boundaries There are two subroutines which apply the standard boundary conditions: field_zero_gradient and field_clamp_zero. The type of boundary condition that the two apply is obvious from the name, but the two functions have different calling conventions.\nSUBROUTINE field_zero_gradient REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field INTEGER, INTENT(IN) :: stagger_type, boundary  field_zero_gradient is the routine which applies zero gradient boundary conditions to a field variable passed in the parameter field. The remaining two parameters are the stagger type and the boundary number. These are named constants defined in src/shared_data.F90, c_stagger_* for the stagger type and c_bd_* for the boundary number. The routine can be used as a global field boundary condition by setting one of the field boundary conditions to c_bc_zero_gradient in setup_particle_boundaries, but it is mostly used to give boundary conditions for the autoloader.\nSUBROUTINE field_clamp_zero REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field INTEGER, INTENT(IN) :: stagger_type, boundary  field_clamp_zero is the routine which clamps the field given by the field variable to zero on the boundary. The remaining two parameters are the stagger type and the boundary number. These are named constants defined in src/shared_data.F90, c_stagger_* for the stagger type and c_bd_* for the boundary number.\nAdditional boundary conditions should follow the same basic principle as these routines. Note that all of the routines test for \\{x,y,z\\}_\\{min,max\\}_boundary to confirm that a given processor is at the edge of the real domain, and so should have a real boundary condition applied to it. This also explains why there are no explicit periodic boundary condition routines, since by connecting the processors cyclically in a periodic direction the domain boundary effectively becomes another internal processor boundary.\nLaser and outflow boundaries The laser boundaries in EPOCH are based on a rewriting of Maxwell\u0026rsquo;s equations (combining Ampere-Maxwell and Faraday-Lenz) into a new form which expresses the fields explicitly in terms of waves propagating in both directions along each co-ordinate axis with both S and P polarisation states. In the $x$ direction,\n$$ \\partial_t(E_y \\pm cB_z) \\pm \\partial_x(E_y \\pm cB_z) = \\pm \\partial_yE_x c + \\partial_zB_x c^2 -\\frac{j_y}{\\epsilon_0} $$\n$$ \\partial_t(E_z \\mp cB_y) \\pm \\partial_x(E_z \\mp cB_y) = \\pm \\partial_zE_x c - \\partial_yB_x c^2 -\\frac{j_z}{\\epsilon_0} $$\nIt is then possible to rewrite these equations to provide a boundary condition on $B_z$ and $B_y$ to give propagating EM waves at the boundary. For waves travelling into the boundary, this gives a transmissive boundary, and if the components for waves propagating out from the boundary are set to be non-zero then it also introduces an EM wave propagating from the left boundary.\nThis boundary condition is found in the file laser.f90 which also includes the routines for handling the laser_block objects which represent how lasers are represented in EPOCH.\nParticle boundaries Due to the time that is required to loop over all the particles the particle boundary conditions in EPOCH combine the inter-processor boundary conditions with the real boundary conditions. The boundary conditions for particles are in the routine particle_bcs in the file boundary.f90\nCurrently EPOCH includes only three particle boundary conditions\n c_bc_open - Particles pass through the boundary and are destroyed. Total pseudoparticle number is not conserved in this mode. c_bc_periodic - Particles which leave one side of the box reappear on the other side. c_bc_reflect - Particles reflect off the boundary as if it was a hard boundary.  Although the routine looks rather messy, it is fairly easy to understand. The sequence goes:\n Loop over all species. Create particle list objects for particles to be sent to and received from other processors. Loop over all particles in the species. If the particle has crossed a local boundary then it either has crossed the boundary of the problem domain and needs a boundary condition to be applied or it has just crossed a processor boundary and needs to be transferred to a neighbouring process. Set {x,y,z}bd which is used to identify which processor relative to the current processor the particle potentially needs to be moved to and then test for the domain boundary. If the particle has crossed an open domain boundary then either add it to another list to be dumped to disk if the user has requested this, or otherwise just deallocate the particle to reclaim memory. Set out_of_bounds to indicate that the particle has left the system. If the particle has crossed the domain boundary and that boundary has reflecting boundary conditions then reflect the particle. If the particle has crossed the domain boundary and that boundary has periodic boundary conditions then move the particle to the opposite side of the domain. End particle loop. Remove all the particles which have left the current process. Loop over all possible neighbouring processors for the current processor and exchange particle lists with that processor. Add any received particles onto the particle list for the current species. End species loop.  Note that, unlike for fields, there is explicit periodic boundary code. This is because although the MPI routines place the particle on the correct processor after the MPI routines, the particle\u0026rsquo;s position variable still places it beyond the other end of the domain. The MPI parallelism for exchanging particles is hidden in the routines which deal with the particle list objects and are described in the next section.\nMPI Boundaries There are three routines which deal with MPI exchange for field variables in EPOCH. Two are closely related and will be considered together. The third deals with using MPI to sum variables at processor boundaries rather than synchronise ghost cells.\nSUBROUTINE field_bc REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field  field_bc exchanges the information in the ghost cells between adjacent processors. Any field variable which is used in a calculation that requires operations involving information from points other than the current point should call this routine each time the variable is updated. This will ensure that the ghost cells are populated from adjacent processors. (i.e. if you only need to access field(ix,iy,iz) there is no need to update ghost cells, whilst if you use field(ix-1,iy,iz) you do).\nThe field_bc routine just calls the do_field_mpi_with_lengths routine which is a more general routine that allows ghost cell information to be exchanged for fields with an arbitrary number of cells, rather than fields which are (-2:nx+3,-2:ny+3,-2:nz+3). This routine is used internally in the load balancing routine when fields with both the old and new sizes must be handled at the same time.\nSUBROUTINE processor_summation_bcs REAL(num), DIMENSION(-2:,-2:,-2:), INTENT(INOUT) :: field INTEGER, INTENT(IN), OPTIONAL :: flip_direction  processor_summation_bcs is a routine which is used to deal with variables, like $\\vec{j}$ or number density that should be added at boundaries to include contributions from particles on both sides of a processor boundary. The routine is used for the current inside the particle pusher and inside most of the routines for calculating derived variables. If you have a variable which needs to add contributions from adjacent processors then you should calculate the quantity on each processor, including contributions from the particles to the ghost cells and then call this routine. When reflecting boundary conditions are in operation, the current in the direction crossing the boundary needs to be flipped over. This is decided upon using the flip_direction parameter.\nThese routines can be used for most MPI calls required by all but the most extreme modifications to EPOCH.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"158985cf44db7d0c6035acd99762bbef","permalink":"/developer/core_structure/boundary_conditions.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/boundary_conditions.html","section":"developer","summary":"Boundary conditions in EPOCH are split into three types\n Simple field boundaries. Laser and outflow boundaries. Particle boundaries.  These boundaries can be combined in different ways to give different effects.","tags":null,"title":"Boundary Conditions","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH uses the Villasenor and Buneman current calculating scheme which solves the additional equation ${\\partial \\rho}/{\\partial t} = \\nabla\\cdot\\vec{J}$ to calculate the current at each timestep. The main advantage of this scheme is that it conserves charge on the grid rather than just globally conserving charge on the particles. This means that the error in the solution to Gauss\u0026rsquo;s law is conserved, so if Gauss\u0026rsquo;s law is satisfied for $t = 0$ it remains satisfied for all time.\nThe Villasenor and Buneman scheme works because exactly the same charge added to one cell is subtracted from another cell, which in turn means that exactly the same current added to one cell is subtracted from another cell. This is intuitively correct since a point particle crossing a cell boundary would represent the loss of that particle\u0026rsquo;s contribution to the current from the source cell and the gain of that particle\u0026rsquo;s contribution to the current by the destination cell. In fact this simple type of cell boundary crossing current calculation was used in classical Buneman type PIC codes.\nThe scheme is messy, in practise, but simple. After the main particle push, the particle is advanced a further half timestep into the future to first order using the velocities calculated at the end of the particle push. The particle position at $t + dt/2$ were stored earlier, and combined with the newly calculated particle position at $t + {3dt}/{2}$ this allows a time centred evaluation of ${\\partial \\rho}/{\\partial t}$ meaning that the current update is second order accurate in time. The spatial order of the scheme matches the spatial order of the particle weight function.\nThe weight functions for transferring particle properties onto the grid at the two timesteps are calculated including a shift when necessary to allow for the particle having crossed a cell boundary. Since the charge associated with the particle is spatially distributed using the weight function, all that is necessary to calculate ${\\partial \\rho}/{\\partial t}$ is to subtract the two functions, multiply by the charge on the pseudoparticle and the pseudoparticle weight and finally divide by $dt$. The spatial derivative of $\\vec{J}$ is then converted to a one sided finite difference form and solved directly. In multiple dimensions this is slightly complicated by the effects of offsets in directions other than the direction that a given current component is pointing in, with this adding additional weight factors based on the overlap of the shape functions in other directions. This is explained in full in the Villasenor and Buneman paper already quoted.\nCurrents in ignorable directions are simply calculated using $J = n\\rho\\vec{v}$ with the correct shape functions to ensure that the current is placed in the correct places.\nExample In EPOCH2D V4.19.2, the source-code for the current update looks like this:\n jyh = 0.0_num DO iy = ymin, ymax cy = cell_y1 + iy yfac1 = gy(iy) + 0.5_num * hy(iy) yfac2 = third * hy(iy) + 0.5_num * gy(iy) hy_iy = hy(iy) jxh = 0.0_num DO ix = xmin, xmax cx = cell_x1 + ix xfac1 = gx(ix) + 0.5_num * hx(ix) wx = hx(ix) * yfac1 wy = hy_iy * xfac1 wz = gx(ix) * yfac1 + hx(ix) * yfac2 ! This is the bit that actually solves d(rho)/dt = -div(J) jxh = jxh - fjx * wx jyh(ix) = jyh(ix) - fjy * wy jzh = fjz * wz jx(cx, cy) = jx(cx, cy) + jxh jy(cx, cy) = jy(cx, cy) + jyh(ix) jz(cx, cy) = jz(cx, cy) + jzh END DO END DO  At this point in the code, gx and gy contain the weight distribution of the macro-particle at time $t+dt/2$, where the 0 index in these arrays correspond to the cell containing the macro-particle centre at this time (or the low-x, low-y corner for TOPHAT shapes). The hx and hy parameters contain the difference of weights in each cell between $t+3dt/2$ and $t+dt/2$. The loop occurs from gx index xmin to xmax, and gy index ymin to ymax. These min/max indices will describe an array which has the same size as the number of cells which the macro-particle shape has touched over the time-step.\nAs an example, consider the $j_x$ update. For cell index ix=xmin, we first calculate the average y-weight for each iy using the line:\n yfac1 = gy(iy) + 0.5_num * hy(iy)  as gy(iy) is the initial y-weight, and gy(iy) + hy(iy) is the final y-weight. We assume the macro-particle moves at a constant speed when taking the average. Hence, the change in macro-particle weight due to motion in the $x$ direction from the ix=xmin cell is hx(xmin) * (gy(iy) + 0.5*hy(iy)). In the code, this is wx. We can multiply this by the macro-particle charge (charge * weight) to get the charge change due to $x$ motion, divide by dt to get a current, and divide by dy to get the current per unit area (as dz = 1m in EPOCH2D). These particle variables and simulation constants are contained in the fjx variable.\nFinally, we must remember that this refers to the total current density change in the cell - we do not know the boundary this current flows through. In the xmin cell, we know no macro-particle weight enters xmin-1 by definition of xmin, so all the current density flows into the cell with ix=xmin+1. Hence, the current change is unambiguous here. If there is no current change in xmin+1, then an equal current must flow in and out. We have just calculated the xmin to xmin+1 current, so we can subtract this from the new cell to determine the current on the next boundary. Because we need to remember the current from the previous calculation, we must subtract jxh from the previously calculated jxh in:\njxh = jxh - fjx * wx  This calculation may then iterate through the particle shape, until the $j_x$ contribution from this macro-particle is recorded in all cells it influences. The remaining current density components can be calculated using similar logic.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"2d4eb8ce9369c9477bb65baedec7e3a3","permalink":"/developer/core_structure/current_solver.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/current_solver.html","section":"developer","summary":"EPOCH uses the Villasenor and Buneman current calculating scheme which solves the additional equation ${\\partial \\rho}/{\\partial t} = \\nabla\\cdot\\vec{J}$ to calculate the current at each timestep. The main advantage of this scheme is that it conserves charge on the grid rather than just globally conserving charge on the particles.","tags":null,"title":"Current solver","type":"docs"},{"authors":null,"categories":null,"content":"For some types of changes to the code it is more convenient to have the end user pass new parameters into the code. This can be for several reasons, and the section on permanent additions to the input deck is given in extensions. At this stage, we will describe how to temporarily add new elements to the input deck parser routines, allowing parameterising of internal and manual initial conditions.\nCustom input deck elements are setup in the file src/user_interaction/custom_deck.f90. The function custom_blocks_handle_element is called when a new block is started which the core parser is not familiar with, and once for each element of a block. The function custom_blocks_check is called once the entire deck has been parsed and is used to check that all the elements which are required for the code to run have been specified.\ncustom_blocks_handle_element There are three parameters passed to custom_blocks_handle_element, which are:\n block_name - The name of the block specified in the begin:blockname part of the input deck. element - The name of the element in an input deck element = value pair. value - The string representation of the value in an input deck element = value pair.  custom_blocks_handle_element is first called when a new block is begun using begin:blockname and \u0026ldquo;blockname\u0026rdquo; is not recognised by the core input deck parser. The first thing that it does is test whether or not it is a valid custom block. The code does this by passing in the blockname with element and value set to the special constant called \u0026ldquo;blank\u0026rdquo;. When extending the input deck, an end user should check if either element or value are set to the special constant \u0026ldquo;blank\u0026rdquo;, and if they are then test to see whether the blockname is known or not. If the blockname is known then the code should return the error code c_err_none (No error). If the blockname is not known then the code should return c_err_unknown_block and the deck parser will just skip the block. In operation, this looks like:\nFUNCTION custom_blocks_handle_element(block_name, element, value) \u0026amp; RESULT(errcode) CHARACTER(LEN=string_length), INTENT(IN) :: block_name, element, value INTEGER :: errcode IF (str_cmp(block_name, \u0026quot;custom\u0026quot;)) THEN IF (element .EQ. blank .OR. value .EQ. blank) THEN ! If element or value are blank then just testing block so ! return c_err_none errcode = c_err_none RETURN ENDIF ENDIF ! The following line must always be present errcode = c_err_unknown_block END FUNCTION custom_blocks_handle_element  In order to simplify Fortran\u0026rsquo;s rather annoying string handling behaviour, several helper functions have been defined and the most used one is str_cmp(string1, string2). This is a simple routine which returns true if string1 == string2 and false otherwise. It is case sensitive but can deal with differing string lengths etc. The next stage is to deal with the actual element = value pairs in the deck. Each time that a new pair is read from the deck, custom_blocks_handle_element is called with element and value having the values read from the deck. To test for known elements they should just be checked against a known list of names using str_cmp and return the error code c_err_unknown_element if the element isn\u0026rsquo;t a known element. This looks like:\nFUNCTION custom_blocks_handle_element(block_name, element, value) \u0026amp; RESULT(errcode) CHARACTER(LEN=string_length), INTENT(IN) :: block_name, element, value INTEGER :: errcode IF (str_cmp(block_name, \u0026quot;custom\u0026quot;)) THEN IF (element .EQ. blank .OR. value .EQ. blank) THEN ! If element or value are blank then just testing block so ! return c_err_none errcode = c_err_none RETURN ENDIF errcode = c_err_unknown_element ! Now test for the real elements IF (str_cmp(element, \u0026quot;int_element\u0026quot;)) THEN errcode = c_err_none ENDIF IF (str_cmp(element, \u0026quot;real_element\u0026quot;)) THEN errcode = c_err_none ENDIF IF (str_cmp(element, \u0026quot;logical_element\u0026quot;)) THEN errcode = c_err_none ENDIF RETURN ENDIF ! The following line must always be present errcode = c_err_unknown_block END FUNCTION custom_blocks_handle_element  This version of the code will allow you to add a new block called \u0026ldquo;custom\u0026rdquo; with elements \u0026ldquo;int_element\u0026rdquo;, \u0026ldquo;real_element\u0026rdquo; and \u0026ldquo;logical_element\u0026rdquo; and the code will parse them successfully, while any other block or any other element in the block \u0026ldquo;custom\u0026rdquo; will throw errors. However, at this stage the code doesn\u0026rsquo;t actually read any of the values from the deck. To make it useful, any variable which is read from the input deck must be stored in a global variable. Defining global variables are explained in more detail in the relevant section of the manual, but in short, any variable defined in the module shared_data in the file src/shared_data.F90 will be a global variable. After the variables have been setup, there are once again helper functions to make converting the text from the deck into a normal Fortran90 variable. These helper functions are:\n as_integer - Attempts to convert a string to an integer. Invokes the maths parser. as_real - Attempts to convert a string to a REAL(num). Invokes the maths parser. as_logical - Attempts to convert a string to a logical. Does not invoke the maths parser (must be either \u0026ldquo;T\u0026rdquo; or \u0026ldquo;F\u0026rdquo;).  They are used pretty much as expected, except that the return value is passed to the functions so that they can report errors while trying to parse the string. An example would then be:\nFUNCTION custom_blocks_handle_element(block_name, element, value) \u0026amp; RESULT(errcode) CHARACTER(LEN=string_length), INTENT(IN) :: block_name, element, value INTEGER :: errcode, int_element REAL(num) :: real_element LOGICAL :: logical_element IF (str_cmp(block_name, \u0026quot;custom\u0026quot;)) THEN IF (element .EQ. blank .OR. value .EQ. blank) THEN ! If element or value are blank then just testing block so ! return c_err_none errcode = c_err_none RETURN ENDIF errcode = c_err_unknown_element ! Now test for the real elements IF (str_cmp(element, \u0026quot;int_element\u0026quot;)) THEN errcode = c_err_none int_element = as_integer(value, errcode) ENDIF IF (str_cmp(element, \u0026quot;real_element\u0026quot;)) THEN errcode = c_err_none real_element = as_real(value, errcode) ENDIF IF (str_cmp(element, \u0026quot;logical_element\u0026quot;)) THEN errcode = c_err_none logical_element = as_logical(value, errcode) ENDIF RETURN ENDIF ! The following line must always be present errcode = c_err_unknown_block END FUNCTION custom_blocks_handle_element  It is possible to perform more advanced types of evaluation of maths expressions such as reading arrays etc. but this is beyond the scope of this manual at present.\ncustom_blocks_check This function is called when all the blocks in the input deck have been evaluated and is used to check that all required parameters have been set. If all required elements have been set then you should just return c_err_none, otherwise return c_err_missing_elements. How you test that required elements have been set is up to the developer, and for testing and personal use (which is all that the custom deck parts of the code should be used for) it is acceptable to just not check and always return c_err_none. If permanently expanding the deck, error trapping should always be written.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"21ca804e14e58bc2b7bd0cdb93cfdf99","permalink":"/developer/input_output/custom_deck.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/input_output/custom_deck.html","section":"developer","summary":"For some types of changes to the code it is more convenient to have the end user pass new parameters into the code. This can be for several reasons, and the section on permanent additions to the input deck is given in extensions.","tags":null,"title":"Custom Deck","type":"docs"},{"authors":null,"categories":null,"content":"Sometimes the complexity in changing the input.deck file is due to the fact that a function which must be used is fairly complex in form and is not supplied with the core code. It must therefore be represented in the input deck maths parser. This can be a significant cause of complexity for some problems, and in this case, there are three options:\n Put up with it and implement in the deck Use the internal initial conditions rather than the deck Extend the maths parser to include your function  Extending the maths parser can either be permanent (described in extensions) or temporary (described here). All of the routines used in extending the maths parser are in the file user_interaction/custom_parser.f90. Temporarily adding elements to the parser is much easier than a permanent addition. It is possible to add new constants and functions to the maths parser. It is hoped that in a future release of EPOCH this will be extended to allow custom operators as well.\nAs an example, lets look at adding a new function (lorentz) for a Lorentzian distribution, and adding a new constant, phi.\nRegistering your new constant/function Before a new constant or function can be defined it must be registered. In the registration phase the text representation of the function or constant is given to the parser subroutines and the user is returned an integer handle for the registered object. The numerical handle must be stored so that that all of the functions in this module can access it, so they should be placed after the IMPLICIT NONE statement at the top of the file and defined as:\nINTEGER :: c_func_lorentz INTEGER :: c_const_phi  Note that the names given to the constants is obviously at the developers discretion, but these names comply with the EPOCH style guide. Actually registering the objects is done in the register_objects subroutine which should include lines to register functions and constants. An example is given below.\nSUBROUTINE register_objects c_func_lorentz = register_function(\u0026quot;lorentz\u0026quot;) c_const_phi = register_constant(\u0026quot;phi\u0026quot;) END SUBROUTINE register_objects  Note that the input deck parser is case sensitive, so the strings which are given to register_function and register_constant should be in the case that they will appear in the input deck. To follow the EPOCH style guide this should be all lowercase. At this point, the maths parser would start to recognise the new function/constant, but would still give error messages since they haven\u0026rsquo;t yet been implemented.\nSetting up new constants Once a new constant has been registered it must be described using the custom_constant function. In 2D this function looks like:\nFUNCTION custom_constant(opcode, ix, iy, errcode) INTEGER, INTENT(IN) :: opcode, ix, iy INTEGER, INTENT(INOUT) :: errcode REAL(num) :: custom_constant ! Leave these lines in place. They cause the code to throw an error if ! The opcode is unknown custom_constant = 0.0_num errcode = IOR(errcode, c_err_unknown_element) END FUNCTION custom_constant  The parameters are\n opcode - The operator code of the constant requested. This will be the integer handle returned from register_constant. ix, iy, iz - Some constants are actually evaluated at specific points in space and ix, iy, iz are the gridpoint number of the location currently being evaluated. If you are specifying a simple constant then just ignore these. If your constant does depend upon space then directly subscript your array with ix, iy, iz as needed to read the correct location. errcode - The error code which should be passed back to the parser. If for some reason you cannot evaluate your constant then you should IOR errcode with the appropriate error code (all the error codes are listed in appendix A). Note that errcode should never be SET to any specific error code when extending the parser, since this might overwrite errors put in place earlier in the parsing sequence. This is different to extending the input deck where the error code is set.  The function should just return the evaluated value of the constant requested by opcode. This might look like:\nFUNCTION custom_constant(opcode, ix, iy, errcode) INTEGER, INTENT(IN) :: opcode, ix, iy INTEGER, INTENT(INOUT) :: errcode REAL(num) :: custom_constant IF (opcode .EQ. c_const_phi) THEN custom_constant = pi RETURN ENDIF ! Leave these lines in place. They cause the code to throw an error if ! The opcode is unknown custom_constant = 0.0_num errcode = IOR(errcode, c_err_unknown_element) END FUNCTION custom_constant  Note that when opcode is successfully recognised, the code sets the return value and returns straight away. This is how all constants should work, since the last line forces the function to return an error code. This last line is in place to trap people registering constants but never defining them. Without this line, it is possible to define a constant which is never specified and have the code complete OK with a random value for that constant.\nThe constant \u0026ldquo;phi\u0026rdquo; should now work fine when used anywhere in the input deck and will return a value of $\\pi$.\nSetting up new functions Setting up the new function lorentz is very similar to setting up the new constant. The relevant function is custom_function and when empty looks like:\nFUNCTION custom_function(opcode, ix, iy, errcode) INTEGER, INTENT(IN) :: opcode, ix, iy INTEGER, INTENT(INOUT) :: errcode REAL(num) :: custom_function REAL(num) :: values(5) ! Leave these lines in place. They cause the code to throw an error if ! The opcode is unknown custom_function = 0.0_num errcode = IOR(errcode, c_err_unknown_element) END FUNCTION custom_function  The parameters are\n opcode - The operator code of the constant requested. This will be the integer handle returned from \\inlinecode {register_function}. ix, iy, iz - Some functions are evaluated differently at specific points in space and ix, iy, iz are the gridpoint number of the location currently being evaluated. If you are specifying a simple function then just ignore these. If your function does depend upon space then directly subscript your array with ix, iy, iz as needed to read the correct location. errcode - The error code which should be passed back to the parser. If for some reason you cannot evaluate your function then you should IOR errcode with the appropriate error code. Note that errcode should never be SET to any specific error code, since this might overwrite errors put in place earlier in the parsing sequence.  The function should return the value of your evaluated constant. The parameters which are passed to the function can be retrieved by the function get_values(n, values), where n is the number of parameters to be returned and values is a REAL(num) array of length n which will hold the returned values . In this implementation of the Lorentzian function there are three parameters: The dependent variable, the location parameter and the scale parameter. The code to implement the function therefore looks like:\nFUNCTION custom_function(opcode, ix, iy, errcode) INTEGER, INTENT(IN) :: opcode, ix, iy INTEGER, INTENT(INOUT) :: errcode REAL(num) :: custom_function REAL(num) :: values(5) IF (opcode .EQ. c_func_lorentz) THEN CALL get_values(3, values(1:3)) ! values(1) - Dependent variable ! values(2) - location parameter ! values(3) - scale parameter custom_function = values(3)**2/((values(1)-values(2))**2+values(3)**2) RETURN ENDIF ! Leave these lines in place. They cause the code to throw an error if ! The opcode is unknown custom_function = 0.0_num errcode = IOR(errcode, c_err_unknown_element) END FUNCTION custom_function  This function is then available at any point in the input deck and if I return to the previous example ic.deck file, it would be used as follows:\nbegin:constant particle_density = 100.0 # Particle number density profile_x = lorentz(x,0.0,1.0) profile_y = lorentz(y,0.0,1.0) end:constant begin:species name = s1 # multiply density by real particle density density = particle_density * profile_x * profile_y # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum density for this species density_min = 0.3*particle_density end:species begin:species name = s2 # Just copy the density for species s1 density = density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum density for this species density_min = 0.3*particle_density end:species  It is therefore clear that the new lorentz function is essentially the same as the built in gauss function. Note that due to the way that the parser works, the end user is not required to deal with parameters which are themselves maths expressions. They have been fully evaluated by the time they are returned by get_values. Note that the parser is not guaranteed to be bulletproof. If a user calls get_values requesting more parameters than have been passed to the function then it will scramble the stack which is used by the parser and cause the code to fail. Note that calling get_values(2, values) is not the same as calling get_values(1, values) twice, in fact calling get_values(1, values) multiple times will return the parameters in reverse order. This is normal and is a feature of how the maths parser operates. It is possible to use this property to write functions which have a variable number of parameters, but this is not recommended.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"848f47934e7342c9d6b1e1990ea6f451","permalink":"/developer/input_output/custom_maths_parser.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/input_output/custom_maths_parser.html","section":"developer","summary":"Sometimes the complexity in changing the input.deck file is due to the fact that a function which must be used is fairly complex in form and is not supplied with the core code.","tags":null,"title":"Custom Maths Parser","type":"docs"},{"authors":null,"categories":null,"content":"The input deck and maths parser in EPOCH use various named error codes to report on errors which occur during the evaluation of the input deck. These codes are\n c_err_none - No error. Set an error code to c_err_none to state that no error has occurred. c_err_unknown_block - In the input deck a block has been found which is not known. This should be returned in custom_blocks_handle_element if it is passed any block that it has not been written to handle. c_err_unknown_element - In the input deck an element of a valid block has been found which is not known. This should be returned in custom_blocks_handle_element if an element is requested which is unknown. c_err_preset_element - An element of the input deck has already been set and is being set again. Usually this is an indication of a malformed input deck file, so custom_blocks_handle_element should try to identify such situations and return this error message if subsequent attempts to set the variable are being ignored. c_err_preset_element_use_later - An element of the input deck has already been set and is being set again. Usually this is an indication of a malformed input deck file, so custom_blocks_handle_element should try to identify such situations and return this error message if the subsequent attempts to set the variable override previous ones. c_err_bad_value - A value which is being evaluated for the right hand side of an element assignment is in some way invalid. Internally to the code this usually means that a string which must be interpreted as a maths expression or numerical constant is in some way malformed. It is also acceptable to return this error code when a value has been passed which is invalid for some other reason (the value is outside an acceptable range, etc.) c_err_missing_elements - This is an error code returned when the code is testing to make sure that all necessary elements of an input deck file have been specified. It should be returned when some required parameter is missing in the subroutine custom_blocks_check. c_err_terminate - This error code means that the code is in a state where execution is impossible and the code must terminate once the input deck has been read. Some other error codes automatically set c_err_terminate, but it can always be IOR\u0026rsquo;ed with any error code to force the code to exit. Note that just returning c_err_terminate will cause the code to silently quit. c_err_required_element_not_set - This means that the code cannot parse an input deck element since another element which must be known beforehand has not been set. This is intended for things like setting the species information where the number of species must be known in advance. This error code uses the extended error string to give user friendly feedback. If you return this error code then you should set extended_error_string to be equal to the name of the required element which has not been set. If multiple previous elements are required then the code should be set up so that it checks for the presence of the required elements in order and reports on missing elements so that the end user can fix them one by one. c_err_pp_options_wrong - If you\u0026rsquo;ve written a section of the code that is controlled by preprocessor options then you should return this error message if someone attempts to set input deck elements which refer to that part when the correct preprocessor options are not used. This means that the user is aware of the fact that the requested feature will not be active. This error code also uses the extended error string to give user friendly feedback. If you return this error code, you should set the string extended_error_string to the define command that would turn on the requested feature of the code (\u0026quot;-DPER_PARTICLE_WEIGHT\u0026quot;, for example). c_err_other - This error code is a catch all error which causes the code to quit with a sarcastic error message. It\u0026rsquo;s mainly intended for debugging and is used before the final error code is implemented.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"e63358e256ec85cfe9fab5b93626c26a","permalink":"/developer/input_output/error_codes.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/input_output/error_codes.html","section":"developer","summary":"The input deck and maths parser in EPOCH use various named error codes to report on errors which occur during the evaluation of the input deck. These codes are\n c_err_none - No error.","tags":null,"title":"Error Codes","type":"docs"},{"authors":null,"categories":null,"content":"Each EPOCH MPI rank tracks a separate part of the simulation domain, using arrays of indices (1:nx, 1:ny, 1:nz) in 3D. The MPI ranks also track a small number of cells in neighbouring ranks, such that fields can be interpolated to macro-particle shapes which extend beyond the boundaries of a single rank. These additional surrounding copy-cells are termed \u0026ldquo;ghost cells\u0026rdquo;.\nField variables There are nine variables which are used in updating the EM field solver. These are\n ex - Electric field in the X direction. ey - Electric field in the Y direction. ez - Electric field in the Z direction. bx - Magnetic field in the X direction. by - Magnetic field in the Y direction. bz - Magnetic field in the Z direction. jx - Current in the X direction. jy - Current in the Y direction. jz - Current in the Z direction.  The EM fields in EPOCH are simple allocatable arrays, which are of size (-2:nx+3,-2:ny+3,-2:nz+3), although this includes the ghost cells. The length of the core domain is different for each variable due to the grid stagger.\nThe EPOCH field solver is a Yee staggered 2nd order FDTD scheme, directly based on the scheme in the PSC by Hartmut Ruhl and is contained in the file fields.f90. To locate a variable on the grid there is a simple rule.\n Start at the cell centre. For an $E$ field component, move the field half a grid point in the direction that the field points if possible. For a $B$ field component, move the field half a grid point in all directions except the one it points.  This is illustrated below for the 2D case.\nThe grid stagger means that you have to be careful with boundary conditions since some variables are defined on the domain boundaries whereas others are defined on either side of a domain boundary. This is handled automatically by the built in boundary routines, but must be understood if developing other boundary conditions. To explain it, consider only the left/right boundary in 1D and consider $E_x$ and $B_x$.\n$E_x$ is defined on the cell boundary, so ex(0) is the value of $E_x$ on the left boundary and similarly ex(nx) is the value on the right boundary. Conversely, in the 1D code $B_x$ is cell centred (in reality, $B_x$ is never used in the field update and is unimportant since any gradients in $B_x$ in 1D automatically break the solenoidal condition, but this is still a useful example.). This means that bx(1) is the centre of the first cell in the domain, and bx(0) is the value at the centre of the first left hand ghost cell. This means the you must do different things as boundary conditions for the two fields for some boundary conditions.\nFor example, if you want to clamp the value of $E_x$ to be zero on the boundary, then just set ex(0) = 0.0_num since ex(0) lies on the boundary. To do the same for $B_x$ on the boundary you have to set bx(0) = -bx(1). This is because if you use a linear reconstruction of $B_x$ (i.e second order) then the point between bx(0) and bx(1) has the value $B_x(1/2) = \\left(B_x(1)+B_x(0)\\right)/2$. Similarly, if you want to set zero gradient on the boundary then for $E_x$ you set ex(-1) = ex(1), whereas for $B_x$ you would set bx(0) = bx(1).\nIn the particle pusher, time centred field variables are needed for second order accuracy, so an FDTD scheme is used to advance the fields. This looks like\n $\\vec{E}^{n+\\frac{1}{2}} = \\vec{E}^n + \\frac{\\Delta t}{2} \\left( c^2 \\nabla \\wedge \\vec{B}^{n} -\\vec{j}^{n} \\right)$ $\\vec{B}^{n+\\frac{1}{2}} = \\vec{B}^n - \\frac{\\Delta t}{2} \\left( \\nabla \\wedge \\vec{E}^{n+\\frac{1}{2}} \\right)$ Call particle pusher which calculates $j^{n+1}$ currents $\\vec{B}^{n+1} = \\vec{B}^{n+\\frac{1}{2}} - \\frac{\\Delta t}{2} \\left( \\nabla \\wedge \\vec{E}^{n+\\frac{1}{2}} \\right)$ $\\vec{E}^{n+1} = \\vec{E}^{n+\\frac{1}{2}} + \\frac{\\Delta t}{2} \\left( c^2 \\nabla \\wedge \\vec{B} ^{n+1} - \\vec{j}^{n+1} \\right)$  Note that all spatial derivatives are calculated using the staggered grid, so the final derivatives in the code appear one sided. However, this is not the case, and all spatial derivatives are second order accurate. Higher order spatial derivatives schemes for EPOCH are being developed to improve the dispersion properties of the code when resolving small timescales.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"07d933cdad5c3725a85b6be225a6a9fd","permalink":"/developer/core_structure/field_solver.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/field_solver.html","section":"developer","summary":"Each EPOCH MPI rank tracks a separate part of the simulation domain, using arrays of indices (1:nx, 1:ny, 1:nz) in 3D. The MPI ranks also track a small number of cells in neighbouring ranks, such that fields can be interpolated to macro-particle shapes which extend beyond the boundaries of a single rank.","tags":null,"title":"Field Solver","type":"docs"},{"authors":null,"categories":null,"content":"While using the custom_deck subroutine is a good way of passing parameters into the code or for temporary additions, it is not suitable for permanent additions to the code. Adding new blocks to the code permanently is very similar to doing it temporarily, but requires changes to some of the subroutines in deck.F90.\nThere are six subroutines which may need to be changed to add new blocks to the deck. These are\n deck_initialise - Called before parsing of the input deck is begun. deck_finalise - Called after parsing of the input deck is complete. start_block(block_name) - Called when the deck directive begin:block_name appears in a deck file. end_block(block_name) - Called when the deck directive end:block_name appears in a deck file. handle_block(block_name, block_element, block_value) - Called once for each element in a block. check_compulsory_blocks(errcode_deck) - Called once when the deck file has been read to check that all necessary blocks have been populated.  There is one final variable which is important for modifying the input deck, deck_state. The input deck parser routine used to read the main input deck uses the variable deck_state to determine which stage of parsing the deck is required. The possible values of deck_state are\n c_ds_first - The first pass through the deck, before memory has been allocated. c_ds_last - After the initial deck pass, all arrays and lists are allocated. The deck is then parsed a final time so that allocated memory can be populated with initial conditions.  These constants are defined in shared_data.F90.\nThe layout of deck_initialise and deck_finalise is extremely simple. They just call *_deck_initialise or *_deck_finalise for each of the possible block types. start_block and end_block are also fairly straightforward. They examine the block name and call the *_block_start or *_block_end routine corresponding to the current block.\nThe handle_block routine acts in a similar manner except that it also does some error handling. At the simplest level the routine simply calls another function which takes the block_element and block_value as parameters and returns an error code determining the success or failure of reading the element.\nThe final routine is check_compulsory_blocks which is used to check that all the needed elements of the input deck have been set. A single parameter errcode_deck is passed in. The routine checks deck_state to make sure that it is the last pass through the deck. It then goes through and calls functions to check that all the necessary parts of a block have been set. The subroutines are contained in the same file as the routine which is called in handle_block to handle elements of the block. The error handler functions should return an error code, usually c_err_missing_elements. The return code from the error handler function should then be IOR-ed with errcode_deck to allow error codes to be returned from several different checks with errors occurring.\nThe element handler routines for deck elements The exact form of the handler routines is up to the end user. The only requirements are that the routine should return an error code detailing whether or not there are any problems with reading the block and that the error code should be c_err_none if either the element name or element value are the special constant blank. The typical implementation of an element handler routine is shown in the file src/deck/deck_control_block.f90, and this general layout should be copied for compatibility if possible.\nSometimes, it is useful to have each new block correspond to a new instance of an object in the code. An example of this in EPOCH is in src/deck/deck_laser_block.f90 where each new laser block in the input deck corresponds to a new laser being attached to a boundary. This is accomplished by implementing the lasers as a linked list on each boundary, with a new laser object being created when a laser block is started, the laser information being set during the main reader routine, and then the laser being attached to the linked list by a call to attach_laser in src/laser.f90 when the block is ended. When a new laser block is started the process simply repeats allowing the end user to have as many lasers as desired.\nAdding elements to existing blocks The existing blocks in the code are read in the files listed in \\sect{src_deck}\nThe existing structure of the blocks is simple enough in most cases that it should be fairly easy to add new elements if needed. The most likely change needed is to change the list of variables to dump in the output block. How to do this is detailed in \\sect{io}.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"16bc28a709bab68e603c2a5b6cb9c550","permalink":"/developer/extensions/input_deck.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/extensions/input_deck.html","section":"developer","summary":"While using the custom_deck subroutine is a good way of passing parameters into the code or for temporary additions, it is not suitable for permanent additions to the code. Adding new blocks to the code permanently is very similar to doing it temporarily, but requires changes to some of the subroutines in deck.","tags":null,"title":"Input Deck","type":"docs"},{"authors":null,"categories":null,"content":"The EPOCH codes are written using MPI for parallelism, but have no other libraries or dependencies. Currently, the codes are written to only require MPI1.2 compatible libraries, although this may change to require full MPI2 compliance in the future. Current versions of both MPICH and OpenMPI implement the MPI2 standard and are known to work with this code. The SCALI MPI implementation is only compliant with the MPI1.2 specification and may loose support soon. There are no plans to write a version of EPOCH which does not require the MPI libraries.\nThe code is supplied with a standard GNU make Makefile, which is also compatible with most other forms of the *make* utility. In theory it is possible to compile the code without a *make* utility, but it is much easier to compile the code using the supplied makefile.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"bddb619d011ae55fa45467b837a1792a","permalink":"/documentation/basic_usage/libraries.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/libraries.html","section":"documentation","summary":"The EPOCH codes are written using MPI for parallelism, but have no other libraries or dependencies. Currently, the codes are written to only require MPI1.2 compatible libraries, although this may change to require full MPI2 compliance in the future.","tags":null,"title":"Library requirements for the EPOCH codes","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602943396,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"/contact.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact.html","section":"","summary":"Code licensing","tags":null,"title":"License","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602943396,"objectID":"ec751500388d501a532eaca39aeccb9e","permalink":"/license.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/license.html","section":"","summary":"Code licensing","tags":null,"title":"License","type":"widget_page"},{"authors":null,"categories":null,"content":"In EPOCH, different processors are responsible for different cells, and each MPI rank only tracks the particles which exist with these cells. Hence, as macro-particles move around the simulation, they must be removed from one processor and added to another. If macro-particles were stored in arrays, these would continuously have to be resized as macro-particles moved around. Instead, EPOCH stores macro-particles in linked lists.\nLinked lists are a standard computer programming technique which is still slightly unusual in Fortran, and may well be unfamiliar to many Fortran programmers. They effectively allow you to have an array of arbitrary length, although this comes with various trade-offs about memory locality and speed of accessing elements. The general concept is that of a chain where each link in the chain only knows about the previous link in the chain and the next link in the chain. Although there are schemes for doing this in languages which don\u0026rsquo;t have pointers, the normal method of implementing linked lists is to use pointers to point to previous and next elements in the list, and this is how they are implemented in EPOCH. Since both linked lists and Fortran pointers are slightly esoteric concepts, while being key to the operation of EPOCH a brief overview of them is presented here.\nThe simplest possible form of a linked list element would be a TYPE which looks like:\nTYPE linked_list TYPE(linked_list), POINTER :: next TYPE(linked_list), POINTER :: prev END TYPE linked_list  You also have to have a pointer to the start of the list, and to speed up adding new elements to the list, you normally also keep a pointer to the last element of the list. Therefore, you would also have variables which look like:\nTYPE(linked_list) :: head, tail  Since Fortran pointers are not initialised in any particular state, you have to remember to set the head and tail pointers to explicitly point nowhere (normally called a null pointer by analogy with the older C style pointers). This is done using the nullify command.\nNULLIFY(head) NULLIFY(tail)  The same thing is important when creating a new linked list element, so you would normally have a creation function for linked list elements.\nSUBROUTINE create_element(element) TYPE(linked_list), POINTER :: element ALLOCATE(element) NULLIFY(element%next) NULLIFY(element%prev) END SUBROUTINE create_element  Note that the allocate function can be used on pointers in the same way that it can be used with variables which have the allocatable attribute. However, there is one important difference between a pointer and an allocatable variable. If you attempt to allocate an already allocated variable which has the allocatable attribute then the code will fail, whereas allocating an already allocated pointer is perfectly valid, and will allocate the new variable and point the pointer to it. This does not deallocate the memory that the pointer previously pointed to, and Fortran does not have a \u0026ldquo;garbage collector\u0026rdquo; which deallocates memory no longer accessible. So if you allocate a pointer which already points to a variable, it is very important that you have another pointer somewhere which points to the same memory. Once you no longer have a pointer to an area of memory, that area of memory is completely inaccessible and cannot even be deallocated. This is termed a memory leak and for programs which run for many cycles and have a memory leak on each cycle, the entire memory can very quickly be used up.\nSo, to add a new element to the list you would have a subroutine which looks like:\nSUBROUTINE add_element(element) TYPE(linked_list), POINTER :: element IF (.NOT. ASSOCIATED(head)) THEN ! Adding first element to list, so just set ! both head and tail to the element head=\u0026gt;element tail=\u0026gt;element RETURN ENDIF tail%next=\u0026gt;element element%prev=\u0026gt;tail tail=\u0026gt;element END SUBROUTINE add_element  This subroutine adds the new Fortran operator of =\u0026gt; which means \u0026ldquo;points to\u0026rdquo;. Unlike C or similar languages, Fortran pointers try to be partially transparent to the end user, so the following code would fail:\nPROGRAM test REAL, TARGET :: a = 10.0 REAL, POINTER :: b b = a END PROGRAM test  This happens because Fortran will try to copy the value of \u0026ldquo;a\u0026rdquo; into \u0026ldquo;b\u0026rdquo;. However, \u0026ldquo;b\u0026rdquo; is a pointer which hasn\u0026rsquo;t been initialised, so the code will crash when it tries to copy the data in (in theory, the code may not crash if the uninitialised \u0026ldquo;b\u0026rdquo; pointer happens to point somewhere in memory which is a valid target, but this is very unlikely). Note also that \u0026ldquo;a\u0026rdquo; has the attribute \u0026ldquo;TARGET\u0026rdquo;. The target attribute means that it is possible to point a pointer to this variable. You can only point a pointer to a variable which is either a pointer itself or has the target attribute. This is to try and keep Fortran pointers \u0026ldquo;safer\u0026rdquo; than C style pointers. The correct code would use b=\u0026gt;a, at which point \u0026ldquo;b\u0026rdquo; is set to point to \u0026ldquo;a\u0026rdquo; and can then be used everywhere in place of \u0026ldquo;a\u0026rdquo;.\nSo, to set up a linked list of n elements, you would use the following code:\nTYPE(linked_list), POINTER :: new NULLIFY(new) DO i = 1,n CALL create_element(new) CALL add_element(new) ENDDO  To then run through the elements of your newly created linked list, you would use code like:\nTYPE(linked_list), POINTER :: current current=\u0026gt;head DO WHILE(ASSOCIATED(current)) ! Do stuff current=\u0026gt;current%next ENDDO  This code snippet introduces one new function \u0026ldquo;ASSOCIATED\u0026rdquo;, which tells you whether a pointer is a null pointer or not (this is why it is so important to nullify new pointers, because ASSOCIATED on its own doesn\u0026rsquo;t check whether a pointer is valid, just whether or not it is a null pointer). You can also use ASSOCIATED to check whether a pointer points to a particular object or not, in which case the syntax is RESULT = ASSOCIATED(b, TARGET=a), which returns true if \u0026ldquo;b\u0026rdquo; points to \u0026ldquo;a\u0026rdquo;, or false if it doesn\u0026rsquo;t, even if \u0026ldquo;b\u0026rdquo; is a valid pointer pointing to something else. It also introduces the way in which you must use linked lists in EPOCH. The execution flow is as follows\n Point current to the current element to the start of the linked list (head). Iterate while current points to a valid element. Perform whatever actions you want on current. Point current to the next element in the chain.  This leads to the slightly counter intuitive behaviour where even though the loop only acts on the variable named \u0026ldquo;current\u0026rdquo;, all of the elements in the list are operated on. Although there are many tricks which can be performed with linked lists, the only other aspect which needs to be explained is how to delete elements. A subroutine to remove a single element from a linked list would look like:\nSUBROUTINE remove_element(element) TYPE(linked_list), POINTER :: element IF (ASSOCIATED(element%prev)) THEN ! Previous element exists element%prev%next=\u0026gt;element%next ELSE ! Previous element does not exist therefore element is the head. When ! element is removed the head is the element after the one being removed head=\u0026gt;element%next ENDIF IF (ASSOCIATED(element%next)) THEN ! next element exists element%next%prev=\u0026gt;element%prev ELSE ! next element does not exists therefore element is the tail. When element ! is removed the head is the element before the one being removed tail=\u0026gt;element%prev ENDIF END SUBROUTINE remove_element  Once again, this code looks slightly counter-intuitive, but if you go through step by step, it\u0026rsquo;s fairly simple. In the following discussion the element being removed is called \u0026ldquo;C\u0026rdquo;, the element before \u0026ldquo;C\u0026rdquo; (if it exists) is called \u0026ldquo;P\u0026rdquo; and the element after \u0026ldquo;C\u0026rdquo; (if it exists) is called \u0026ldquo;N\u0026rdquo;\n Check whether C\u0026rsquo;s prev element exists, this means that P exists. If P exists then the element to be removed isn\u0026rsquo;t at the start of the chain. When C is removed, we need P%next to point to C%next. This leads to the odd looking element%prev%next=\u0026gt; element%next syntax. If P does not exist then C is at the the start of the chain. In order to not leave the chain orphaned when C is removed, we need head to point to C%next. Exactly the same logic applies for updating the element after C. Check whether C\u0026rsquo;s next element exists, this means that N exists. If N exists then the element to be removed isn\u0026rsquo;t at the end of the chain. When C is removed, we need N%prev to point to C%prev. If P does not exist then C is at the the start of the chain. In order to not leave the chain orphaned when C is removed, we need head to point to C%next.  Therefore, code to remove some elements from a linked list would look like:\nTYPE(linked_list), POINTER :: current, next current=\u0026gt;head DO WHILE(ASSOCIATED(current)) next=\u0026gt;current%next IF (dealloc) THEN CALL remove_element(current) DEALLOCATE(current) ENDIF current=\u0026gt;next ENDDO  Note that \u0026ldquo;current\u0026rdquo; must be deallocated explicitly even after it has been removed from the linked list to prevent a memory leak. Note also that the pointer to the \u0026ldquo;next\u0026rdquo; element is saved before \u0026ldquo;current\u0026rdquo; is deallocated. This is not necessary but means that there is only one IF statement rather than the two otherwise required.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"dc0a554ddc736249dc9d168a98b0915c","permalink":"/developer/core_structure/linked_lists.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/linked_lists.html","section":"developer","summary":"In EPOCH, different processors are responsible for different cells, and each MPI rank only tracks the particles which exist with these cells. Hence, as macro-particles move around the simulation, they must be removed from one processor and added to another.","tags":null,"title":"Linked Lists","type":"docs"},{"authors":null,"categories":null,"content":"When an extension is intended for a new release, the temporary custom extensions are not appropriate. In these cases, it is possible to permanently add functions and constants to EPOCH\u0026rsquo;s maths parser. Although adding new operators is possible, it is sufficiently likely to cause problems with the operation of the maths parser that it is formally not recommended by the author of the program, and hence is not documented here.\nAdding the new tokenizer handle When adding a new function or constant to the maths parser using the temporary routines, there are two calls (register_function and register_constant) which give a numerical handle. This is the token used to represent that function or constant after the text has been parsed (remember that EPOCH\u0026rsquo;s maths parser tokenizes before evaluation!). When permanently adding objects to the maths parser, the tokenizer handles have to be set up manually. This takes place in src/shared_data.F90 in the module shared_parser_data. There are several lines which look like:\nINTEGER, PARAMETER :: c_const_ix = 40 INTEGER, PARAMETER :: c_const_iy = 41 . . . INTEGER, PARAMETER :: c_func_interpolate = 22 INTEGER, PARAMETER :: c_func_tanh = 23  Constants beginning with c_const_ are tokenizer handles for constants, and those beginning with c_func_ are tokenizer handles for functions. Each number must be unique and has to be less than the lower bound of values reserved for temporary or deck specified values. This means that any tokenizer handle for a function has to be less than the value of the variable c_func_custom_lowbound and any handle for a constant must be less than c_const_deck_lowbound. It is acceptable to simply increase the value of c_func_custom_lowbound and c_const_deck_lowbound to allow the use of more values for internal constants and functions, although care should be taken since this could lead to performance issues. If c_const_deck_lowbound is increased then the constant c_constant_custom_lowbound should be increased by the same amount (the values between c_const_deck_lowbound and c_constant_custom_lowbound-1 are used for constants specified inside the input deck while values greater than or equal to c_constant_custom_lowbound are used for constants specified by register_constant.\nOnce the tokenizer handle is specified in shared_parser_data, it is now possible to extend the main areas of the maths parser. Note that from here on, you MUST always use the constant named handle, NEVER the numerical value that you specified for the value of the handle. If this is not done then combining functions and constants from several sources becomes much harder.\nAdding the new function or constant to the tokenizer The next stage is to add the string representation of your constant or function to the tokenizer routines in src/parser/tokenizer_blocks.f90. This is very simple to do, just find either the function as_constant or as_function and look at the existing code. These functions are just long lists of str_cmp commands followed by code to deal with custom functions/constants. To add the new code, create an additional line such as:\nIF (str_cmp(name, \u0026quot;my_const\u0026quot;)) as_constant = c_const_my_const . . . IF (str_cmp(name, \u0026quot;my_func\u0026quot;)) as_function = c_func_my_func  Note that neither routine returns immediately after recognising the name of the function/constant. This allows users to override built in constants or functions with custom versions using register_constant} and register_function. This is not significant, since tokenizing should never be used in a speed critical part of the code.\nImplementing the function or constant in the evaluator The evaluator is the part of the code that actually takes the streams of tokens produced by the tokenizer and evaluates them into a number. The relevant parts of the evaluator for adding new constants or functions are in src/parser/evaluator_blocks.f90 and the functions which may need changing are do_constant and do_functions. These are both passed up to five parameters:\n INTEGER :: opcode - The operation code, this is the tokenizer handle which was defined in shared_parser_data. INTEGER :: ix, iy, iz - The position of the current evaluation in the domain. If your function or constant behaves differently at different points in space then you should use these parameters to reference the correct point of an array. INTEGER :: errcode - This should be set to an error code, usually c_err_bad_value if for some reason it is not possible to evaluate your constant or function.  The rest of the routine to set a constant is as simple as testing for the tokenizer handle already set up in shared_parser_data and then calling the subroutine push_on_eval. This pushes the final constant onto the evaluation stack which is used by the RPN parser. The basic sequence for functions is similar except for the addition of a code to read the values that the function takes. This is again the subroutine get_values which is also used in custom_function. The calling sequence in do_function looks like:\nIF (opcode .EQ. c_func_gauss) THEN CALL get_values(3, values) CALL push_on_eval(EXP(-((values(1)-values(2))/values(3))**2)) RETURN ENDIF  Simply call the get_values subroutine, passing the number of required parameters and an array of type REAL(num) which is at least as long as the number of required parameters. The array is populated by the values passed into the function. Constants and maths expressions are already evaluated by the time that this section of code is reached, so there is no need to deal with further parsing. Next, simply call push_on_eval to push the result of your function onto the evaluation stack.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"a1047ec7eb01e5a371e64906432160bd","permalink":"/developer/extensions/maths_parser.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/extensions/maths_parser.html","section":"developer","summary":"When an extension is intended for a new release, the temporary custom extensions are not appropriate. In these cases, it is possible to permanently add functions and constants to EPOCH\u0026rsquo;s maths parser.","tags":null,"title":"Maths Parser","type":"docs"},{"authors":null,"categories":null,"content":"Adding a new module or physics package can turn out to be a very complicated process, but plugging it into the existing PIC-loop is usually quite straightforward. In this page, we will assume you have the source-code for a new module, and we will explain how to add it to EPOCH\u0026rsquo;s calculations.\nThe main driver routine When adding completely new routines to the code, they should be added to the file src/epochnd.F90. This routine simply calls other routines to perform the actual execution of the code. The first section of the code controls basic setup, MPI initialisation and initial conditions. If you wish to add new startup conditions then you should find the location in this routine where the initial conditions are setup. The code is fairly complicated, but there are a few key points at which the code significantly changes state.\n  After the call to read_deck the code has read the basic information from the input deck files and any tests or changes which have to be made to input deck values should be made immediately after this line. Note that although the variables from the deck have been set, none of these values have been used so allocatable variables have yet to be allocated. The grid does not exist at this point.\n  After the call to open_files the code has finished allocating all field variables, although particles may not yet have been set up. The grid now exists.\n  There are now a series of IF statements which test for things like IF (IOR(ictype, c_ic_autoload) .NE. 0). These are the lines which test for all possible states of the initial conditions. The last test is for the manual load routine (c_ic_manual). After this test all the particles have been loaded and are now on their correct processor. The load balancer has now been called at least once so the domains may no longer be identical.\n  The main loop is a simple do loop beginning with just the single command DO. Inside this loop there are several calls to routines which actually advance the system. Most routines which can change currents should take place after the particle pusher but before the final update for the $E$ and $B$ fields. These routines are\n set_dt - This routine sets the timestep. update_eb_fields_half - Time centre the $E$ and $B$ fields. push_particles - The particle pusher. reorder_particles_to_grid - Groups particles into linked lists at each grid point. Used for the particle splitting routine, and binary collisions. Any routine which needs to have nearby particles grouped together should take place after the call to this routine. split_particles - The particle splitting operator. reattach_particles_to_mainlist - Undoes the particle grouping and rebuilds the main list of particles used by the particle pusher. Any routine which needs to have nearby particles grouped together should take place before the call to this routine. update_eb_fields_final - Updates the $E$ and $B$ fields to the full timestep.    After the call to update_eb_fields_final the code is ready for another timestep. Any routines which do not change the time integrated properties of the code (like the moving window) should come after this call.\n  The particle reordering routine After reorder_particles_to_grid, the particles have been moved to particle-lists unique to each cell. The main list species(ispecies)%attached_list is empty and cannot be used during this period. The particles should now be accessed using the variable species(ispecies)%secondary_list(ix,iy,iz) which is the array of linked lists. This array is allocated on the call to reorder_particles_to_grid and deallocated on the call to reattach_particles_to_mainlist, and should not be used outside the section of code between these two calls. The particles themselves remain unchanged. No attempt is made to check that particles do not cross processor boundaries in this section, so if a particle\u0026rsquo;s position is changed, it is up to the user to ensure that the particle is transferred to another processor if required. However, if a particle is transferred to another processor, it is acceptable to relink it to species(ispecies)%attached_list since the other lists are simply appended to that list when the particles are reattached to the main list.\nYou should avoid using these routines if possible, as they have a significant impact on performance. However, this remains the best method for cycling through processes which require particles to interact with other particles within the same cell, such as collisions or collisional ionisation. It is likely that new physics modules for two-body interactions between incident and target particles will also need to use this method (especially if the target particle changes).\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"ecf47aaaac56394844415c6cdc2b0dc4","permalink":"/developer/extensions/new_modules.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/extensions/new_modules.html","section":"developer","summary":"Adding a new module or physics package can turn out to be a very complicated process, but plugging it into the existing PIC-loop is usually quite straightforward. In this page, we will assume you have the source-code for a new module, and we will explain how to add it to EPOCH\u0026rsquo;s calculations.","tags":null,"title":"New Module","type":"docs"},{"authors":null,"categories":null,"content":"Sometimes you may wish to output a new variable associated with a particle. Such extensions may be specific to a particular task, and may be too niche to be added to the core EPOCH code. Alternatively, users may wish to quickly add new particle variables, without submitting a request to the developers and waiting for a new release. This section will detail how to define a new particle variable, and how to dump it to SDF files.\nThere are multiple parts of the code which need to be modified to create and print a new particle variable, these are:\n Makefile: New pre-compiler option to deactivate new variable when not needed (for speed) shared_data.F90: Give the particle datatype a new variable housekeeping/welcome.F90: Alert the user when the code is compiled with your new option housekeeping/partlist.F90: As particles move between MPI ranks, move your new variable with them constants.F90: Create tags for the new output and compiler flag deck/deck_io_block.F90: Lets the output block see the new output variable io/diagnostics.F90: Writes the new variable to the SDF file io/iterators.F90: Gives diagnostics.F90 variables to write to file Extra: The user should set the value of the new variable to something  On this page, we provide an example of how to add and output a new particle variable, which has actually been requested by an EPOCH user. When electrons emit photons in the QED package, the photon macro-particle contains no information about the electron which generated it. In this example, let us output the Lorentz $\\gamma$ factor of the radiating electron for each emitted photon, at the time of photon emission. We will use EPOCH2D, although this methodology would work for any dimension of the code. In these examples, we will include some of the neighbouring lines of code, so you can get a sense of where to insert the new code for your variable.\nMakefile We want a new pre-compiler flag for the new addition. As macro-particles move around the simulation, they are passed between MPI ranks. The more particle variables to transfer, the slower the code runs. Hence, if we don\u0026rsquo;t need to use the new particle variables, the code should be compiled without them. This is achieved with new pre-compiler variables.\nIn the Makefile, there is a section with multiple commented-out pre-compiler flags. Let us add a new one called \u0026ldquo;extended_io\u0026rdquo;. To do this, insert a line such that the Makefile reads like:\n# Use second order particle weighting (default is third order). #DEFINES += $(D)PARTICLE_SHAPE_TOPHAT # Use fifth order particle weighting (default is third order). #DEFINES += $(D)PARTICLE_SHAPE_BSPLINE3 # Include a unique global particle ID. The first flag defines the ID using # an 8-byte integer, the second uses 4-bytes. #DEFINES += $(D)PARTICLE_ID #DEFINES += $(D)PARTICLE_ID4 # Include QED routines DEFINES += $(D)PHOTONS # Extended I/O for QED routines DEFINES += $(D)EXTENDED_IO # Use the Trident process for pair production #DEFINES += $(D)TRIDENT_PHOTONS # Include bremsstrahlung routines #DEFINES += $(D)BREMSSTRAHLUNG  Note that we have un-commented the new extended_io flag, and the photons flag, as we will have to run the code with both for the new output in this example.\nConstants.F90 Let us make new global integer flags for both the pre-compiler flag, and the new output.\nFor the EXTENDED_IO pre-compiler flag, find the c_def... list and append a new c_def_extended_io variable to the end:\n INTEGER(i8), PARAMETER :: c_def_use_mpi3 = 2**25 INTEGER(i8), PARAMETER :: c_def_bremsstrahlung = 2**26 INTEGER(i8), PARAMETER :: c_def_probe_time = 2**27 INTEGER(i8), PARAMETER :: c_def_extended_io = 2**28 ! New line  Next, let us make a new output flag: c_dump_qed_el_gamma. Find the list of c_dump... parameters, and add our new one to the end. Remember to update the num_vars_to_dump variable with the new number of dump flags.\n INTEGER, PARAMETER :: c_dump_probe_time = 72 INTEGER, PARAMETER :: c_dump_cou_log = 73 INTEGER, PARAMETER :: c_dump_qed_el_gamma = 74 ! New line INTEGER, PARAMETER :: num_vars_to_dump = 74 ! Modified line  Note, you may wish to introduce multiple outputs with one pre-compiler flag. For example, the WORK_DONE_INTEGRATED pre-compiler flag introduces six new outputs.\nShared_data.F90 Here we declare a new variable for the particle data-type. Be sure to wrap this inside your new pre-compiler flag using #ifdef commands (note these cannot be indented - the first character of these lines must be #). In our example, we have called the new variable electron_gamma.\n ! Object representing a particle ! If you add or remove from this section then you *must* update the ! particle pack and unpack routines TYPE particle REAL(num), DIMENSION(3) :: part_p REAL(num), DIMENSION(c_ndims) :: part_pos #ifdef EXTENDED_IO REAL(num) :: electron_gamma ! New line, and the surrounding ifdef, endif #endif  Welcome.F90 For consistency with the other EPOCH pre-compiler options, we should print a message when the code has been compiled with our new EXTENDED_IO.\nThe first part of the module scans through all possible pre-compiler variables, and checks if any are present. Add new lines for the new pre-compiler flag.\n#ifdef PHOTONS found = .TRUE. #ifdef TRIDENT_PHOTONS found = .TRUE. #endif #endif #ifdef EXTENDED_IO found = .TRUE. ! New line #endif  Next, a message is printed for each present module. Here we have written a generic message for our extended_io pre-compiler flag.\n#ifdef PHOTONS defines = IOR(defines, c_def_photons) WRITE(*,*) 'QED Effects -DPHOTONS' #ifdef TRIDENT_PHOTONS defines = IOR(defines, c_def_trident_photons) WRITE(*,*) 'Pair production by Trident process -DTRIDENT_PHOTONS' #endif #endif #ifdef EXTENDED_IO defines = IOR(defines, c_def_extended_io) ! New line WRITE(*,*) 'Additional particle variables for output -DEXTENDED_IO' ! New line #endif  Partlist.F90 Each MPI rank only tracks particles present within its section of the domain. As macro-particles move around the simulation, they can pass between cells controlled by different ranks. When this happens, a new particle is created on the new rank, its properties are set to match the properties on the old rank, and the particle on the old rank is destroyed. New particle variables must also be transferred when particles move between ranks, and this is done here.\nThere are 4 steps here:\n Tell the code how many variables are associated with the particle Copy the variables on the old rank to an array for transfer Set variables on the new rank from the transferred array For new particles, initialise the particle variable  To tell the code how many variables are present, find the set_partlist_size subroutine. The count of particle variables is stored in the nvar integer. In this example, we only introduce one more particle variable when the code is compiled with EXTENDED_IO, so add 1 to nvar if we have compiled with EXTENEDED_IO:\n#ifdef BREMSSTRAHLUNG nvar = nvar+1 #endif #ifdef EXTENDED_IO nvar = nvar+1 ! New line #endif #ifdef PROBE_TIME nvar = nvar+1 #endif  Next, navigate to pack_particle - the subroutine responsible for collecting particle variables to transfer to neighbouring ranks. Now we can add our new variable to the transfer array. Make a note of the position here - variables must be read in the same order they are stored.\n#ifdef BREMSSTRAHLUNG array(cpos) = a_particle%optical_depth_bremsstrahlung cpos = cpos+1 #endif #ifdef EXTENDED_IO array(cpos) = a_particle%electron_gamma ! New line cpos = cpos+1 ! Only 1 new variable, so add 1 #endif #ifdef PROBE_TIME array(cpos) = a_particle%probe_time cpos = cpos+1 #endif  Once the particle variables are packed into an array, this is sent to the neighbouring ranks. These call unpack_particle to set the properties of new particles. The syntax for this with our new variable would be:\n#ifdef BREMSSTRAHLUNG a_particle%optical_depth_bremsstrahlung = array(cpos) cpos = cpos+1 #endif #ifdef EXTENDED_IO a_particle%electron_gamma = array(cpos) ! New line cpos = cpos+1 ! Note this is also between optical_depth_bremsstrahlung and probe_time #endif #ifdef PROBE_TIME a_particle%probe_time = array(cpos) cpos = cpos+1 #endif  Finally, we must set the initial values for these variables. If we don\u0026rsquo;t do this, the code can act unpredictably. In the init_particle subroutine, add the lines:\n#ifdef EXTENDED_IO new_particle%electron_gamma = 0.0_num ! New line #endif #ifdef PROBE_TIME new_particle%probe_time = 0.0_num #endif  Deck_io_block.F90 Unless you want to make a new physics package, a new particle variable is only useful if you can output it. This is done using the standard EPOCH output block. Recall we\u0026rsquo;ve already defined a c_dump_qed_el_gamma flag - now we just need to tell EPOCH how it will appear in the input deck.\nNavigate to io_block_handle_element, find the str_cmp lines which interpret the the deck lines, and add:\n#ifdef BREMSSTRAHLUNG ELSE IF (str_cmp(element, 'bremsstrahlung_optical_depth')) THEN elementselected = c_dump_part_opdepth_brem #endif #ifdef EXTENDED_IO ELSE IF (str_cmp(element, 'electron_gamma')) THEN ! New line elementselected = c_dump_qed_el_gamma ! New line #endif  Whatever you write as the second argument to str_cmp is how you will have to write the variable in the EPOCH output block. As we are keeping things simple in this example, we will not bother with restart dumps. The value of electron_gamma will not be re-loaded when you restart the code from a restart dump.\nDiagnostics.F90 At this point we have declared a new particle variable, wrapped it in pre-compiler flags, made it visible to MPI routines, and told EPOCH it can be dumped. Now we actually have to write the variable to file.\nThere is a section in the output_routines subroutine which contains lines with write_particle_variable calls. Add a new one for our variable:\n#ifdef BREMSSTRAHLUNG CALL write_particle_variable(c_dump_part_opdepth_brem, code, \u0026amp; 'Bremsstrahlung Depth', '', it_output_real) #endif #ifdef EXTENDED_IO CALL write_particle_variable(c_dump_qed_el_gamma, code, \u0026amp; 'Emitting Electron Gamma', '', it_output_real) #endif  The 'Emitting Electron Gamma' string controls how the variable will be labelled in the SDF file.\nIterators.F90 One of the arguments of the write_particle_variable subroutine is a call to the it_output_real function. We need to modify this function to give our new variable, when requested. To do this, add the following case to the it_output_real function:\n#ifdef EXTENDED_IO CASE (c_dump_qed_el_gamma) DO WHILE (ASSOCIATED(cur) .AND. (part_count \u0026lt; npoint_it)) part_count = part_count + 1 array(part_count) = cur%electron_gamma cur =\u0026gt; cur%next END DO #endif  Setting your variable All the previous steps are required whatever your particle variable is. All we need to do now is figure out how to set it. This may be straightforward or complicated, depending on what the variable is. We can\u0026rsquo;t cover every possible particle variable here, but you may find it useful if we finish our example, to see how one would go about it.\nHere, we want to save the electron gamma factor when a photon has been emitted. Photon emission occurs in the generate_photon subroutine of photons.F90. When in this subroutine, the generating electron information can be accessed through the generating_electron particle pointer. Fortunately for us, the electron $\\gamma$ factor has already been calculated in this subroutine, and is given by generating_gamma. Let us set our new particle variable to this value, as soon as the photon macro-particle has been created.\n CALL create_particle(new_photon) new_photon%part_pos = generating_electron%part_pos #ifdef EXTENDED_IO new_photon%electron_gamma = generating_gamma ! New line #endif  Testing If all has gone well, we have a new particle variable ready for printing. Compile EPOCH (you may need to run make clean first if you have changed the pre-compiler flags).\nIt\u0026rsquo;s best to run with a small input deck for code testing. We have shrank the qed_rese.deck found in the source code, such that it can run in a few seconds. This tiny deck has been included at the end of this section.\nWhen running, the code correctly generates the compiler-flag messages:\n Welcome to EPOCH2D version 4.19.1 (commit v4.19.1-7-g6a1bfa99-dirty) The code was compiled with the following compile time options ************************************************************* QED Effects -DPHOTONS Additional particle variables for output -DEXTENDED_IO *************************************************************  When we inspect 0001.sdf, we find that 21798 macro-photons have been created, and all of them have an emitting electron gamma value. These range from 20 to 1896 in this example. The input deck used for this example is given below. A new particle variable has been successfully created!\nbegin:control nx = 50 # in x ny = 50 nparticles = nx * ny * 2 t_end = 100e-15 x_min = 0 x_max = 50 * 10.0e-9 y_min = 0 y_max = 50 * 10.0e-9 dt_multiplier = 0.8 end:control begin:qed use_qed = T qed_start_time = 0 produce_photons = T photon_energy_min = 50 * kev produce_pairs = F photon_dynamics = F end:qed begin:boundaries bc_x_min = simple_laser bc_x_max = reflect bc_y_max = reflect bc_y_min = reflect end:boundaries begin:species name = Electron fraction = 0.5 dump = T temperature = 0 number_density = if (x gt 0.1*x_max, 1.0e20, 0) identify:electron end:species begin:species name = Ion fraction = 0.5 dump = T number_density = number_density(Electron) temperature = 0 identify:proton end:species begin:species name = Photon frac = 0 dump = T identify:photon end:species begin:output dt_snapshot = t_end electron_gamma = always end:output begin:laser boundary = x_min intensity = 1.0e21 * 1.0e4 lambda = 1.0e-6 polarisation = 0.0 phase = 0.0 t_profile = 1 profile = 1 end:laser  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682352326,"objectID":"a34f318db54cb1b8ff0c0de07873fda7","permalink":"/developer/extensions/new_particle_variable.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/extensions/new_particle_variable.html","section":"developer","summary":"Sometimes you may wish to output a new variable associated with a particle. Such extensions may be specific to a particular task, and may be too niche to be added to the core EPOCH code.","tags":null,"title":"New Particle Variable","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH is a massively parallel code written using standard MPI. Due to the massively parallel nature of EPOCH, there are MPI commands scattered throughout many parts of the code, although the MPI has been hidden as far as possible from the end user. The main use of MPI occurs during I/O, in the boundary conditions and during load balancing. The MPI setup routines are all in src/housekeeping/mpi_routines.F90, and the routines which are used to create the MPI types used by MPI-IO are in src/housekeeping/mpi_subtype_control.f90.\nGeneral MPI in EPOCH EPOCH uses Cartesian domain decomposition for parallelism and creates an MPI Cartesian topology using MPI_CART_CREATE. The use of MPI in EPOCH is deliberately kept as simple as possible, but there are some points which must be made and some variables which must be explained.\n MPI decomposition is reversed compared to array ordering. Due to the layout of arrays in Fortran, you get slightly faster performance if you split arrays so that the first index remains as long as possible. Since EPOCH uses MPI_DIMS_CREATE to do array subdivision, this means that the MPI coordinate system is ordered backwards compared to the main arrays. This means that the coordinates array which holds the coordinates of the current processor in the Cartesian topology is ordered as {coord_z, coord_y, coord_x}. To make this easier, there are some helper variables. The simplest of these just gives the processors attached to each face of the domain on the current processor. These variables are named x_min, x_max, y_min, y_max, z_min and z_max. Since it is possible for particles to cross boundaries diagonally there is another variable neighbour which identifies every possible neighbouring processor including those meeting at single edges and at corners. neighbour is an array which runs (-1:1,-1:1,-1:1) and, perhaps inconsistently, is ordered in normal order rather than reversed order. This means that x_min == neighbour(-1,0,0) and z_max == neighbour(0,0,1). The variable comm is the handle for the Cartesian communicator returned from MPI_CART_CREATE. The variable errcode is the standard error variable for all MPI communications. However, EPOCH uses the standard MPI_ERRORS_ARE_FATAL error handler so this variable is never tested. EPOCH uses a single variable, status, to hold all MPI status calls. Since there is no non-blocking communication this variable is never checked. The rank of the current processor is stored in the variable rank. The number of processors is stored in nproc. The number of processors assigned to any given direction of the Cartesian topology is given by nproc{x,y,z}.  There are some other variables which are not technically part of the MPI implementation, but which only exist because the code is running in parallel. These are\n REAL(num) :: {x,y,z}_min_local - The location of the start of the domain on the local processor in real units. REAL(num) :: {x,y,z}_max_local - The location of the end of the domain on the local processor in real units. INTEGER, DIMENSION(1:nproc{x,y,z}) :: cell_{x,y,z}_min - The cell number for the start of the local part of the global array in each direction. INTEGER, DIMENSION(1:nproc{x,y,z}) :: cell_{x,y,z}_max The cell number for the end of the local part of the global array in each direction.  mpi_routines.F90 mpi_routines.F90 is the file which contains all the MPI setup code. It contains the following routines:\n mpi_minimal_init - Contains code to start MPI enough to allow the input deck reader to work. The default EPOCH code setup means that it needs to initialise MPI, obtain the rank and the number of processors. setup_communicator - Routine which creates the Cartesian communicator used by the code after the input deck has been parsed. It also populates x_min, x_max etc. It is in its own subroutine so that it can be recalled after the start of the window move when the code is using a moving window. This is needed since it is valid to have a non-periodic boundary before the window starts to move and a periodic boundary afterwards. mpi_initialise - This routine calls setup_communicator and then allocates all the arrays to do with fields, etc. It also sets up the particle list objects for each species. If the code is running with only manual initial conditions then this routine loads the requested number of particles on each processor. Otherwise either the restart or the autoloader code load the particles. mpi_close - This routine performs all the needed cleanup before the final call to MPI_FINALIZE.  mpi_subtype_control.f90 This file contains all the routines which are used to create the MPI types which are used in the SDF I/O system. Most of the routines in this section are used to create the types used for writing the default variables and, when modifying the code, it is possible to output anything which has the same shape and size on disk as the default variables without ever having to use the routines in this file. However, if you are creating more general modifications which can include variables of different sizes with different layouts across processors then you may wish to use these routines to create new MPI types which match your data layout. Any valid MPI type describing the data layout will work with the SDF library, so there is no absolute need to use these routines. Only the general purpose subroutines are described here, since most of the other routines are fairly clear and use these routines internally.\ncreate_particle_subtype FUNCTION create_particle_subtype(npart_local) INTEGER(KIND=8), INTENT(IN) :: npart_local  create_particle_subtype is a routine which creates an MPI type representing particles which are spread across different processors with npart_local particles on each processor. npart_local does not have to be the same number on all processors.\nCurrently this is only used for reading particle data from restart snapshots. It is likely to go away in the near future.\ncreate_ordered_particle_offsets SUBROUTINE create_ordered_particle_offsets(n_dump_species,\u0026amp; npart_local) INTEGER, INTENT(IN) :: n_dump_species INTEGER(KIND=8), DIMENSION(n_dump_species), \u0026amp; INTENT(IN) :: npart_local  create_ordered_particle_offsets is a routine which creates an array of offsets representing particles from n_dump_species which are spread across different processors with npart_local(ispecies) particles of each species on each processor. npart_local does not have to be the same number on all processors and does not have to be the same number for each species.\ncreate_field_subtype FUNCTION create_field_subtype(n{x,y,z}_local, \u0026amp; cell_start_{x,y,z}_local) INTEGER, INTENT(IN) :: nx_local, ny_local, nz_local INTEGER, INTENT(IN) :: cell_start_x_local INTEGER, INTENT(IN) :: cell_start_y_local INTEGER, INTENT(IN) :: cell_start_z_local  create_field_subtype is a routine which creates an MPI type representing a field that is defined across some or all of the processors. The n{x,y,z}_local parameters are the number of points in the x, y, z directions (if they exist in the version of the code that you are working on) that are on the local processor. The cell_start_{x,y,z}_local parameters are the offset of the top, left, back corner of the local subarray in the global array that would exist if the code was running on one processor. This is an offset, not a position and so it begins at {0,0,0} NOT {1,1,1}.\nIn EPOCH3D there is also a routine called create_field_subtype_2d which is exactly equivalent to create_field_subtype in EPOCH2D and is used for writing the 2D distribution functions. At present, there are not equivalent 1D functions except in EPOCH1D, but these could easily by added if required.\nThe load balancer One of the major limiting factors in the scalability of PIC codes is load balancing. Due to the synchronisation of the currents required for the update of the EM fields the entire code runs at the speed of the slowest process. Since most of the time in the main EPOCH cycle is taken by the particle pusher, this equates to the process with the highest number of particles being the slowest. Since the location of particles is dependent upon the solution of the problem under consideration, in general the code will not have exactly the same number of particles on each processor. The load balancer is used to move the inter-processor boundaries so that the number of particles is as close to the same on each processor as possible. The load balancer is invoked at the start of the code and when the ratio of the least loaded processor to the most loaded processor falls below a user specified critical point.\nEPOCH\u0026rsquo;s load balancer works by rearranging the processor boundaries in 1D sweeps in each direction, rather than attempting to perform multidimensional optimisation. Also, at present the MPI in EPOCH requires each processor to be simply connected at every point, so it must have one processor to the left, one to the front etc. which introduces a further restriction on the load balancer. Otherwise, the load balancer is fully general. The load balancing sweep is illustrated here:\nThe load balancer is implemented in the file src/housekeeping/balance.F90 and is called by the routine balance_workload(override). The parameter override is used to force the code to perform a load balancing sweep even when it would normally determine that the imbalance is not large enough to force a load balancing sweep. Although the load balancer is hard coded to load balance in all available directions, the code is written in such a way that it is possible to modify the code to load balance in only one direction, or to automatically determine which single direction gives the best performance.\nThe details of the load balancer are fairly intricate, and if major modification to the load balancer is required, it is recommended that the original authors be contacted for detailed advice on how to proceed. However, the general layout of the routine is as follows.\n Use MPI_ALLREDUCE to determine the global minimum and maximum number of particles. If the ratio of the minimum to the maximum is above the load balance threshold then just return from the subroutine. The code uses the routines get_load_in_{x,y,z} to determine the work load along each direction of the domain. The get_load_in_x routine uses the x-coordinate of every particle to create a 1D particle density in the x-direction. This is then combined with the total number of grid cells in the y-z plane to give a 1D array of the work load in the x-direction. Similarly for get_load_in_{y,z}. Next the load array is passed to the calculate_breaks routine which fills the arrays starts_{x,y,z} and ends_{x,y,z}. These arrays contain the starting and ending cell numbers of the hypothetical global array in each direction for each processor. The routine redistribute_fields is then called to move the information about field variables which cannot be recalculated. If new field variables are created that cannot be recalculated after the load balancing is completed then redistribute_fields has to be modified for these new variables. The next section of the routine deals with those variables which can be recalculated after the load balance sweep is complete, such as the coordinate axes and the arrays which hold the particle kinetic energy. The penultimate section of the routine then changes the variables which tell the code where the edges of its domain lie in real space to reflect the changed shape of the domains. The final part is the call to distribute_particles which moves the particles to the new processor. Once this is finished, the code should have as near as possible the same number of particles on each processor.  Most of the load balancer is purely mechanical and should only be changed if the way in which the code is to perform load balancing is fundamentally altered. The redistribution of particles that takes place in distribute_particles uses the standard particle_list objects, so that if the necessary changes have been made to the routines in src/housekeeping/partlist.F90 to allow correct boundary swaps of particles then the load balancer should work with no further modification. The only part of the load balancer which should need changing is redistribute_fields which requires explicit modification if new field variables are required. For fields which are the same shape as the main array there is significant assistance provided within the code to make the re-balancing simpler. There are also routines which can help with re-balancing variables which are the size of only one edge or face of the domain. Variables which are of a completely different size but still need to be rebalanced when coordinate axes move have to have full load balancing routines implemented by the developer. This is beyond the scope of this manual and any developer who needs assistance with development such a modification should contact the original author of the code. The field balancer is fairly simple and mostly calls one of three routines: redistribute_field and either redistribute_field_2d or redistribute_field_1d depending on the dimensionality of your code. To redistribute full field variables the routine to use is redistribute_field, and an example of using the code looks like:\ntemp = 0.0_num CALL redistribute_field(new_domain, bz, temp) DEALLOCATE(bz) ALLOCATE(bz(-2:nx_new+3,-2:ny_new+3)) bz = temp  In this calling sequence the redistribute_field subroutine is used to redistribute the field bz, and the newly redistributed field is copied into temp; an array which is already allocated to the correct size. The new_domain parameter is an array indicating the location of the start and end points of the new domain for the current processor in gridpoints offset from the start of the global array. It is passed into the redistribute_fields subroutine as a parameter from the balance_workload subroutine and should not be changed. The temp variable is needed since Fortran standards before Fortran2000 do not allow the deallocation and reallocation of parameters passed to a subroutine. There is a more elegant solution, where temp is hidden inside the redistribute_field subroutine. However, support for this in current Fortran2000 implementations is unreliable.\nThe routine for re-balancing variables which lie along an edge of the domain are very similar and are demonstrated in the redistribute_fields subroutine for lasers attached to different boundaries. It is recommended that a developer examine this code when developing new routines.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"49b4a53b390077fc399a427885687104","permalink":"/developer/core_structure/parallelism.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/parallelism.html","section":"developer","summary":"EPOCH is a massively parallel code written using standard MPI. Due to the massively parallel nature of EPOCH, there are MPI commands scattered throughout many parts of the code, although the MPI has been hidden as far as possible from the end user.","tags":null,"title":"Parallelism","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH\u0026rsquo;s particle pusher is based on the one from the PSC by Hartmut Ruhl, and is a Birdsall and Landon type PIC scheme using Villasenor and Buneman current weighting. It is contained in the file particles.F90. The operation of the particle pusher is fairly simple, but there are a few elements which need some clarification.\n The update to the particle momenta etc. does not explicitly include the particle weight function. This means that the pseudoparticle momenta etc. are the momentum for a single real particle of the collection of real particles represented by that pseudoparticle, NOT the momentum of the whole collection of real particles. gamma - The variable gamma which appears in various places is the relativistic $\\gamma$ which is needed to convert the particle momentum into the particle velocity using the relation $\\vec{p} = \\gamma m \\vec{v}$. Here, $\\vec{p}$ is the particle momentum, $\\vec{v}$ is the particle velocity and $m$ is the particle rest mass. If EPOCH was not relativistic then this would simply be $1$. Since EPOCH is relativistic, gamma is defined as $\\left(\\vec{p}.\\vec{p}/m c^2 + 1\\right)^{1/2}$. cell_x1=cell_x1+1 - There are lines like this after all the sections of the routine where the cell a particle is in is calculated. This is because, for a cell centred variable, the domain runs (1:nx,1:ny,1:nz) rather than (0:nx-1,0:ny-1,0:nz-1).  The most complicated parts of the particle pusher are interpolating the grid electric and magnetic fields over the macro-particle shape, and the current density solver.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"8b89819e5a0500d250a2c3efc8df3c5e","permalink":"/developer/core_structure/particle_pusher.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/particle_pusher.html","section":"developer","summary":"EPOCH\u0026rsquo;s particle pusher is based on the one from the PSC by Hartmut Ruhl, and is a Birdsall and Landon type PIC scheme using Villasenor and Buneman current weighting. It is contained in the file particles.","tags":null,"title":"Particle Pusher","type":"docs"},{"authors":null,"categories":null,"content":"In the PIC method, the simulation grid is filled with macro-particles, which respresent a large number of real particles. They are described primarily by a position on the grid, and a momentum, charge, mass and weight. In EPOCH, the first few variables describe a single real particle within the macro-particle, and the weight describes how many real particles the macro-particle represents.\nMacro-particles are split between different species, set by the species blocks in the input deck. All macro-particles present on a single rank are contained within the species_list variable, which contains lists of particles for all species present, along with information about each species.\nIn short, the data is distributed among types as follows:\n Particle type: contains information about a single macro-particle. Particle list: a linked list object, containing a list of macro-particles. Particle species: contains information about a set of particles as a whole, and a corresponding particle list. Species list: an array containing all the particle species.  The particle data-type Particles are represented as linked lists of Fortran TYPES. The definition can be found in shared_data.F90, which is shared globally among all modules. Hence, any module can use a particle data-type.\nIn this data-type, you will notice that many parameters are locked behind pre-processor flags, and must be manually switched on through the Makefile. This is because as particles move around the grid, they must be transferred from processor to processor as they move in and out of cells controlled by each rank. This MPI transfer is a major bottleneck for the code, so by default, EPOCH assigns the minimum amount of information to each particle, to minimise the rank-to-rank data transfer.\nThe datatype is shown here:\nTYPE particle REAL(num), DIMENSION(3) :: part_p REAL(num), DIMENSION(c_ndims) :: part_pos #if !defined(PER_SPECIES_WEIGHT) || defined(PHOTONS) REAL(num) :: weight #endif #ifdef DELTAF_METHOD REAL(num) :: pvol #endif #ifdef PER_PARTICLE_CHARGE_MASS REAL(num) :: charge REAL(num) :: mass #endif TYPE(particle), POINTER :: next, prev #ifdef PARTICLE_DEBUG INTEGER :: processor INTEGER :: processor_at_t0 #endif #ifdef PARTICLE_ID4 INTEGER :: id #elif PARTICLE_ID INTEGER(i8) :: id #endif #ifdef COLLISIONS_TEST INTEGER :: coll_count #endif #ifdef WORK_DONE_INTEGRATED REAL(num) :: work_x REAL(num) :: work_y REAL(num) :: work_z REAL(num) :: work_x_total REAL(num) :: work_y_total REAL(num) :: work_z_total #endif #ifdef PHOTONS REAL(num) :: optical_depth #endif #if defined(PHOTONS) || defined(BREMSSTRAHLUNG) REAL(num) :: particle_energy #endif #if defined(PHOTONS) \u0026amp;\u0026amp; defined(TRIDENT_PHOTONS) REAL(num) :: optical_depth_tri #endif #ifdef BREMSSTRAHLUNG REAL(num) :: optical_depth_bremsstrahlung #endif #if defined(PROBE_TIME) REAL(num) :: probe_time #endif END TYPE particle  And the descriptions are\n REAL(num) :: part_p(3) - The particle momentum. Always dimension 3 even in 1D and 2D codes. Describes the momentum of a single particle within the macro-particle. REAL(num) :: part_pos(ndims) - The particle position. Has the same dimensions as that of the code. REAL(num) :: weight - The particle weight if the code is running with per particle weighting (otherwise weight is a species parameter). REAL(num) :: charge - The particle charge in Coulombs if the code is running with per particle charge (otherwise charge is a species parameter). REAL(nun) :: mass - The particle mass in kilograms if the code is running with per particle mass (otherwise mass is a species parameter). TYPE(particle), POINTER :: next, prev - The pointers to the next and previous elements of the linked list. INTEGER :: processor - The rank of the processor that the particle thinks it is on. Used for debugging. INTEGER :: processor_at_t0 - The rank of the processor that the particle started on. Used for debugging. INTEGER :: id - A unique integer assigned to each particle, only set for species which output the id, and only when the code is compiled with ID support. INTEGER :: coll_count - An integer present for debugging the number of collisions a particle undergoes (this is not used in the current version of EPOCH). REAL(num) :: work_{x,y,z} - Work done by the electric field on the particle during the last particle push, in each direction. Describes work done to a single particle within the macro-particle. REAL(num) :: work_{x,y,z}_total - Work done by the electric fields on the particle over the full simulation, in each direction. Describes work done to a single particle within the macro-particle. REAL(num) :: optical_depth - For some secondary-particle emission processes, a particle is assigned an \u0026ldquo;optical depth of emission\u0026rdquo;, related to how far the particle has moved, and the cross section of emission. The total optical depth is tracked, and an emission is sampled once the optical_depth goes negative. The original optical_depth here describes the remaining optical depth to travel before photon emission through the QED non-linear Compton scatter process for electrons. For photons, this describes the remaining optical depth before Breit-Wheeler pair production. REAL(num) :: particle_energy - Contains the relativistic particle energy, primarily for use in the QED routines. REAL(num) :: optical_depth_tri - Remaining optical depth before emission of a pair through the electron trident process. REAL(num) :: optical_depth_bremsstrahlung - Remaining optical depth before emission of a bremsstrahlung photon for electrons, or a Bethe-Heitler pair for photons. REAL(num) :: probe_time - If a particle passes a probe, a copy of the particle is stored in a new list. This parameter is set to the time the particle passes the probe, for the particle copy.  WARNING: Simply adding a new parameter to the definition of the particle type is NOT sufficient to extend the particle type, since the communications when the particle crosses a processor boundary do not know about the new parameter and it will not be transmitted with the particle. How to add new properties to the particle communication layer is described later.\nParticle list type The entire linked list of particles is encapsulated in another Fortran TYPE, called particle_list, which is defined as:\nTYPE particle_list TYPE(particle), POINTER :: head TYPE(particle), POINTER :: tail INTEGER(KIND=8) :: count ! Pointer is safe if the particles in it are all unambiguously linked LOGICAL :: safe TYPE(particle_list), POINTER :: next, prev END TYPE particle_list  And its properties are:\n  TYPE(particle), POINTER :: head - The first particle in the linked list.\n  TYPE(particle), POINTER :: tail - The last particle in the linked list. New particles added to the end of the list are added onto the end of the tail element, and the new last particle becomes the new tail element.\n  INTEGER(KIND=8) :: count - The number of particles in this particle list. Note that the particle_list type is not directly MPI aware, so this is literally the number of particles in this particle list, not the number of particles of this species on all processors.\n  LOGICAL :: safe - A particle list safe if the particles in it are unambiguously linked. That is that the countth particle is guaranteed to have its next property be null. Most particle lists within EPOCH are safe, but sometimes it is useful to be able to have particle lists which are subsets of longer particles lists, and these particle lists are not safe.\n  TYPE(particle_list), POINTER :: next, prev - At present, EPOCH does not use these pointers, which are intended to allow multiple particle lists to be attached together. Certain parts of EPOCH, such as the I/O system are aware of these pointers and will automatically use them if they are ever set. They are reserved for future use.\n  The particle_list objects are used to abstract all the functions of the linked list, including adding and removing particles and transporting particles between processors.\nParticle species type The particle species are represented by yet another Fortran TYPE, this time called particle_species, which in 2D is defined as:\nTYPE particle_species ! Core properties CHARACTER(string_length) :: name TYPE(particle_species), POINTER :: next, prev INTEGER :: id INTEGER :: dumpmask INTEGER :: count_update_step REAL(num) :: charge REAL(num) :: mass REAL(num) :: weight INTEGER(i8) :: count TYPE(particle_list) :: attached_list TYPE(particle_pointer_list), POINTER :: boundary_particles =\u0026gt; NULL() LOGICAL :: immobile LOGICAL :: fill_ghosts ! Parameters for relativistic and arbitrary particle loader INTEGER :: ic_df_type REAL(num) :: fractional_tail_cutoff TYPE(primitive_stack) :: dist_fn TYPE(primitive_stack) :: dist_fn_range(3) #ifndef NO_TRACER_PARTICLES LOGICAL :: zero_current #endif INTEGER :: atomic_no LOGICAL :: atomic_no_set = .FALSE. ! Specify if species is background species or not LOGICAL :: background_species = .FALSE. ! Background density REAL(num), DIMENSION(:,:), POINTER :: background_density ! Do we need to make secondary lists for this species? LOGICAL :: make_secondary_list = .FALSE. ! Has species list been randomised in order? LOGICAL :: is_shuffled ! Specifiy if species is background for collisions LOGICAL :: coll_background = .FALSE. LOGICAL :: coll_fast = .FALSE. LOGICAL :: coll_pairwise = .FALSE. ! ID code which identifies if a species is of a special type INTEGER :: species_type ! particle cell division INTEGER(i8) :: global_count LOGICAL :: split INTEGER(i8) :: npart_max ! Secondary list TYPE(particle_list), DIMENSION(:,:), POINTER :: secondary_list ! Loading of particles REAL(num) :: npart_per_cell TYPE(primitive_stack) :: density_function, temperature_function(3) TYPE(primitive_stack) :: drift_function(3) ! Thermal boundaries REAL(num), DIMENSION(:,:), POINTER :: ext_temp_x_min, ext_temp_x_max REAL(num), DIMENSION(:,:), POINTER :: ext_temp_y_min, ext_temp_y_max ! Species_ionisation LOGICAL :: electron LOGICAL :: ionise INTEGER :: ionise_to_species INTEGER :: release_species INTEGER :: n INTEGER :: l REAL(num) :: ionisation_energy REAL(num), ALLOCATABLE :: coll_ion_incident_ke(:) REAL(num), ALLOCATABLE :: coll_ion_cross_sec(:) REAL(num), ALLOCATABLE :: coll_ion_mean_bind(:,:) REAL(num), ALLOCATABLE :: coll_ion_secondary_ke(:,:) REAL(num), ALLOCATABLE :: coll_ion_secondary_cdf(:,:) ! Attached probes for this species #ifndef NO_PARTICLE_PROBES TYPE(particle_probe), POINTER :: attached_probes #endif ! Particle migration TYPE(particle_species_migration) :: migrate ! Initial conditions TYPE(initial_condition_block) :: initial_conditions ! Per-species boundary conditions INTEGER, DIMENSION(2*c_ndims) :: bc_particle END TYPE particle_species  Again, most of these properties are self explanatory, but they are detailed below.\n  CHARACTER(LEN=entry_length) :: name - The name of the particle species. Used when constructing things like \u0026ldquo;ekbar_electron\u0026rdquo; and similar names.\n  TYPE(particle_species), POINTER :: next, prev - Particle species are connected to each other as a linked list using pointers as well as being available through a simple array. These pointers are used behind the scenes in the I/O.\n  INTEGER :: id - The number of the species, so for the species species_list(1), the id field would be 1. For species_list(2), the id field would be 2 etc.\n  INTEGER :: dumpmask - Bitmask to determine when this species should be dumped in diagnostic output.\n  INTEGER :: count_update_step - The last step where the count parameter was updated.\n  REAL(num) :: charge - The charge on a single particle of the species in Coulombs.\n  REAL(num) :: mass - The mass of a single particle of the species in kilograms.\n  REAL(num) :: weight - The per-species particle weight.\n  INTEGER(KIND=8) :: count - The number of particles of this species on all processors. NOTE that this is only accurate if the code is compiled with the correct preprocessor options. Without the correct preprocessor options, this will be accurate at the start of the code runtime, but will not be if any particles enter or leave the domain. This is mainly a debugging parameter.\n  TYPE(particle_list) :: attached_list - This is the particle_list object which holds the particles assigned to this species on this processor. Particles are attached to this list except between the calls to reorder_particles_to_grid and reattach_particles_to_mainlist in epoch{1,2,3}d.F90 where the particles are instead attached to secondary_list. This is explained later.\n  TYPE(particle_pointer_list), POINTER :: boundary_particles - A list of particles which have been pushed out of the simulation boundaries.\n  LOGICAL :: immobile - These particles skip the particle push if true.\n  LOGICAL :: fill_ghosts - Loads particles into ghost cells surrounding the simulation if true.\n  INTEGER :: ic_df_type - Sets temperature calculation for the delta-f loader.\n  REAL(num) :: fractional_tail_cutoff - Sets a cut-off for the relativistic temperature to momentum calculation in src/user_interaction/particle_temperature.F90\n  TYPE(primitive_stack) :: dist_fn - Arbitrary momentum distribution function for particle loading.\n  TYPE(primitive_stack) :: dist_fn_range(3) - Set upper and lower ranges to the momentum distribution functions.\n  LOGICAL :: zero_current - Whether or not this species is a tracer particle. If a species is a tracer species then it moves under the fields as normal for a particle with its mass and charge but contributes no current.\n  INTEGER :: atomic_no - Set atomic number of species. Used for bremsstrahlung and ionisation.\n  LOGICAL :: atomic_no_set - Identifies is an atomic number has been set for the species.\n  LOGICAL :: background_species - If true, the species is not to load any particles. Instead, this is represented with a density value in each cell, and it can only act as a target species for bremsstrahlung radiation.\n  REAL(num), DIMENSION(:,:,:), POINTER :: background_density - The number density of a background species (for bremsstrahlung radiation).\n  LOGICAL :: make_secondary_list - Checks if this species will ever need to create a secondary list (see secondary_list).\n  LOGICAL :: is_shuffled - Checks if the order of particles in secondary lists has been randomised\n  LOGICAL :: coll_background- Checks if this species forms the background species in a fast-background pair for background particle collisions.\n  LOGICAL :: coll_fast - Checks if this species describes the fast species in a fast-background pair for background particle collisions.\n  LOGICAL :: coll_pairwise - Checks if this species undergoes binary collisions with another species.\n  INTEGER :: species_type - Tag the species as a particular type of particle, using constants like c_species_id_electron. This is required for the physics packages.\n  INTEGER(i8) :: global_count - The number of particles from this species summed over all ranks.\n  LOGICAL :: split - EPOCH includes a very early version of a particle splitting operator. It works mechanically but has undesirable properties at present. If this flag is true then the code attempts to split the particles when the pseudoparticle number density drops too low.\n  INTEGER(KIND=8) :: npart_max - Used with the particle splitting operator. When the total number of particles equals this number, further particle splitting is suppressed.\n  TYPE(particle_list), DIMENSION(:,:,:), POINTER :: secondary_list - This describes an array of particle lists. The subroutine reorder_particles_to_grid allocates secondary_list(0:nx+1,0:ny+1,0:nz+1) and then loops over all particles. It calculates the cell in which each particle is and moves the particle from attached_list to the correct element of secondary_list for that cell. This means the particles which are nearby in space are now linked together in an array of linked lists. This allows things such as collision operators which require direct interaction between nearby particles.\n  INTEGER(KIND=8) :: npart_per_cell - The number of pseudoparticles per cell in the initial conditions. This is used with the moving window function to ensure that the same number of particles per cell are used for the new material introduced at the leading edge of the window.\n  REAL(num), DIMENSION(:,:), POINTER :: density - The density of the plasma at the leading edge of the window at the start of the simulation. This is used to structure the density of the new material introduced at the leading edge of the plasma.\n  REAL(num), DIMENSION(:,:,:), POINTER :: temperature - The temperature in of the plasma at the leading edge of a moving window at the start of the simulation. The final index of the array is the direction in which the temperature is set (1=x, 2=y, 3=z).\n  REAL(num), DIMENSION(:,:,:), POINTER :: ext_temp_{x,y,z}_{min,max} - Sets the temperature on the boundary for this particle species if thermal boundaries have been used.\n  LOGICAL :: electron - Species is tagged as an electron for the ionisation routines.\n  LOGICAL :: ionise - If the ionisation model is activated then this species should ionise.\n  INTEGER :: ionise_to_species - The species number for the next ionised state of this species.\n  INTEGER :: release_species - Specifies what type of particle should be released when this species ionises (i.e. which species is the electron).\n  REAL(num) :: ionisation_energy - The ionisation energy for the next ionisation of this species.\n  INTEGER :: n, l - The principle and angular quantum numbers of the outermost electron for this species, assuming a ground-state electron configuration. This is used for field ionisation.\n  REAL(num), ALLOCATABLE :: coll_ion_incident_ke(:) - A table of logarithmically spaced kinetic energy values for incident electrons in collisional ionisation.\n  REAL(num), ALLOCATABLE :: coll_ion_cross_sec(:) - The collisional ionisation cross sections corresponding to incident electrons with kinetic energies given by coll_ion_incident_ke(:).\n  REAL(num), ALLOCATABLE :: coll_ion_mean_bind(:,:) - For each incident/ejected electron energy pair for collisional ionisation, this gives the mean bound electron energy, weighted by the ionisation cross section of each bound shell.\n  REAL(num), ALLOCATABLE :: coll_ion_secondary_ke(:,:) - An array of possible ejected electron energies for each incident electron kinetic energy in the coll_ion_incident_ke(:) table.\n  REAL(num), ALLOCATABLE :: coll_ion_secondary_cdf(:,:) - The cumulative distribution function for the probability of emission of an ejected electron energy for a given incident energy during collisional ionisation, corresponding to the energies in coll_ion_secondary_ke.\n  TYPE(particle_probe), POINTER :: attached_probes - A pointer pointing to the head of an attached linked list of particle probe diagnostics.\n  TYPE(particle_species_migration) :: migrate - Determines the criteria for particles being moved to other species, using the particle migration routines.\n  TYPE(initial_condition_block) :: initial_conditions - Stores parameters read from the species block, describing the initial conditions of the species.\n  INTEGER, DIMENSION(2*c_ndims) :: bc_particle - Boundary conditions for particles in this species, which override the global boundaries set in the input deck boundary block.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"c2dc4d9a61b1a4dc4e67433db71c643a","permalink":"/developer/core_structure/macro_particles.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/macro_particles.html","section":"developer","summary":"In the PIC method, the simulation grid is filled with macro-particles, which respresent a large number of real particles. They are described primarily by a position on the grid, and a momentum, charge, mass and weight.","tags":null,"title":"Particles","type":"docs"},{"authors":null,"categories":null,"content":"Collections of particles in EPOCH are represented by the particle_list object. These objects abstract much of the operation of the linked lists, including adding and removing particles and sending particles to other processors. This page details the functions present in src/housekeeping/partlist.F90, which details how particle lists are formed.\ncreate_empty_partlist SUBROUTINE create_empty_partlist(partlist) TYPE(particle_list), INTENT(INOUT) :: partlist  create_empty_partlist is a routine which takes a particle_list object and sets it up so that it points to no particles at all. It should be used on newly allocated particle_list objects and when a particle_list has served its purpose. It DOES NOT destroy the particles linked in the list at the point that it is called. If the user wishes to delete all the particles in a particle_list then the routine destroy_partlist should be used instead.\ncreate_unsafe_partlist SUBROUTINE create_unsafe_partlist(partlist, a_particle, \u0026amp; n_elements) TYPE(particle_list), INTENT(INOUT) :: partlist TYPE(particle), POINTER :: a_particle INTEGER(KIND=8), INTENT(IN) :: n_elements  create_unsafe_partlist is a routine which allows the creation of a particle_list which represents a subset of another particle list. This subset is defined as starting at the particle pointed to by a_particle and extending for n_elements elements. The new particle_list is then flagged as \u0026ldquo;unsafe\u0026rdquo; because if it is destroyed for any reason then it will affect other particle lists. Many particle_list functions can only work on safe particle lists.\ncreate_unsafe_partlist_by_tail SUBROUTINE create_unsafe_partlist_by_tail(partlist, head, \u0026amp; tail) TYPE(particle_list), INTENT(INOUT) :: partlist TYPE(particle), POINTER :: head, tail  create_unsafe_partlist_by_tail is almost identical to create_unsafe_partlist, but instead of specifying the first particle and a number of elements, the user specifies the first and last elements in the subset of the particle list. If the particle objects specified for head and tail are not in the same partlist or tail actually comes before head then the routine will fail in an undefined manner.\ncreate_allocated_partlist SUBROUTINE create_allocated_partlist(partlist, n_elements) TYPE(particle_list), INTENT(INOUT) :: partlist INTEGER(KIND=8), INTENT(IN) :: n_elements  create_allocated_partlist is a helper routine to setup a new particle_list and create n_elements new particle objects already in place in the list.\nYou should always use this routine when creating large numbers of new particle objects since there is no guarantee that the internal structure of the particle_list objects will not change in the future. This routine will be modified to reflect any changes in the underlying code.\ncreate_filled_partlist SUBROUTINE create_filled_partlist(partlist, data_in, \u0026amp; n_elements) TYPE(particle_list), INTENT(INOUT) :: partlist REAL(num), DIMENSION(:), INTENT(IN) :: data_in INTEGER(KIND=8), INTENT(IN) :: n_elements  create_filled_partlist is a helper routine to setup a new particle_list and create n_elements new particle objects already in place in the list. These new particle objects are then assigned properties from the array data_in where the particle properties are contained in packed form. The particle data is unpacked from the array using the unpack_particle routine.\nYou should always use this routine, if possible, when copying particles out of packed format since there is no guarantee that the internal structure of the particle_list objects will not change in the future. This routine will be modified to reflect any changes in the underlying code.\ntest_partlist FUNCTION test_partlist(partlist) TYPE(particle_list), INTENT(INOUT) :: partlist  test_partlist is a routine which tests for various possible types of error within a particle_list object. It has a number of possible return codes for different errors, using negative values for errors so severe that the main tests cannot be run, or with a bitmask for errors in the main tests. The return codes are:\n 0 - No error, particle_list has passed all tests. -1 - Either the head or tail of the particle_list object is NULL. This is a serious error and usually means that there is a serious error inside the particle_list routines.  The other error codes are returned as a bitmask and mean the following\n 1 - A particle_list marked as safe has a head element which is linked to a preceding particle object. 2 - A particle_list marked as safe has a tail element which is linked to a proceding particle object. 4 - The count property of a particle_list does not correspond to the actual number of objects linked between the head and tail objects. This error code on its own usually means that the count property has been modified improperly.  Note that this routine is only intended for debugging and is very slow. It should never be used by the code in normal operation and all routines should be written in such a way that it is impossible for a particle_list object to become corrupted.\ndestroy_partlist SUBROUTINE destroy_partlist(partlist) TYPE(particle_list), INTENT(INOUT) :: partlist  destroy_partlist is a helper routine to delete all the particles attached to a particle_list and free up the memory that they use. It also guarantees to leave the particle_list object itself in a blank state where new particles can be added to it. It DOES NOT delete the particle_list object itself, since it does not know whether or not the particle_list is dynamically allocated. If using dynamically allocated particle_list objects then it is up to the user to deallocate them AFTER the attached particles are destroyed using destroy_partlist.\nIf a particle_list is deleted without deleting the attached particle objects, either using this routine or explicitly by the user, then the particles will become orphaned and sit around using memory until the code ends. If this happens regularly then the code will quickly crash, usually with a SIG_SEGV error.\ncopt_partlist SUBROUTINE copy_partlist(partlist1, partlist2) TYPE(particle_list), INTENT(INOUT) :: partlist1, partlist2  copy_partlist is a routine which sets partlist2 to point to the same linked list of particles as partlist1. It does not copy the particles, just sets the head and tail pointers of partlist1 to point to the same particle objects as partlist1.\nappend_partlist SUBROUTINE append_partlist(head, tail) TYPE(particle_list), INTENT(INOUT) :: head, tail  append_partlist is a routine which takes the particles attached to the particle_list object tail and adds them to the end of the linked list for particle_list head. The particle_list tail is then set to be an empty particle_list.\nThis routine can only append one safe particle_list to another safe particle_list.\nadd_particle_to_partlist SUBROUTINE add_particle_to_partlist(partlist, new_particle) TYPE(particle_list), INTENT(INOUT) :: partlist TYPE(particle), POINTER :: new_particle  add_particle_to_partlist adds a new particle (new_particle) to the end of the linked list of particles in the particle_list object partlist. It deals with cases of empty particle_list objects automatically.\nIf you want to add a new particle to the end of a particle list you should always use this routine.\nremove_particle_from_partlist SUBROUTINE remove_particle_from_partlist(partlist, \u0026amp; a_particle) TYPE(particle_list), INTENT(INOUT) :: partlist TYPE(particle), POINTER :: a_particle  remove_particle_from_partlist removes the particle object specified by a_particle from the particle_list object given by partlist. Be very careful that a_particle is indeed in the linked list pointed to by partlist, otherwise it is possible for the particle_list object which really does contain a_particle to be left with an invalid pointer as its head or tail element if a_particle is either the head or tail element.\nAlthough this routine does work with unsafe particle_list objects, you should be very careful using it in this case as it can break the head or tail element of the primary particle_list which the unsafe particle_list is a subset of. As a general rule, you should only use this routine to remove particles from a simple particle_list which is a singly referenced primary, safe particle_list.\nsetup_partlists SUBROUTINE setup_partlists()  setup_partlists is a routine which is called once when EPOCH first starts. It sets the variable nvars which is the number of REAL(num) values required to contain all the information about a single particle object needed when a particle is transferred to another processor. How the information is packed and unpacked from the particle object into an array of REAL(num) values is controlled in the functions pack_particle and unpack_particle.\nIf the particle type gains additional properties as the result of preprocessor directives then there should be a line which increments nvars by the correct number when that preprocessor directive is active. For example:\n#ifdef PER_PARTICLE_CHARGE_MASS nvar = nvar+2 #endif  pack_particle and unpack_particle SUBROUTINE pack_particle(array, a_particle) SUBROUTINE unpack_particle(array, a_particle) REAL(num), DIMENSION(:), INTENT(INOUT) :: array TYPE(particle), POINTER :: a_particle  pack_particle and unpack_particle are subroutines which are used to copy all the information about a particle necessary for the particle to be transferred to another processor into a temporary array before sending to another processor. If a new particle property has been added to the particle then these routines must be modified to allow the copying of the new data into the array. The parameter array is a REAL(num) array of length nvars and is the array into which the data either must be packed or from which it must be unpacked. a_particle is the particle object which must either have its data copied into the array or be populated with data from the array. No restriction is placed on how the data should be packed into the data array, but obviously pack_particle and unpack_particle must be inverse operations so that particles packed by one processor can be unpacked correctly by another processor.\nSince it is very unlikely that EPOCH will be run on anything other than a homogeneous cluster, it is acceptable to use the Fortran TRANSFER function to pack incompatible data types into the array array. Just make sure that nvars is defined in setup_partlists to be long enough to contain all the information. More documentation on the TRANSFER function (which is rarely used and dangerous!) can be found here.\ndisplay_particle SUBROUTINE display_particle(a_particle) TYPE(particle), POINTER :: a_particle  Displays the key information about a particle given by the parameter a_particle. Used by compare_particles.\ncompare_particles FUNCTION compare_particles(particle1, particle2) TYPE(particle), POINTER :: particle1, particle2 LOGICAL :: compare_particles  Compares all the properties of two particle objects and displays the information if they don\u0026rsquo;t match. Used internally by test_packed_particles. If the particle object is extended then this routine should also be modified to test for equivalence of the new properties.\ntest_packed_particles FUNCTION test_packed_particles(partlist, array, \u0026amp; npart_in_data) TYPE(particle_list), INTENT(IN) :: partlist REAL(num), DIMENSION(:), INTENT(IN) :: array INTEGER(KIND=8), INTENT(IN) :: npart_in_data LOGICAL :: test_packed_particles  test_packed_particles is a routine which checks that a packed array of particles can be successfully unpacked back into particle objects. The parameters are:\n partlist - The particle_list corresponding to the original unpacked particles. array - The REAL(num) array containing the packed data. npart_in_data - The number of particles which were packed into array.  The routine tests that the number of particles in the particle_list match the number believed to be in the data array, that the length of the data array is correct and then unpacks each particle in turn from the data array and uses the compare_particles function to compare the particles with the original versions in the particle_list. If any particles fail the comparison then an error is output to stdout and the function returns a value of .FALSE.. The error message includes the processor rank on which the problem occurs but the routine does not specifically include any MPI commands, so it is possible to call the routine on a subset of processors.\npartlist_send SUBROUTINE partlist_send(partlist, dest) TYPE(particle_list), INTENT(INOUT) :: partlist INTEGER, INTENT(IN) :: dest  partlist_send is a routine for sending all the particles in the particle_list object partlist to another processor. The destination processor is identified by its rank which is given by the dest parameter. The routine does not destroy the particle_list object which is given to it.\npartlist_send uses MPI blocking sends, so unless a matching partlist_recv has been posted on dest then the routine will deadlock. It would be fairly simple to write a non-blocking version of partlist_send, but at present no need for such a routine has been found.\npartlist_recv SUBROUTINE partlist_recv(partlist, src) TYPE(particle_list), INTENT(INOUT) :: partlist INTEGER, INTENT(IN) :: src  partlist_recv is a routine for receiving particles sent by a call to partlist_send and loading them into the particle_list object partlist. The source processor is identified by its rank which is given by the src parameter. The routine destroys the particle_list which it is given and indeed will leave orphaned particles if it is not given an empty particle_list to receive the data.\n  partlist_recv uses MPI blocking receives, so unless a matching partlist_send has been posted on src then the routine will deadlock. It would be fairly simple to write a non-blocking version of partlist_recv, but at present no need for such a routine has been found.\n  Although it is not possible to directly use partlist_recv to add new particles onto an existing particle_list, it is only two lines to do this. First call partlist_recv with a temporary particle_list to receive the data and then use append_partlist to attach the particles to the end of the already populated list.\n  partlist_send_recv SUBROUTINE partlist_send_recv(partlist_send, \u0026amp; partlist_recv, dest, src) TYPE(particle_list), INTENT(INOUT) :: partlist_send TYPE(particle_list), INTENT(INOUT) :: partlist_recv INTEGER, INTENT(IN) :: dest, src  partlist_sendrecv is a routine equivalent to MPI_SENDRECV in that it allows overlapping sends and receives to be written in a single line rather than the end user having to split processors into red/black ordered pairs for communication. It sends the particle data in partlist_send to the processor with rank dest and receives particle data sent by processor src and stores it in the particle_list partlist_recv. The routine is destructive to both sending and receiving particle_lists, and can lead to orphaned particles if a filled particle_list is passed as partlist_recv. this is the routine which is used in the particle boundary conditions.\n  partlist_sendrecv uses MPI blocking sendrecv commands, so should be used in matching pairs or the routine will deadlock.\n  Although it is not possible to directly use partlist_sendrecv to add new particles onto an existing particle_list, it is only two lines to do this. First call partlist_sendrecv with a temporary particle_list to receive the data and then use append_partlist to attach the particles to the end of the already populated list.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"bc72b496e1709a032d8e4f669ae679ec","permalink":"/developer/core_structure/partlist.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/partlist.html","section":"developer","summary":"Collections of particles in EPOCH are represented by the particle_list object. These objects abstract much of the operation of the linked lists, including adding and removing particles and sending particles to other processors.","tags":null,"title":"Partlist","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH uses precompiler directives to switch certain features of the code on or off. The precompiler directives all begin with a \u0026ldquo;#\u0026rdquo; character and look like:\n#ifdef MY_PRECOMPILER_DIRECTIVE some_fortran_of_some_kind #else some_other_fortran #endif  They behave in a very simple manner. The precompiler runs BEFORE the Fortran compiler and, until it reaches a precompiler directive, it just creates a temporary file which is an exact copy of the source file. When it reaches a precompiler directive of this kind it treats the #ifdef commands as if/then/else statements. If MY_PRECOMPILER_DIRECTIVE was defined in the makefile then some_fortran_of_some_kind is pushed out to the temporary file. Otherwise some_other_fortran is written instead. The precompiler directives themselves are never output to the temporary file. Once then preprocessor has finished, it passes this temporary file to the Fortran compiler which can then compile it just like any other standard Fortran file.\nWhen to use precompiler directives  When adding properties to the particle structure. When adding time consuming calculations to the particle pusher.  Precompiler directives should be avoided when there is no significant performance gain or memory reduction to be made. Wherever possible, optional features should be controlled by parameters in the input deck.\nThe directive printing routine on code startup When EPOCH starts it prints the precompiler directives that it was built with and what they mean. This isn\u0026rsquo;t required, but has proved very useful and is implemented in a very simple way. Just open the file src/housekeeping/welcome.F90 and find the subroutine compiler_directives. There are a large block of precompiler directives which read:\n#ifdef TRACER_PARTICLES defines = IOR(defines, c_def_tracer_particles) WRITE(*, *) \u0026quot;Tracer particle support -DTRACER_PARTICLES\u0026quot; #endif  Simply add a new element to the end of the list.\n#ifdef MY_PRECOMPILER_DIRECTIVE defines = IOR(defines, c_def_my_precompiler_directive) WRITE(*,*) \u0026quot;My new physics -DMY_PRECOMPILER_DIRECTIVE\u0026quot; #endif  You will also need to add c_def_my_precompiler_directive to the list of constants in src/shared_data.F90.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"e96db69b2fa327e236c2ae26e3c4d955","permalink":"/developer/core_structure/precompiler_flags.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/precompiler_flags.html","section":"developer","summary":"EPOCH uses precompiler directives to switch certain features of the code on or off. The precompiler directives all begin with a \u0026ldquo;#\u0026rdquo; character and look like:\n#ifdef MY_PRECOMPILER_DIRECTIVE some_fortran_of_some_kind #else some_other_fortran #endif  They behave in a very simple manner.","tags":null,"title":"Pre-compilation Flags","type":"docs"},{"authors":null,"categories":null,"content":"Fortran is not a language famous for its string handling capabilities, but due to the presence of the input deck EPOCH has fairly extensive string handling routines. Strings used are all of the standard Fortran CHARACTER type and are defined as:\nCHARACTER(LEN=string_length) :: string  string_length is a global constant defined in src/constants.F90 which can be increased to allow EPOCH to handle longer strings. There may be reasons to increase this length if you wish to use long complex expressions in the input deck. Note that many Fortran compilers do not allow strings to exceed 512 characters in length.\nListed here are the string handling routines (other than those in the core maths parser routine which are documented elsewhere) which are currently used in EPOCH. These functions can be found in src/deck/strings.f90 and src/deck/strings_advanced.f90\nstr_cmp FUNCTION str_cmp(str_in, str_test) CHARACTER(LEN=*), INTENT(IN) :: str_in, str_test LOGICAL :: str_cmp  str_cmp is the routine which does all the string comparisons in EPOCH. It deals with leading and trailing whitespace automatically and tests for length differences. It does not test for strings being valid substrings of each other, only for full equality.\nA developer should always use str_cmp rather than doing their own string testing to ensure consistent behaviour across the entire EPOCH code base.\nas_real_simple FUNCTION as_real_simple(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err REAL(num) :: as_real_simple  as_real_simple is a routine to convert a string into a real number without invoking the maths parser. It can cope with standard form as well as simple decimal reals. It is significantly faster than the maths parser, but should only be used when the user explicitly shouldn\u0026rsquo;t be able to use a mathematical expression. If the string cannot be parsed then the routine sets the bitmask c_err_bad_value on the parameter err\nIf you have a string which has to be converted into a real quickly then this is the routine to use. You probably shouldn\u0026rsquo;t use it when parsing a string from the input deck, since there is no reason to restrict the user from specifying a mathematical expression. The routine is used inside the maths parser to parse simple numbers.\nas_integer_simple FUNCTION as_integer_simple(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err INTEGER :: as_integer_simple  as_integer_simple is a routine to convert a string into an integer without invoking the maths parser. It can cope with standard form as well as simple decimal integers. It is significantly faster than the maths parser, but should only be used when the user explicitly shouldn\u0026rsquo;t be able to use a mathematical expression. If the string cannot be parsed then the routine sets the bitmask c_err_bad_value on the parameter err\nThis routine is used internally in several parts of the code when parsing things like numbers which are parts of strings (i.e. the 1 in direction1 for distribution functions). It probably shouldn\u0026rsquo;t be used to directly parse input deck parameters, since there is no reason to restrict the user from specifying mathematical expressions.\nas_long_integer_simple FUNCTION as_long_integer_simple(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err INTEGER(KIND=8) :: as_long_integer_simple  as_long_integer_simple is equivalent to as_integer_simple, but returns the larger INTEGER(KIND=8) rather than a normal INTEGER(KIND=4).\nas_boundary FUNCTION as_boundary(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err INTEGER :: as_boundary  as_direction is used when assigning a laser to a boundary and recognises the strings\n x_min or left - c_bd_x_min. x_max or right - c_bd_x_max. y_min or down - c_bd_y_min. y_max or up - c_bd_y_max. z_min or back - c_bd_z_min. z_max or front - c_bd_z_max.  It returns the associated direction code (given after the dash in the definition).\nIf you\u0026rsquo;re writing code which requires attaching something to a boundary, whether a boundary condition, a diagnostic or some other routine, then this is the routine that should be used. Note that in order to prevent confusion when moving input decks between different dimension versions of EPOCH, each code only recognises the strings for boundaries that it actually has.\nas_logical FUNCTION as_logical(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err Logical :: as_logical  as_logical simply tests for the strings \u0026ldquo;T\u0026rdquo; and \u0026ldquo;F\u0026rdquo; to determine a boolean value. The default behaviour of as_logical is to treat any string that isn\u0026rsquo;t \u0026ldquo;T\u0026rdquo; as a false value.\nYou should use this rather than using a 0/1 boolean flag in the input deck for consistency.\nsplit_off_int SUBROUTINE split_off_int(str_in, str_out, int_out, err) CHARACTER(LEN=*), INTENT(IN) :: str_in CHARACTER(LEN=*), INTENT(OUT) :: str_out INTEGER, INTENT(OUT) :: int_out INTEGER, INTENT(INOUT) :: err  split_off_int is a routine which splits a string of the format string n into a string string and an integer n which are returned separately in the str_out and int_out parameters respectively. If it can\u0026rsquo;t split the string successfully then it sets the c_err_bad_value bitfield of the err parameter.\nThis is used in the core of the deck parser to deal with blocks like the numbered species blocks in the initial conditions, and also in some of the specific block parsers. Again, this routine should be used to split strings like this rather than coding a new routine.\nsplit_range SUBROUTINE split_range(str_in, real1, real2, err) CHARACTER(LEN=*), INTENT(IN) :: str_in REAL(num), INTENT(OUT) :: real1, real2 INTEGER, INTENT(INOUT) :: err  split_range is a routine which splits a string of the format (n, m) into two reals n and m which are returned separately in the real1 and real2 parameters respectively. If it can\u0026rsquo;t split the string successfully then it sets the c_err_bad_value bitfield of the err parameter.\nThis is used when specifying ranges in the input decks at present. Any ranges which should be specified in a single parameter should be specified in this form and this routine used to split the string.\nas_integer FUNCTION as_integer(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err INTEGER :: as_integer  as_integer is the routine which returns integers from strings using the maths parser. If a mathematical expression resolves to a non-integer result then this routine rounds to the NEAREST integer. There are explicit rounding routines in the maths parser to force other behaviour.\nThis routine should be used when evaluating most strings into integers. Note that this routine evaluates spatially dependent quantities at (0,0) on each processor, so will give unpredictable results when spatially dependent quantities are given to it (like density, bx etc.). To evaluate a spatially varying quantity use evaluate_string_in_space.\nas_long_integer FUNCTION as_long_integer(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err INTEGER(KIND=8) :: as_long_integer  as_long_integer is the routine which returns long integers from strings using the maths parser. If a mathematical expression resolves to a non-integer result then this routine rounds to the NEAREST integer. There are explicit rounding routines in the maths parser to force other behaviour.\nThis routine should be used when evaluating strings which are likely to be too large to be stored in an INTEGER(KIND=4).\nas_real FUNCTION as_real(str_in, err) CHARACTER(LEN=*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err REAL(num) :: as_real  as_real is the routine which returns reals from strings using the maths parser.\nThis routine should be used when evaluating most strings into reals. Note that this routine evaluates spatially dependent quantities at (0,0) on each processor, so will give unpredictable results when spatially dependent quantities are given to it (like density, bx etc.). To evaluate a spatially varying quantity use evaluate_string_in_space.\nevaluate_string_in_space SUBROUTINE evaluate_string_in_space(str_in, data_out, \u0026amp; x1, x2, \\{y1, y2, z1, z2,\\} err) CHARACTER(*), INTENT(IN) :: str_in INTEGER, INTENT(INOUT) :: err INTEGER, INTENT(IN) :: x1, x2\\{, y1, y2, z1, z2\\} REAL(num), DIMENSION(1:,1:,1:), INTENT(OUT) :: data_out  evaluate_string_in_space is a routine which is used to evaluate a tokenized maths expression over a region of the domain. The dimensionality of data_out, and the presence or absence of y1, y2 and z1, z2 depend on the dimensionality of the code being used. The x1, x2, ... parameters represent the indices in that direction over which the expression should be evaluated. For example, in 2D to evaluate an expression over the entire domain, the code would look like:\nREAL(num), DIMENSION(:,:), ALLOCATABLE :: data ALLOCATE(data(-2:nx+3,-2:ny+3)) CALL evaluate_string_in_space(string, data, -2, nx+3, -2, ny+3, err)  This routine is suitable to evaluate expressions over a subsection or all of the domain, and is used in this way in the initial condition deck parser routines. However, the routine does have one significant weakness, which is that it tokenizes the string each time it is called. Tokenizing the string is a time consuming process, so if the string is to be evaluated several times for different reasons (for example, the time profile for the laser) then a different procedure should be followed using the lower level parser routines.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"15753024dd244d7b71e99ee452974886","permalink":"/developer/input_output/string_handling.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/input_output/string_handling.html","section":"developer","summary":"Fortran is not a language famous for its string handling capabilities, but due to the presence of the input deck EPOCH has fairly extensive string handling routines. Strings used are all of the standard Fortran CHARACTER type and are defined as:","tags":null,"title":"String Handling","type":"docs"},{"authors":null,"categories":null,"content":"The key feature of a PIC code controlling the smoothness of the solution is the particle shape function. That is the function that describes the assumed distribution of the real particles making up a macro-particle. The simplest solution is to assume that the macro-particles uniformly fill the cell in which the macro-particle is located. This has the advantages of speed and simplicity but produces very noisy solutions. The next simplest approach is to assume a triangular shape function with the peak of the triangle located at the position of the macro-particle and a width of $ 2 \\Delta x$, as illustrated below.\nThis is the approach used in EPOCH and is a good trade-off between cleanness of solution and speed. Higher order methods based on spline interpolation can be used and do produce smoother solutions, but they are significantly slower and the benefits of the schemes can easily be overstated. EPOCH does now include an option to use 3rd order b-spline interpolation in all parts of the code. This option is enabled with the -DPARTICLE_SHAPE_BSPLINE3 compile time option in the makefile.\nFunctions derived from the particle shape function appear in two places in the core solver: when the EM fields are interpolated to the position of the macro-particle and when the current is updated and properties of the macro-particle are copied onto the grid. These two uses of the shape function are conceptually similar, but have different forms.\nInterpolating grid variables to macro-particles To derive the equations for calculating the field acting on a particle, you calculate the overlap of the particle shape function with the function representing the fields on the grid. In EPOCH, the fields are approximated at first order so that the field is constant over each cell. Consider a particle with position $X$, where $X$ lies in the cell centred at $x_i$ and grid spacing $\\Delta x$. The integral is split into four parts; that part of the shape function which overlaps with the cell $x_{i-1}$, the part of the shape function from the left boundary of $x_i$ to the point of the triangle, the part of the shape function from the point of the triangle to the right hand edge of $x_i$ and finally that part of the shape function which overlaps cell $x_{i+1}$. Assuming that fields are constant inside each cell ($F_i$), this takes the form\nPerforming these integrals and remembering that $x_{i-1}+\\frac{\\Delta x}{2}$ is equal to $x_i-\\frac{\\Delta x}{2}$ since the grid is uniformly spaced with spacing $\\Delta x$, this gives a final formula for the field at a particle of\nIn the code calculating the strength of a cell centred field on the particle is done as follows.\nREAL(num) :: cell_x_r, cell_frac_x INTEGER :: cell_x1 REAL(num) :: gx(-2:2) TYPE(particle), POINTER :: current part_x = current%part_pos(1) - x_min_local ! Work out the grid cell number for the particle. ! Not an integer in general. cell_x_r = part_x / dx ! Round cell position to nearest cell cell_x1 = FLOOR(cell_x_r + 0.5_num) ! Calculate fraction of cell between nearest cell boundary and particle cell_frac_x = REAL(cell_x1, num) - cell_x_r cell_x1 = cell_x1 + 1 cf2 = cell_frac_x**2 gx(-1) = 0.25_num + cf2 + cell_frac_x gx( 0) = 1.5_num - 2.0_num * cf2 gx( 1) = 0.25_num + cf2 - cell_frac_x f_part = \u0026amp; gx(-1) * F(cell_x1-1) \u0026amp; + gx( 0) * F(cell_x1 ) \u0026amp; + gx( 1) * F(cell_x1+1)  where f_part is the field at the particle location. Note that this has been simplified a little for brevity. Just the triangle shape function is given. In 2D or 3D, you just calculate gy in the same manner as gx and calculate the weight over all the cells affected by the individual 1D shape functions. In 2D this looks like:\nf_part = 0.0_num DO iy = sf_min, sf_max DO ix = sf_min, sf_max f_part = f_part + f(cell_x+ix, cell_y+iy) * gx(ix) * gy(iy) ENDDO ENDDO  The variables sf_min and sf_max contain the shape function order parameters which indicate the cells each side of the cell containing the particle which are overlapped by the particle shape function. They are defined in shared_data.F90 and should only be changed by the developer if a new particle shape function is being added. Although provided here as pseudo-code for the particle push, it should be noted that the actual particle push unrolls these loops for the sake of speed.\nInside the particle pusher the $E$ and $B$ fields are not cell centred fields, but Yee staggered. This means that there is a small change to the above mentioned example. In 1D this change looks like\nREAL(num) :: cell_x_r, cell_frac_x INTEGER :: cell_x1, cell_x2 REAL(num) :: gx(-2:2), hx(-2:2) TYPE(particle), POINTER :: current part_x = current%part_pos(1) - x_min_local ! Work out the grid cell number for the particle. ! Not an integer in general. cell_x_r = part_x / dx ! Round cell position to nearest cell cell_x1 = FLOOR(cell_x_r + 0.5_num) ! Calculate fraction of cell between nearest cell boundary and particle cell_frac_x = REAL(cell_x1, num) - cell_x_r cell_x1 = cell_x1 + 1 ! Calculate weights INCLUDE 'include/triangle/gx.inc' ! Now redo shifted by half a cell due to grid stagger. ! Use shifted version for ex in X, ey in Y, ez in Z ! And in Y\u0026amp;Z for bx, X\u0026amp;Z for by, X\u0026amp;Y for bz cell_x2 = FLOOR(cell_x_r) cell_frac_x = REAL(cell_x2, num) - cell_x_r + 0.5_num cell_x2 = cell_x2 + 1 ! Calculate weights INCLUDE 'include/triangle/hx_dcell.inc' ! bx is cell centred bx_part = 0.0_num DO ix = sf_min, sf_max bx_part = bx_part + bx(cell_x1+ix) * gx(ix) ENDDO ! ex is staggered 1/2 a cell to the right ex_part = 0.0_num DO ix = sf_min, sf_max ex_part = ex_part + ex(cell_x2+ix) * hx(ix) ENDDO  In 2D and 3D, you just combine the shifted and unshifted shape functions and associated cell positions depending on the position of the variable in the cell. Therefore, in 3D and using the loop notation for clarity you would get:\nDO iz = sf_min, sf_max DO iy = sf_min, sf_max DO ix = sf_min, sf_max ex_part = ex_part + hx(ix) * gy(iy) * gz(iz) * \u0026amp; ex(cell_x2+ix, cell_y1+iy, cell_z1+iz) ENDDO ENDDO ENDDO DO iz = sf_min, sf_max DO iy = sf_min, sf_max DO ix = sf_min, sf_max bx_part = bx_part + gx(ix) * hy(iy) * hz(iz) * \u0026amp; bx(cell_x2+ix, cell_y1+iy, cell_z1+iz) ENDDO ENDDO ENDDO  Since $E_x$ is staggered half a grid cell in the x direction, whereas $B_x$ is staggered by half a grid cell in the y and z directions.\nWriting macro-particle properties on the grid The next stage is to consider how to copy macro-particle properties on the grid. This is very similar to the function for calculating grid variables at the particle location and, for each grid point $x_i$, consists of integrating the part of the particle shape function which overlaps the $i^{th}$ cell. That is\n$$ F(i) = Data \\int^{x_i+\\frac{\\Delta x}{2}}_{x_i-\\frac{\\Delta x}{2}} S(X-x) dx $$\nWhere $Data$ is the particle property to be copied onto the grid. In EPOCH, since the particle shape function is known to go to zero outside a distance of $2 \\Delta x$ from the maximum, the maximum number of cells that can possibly be overlapped by a given particle shape function is 3; the cell containing the particle maximum and the two cells to either side. Performing the integration using the triangular shape function given above gives the result\nWhen this is translated into the code, it looks very similar to that presented for the case where grid properties are interpolated to the particle position. This form is used in the particle pusher to perform the current update and in the routines in src/io/calc_df.F90 to copy particle properties onto the grid for output. The form from calc_df is rather clearer and easier to see in operation. In 1D it looks like:\ncell_x_r = (current%part_pos - x_min_local) / dx + 1.5_num cell_x = FLOOR(cell_x_r) cell_frac_x = REAL(cell_x, num) - cell_x_r + 0.5_num CALL particle_to_grid(cell_frac_x, gx) wdata = part_m * fac DO ix = sf_min, sf_max data_array(cell_x+ix) = data_array(cell_x+ix) + gx(ix) * wdata ENDDO  Once again multi-dimensional codes just have the weighting functions multiplied together.\nDO iy = sf_min, sf_max DO ix = sf_min, sf_max data_array(cell_x+ix, cell_y+iy) = \u0026amp; data_array(cell_x+ix, cell_y+iy) + gx(ix) * gy(iy) * wdata ENDDO ENDDO  Other particle shapes The previous sections dealt with the default macro-particle shape (triangular). EPOCH also supports TOPHAT and BSPLINE particle shapes, although the implementation of these can be different. Interpolating fields to particles and writing particle properties to the grid is performed using the same method as before, but for an altered shape function for TOPHAT:\nand for BSPLINE:\nIn the TRIANGLE and BSPLINE set-ups, the particle shape extends over a size of $2\\Delta x$ and $4\\Delta x$. Unless the paricle centre is on a cell boundary, the shape will always extend over 3 or 5 cells respectively. However, the TOPHAT shape has a size of $1 \\Delta x$, which is an odd number of cell-sizes. If we evaluate this shape at the particle centre, the shape may extend over the cell on the low-$x$ side, or the high-$x$ side. To simplify the code, we evaluate the TOPHAT shape position from the low-$x$, low-$y$, low-$z$ corner of the shape, such that the shape always extends over the current cell and the higher cell only. This is why the cell-calculation for TOPHAT differs from the other shapes, in lines like:\n#ifdef PARTICLE_SHAPE_TOPHAT cell_x_r = part_x * idx - 0.5_num cell_y_r = part_y * idy - 0.5_num #else cell_x_r = part_x * idx cell_y_r = part_y * idy #endif  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680612074,"objectID":"e3d5c229522a7d43ff94b5fe6a434a8c","permalink":"/developer/core_structure/shape_functions.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/developer/core_structure/shape_functions.html","section":"developer","summary":"The key feature of a PIC code controlling the smoothness of the solution is the particle shape function. That is the function that describes the assumed distribution of the real particles making up a macro-particle.","tags":null,"title":"Weighting Functions","type":"docs"}]