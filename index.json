[{"authors":null,"categories":null,"content":"How to use these pages If you are new to EPOCH, start with the FAQ and the introductory information. Then read the basic examples. There\u0026rsquo;s quite a lot to learn in order to get started, so you should plan to read through all of this section. You will also need to refer to the input deck pages. Next, look at the code and have a play with some test problems. After that re-read the FAQ. This should be enough for testing simple problems. See below for more information on visualising the output files.\nFor specific information, see the index below or use the search function. Alternately, start with the FAQ and read through the pages in order by following the \u0026ldquo;Next section\u0026rdquo; links.\nBasic usage   The EPOCH FAQ list  Getting the code  The structure of the EPOCH codes  Library requirements for the EPOCH codes  Compiling EPOCH  Compiler flags and preprocessor defines  Running EPOCH and basic control of EPOCH  The input deck   The EPOCH input deck   The control block  The boundaries block  The species block  The laser block  The fields block  The window block  The output block  The output_global block  The dist_fn block  The probe block  The collisions block  The qed block  The subset block  The constant block  The injector block    Code details   The EPOCH maths parser  EPOCH use in practice  Using EPOCH in delta_f form  Basic examples of using EPOCH  Changes from previous versions of EPOCH  Visualising EPOCH output   Visualising SDF files using IDL or GNU Data Language (GDL)  Visualising SDF files using LLNL VisIt  Visualising SDF files using Python  Examples with EPOCH Example decks and output are available here:\n  Basic examples of using EPOCH from the manual  A link to submit your own examples will be provided soon\nThe EPOCH workshop The examples from the EPOCH workshop are in two parts: (part 1) (part 2)\nHelpful information  Acknowledging EPOCH The EPOCH Developer Manual is quite out of date at this point, so it contains some information which is no longer correct. However, the fundamental algorithms have not changed so it still contains plenty of useful and relevant information.\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1635857383,"objectID":"7ebcaaa360436ed18cc5fe3ced42705f","permalink":"/documentation.html","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/documentation.html","section":"documentation","summary":"How to use these pages If you are new to EPOCH, start with the FAQ and the introductory information. Then read the basic examples. There\u0026rsquo;s quite a lot to learn in order to get started, so you should plan to read through all of this section.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"1f7de15fc154296a0810ece8d007eb3a","permalink":"/documentation/basic_usage.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage.html","section":"documentation","summary":"","tags":null,"title":"Basic usage","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"9f455340985649684a32d8c48dc6ec92","permalink":"/documentation/code_details.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details.html","section":"documentation","summary":"","tags":null,"title":"Code details","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"367e567d8f787d773400d890535b775e","permalink":"/documentation/examples.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples.html","section":"documentation","summary":"","tags":null,"title":"Examples","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1624401345,"objectID":"12baaa8579fa05126afecf4f78d995a4","permalink":"/documentation/visualising_output.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output.html","section":"documentation","summary":"","tags":null,"title":"Visualising output","type":"docs"},{"authors":null,"categories":null,"content":"Is this manual up to date? Whenever a new milestone version of EPOCH is finalised, the version number is changed and this manual is updated accordingly. The version number of the manual should match the first two digits for that of the EPOCH source code. This version number is printed to screen when you run the code. The line looks something like the following:\n Welcome to EPOCH2D version 4.16.0 (commit v4.16.0-0-g69eb0fa6-clean)  Here, only the number \u0026ldquo;4.16\u0026rdquo; is important.\nSince version 3.1 of the manual, new additions and changes are mentioned in the appendix.\nWhat is EPOCH? EPOCH is a plasma physics simulation code which uses the Particle in Cell (PIC) method. In this method, collections of physical particles are represented using a smaller number of pseudoparticles, and the fields generated by the motion of these pseudoparticles are calculated using a finite difference time domain technique on an underlying grid of fixed spatial resolution. The forces on the pseudoparticles due to the calculated fields are then used to update the pseudoparticle velocities, and these velocities are then used to update the pseudoparticle positions. This leads to a scheme which can reproduce the full range of classical micro-scale behaviour of a collection of charged particles.\nFeatures of EPOCH   MPI parallelised, explicit, second-order, relativistic PIC code.\n  Dynamic load balancing option for making optimal use of all processors when run in parallel.\n  MPI-IO based output, allowing restart on an arbitrary number of processors.\n  Data analysis and visualisation options include ITT IDL, LLNL VisIt, Mathworks MatLab and matplotlib in Python.\n  Control of setup and runs of EPOCH through a customisable input deck.\n  The origins of the code The EPOCH family of PIC codes is based on the older PSC code written by Hartmut Ruhl and retains almost the same core algorithm for the field updates and particle push routines. EPOCH was written to add more modern features and to structure the code in such a way that future expansion of the code is made as easy as possible.\nHow do I obtain the code? The latest version of EPOCH can be found on GitHub at https://github.com/Warwick-Plasma/epoch\nA tarred and gzipped archive (commonly referred to as a tarball) of the latest release is always made available in the Releases section\nAlternately, using git the code can be cloned using the following command. Note that it is important to include the \u0026lsquo;\u0026lsquo;recursive\u0026rsquo;\u0026rsquo; flag in order to download the SDF submodules..\ngit clone \u0026ndash;recursive https://github.com/Warwick-Plasma/epoch.git\nWhat normalisations are used in EPOCH? Since the idea from the start was that EPOCH would be used by a large number of different users and that it should be as easy as possible to \u0026ldquo;plug in\u0026rdquo; different modules from different people into a given copy of the code, it was decided to write EPOCH in SI units. There are a few places in the code where some quantities are given in other units for convenience (for example charges are specified in multiples of the electron charge), but the entire core of the code is written in SI units.\nWhat are those _num things doing everywhere? Historically using the compiler auto-promotion of REAL to DOUBLE PRECISION was unreliable, so EPOCH uses \u0026ldquo;kind\u0026rdquo; tags to specify the precision of the code. The _num suffixes and the associated definition of REALs as REAL(num) are these \u0026ldquo;kind\u0026rdquo; tags in operation. The _num tags force numerical constants to match the precision of the code, preventing errors due to precision conversion. The important thing is that all numerical constants should be tagged with an _num tag and all REALs should be defined as REAL(num).\nWhat is an input deck? An input deck is text file which can be used to set simulation parameters for EPOCH without needing to edit or recompile the source code. It consists of a list of blocks which start as begin:blockname and end with end:blockname. Within the body of each block is a list of key/value pairs, one per line, with key and value separated by an equals sign. Most aspects of a simulation can be controlled using an input deck, such as the number of grid points in the simulation domain, the initial distribution of particles and initial electromagnetic field configuration. It is designed to be relatively easy to read and edit. For most projects it should be possible to set up a simulation without editing the source code at all. For more details, read the section titled \u0026ldquo;The EPOCH input deck\u0026rdquo;\nI just want to use the code as a black box, or I\u0026rsquo;m just starting. How do I do that? Begin by reading the basic examples. There\u0026rsquo;s quite a lot to learn in order to get started, so you should plan to read through all of this section. You will also need to refer to the input deck pages. Next, look at the code and have a play with some test problems. After that re-read this section. This should be enough for testing simple problems.\nWhat is the auto-loader? Throughout this document we will often refer to the \u0026ldquo;auto-loader\u0026rdquo; when setting up the initial particle distribution. In the input deck it is possible to specify a functional form for the density and temperature of a particle species. EPOCH will then place the particles to match the density function and set the velocities of the particles so that they match the Maxwellian thermal distribution for the temperature. The code which performs this particle set up is called the \u0026ldquo;auto-loader\u0026rdquo;.\nAt present, there is no way to specify a non-Maxwellian particle distribution from within the input deck. In such cases, it is necessary to edit and recompile the EPOCH source code. The recommended method for setting the initial particle properties is to use the \u0026ldquo;manual_load\u0026rdquo; function as described here.\nWhat is a maths parser? As previously mentioned, the behaviour of EPOCH is controlled using an input deck which contains a list of key/value pairs. The value part of the pair is not restricted to simple constants but can be a complex mathematical expression. It is evaluated at run time using a section of code called the \u0026ldquo;maths parser\u0026rdquo;. There is no need for the end user to know anything about this code. It is just there to enable the use of mathematical expressions in the input deck. Further information about this facility can be found here.\nI am an advanced user, but I want to set up the code so that less experienced users can use it. How do I do that? See here.\nI want to develop an addition to EPOCH. How do I do that? A slightly outdated developers manual exists which should be sufficient to cover most aspects of the code functionality. However, the code is written in a fairly modular and consistent manner, so reading through that is the best source of information. If you get stuck then you can post questions on the GitHub forums.\nI want to have a full understanding of how EPOCH works. How do I do that? If you really want to understand EPOCH in full, the only way is to read all of this manual and then read through the code. Most of it is commented.\nHow do I acknowledge use of the code? See here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"e17b74a6c4a52306539497a766fb1fff","permalink":"/documentation/basic_usage/faq.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/faq.html","section":"documentation","summary":"Is this manual up to date? Whenever a new milestone version of EPOCH is finalised, the version number is changed and this manual is updated accordingly. The version number of the manual should match the first two digits for that of the EPOCH source code.","tags":null,"title":"FAQs","type":"docs"},{"authors":null,"categories":null,"content":"When obtained, the EPOCH codes all have a similar structure. If the tarred and gzipped archive (commonly referred to as a tarball) is downloaded and unpacked into the user\u0026rsquo;s $HOME directory, then the extracted contents will consist of a directory named \u0026ldquo;$HOME/epoch-4.12.0\u0026rdquo; (with \u0026ldquo;4.12.0\u0026rdquo; substituted by the current version number) and the subdirectories and files listed below.\nAlternatively, if the code is checked out from the GitHub git repository with the command\ngit clone --recursive https://github.com/Warwick-Plasma/epoch.git\nthen the directory will be \u0026ldquo;$HOME/epoch\u0026rdquo;.\nOnce the code has been obtained, the top-level directory will contain the following 4 directories and several files\n epoch1d - Source code and other files required for the 1D version of EPOCH. epoch2d - Source code and other files required for the 2D version of EPOCH. epoch3d - Source code and other files required for the 3D version of EPOCH. SDF - Source code for the SDF file format which is used to generate output for EPOCH runs. This directory also includes various tools and readers for working with SDF files. CHANGELOG - A brief overview of the change history for each released version of EPOCH. CODING_STYLE - This document contains the conventions which must be used for any code being submitted for inclusion in the EPOCH project. LICENSE - A copy of the GPLv3 license which is used by the EPOCH project. README.md - A brief overview of obtaining and using the EPOCH code. make_tarball.sh - This is a shell script which is used for creating the tarred and gzipped archives of EPOCH which are posted to the GitHub server each time a new release is made. test_all.sh - A regression test script used when testing the code.  The three EPOCH subdirectories all have a similar structure. Inside each of the epoch{1,2,3}d directories, there are 3 sub-directories:\n src - The EPOCH source code. example_decks - A sample data directory containing example input deck files. Data - This is an empty directory to use for running simulations.  there are also 3 files:\n Makefile - A standard makefile. Start.pro - An IDL script which starts the IDL visualisation routines. Execute it using \u0026ldquo;idl Start\u0026rdquo;. unpack_source_from_restart - Restart dumps can be written to contain a copy of the input decks and source code used to generate them. This script can be used to unpack that information from a given restart dump. It is run from the command line and must be passed the name of the restart dump file.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"0be0ede1fad1b389d1892668595ddcd9","permalink":"/documentation/basic_usage/structure.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/structure.html","section":"documentation","summary":"When obtained, the EPOCH codes all have a similar structure. If the tarred and gzipped archive (commonly referred to as a tarball) is downloaded and unpacked into the user\u0026rsquo;s $HOME directory, then the extracted contents will consist of a directory named \u0026ldquo;$HOME/epoch-4.","tags":null,"title":"Code structure","type":"docs"},{"authors":null,"categories":null,"content":"To compile EPOCH in the supplied state, you must first change to the correct working directory. As explained in , the root directory for EPOCH contains several subdirectories, including separate directories for each of the 1D, 2D and 3D versions of the code. To compile the 2D version of the code, you first switch to the \u0026ldquo;epoch2d\u0026rdquo; directory using the command cd $HOME/epoch/epoch2d and then type make and the code will compile. There are certain options within the code which are controlled by compiler preprocessors and are described in the next section. When the code is compiled, it creates a new directory called \u0026ldquo;bin\u0026rdquo; containing the compiled binary which will be called epoch1d, epoch2d or epoch3d. To run the code, just execute the binary file by typing: ./bin/epoch2d or whatever the correct binary is for the dimensionality of the code that you have. You should be given a screen which begins with the EPOCH logo, and then reads:\nThe code was compiled with no compile time options Welcome to EPOCH2D version 4.12.0 (commit v4.12.0-0-gfd74a464-clean) Code is running on 1 processing elements Specify output directory  At this point, the user simply types in the name of the (already existing) output directory and the code will read the input deck files inside the specified directory and start running. To run the code in parallel, just use the normal mpirun or mpiexec scripts supplied by your MPI implementation. If you want the code to run unattended, then you will need to pipe in the output directory name to be used. The method for doing this varies between MPI implementations. For many MPI implementations (such as recent versions of OpenMPI) this can be achieved with the following: echo Data | mpirun -np 2 ./bin/epoch2d Some cluster setups accept the following instead: mpirun -np 2 ./bin/epoch2d \u0026lt; deck.file where \u0026ldquo;deck.file\u0026rdquo; is a file containing the name of the output directory. Some cluster queueing systems do not allow the use of input pipes to mpirun. In this case, there is usually a \u0026ldquo;-stdin\u0026rdquo; command line option to specify an input file. See your cluster documentation for more details.\nAs of version 4.2.12, EPOCH now checks for the existence of a file named \u0026ldquo;USE_DATA_DIRECTORY\u0026rdquo; in the current working directory before it prompts the user for a Data directory. If such a file exists, it reads it to obtain the name of the data directory to use and does not prompt the user. If no such file exists, it prompts for a data directory name as before. This is useful for cluster setups in which it is difficult or impossible to pipe in the directory name using a job script.\nThe \u0026ldquo;Makefile\u0026rdquo; contains configurations for fort, gfortran, pgi, g95, hector/archer and ibm (the compiler suite used on IBM\u0026rsquo;s BlueGene machines). In order to compile using one of the listed configurations, add the \u0026ldquo;COMPILER=\u0026rdquo; option to the \u0026ldquo;make\u0026rdquo; command. For example make COMPILER=gfortran will compile the code using the gfortran compiler and appropriate compiler flags. The options are\n COMPILER=gfortran - GNU Fortran COMPILER=intel - Intel ifort COMPILER=pgi - Portland group compiler COMPILER=g95 - G95 compiler COMPILER=ibm - IBM AIX Fortran compiler for BlueGene COMPILER=hector - Cray compiler as used on hector and archer  As of version 4.11, it is now possible for the build system to automatically detect the correct compiler to use. Typing make COMPILER=auto will cause the build system to guess which compiler is in use. Note that this might not always work, so it is better to use the correct value for COMPILER if it is already known.\nYou can also compile the code with debugging flags by adding \u0026ldquo;MODE=debug\u0026rdquo; and can compile using more than one processor by using \u0026ldquo;-j\u0026lt;n\u0026gt;\u0026rdquo;, where \u0026ldquo;\u0026lt;n\u0026gt;\u0026rdquo; is the number of processors to use. Note that this is just to speed up the compilation process; the resulting binary can be run on any number of processors.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"d50515e99eb5d4744eb8d368c13b3911","permalink":"/documentation/basic_usage/compiling.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/compiling.html","section":"documentation","summary":"To compile EPOCH in the supplied state, you must first change to the correct working directory. As explained in , the root directory for EPOCH contains several subdirectories, including separate directories for each of the 1D, 2D and 3D versions of the code.","tags":null,"title":"Compiling EPOCH","type":"docs"},{"authors":null,"categories":null,"content":"As already stated, some features of the code are controlled by compiler preprocessor directives. The flags for these preprocessor directives are specified in \u0026ldquo;Makefile\u0026rdquo; and are placed on lines which look like the following:\nDEFINES += $(D)PER_SPECIES_WEIGHT  On most machines $(D) just means -D but the variable is required to accommodate more exotic setups.\nMost of the flags provided in the \u0026ldquo;Makefile\u0026rdquo; are commented out by prepending them with a \u0026ldquo;#\u0026rdquo; symbol (the \u0026ldquo;make\u0026rdquo; system\u0026rsquo;s comment character). To turn on the effect controlled by a given preprocessor directive, just uncomment the appropriate \u0026ldquo;DEFINES\u0026rdquo; line by deleting this \u0026ldquo;#\u0026rdquo; symbol. The options currently controlled by the preprocessor are:\n  PER_SPECIES_WEIGHT - By default, each pseudoparticle in the code can represent a different number of real particles. Memory can be saved by disabling this feature and have all of the pseudoparticles in a species use the same particle weight. Many of the codes more advanced features require per-particle weighting so it is enabled by default. Use this flag to disable per- particle weighting if you need to save on memory, but it this option is recommended only for advanced users.\n  NO_TRACER_PARTICLES - This flag will disable the option to specify one or more species as zero-current particles. Zero-current particles move about as would a normal particle with the same charge and mass, but they do not generate any current and are therefore passive elements in the simulation. Zero-current particles should be included in collisions to ensure they move identically to ordinary particles. The implementation of zero-current particles requires an additional \u0026ldquo;IF\u0026rdquo; clause in the particle push, so it has a slight performance impact. If you do not require the feature then setting this flag will give a slight performance improvement. WARNING: Since the particles effectively have zero weight in terms of their numerical heating properties, they do not always behave in the same way that an ordinary particle with weight would behave and this can sometimes lead to unexpected behaviour. If the purpose is merely to track a subset of a particle species to use as output then a better mechanism to use is \u0026ldquo;persistent subsets\u0026rdquo; (see here). In version 5.0, this flag will be and replaced with \u0026ldquo;ZERO_CURRENT_PARTICLES\u0026rdquo;.\n  NO_PARTICLE_PROBES - For laser plasma interaction studies it can sometimes be useful to be able to record information about particles which cross a plane in the simulation. Since this requires the code to check whether each particles has crossed the plane in the particles pusher and also to store copies of particles until the next output dump, it is a heavyweight diagnostic. If you don\u0026rsquo;t require the diagnostic you can set this flag to disable it.\n  PARTICLE_SHAPE_TOPHAT - By default, the code uses a first order b-spline (triangle) shape function to represent particles giving third order particle weighting. Using this flag changes the particle representation to that of a top-hat function (0th order b-spline yielding a second order weighting).\n  PARTICLE_SHAPE_BSPLINE3 - This flag changes the particle representation to that of a 3rd order b-spline shape function (5th order weighting).\n  PARTICLE_ID - When this option is enabled, all particles are assigned a unique identification number when writing particle data to file. This number can then be used to track the progress of a particle during the simulation.\n  PARTICLE_ID4 - This does the same as the previous option except it uses a 4-byte integer instead of an 8-byte one. Whilst this saves storage space, care must be taken that the number does not overflow.\n  PHOTONS - This enables support for photon particle types in the code. These are a pre-requisite for modelling synchrotron emission, radiation reaction and pair production (see here).\n  TRIDENT_PHOTONS - This enables support for virtual photons which are used by the Trident process for pair production.\n  PREFETCH - This enables an Intel-specific code optimisation.\n  PARSER_DEBUG - The code outputs more detailed information whilst parsing the input deck. This is a debug mode for code development.\n  PARTICLE_DEBUG - Each particle is additionally tagged with information about which processor it is currently on, and which processor it started on. This is a debug mode for code development.\n  MPI_DEBUG - This option installs an error handler for MPI calls which should aid tracking down some MPI related errors.\n  SIMPLIFY_DEBUG - This option enables debugging code related to the deck parser simplification routine.\n  NO_IO - This option disables all file I/O which can be useful when doing benchmarking.\n  COLLISIONS_TEST - This enables some routines for debugging the collision routines. It completely alters the behaviour of the code. This flag should never be enabled by the end user.\n  PER_PARTICLE_CHARGE_MASS - By default, the particle charge and mass are specified on a per-species basis. With this flag enabled, charge and mass become a per-particle property. This is a legacy flag which will be removed soon.\n  PARSER_CHECKING - Setting this flag adds code which checks for valid values on evaluated deck expressions. This slows down the code but may be required if floating point exceptions are enabled.\n  WORK_DONE_INTEGRATED - This enables support for tracking the work done on each particle by the electric field. Note that this increases the size of each particle by 48 bytes. The information gathered can be output to file using the \u0026ldquo;work_{x,y,z}\u0026rdquo; and \u0026ldquo;work_{x,y,z}_total\u0026rdquo; dumpmasks. See here\n  DELTAF_METHOD - Compile the code to use the delta-f method to represent particles rather than standard PIC. Note that this completely changes the code behaviour and should not be enabled for normal use. See here.\n  DELTAF_DEBUG - Add debug code for the delta-f method.\n  HC_PUSH - Use the push from Higuera and Cary rather than the Boris push. This is slightly slower than the Boris push but gives the correct $\\mathbf{E} \\times \\mathbf{B}$ velocity, improving performance for highly relativistic simulations.\n  NO_USE_ISATTY - When printing the initial welcome message, EPOCH makes use of the C-library\u0026rsquo;s isatty function. This requires Fortran2003 features that might not be available on all platforms. The flag allows this functionality to be disabled on platforms that don\u0026rsquo;t support it.\n  NO_MPI3 - This compiler flag allows the user to disable MPI-3 features such as the \u0026ldquo;MPI_TYPE_SIZE_X\u0026rdquo; routine. This allows the code to be compiled against older versions of the MPI library. The flag should only be enabled if the code fails to compile without it.\n  Errors for unspecified precompiler directives If a user requests an option which the code has not been compiled to support then the code will give an error or warning message as follows:\n *** ERROR *** Unable to set \u0026quot;use_qed=T\u0026quot; in the \u0026quot;qed\u0026quot; block. Please recompile with the -DPHOTONS preprocessor flag.  Other Makefile flags It is also possible to pass other flags to the compiler. In \u0026ldquo;Makefile\u0026rdquo; there is a line which reads\nFFLAGS = -O3 -fast  The two commands to the right are compiler flags and are passed unaltered to the FORTRAN compiler. Change this line to add any additional flags required by your compiler.\nBy default, EPOCH will write a copy of the source code and input decks into each restart dump. This can be very useful since a restart dump contains an exact copy of the code which was used to generate it, ensuring that you can always regenerate the data or continue running from a restart. The output can be prevented by using \u0026ldquo;dump_source_code = F\u0026rdquo; and \u0026ldquo;dump_input_deck = F\u0026rdquo; in the output block. However, the functionality is difficult to build on some platforms so the Makefile contains a line for bypassing this section of the build process. Just below all the DEFINE flags there is the following line:\n#ENCODED_SOURCE = epoch_source_info_dummy.o  Just uncomment this line and source code in restart dumps will be permanently disabled.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"5e0f22e4cea7007dfc4b8062fa2735f1","permalink":"/documentation/basic_usage/compiler_flags.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/compiler_flags.html","section":"documentation","summary":"As already stated, some features of the code are controlled by compiler preprocessor directives. The flags for these preprocessor directives are specified in \u0026ldquo;Makefile\u0026rdquo; and are placed on lines which look like the following:","tags":null,"title":"Compiler flags and preprocessor defines","type":"docs"},{"authors":null,"categories":null,"content":"When the code is run, the output is\n d########P d########b .######b d####### d##P d##P d########P d########### d########### .########## d##P d##P ---- ---- ---- ----- ---- ----- ---- -- P d########P d####,,,####P ####. .#### d###P d############P d########P d#########P #### .###P ####. d############P d##P d##P #### d#### ####. d##P d##P d########P d##P ###########P ##########P d##P d##P d########P d##P d######P #######P d##P d##P The code was compiled with no compile time options Welcome to EPOCH2D version 4.12.0 (commit v4.12.0-0-gfd74a464-clean) Code is running on 1 processing elements Specify output directory  At which point the end user should simply type in the name of the directory where the code output is to be placed. This directory must also include the file which controls the code setup, specifies how to set the initial conditions and controls the I/O. Writing an input deck for EPOCH is fairly time consuming and so the code is supplied with some example input decks which include all the necessary sections for the code to run. Alternately, the code checks for the Data directory in a file named \u0026ldquo;USE_DATA_DIRECTORY\u0026rdquo; before prompting at the command-line. This allows the code to be run without waiting for input at the command-line.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"0aadc5a22eae3b31c89ca7097c935699","permalink":"/documentation/basic_usage/running.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/running.html","section":"documentation","summary":"When the code is run, the output is\n d########P d########b .######b d####### d##P d##P d########P d########### d########### .########## d##P d##P ---- ---- ---- ----- ---- ----- ---- -- P d########P d####,,,####P ####.","tags":null,"title":"Running EPOCH and basic control of EPOCH","type":"docs"},{"authors":null,"categories":null,"content":"How do I acknowledge use of the code? There is a paper1 which details many aspects of the EPOCH implementation and also includes useful information on current PIC codes. This paper is OpenAccess so freely available to all. If using EPOCH in your research output please use this as the reference for EPOCH and ideally also acknowledge the UK grant which funded this work. The BibTeX entry for this paper is as follows.\n@article{Arber:2015hc, author = {Arber, T D and Bennett, K and Brady, C S and Lawrence-Douglas, A and Ramsay, M G and Sircombe, N J and Gillies, P and Evans, R G and Schmitz, H and Bell, A R and Ridgers, C P}, title = {{Contemporary particle-in-cell approach to laser-plasma modelling}}, journal = {Plasma Physics and Controlled Fusion}, year = {2015}, volume = {57}, number = {11}, pages = {1--26}, month = nov }  Acknowledgement: \u0026ldquo;This work was in part funded by the UK EPSRC grants EP/G054950/1, EP/G056803/1, EP/G055165/1 and EP/ M022463/1.\u0026rdquo;\nReferences   T D Arber, K Bennett, C S Brady, A Lawrence-Douglas, M G Ramsay, N J Sircombe, P Gillies, R G Evans, H Schmitz, A R Bell, \u0026ldquo;Contemporary particle-in-cell approach to laser-plasma modelling,\u0026rdquo; Plasma Physics and Controlled Fusion, 2015. link\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"82d332a3a356e7bb467541e5961ab09d","permalink":"/documentation/basic_usage/acknowledging_epoch.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/acknowledging_epoch.html","section":"documentation","summary":"How do I acknowledge use of the code? There is a paper1 which details many aspects of the EPOCH implementation and also includes useful information on current PIC codes. This paper is OpenAccess so freely available to all.","tags":null,"title":"Acknowledging EPOCH","type":"docs"},{"authors":null,"categories":null,"content":"Most of the control of EPOCH is through a text file called input.deck. The input deck file must be in the output directory which is passed to the code at runtime and contains all the basic information which is needed to set up the code, including the size and subdivision of the domain, the boundary conditions, the species of particles to simulate and the output settings for the code. For most users this will be capable of specifying all the initial conditions and output options they need. More complicated initial conditions will be handled in later sections.\nThe input deck is a structured file which is split into separate blocks, with each block containing several \u0026ldquo;parameter\u0026rdquo; = \u0026ldquo;value\u0026rdquo; pairs. The pairs can be present in any order, and not all possible pairs must be present in any given input deck. If a required pair is missing the code will exit with an error message. The blocks themselves can also appear in any order. The input deck is case sensitive, so true is always \u0026ldquo;T\u0026rdquo;, false is always \u0026ldquo;F\u0026rdquo; and the names of the parameters are always lower case. Parameter values are evaluated using a maths parser which is described in EPOCH maths parser. If the deck contains a \u0026ldquo;\\\u0026rdquo; character then the rest of the line is ignored and the next line becomes a continuation of the current one. Also, the comment character is \u0026ldquo;#\u0026quot;; if the \u0026ldquo;#\u0026rdquo; character is used anywhere on a line then the remainder of that line is ignored. There are three input deck directive commands, which are:\n begin:block - Begin the block named block. end:block - Ends the block named block. import:filename - Includes another file (called filename) into the input deck at the point where the directive is encountered. The input deck parser reads the included file exactly as if the contents of the included file were pasted directly at the position of the import directive.  Each block must be surrounded by valid begin: and end: directives or the input deck will fail. There are currently fourteen valid blocks hard coded into the input deck reader, but it is possible for end users to extend the input deck. The fourteen built in blocks are:\n control - Contains information about the general code setup. See here boundaries - Contains information about the boundary conditions for this run. See here species - Contains information about the species of particles which are used in the code. Also details of how these are initialised. See here laser - Contains information about laser boundary sources. See here. fields - Contains information about the EM fields specified at the start of the simulation. See here. particles_from_file - Contains information about files used to load particle data. See here. window - Contains information about the moving window if the code is used in that fashion. See here. output - Contains information about when and how to dump output files. See here. output_global - Contains parameters which should be applied to all output blocks. See here. dist_fn - Contains information about distribution functions that should be calculated for output. See here. probe - Contains information about particle probes used for output. See here. collisions - Contains information about particle collisions. See here. qed - Contains information about QED pair production. See here. subset - Contains configuration for filters which can be used to modify the data to be output. See here. constant - Contains information about user defined constants and expressions. These are designed to simplify the initial condition setup. See here.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"2c34596a53c5ed5a08c3369ce13fe03b","permalink":"/documentation/input_deck/input_deck.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck.html","section":"documentation","summary":"Most of the control of EPOCH is through a text file called input.deck. The input deck file must be in the output directory which is passed to the code at runtime and contains all the basic information which is needed to set up the code, including the size and subdivision of the domain, the boundary conditions, the species of particles to simulate and the output settings for the code.","tags":null,"title":"The EPOCH input deck","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about bremsstrahlung radiation. See EPOCH input deck for more information on the input deck.\nEPOCH is capable of simulating bremsstrahlung radiation using the teqhniques described by Morris et al 1 and Vyskočil et al 2. In order to run this module, the compiler flag -DBREMSSTRAHLUNG must be switched on in the Makefile. There should also be a corresponding \u0026ldquo;bremsstrahlung\u0026rdquo; block for the input deck which uses a similar format to the \u0026ldquo;qed\u0026rdquo; block. Bremsstrahlung cross sections may be calculated for both electrons and positrons. Photons may also undergo pair production according to the Bethe-Heitler model.\nAn example bremsstrahlung block is shown below:\nbegin:bremsstrahlung enable = T start_time = 0 produce_photons = T photon_energy_min = 1 * kev photon_weight = 1.0 photon_dynamics = F use_plasma_screening = F use_brem_scatter = T use_bethe_heitler = F use_positron_brem = F end:bremsstrahlung    enable - Logical flag to turn bremsstrahlung on or off. \u0026ldquo;use_bremsstrahlung\u0026rdquo; is accepted as an alias. The default is \u0026ldquo;F\u0026rdquo;.\n  start_time - Floating point value specifying the time after which bremsstrahlung radiation is modelled. The default is 0.\n  produce_photons - Logical flag to allow population of a photon species. If \u0026ldquo;F\u0026rdquo;, then only the energy loss of the electrons will be simulated. The photon species can be specified by including the line identify:brem_photon in the corresponding species block. If the compiler flag -DPHOTONS is active, QED and bremsstrahlung will both populate the first species with identify:photon if no brem_photon species is specified. The default is \u0026ldquo;F\u0026rdquo;.\n  photon_energy_min - Floating point value specifying the minimum energy of produced photons. Electron energy loss is still calculated for lower energy photon emissions, but these photons are not added to the photon species. The default is 0.\n  photon_weight - Floating point value which applies a multiplier to the weight of produced macro-photons, in order to increase the number of overall emissions and obtain better spectra. Must be less than or equal to 1 and greater than 0. For example, 0.1 would make emission 10 times more likely, but for macro-photons only 10% the weight of the generating macro-electrons. Electron recoil would be reduced accordingly. The default is 1. Note that only one emission is possible per macro-electron per timestep, so setting this too low will saturate emissions.\n  photon_dynamics - Logical flag to specify whether or not to push photons. If \u0026ldquo;F\u0026rdquo;, then the generated photons are immobilised at the point of emission. The default is \u0026ldquo;F\u0026rdquo;.\n  use_plasma_screening - Logical flag to specify whether a cross section enhancement due to heated ionised targets is considered, based on theory described by Wu et al3. It is expected that for high energy electrons passing through low density, ionised plasmas with electron temperatures over $\\sim$100 eV ($\\sim8\\times 10^{5}$ K), the bremsstrahlung emission rate could increase by a factor of 2-3. This has not been tested experimentally, and so the default value is set to \u0026ldquo;F\u0026rdquo;.\n  use_radiation_reaction - Logical flag to specify whether the electrons experience energy loss when emitting photons or not. \u0026ldquo;use_bremsstrahlung_recoil\u0026rdquo; is accepted as an alias. Debugging flag, default \u0026ldquo;T\u0026rdquo;.\n  table_location - String specifying the location of the emission look-up tables for bremsstrahlung. The default path is set to src/physics_packages/TABLES/br.\n  use_brem_scatter - Samples photon ejection angle from a differential cross section. Default is \u0026ldquo;F\u0026rdquo;, where photons are emitted in the direction of the incident particle (ultra-relativistic approximation).\n  use_bethe_heitler - Allows photons to undergo Bethe-Heitler pair production. Default is \u0026ldquo;F\u0026rdquo;. This requires both electron and positron species to be defined.\n  use_positron_brem - Samples bremsstrahlung radiation from positrons. Default is \u0026ldquo;F\u0026rdquo;. If \u0026ldquo;T\u0026rdquo;, electrons and positrons share the same parameter values set in the bremsstrahlung block.\n  Bremsstrahlung, like QED, requires the code to know which species are electrons and which are photons, so uses the same identify system (with identify:brem_photon for a bremsstrahlung-only photon species). Additionally, the atomic numbers of the atom/ion species are required in the species block. For example, atomic aluminium (charge = 0) could be specified as:\nbegin:species name = Aluminium atomic_number = 13 charge = 0 mass = 49218 number_density = 6.022e28 fraction = 0.5 dump = T end:species  If the atomic number is not specified then it will be assumed that the ion is fully ionised and the atomic number would be set to the charge (the nearest integer to the ion charge when expressed in units of elementary charge). If ionisation is considered, the atomic number must be specified once, and all child species will retain the same atomic number.\nIf Bethe-Heitler pair production is considered, the user may identify specific species to populate with Bethe-Heitler electrons and positrons using the identity aliases:\n  identify:bethe_heitler_electron - bh_electron is also accepted.\n  identify:bethe_heitler_positron - bh_positron is also accepted.\n  If these species are unspecified, EPOCH will populate the first electron and positron species present read in from the input deck. Additional identity aliases are provided in the QED section.\nReferences   Morris, S., Robinson, A., \u0026amp; Ridgers, C. (2021). Highly efficient conversion of laser energy to hard x-rays in high-intensity laser–solid simulations. Physics of Plasmas, 28(10), 103304. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n J. Vyskočil, O. Klimo, and S. Weber, “Simulations of bremsstrahlung emission in ultra-intense laser interactions with foil targets,” Plasma Physics and Controlled Fusion, vol. 60, no. 5, p. 054013, 2018. 2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Wu, D., He, X. T., Yu, W., \u0026amp; Fritzsche, S. (2018). Particle-in-cell simulations of laser–plasma interactions at solid densities and relativistic intensities: the role of atomic processes. High Power Laser Science and Engineering, 6. 3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673359416,"objectID":"7a1e156a99f2f3bc781ef5ca35a86040","permalink":"/documentation/input_deck/input_deck_bremsstrahlung.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_bremsstrahlung.html","section":"documentation","summary":"This block contains information about bremsstrahlung radiation. See EPOCH input deck for more information on the input deck.\nEPOCH is capable of simulating bremsstrahlung radiation using the teqhniques described by Morris et al 1 and Vyskočil et al 2.","tags":null,"title":"bremsstrahlung block","type":"docs"},{"authors":null,"categories":null,"content":"The control block contains information about the general code setup. See EPOCH input deck for more information on the input deck.\nBasics The block sets up the basic code properties for the domain, the end time of the code, the load balancer and the types of initial conditions to use.\nThe control block of a valid input deck for EPOCH2D reads as follows:\nbegin:control # Global number of gridpoints nx = 512 # in x ny = 512 # in y # Global number of particles npart = 10 * nx * ny # Final time of simulation t_end = 1.0e-12 # nsteps = -1 # Size of domain x_min = -0.1e-6 x_max = 400.0e-6 y_min = -400.0e-6 y_max = 400.0e-6 # dt_multiplier = 0.95 # dlb_threshold = 0.8 # restart_snapshot = 98 # field_order = 2 # maxwell_solver = yee # stdout_frequency = 10 end:control  As illustrated in the above code block, the \u0026ldquo;#\u0026rdquo; symbol is treated as a comment character and the code ignores everything on a line following this character. The allowed entries are as follows:\n  nx, ny, nz - Number of grid points in the x,y,z direction. This parameter is mandatory.\n  npart - The global number of pseudoparticles in the simulation. This parameter does not need to be given if a specific number of particles is supplied for each particle species by using the \u0026ldquo;npart\u0026rdquo; directive in each species block. If both are given then the value in the control block will be ignored.\n  nsteps - The number of iterations of the core solver before the code terminates. Negative numbers instruct the code to only terminate at t_end. If nsteps is not specified then t_end must be given.\n  t_end - The final simulation time in simulation seconds before the code terminates. If t_end is not specified then nsteps must be given. If they are both specified then the first time restriction to be satisfied takes precedence. Sometimes it is more useful to specify the time in picoseconds or femtoseconds. To accomplish this, just append the appropriate multiplication factor. For example, \u0026ldquo;t_end = 3 * femto\u0026rdquo; specifies 3 femtoseconds. A list of multiplication factors is supplied here.\n  {x,y,z}_min - Minimum grid position of the domain in metres. These are required parameters. Can be negative. \u0026ldquo;{x,y,z}_start\u0026rdquo; is accepted as a synonym. In a similar manner to that described above, distances can be specified in microns using a multiplication constant. eg. \u0026ldquo;x_min = 4 * micron\u0026rdquo; specifies a distance of 4 μm.\n  {x,y,z}_max - Maximum grid position of the domain in metres. These are required parameters. Must be greater than {x,y,z}_min. \u0026ldquo;{x,y,z}_end\u0026rdquo; is accepted as a synonym.\n  dt_multiplier - Factor by which the timestep is multiplied before it is applied in the code, i.e. a multiplying factor applied to the CFL condition on the timestep. Must be less than one. If no value is given then the default of 0.95 is used. If maxwell_solver is different from \u0026ldquo;yee\u0026rdquo; (the default) this parameter becomes increasingly relevant.\n  dlb_threshold - The minimum ratio of the load on the least loaded processor to that on the most loaded processor allowed before the code load balances. Set to 1 means always balance, set to 0 means never balance. If this parameter is not specified then the code will only be load balanced at initialisation time.\n  restart_snapshot - The number of a previously written restart dump to restart the code from. If not specified then the initial conditions from the input deck are used. Note that as of version 4.2.5, this parameter can now also accept a filename in place of a number. If you want to restart from \u0026ldquo;0012.sdf\u0026rdquo; then it can either be specified using \u0026ldquo;restart_snapshot = 12\u0026rdquo;, or alternatively it can be specified using \u0026ldquo;restart_snapshot = 0012.sdf\u0026rdquo;. This syntax is required if output file prefixes have been used (see the output block page).\n  field_order - Order of the finite difference scheme used for solving Maxwell\u0026rsquo;s equations. Can be 2, 4 or 6. If not specified, the default is to use a second order scheme.\n  maxwell_solver - Choose a Maxwell solver scheme with an extended stencil. This option is only active if field_order is set to 2. Possible options are \u0026ldquo;yee\u0026rdquo;, \u0026ldquo;lehe_{x,y,z}\u0026rdquo;, \u0026ldquo;pukhov\u0026rdquo;, \u0026ldquo;cowan\u0026rdquo; and since v4.12 \u0026ldquo;custom\u0026rdquo;. Note that not all options are available in 1d and 2d. The default is \u0026ldquo;yee\u0026rdquo; which is the default second order scheme.\n  stdout_frequency - If specified then the code will print a one line status message to stdout after every given number or timesteps. The default is to print nothing to screen (i.e. stdout_frequency = 0).\n  use_random_seed - The initial particle distribution is generated using a random number generator. By default, EPOCH uses a fixed value for the random generator seed so that results are repeatable. If this flag is set to \u0026ldquo;T\u0026rdquo; then the seed will be generated using the system clock.\n  nproc{x,y,z} - Number of processes in the x,y,z directions. By default, EPOCH will try to pick the best method of splitting the domain amongst the available processors but occasionally the user may wish to override this choice.\n  smooth_currents - This is a logical flag. If set to \u0026ldquo;T\u0026rdquo; then a smoothing function is applied to the current generated during the particle push. This can help to reduce noise and self-heating in a simulation. The smoothing function used is the same as that outlined in Buneman 1. The default value is \u0026ldquo;F\u0026rdquo;.\n  field_ionisation - Logical flag which turns on field ionisation. See here .\n  use_bsi - Logical flag which turns on barrier suppression ionisation correction to the tunnelling ionisation model for high intensity lasers. See here . This flag should always be enabled when using field ionisation and is only supplied for testing purposes. The default is \u0026ldquo;T\u0026rdquo;.\n  use_multiphoton - Logical flag which turns on modelling ionisation by multiple photon absorption. This should be set to \u0026ldquo;F\u0026rdquo; if there is no laser attached to a boundary as it relies on laser frequency. See here. This flag should always be enabled when using field ionisation and is only supplied for testing purposes. The default is \u0026ldquo;T\u0026rdquo;.\n  particle_tstart - Specifies the time at which to start pushing particles. This allows the field to evolve using the Maxwell solver for a specified time before beginning to move the particles.\n  use_exact_restart - Logical flag which makes a simulation restart as close as is numerically possible to if the simulation had not been stopped and restarted. Without this flag set to T then the simulation will still give a correct result after restart, it is simply not guaranteed to be identical to if the code had not been restarted. This flag is mainly intended for testing purposes and is not normally needed for physical simulations. If set to \u0026ldquo;T\u0026rdquo; then the domain split amongst processors will be identical along with the seeds for the random number generators. Note that the flag will be ignored if the number of processors does not match that used in the original run. The default value is \u0026ldquo;F\u0026rdquo;.\n  use_current_correction - Logical flag to specify whether EPOCH should correct for residual DC current in the initial conditions. If set to true, the DC current in the initial conditions is calculated and is subtracted from all subsequent current depositions.\n  allow_cpu_reduce - Logical flag which allows the number of CPUs used to be reduced from the number specified. In some situations it may not be possible to divide the simulation amongst all the processors requested. If this flag is set to \u0026ldquo;T\u0026rdquo; then EPOCH will continue to run and leave some of the requested CPUs idle. If set to \u0026ldquo;F\u0026rdquo; then code will exit if all CPUs cannot be utilised. The default value is \u0026ldquo;T\u0026rdquo;.\n  check_stop_file_frequency - Integer parameter controlling automatic halting of the code. The frequency is specified as number of simulation cycles. Refer to description later in this section. The default value is 10.\n  stop_at_walltime - Floating point parameter controlling automatic halting of the code. Refer to description later in this section. The default value is -1.0.\n  stop_at_walltime_file - String parameter controlling automatic halting of the code. See below. The default value is an empty string.\n  simplify_deck - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the deck parser will attempt to simplify the maths expressions encountered after the first pass. This can significantly improve the speed of evaluation for some input deck blocks. The default value is \u0026ldquo;F\u0026rdquo;.\n  print_constants - If this logical flag is set to \u0026ldquo;T\u0026rdquo;, deck constants are printed to the \u0026ldquo;deck.status\u0026rdquo; (and \u0026ldquo;const.status\u0026rdquo; after 4.11) file as they are parsed. The default value is \u0026ldquo;F\u0026rdquo;.\n  use_migration - Logical flag which determines whether or not to use particle migration. The default is \u0026ldquo;F\u0026rdquo;.\n  migration_interval - The number of timesteps between each migration event. The default is 1 (migrate at every timestep).\n  allow_missing_restart - Logical flag to allow code to run when a restart dump is absent. When \u0026ldquo;restart_snapshot\u0026rdquo; is specified then the simulation first checks that the specified restart dump is valid. If the restart dump exists and is valid then it is used to provide initial conditions for the simulation. However, if the restart dump does not exist or is not usable for some reason then by default the simulation will abort. If \u0026ldquo;allow_missing_restart\u0026rdquo; is set to \u0026ldquo;T\u0026rdquo; then the simulation will not abort but will continue to run and use the initial conditions contained in the input deck to initialise the simulation. The default value is \u0026ldquo;F\u0026rdquo;.\n   print_eta_string - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the current estimated time to completion will be appended to the status updates. The default value is \u0026ldquo;T\u0026rdquo;.\n   n_zeros - Integer flag which specifies the number of digits to use for the output file numbers. (eg. \u0026ldquo;0012.sdf\u0026rdquo;). By default, the code tries to calculate the number of digits required by dividing t_end by dt_snapshot. Note that the minimum number of digits is 4.\n  use_accurate_n_zeros - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the code performs a more rigorous test to determine the number of digits required to accommodate all outputs that are to be generated by a run. Since this can be time consuming and is overkill for most cases, it is disabled by default. The default value is \u0026ldquo;F\u0026rdquo;.\n  use_particle_count_update - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the code keeps global particle counts for each species on each processor. This information isn\u0026rsquo;t needed by the core algorithm, but can be useful for developing some types of additional physics packages. It does require one additional MPI_ALL_REDUCE per species per timestep, so it is not activated by default. The default value is \u0026ldquo;F\u0026rdquo;.\n  reset_walltime - When restarting from a dump file, the current walltime displayed will include the elapsed walltime recorded in the restart dump. The user can request that this time is ignored by setting the \u0026ldquo;reset_walltime\u0026rdquo; flag to \u0026ldquo;T\u0026rdquo;. The default value is \u0026ldquo;F\u0026rdquo;.\n  dlb_maximum_interval - This integer parameter determines the maximum number of timesteps to allow between load balancing checks. Each time that the load balancing sweep is unable to improve the load balance of the simulation, it doubles the number of steps before the next check will occur. It will keep increasing the check interval until it reaches the value given by dlb_maximum_interval. If the value of dlb_maximum_interval is negative then the check interval will increase indefinitely. When the load balancing sweep finds an improvement to the load balance of the simulation, the check interval is reset to one. The default value is 500.\n  dlb_force_interval - This integer parameter determines the maximum number of timesteps to allow between forcing a full load balance sweep. If the current load balance is greater than the value of dlb_threshold then the load balancer exits before attempting to improve the loading. If dlb_force_interval is greater than zero, then the full load balancer will be run at the requested interval of timesteps, regardless of the value of dlb_threshold. Note that the simulation will only be redistributed if this would result in an improved load balance. The default value is 2000.\n  balance_first - This logical flag determines whether a load balance will be attempted on the first call of the load balancer. The load balancer performs to functions: first it attempts to find a domain decomposition that balances the load evenly amongst processors. Next, it redistributes the domain and particles onto the new layout (if requred). This latter step is always required when setting up the simulation, so the load balancer is always called once during set-up. This flag controls whether or not a load balance is attempted during this call, regardless of the value of dlb_threshold. The default value is \u0026ldquo;T\u0026rdquo;.\n  use_pre_balance - This logical flag determines whether a load balance will be attempted before the particle load occurs. If this flag is set to \u0026ldquo;T\u0026rdquo; then the particle auto-loader will be called at setup time, but instead of creating particles it will just populate a particle-per-cell field array. This will then be used to calculate the optimal domain decomposition and all field arrays will be redistributed to use the new layout. Finally, after all of this has been done, the auto-loader will be called again and create just the particles that are present on their optimally load-balanced domains. In contrast, if the flag is set to \u0026ldquo;F\u0026rdquo; then the domain is just divided evenly amongst processors and the particles are loaded on this domain decomposition. Balancing is then carried out on to redistribute the work load. For heavily imbalanced problems, this can lead to situations in which there is insufficient memory to setup a simulation, despite there being sufficient resources for the final load-balanced conditions. The default value is \u0026ldquo;T\u0026rdquo;.\n  use_optimal_layout - This logical flag determines whether the load balancer attempts to find an optimal processor split before loading the particles. The initial domain split is chosen in such a way as to minimize the total surface area of the resulting domains in 3D, or edge lengths in 2D. For example, if a 2D square domain is run on 16 CPUs then the domain will be divided by 4 in the x-direction and 4 in the y-direction. The other possible splits (1x16, 2x8, 8x2, 16x1) are rejected because they all yield rectangular subdomains whose total edge length is greater than the 4x4 edge length. For some problems (eg. a density ramp or thin foil) this is a poor choice and a better load balance would be obtained by a less even split. It is always possible to specify such a split by using nproc{x,y,z} flags but enabling the use_optimal_layout flag will automatically determine the best split for you. Future versions of the code will also allow the split to be changed dynamically at run time. The default value is \u0026ldquo;T\u0026rdquo;.\n  use_more_setup_memory - This logical flag determines whether the extra memory will be used during the initial setup of particle species. If set to false then only one set of arrays will be used for storing temperature, density and drift during species loading. This can be a significant memory saving but omes at the expense of recalculating grid quantities multiple times. Setting the flag to true enables one set of arrays per species. The default value is \u0026ldquo;F\u0026rdquo;.\n  deck_warnings_fatal - This logical flag controls the behaviour of the deck parser when a warning is encountered. Usually the code will just print a warning message and continue running. Setting this flag to \u0026ldquo;T\u0026rdquo; will force the code to abort. The default value is \u0026ldquo;F\u0026rdquo;.\n  Maxwell Solvers With the default settings \u0026ldquo;field_order=2\u0026rdquo;, \u0026ldquo;maxwell_solver=yee\u0026rdquo; EPOCH will use the standard second order Yee scheme for solving Maxwell\u0026rsquo;s equations. This scheme has a grid dispersion relation with phase velocities smaller than $c$, especially for large spatial frequencies. Since EPOCH v4.11 it is possible to introduce extended stencils into the update step of the Maxwell-Faraday equation which will help improving the dispersion relation. All of the following extended stencils are only available when \u0026ldquo;field_order=2\u0026rdquo;. Please note that you will also need to choose an appropriate dt_multiplier, according to the selected scheme. A dt_multiplier equal to unity would result in using the largest time-step allowed by the CFL condition for any of the implemented schemes. This time-step is said to be marginally stable. While, in general, the marginally stable time-step has the best dispersion properties, simulations may suffer from numerical problems such as exponentially growing noise. Choosing smaller values for the dt_multiplier tend to improve on this, while adversely affecting the dispersion relation. The implemented solvers behave differently in this regard.\nDifferent options are available as follows:\n  maxwell_solver = lehe_{x,y,z} - This setting will enable an extended stencil proposed by Lehe et al 2. This stencil focusses on improving the dispersion relation on the $x$-axis, please take this into account when defining your laser input. It is available in EPOCH1D, EPOCH2D and EPOCH3D. While it is not technically required to use a dt_multiplier smaller than unity, the value proposed by Lehe et al 2 is \u0026ldquo;dt_multiplier=0.96\u0026rdquo;.\n  maxwell_solver = pukhov - This setting will enable an extended stencil proposed by Pukhov 3 under the name of NDFX. It is available in EPOCH2D and EPOCH3D. In EPOCH1D, setting maxwell_solver = pukhov will make the code fall back silently to Yee\u0026rsquo;s scheme. Pukhov\u0026rsquo;s NDFX scheme aims at improving the numerical dispersion relation by allowing to choose \u0026quot; dt_multiplier= 1.0\u0026quot;, while smaller values are also valid. The resulting dispersion relation is best along the axis with the smallest grid spacing.\n    maxwell_solver = cowan - This setting will enable en extended stencil proposed by Cowan et al 4. It is available only in EPOCH3D. In EPOCH1D and EPOCH2D, setting maxwell_solver = cowan will make the code fall back silently to Yee\u0026rsquo;s scheme. Cowan et al 4 proposes to numerically calculate a time step that has the correct group velocity for the input laser. Typically these time steps are only slightly below the CFL condition, e.g. \u0026quot; = 0.999\u0026quot;. When Cowan\u0026rsquo;s scheme is reduced to 2D it is the same as Pukhov\u0026rsquo;s scheme with dt_multiplier \u0026lt;1.0. The resulting dispersion relation is best along the axis with the smallest grid spacing.\n  maxwell_solver = custom - This setting will enable full user control over the extended stencil coefficients. This allows for the specification of optimised coefficients as outlined in 5. This option must be accompanied by a \u0026ldquo;stencil\u0026rdquo; block. See below.\n  Stencil Block The extended stencil Maxwell solvers described above all operate by including points in neighbouring cells with a carefully chosen weighting. These weightings are determined by adjusting the coefficients shown in the Figure. Full control over these coefficients can be achieved by specifying \u0026ldquo;custom\u0026rdquo; for the \u0026ldquo;maxwell_solver\u0026rdquo; parameter in the control block and then supplying a \u0026ldquo;stencil\u0026rdquo; block to provide the desired coefficient values.\nThis option allows the user to specify an extended stencil scheme that has been specifically optimised for the simulation grid spacing and timestep. See 5 for further details. or see 6 for stencil optimization code. Note that there is no option for changing the value of $\\alpha_{x,y,z}$ since these are calculated using the following equations: $$ \\begin{aligned} \\alpha_x \u0026amp;= 1 - 2\\beta_{xy} - 2\\beta{xz} - 3\\delta_x\\,, \\\\\\\n\\alpha_y \u0026amp;= 1 - 2\\beta_{yx} - 2\\beta{yz} - 3\\delta_y\\,, \\\\\\\n\\alpha_z \u0026amp;= 1 - 2\\beta_{zx} - 2\\beta{zy} - 3\\delta_z\\,. \\end{aligned} $$\n delta{x,y,z}, gamma{x,y,z}, beta{xy,xz,yx,yz,zx,zy} - The coefficients to use for the extended stencil points as shown in Figure [stencil]. See for further details. These coefficients are specified as floating point numbers. The default values are to set all coefficients to zero which results in $\\alpha_{x,y,z}$ having values of unity. This corresponds to the standard Yee scheme. dt - The timestep restriction to use for the field solver  Strided Current Filtering EPOCH 4.15 introduces strided multipass digital current filtering as described and benchmarked in the review by Vay and Godfrey. This can be tuned to substantially damp high frequencies in the currents and can be used to reduce the effect of numerical Cherenkov radiation. Once you turn on current filtering by specifying \u0026ldquo;smooth_currents=T\u0026rdquo; you can then set the following keys\n smooth_iterations - Integer number of iterations of the smoothing function to be performed. If not present defaults to one iteration. More iterations will produce smoother results but will be slower. smooth_compensation - Logical flag. If true then perform a compensation step (see Vay and Godfrey 6) after the smoothing steps are performed. Total number of iterations if true is smooth_iterations + 1. If not specified defaults to false smooth_strides - Either a comma separated list of integers or \u0026ldquo;auto\u0026rdquo; (without quote marks). This specifies the strides (in number of grid cells) to use when performing strided filtering. Specifying \u0026ldquo;1, 3\u0026rdquo; will smooth each point with the points immediately adjacent and with the points 3 cells away on each side of the current cell. Setting this key to \u0026ldquo;auto\u0026rdquo; uses a \u0026ldquo;1, 2, 3, 4\u0026rdquo; set of strides as a \u0026ldquo;good\u0026rdquo; starting point for strided filtering.  It should be stressed that there is no set of values that is guaranteed to give any given result from filtering while not affecting the physical correctness of your simulation. Current filtering should be tuned to match the problem that you want to work on and should always be carefully tested to ensure that it doesn\u0026rsquo;t produce unphysical results.\nDynamic Load Balancing \u0026ldquo;dlb\u0026rdquo; in the input deck stands for Dynamic Load Balancing and, when turned on, it allows the code to rearrange the internal domain boundaries to try and balance the workload on each processor. This rearrangement is an expensive operation, so it is only performed when the maximum load imbalance reaches a given critical point. This critical point is given by the parameter \u0026ldquo;dlb_threshold\u0026rdquo; which is the ratio of the workload on the least loaded processor to the most loaded processor. When the calculated load imbalance is less than \u0026ldquo;dlb_threshold\u0026rdquo; the code performs a re-balancing sweep, so if \u0026ldquo;dlb_threshold = 1.0\u0026rdquo; is set then the code will keep trying to re-balance the workload at almost every timestep. At present the workload on each processor is simply calculated from the number of particles on each processor, but this will probably change in future. If the \u0026ldquo;dlb_threshold\u0026rdquo; parameter is not specified then the code will only be load balanced at initialisation time.\nAutomatic halting of a simulation It is sometimes useful to be able to halt an EPOCH simulation midway through execution and generate a restart dump. Two methods have been implemented to enable this.\nThe first method is to check for the existence of a \u0026ldquo;STOP\u0026rdquo; file. Throughout execution, EPOCH will check for the existence of a file named either \u0026ldquo;STOP\u0026rdquo; or \u0026ldquo;STOP_NODUMP\u0026rdquo; in the simulation output directory. The check is performed at regular intervals and if such a file is found then the code exits immediately. If \u0026ldquo;STOP\u0026rdquo; is found then a restart dump is written before exiting. If \u0026ldquo;STOP_NODUMP\u0026rdquo; is found then no I/O is performed.\nThe interval between checks is controlled by the integer parameter \u0026ldquo;check_stop_frequency\u0026rdquo; which can be specified in the \u0026ldquo;control\u0026rdquo; block of the input deck. If it is less than or equal to zero then the check is never performed.\nThe next method for automatically halting the code is to stop execution after a given elapsed walltime. If a positive value for \u0026ldquo;stop_at_walltime\u0026rdquo; is specified in the control block of an input deck then the code will halt once this time is exceeded and write a restart dump. The parameter takes a real argument which is the time in seconds since the start of the simulation.\nAn alternative method of specifying this time is to write it into a separate text file. \u0026ldquo;stop_at_walltime_file\u0026rdquo; is the filename from which to read the value for \u0026ldquo;stop_at_walltime\u0026rdquo;. Since the walltime will often be found by querying the queueing system in a job script, it may be more convenient to pipe this value into a text file rather than modifying the input deck.\nRequesting output dumps at run time In addition to polling for the existence of a \u0026ldquo;STOP\u0026rdquo; file, EPOCH also periodically checks the output directory for a file named \u0026ldquo;DUMP\u0026rdquo;. If such a file is found then EPOCH will immediately create an output dump and remove the \u0026ldquo;DUMP\u0026rdquo; file. By default, the file written will be a restart dump but if the \u0026ldquo;DUMP\u0026rdquo; file contains the name of an output block then this will be used instead.\nReferences   O. Buneman, \u0026ldquo;TRISTAN: The 3-D Electromagnetic Particle Code.\u0026rdquo; in Computer Space Plasma Physics: Simulations Techniques and Software, 1993. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n R. Lehe, A. Lifschitz, C. Thaury, V. Malka, and X. Davoine, \u0026ldquo;Numerical growth of emittance in simulations of laser-wakefield acceleration,\u0026rdquo; Phys. Rev. Accel. Beams, vol. 16, no. 2, p.021301, 2013 2.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Pukhov, A., \u0026ldquo;Three-dimensional electromagnetic relativistic particle-in-cell code VLPL (Virtual Laser Plasma Lab)\u0026rdquo;, J. Plasma Phys., vol. 61, no. 3, p. 425, 1999 3.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n B. Cowan, D. Bruhwiler, J. Cary, E. Cormier-Michel, and C. Geddes, \u0026ldquo;Generalized algorithm for control of numerical dispersion in explicit time-domain electromagnetic simulations\u0026rdquo;, Phys. Rev. Accel. Beams, vol. 16, no. 4, p. 041303, 2013 4.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n A. Blinne, D. Schinkel, S. Kuschel, N. Elkina, S. G. Rykovanov, and M. Zepf, \u0026ldquo;A systematic approach to numerical dispersion in Maxwell solvers\u0026rdquo;, Computer Physics Communications, 00104655, 2017 5\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n J. L. Vay and B. B. Godfrey, \u0026ldquo;Modeling of relativistic plasmas with the particle-in-cell method\u0026rdquo;, Comptes Rendus Mcanique, 2014 6\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"22b02d7930309948ce443fa5cf2177ac","permalink":"/documentation/input_deck/input_deck_control.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_control.html","section":"documentation","summary":"The control block contains information about the general code setup. See EPOCH input deck for more information on the input deck.\nBasics The block sets up the basic code properties for the domain, the end time of the code, the load balancer and the types of initial conditions to use.","tags":null,"title":"control block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the boundary conditions for this run. See EPOCH input deck for more information on the input deck.\nBasics The boundaries block sets the boundary conditions of each boundary of the domain. Some types of boundaries allow EM wave sources (lasers) to be attached to a boundary. Lasers are attached at the initial conditions stage.\nAn example boundary block for EPOCH2D is as follows:\nbegin:boundaries bc_x_min = simple_laser bc_x_max_field = simple_outflow bc_x_max_particle = simple_outflow bc_y_min = periodic bc_y_max = periodic end:boundaries  The boundaries block accepts the following parameters:\n bc_{x,y,z}_min - The condition for the lower boundary for both fields and particles. \u0026ldquo;xbc_left\u0026rdquo;, \u0026ldquo;ybc_down\u0026rdquo; and \u0026ldquo;zbc_back\u0026rdquo; are accepted as a synonyms. bc_{x,y,z}_min_{field,particle} - The condition for the lower boundary for {fields,particles}. \u0026ldquo;xbc_left_{field,particle}\u0026rdquo;, \u0026ldquo;ybc_down_{field,particle}\u0026rdquo; and \u0026ldquo;zbc_back_{field,particle}\u0026rdquo; are accepted as a synonyms. bc_{x,y,z}_max - The condition for the upper boundary for both fields and particles. \u0026ldquo;xbc_right\u0026rdquo;, \u0026ldquo;ybc_up\u0026rdquo; and \u0026ldquo;zbc_front\u0026rdquo; are accepted as a synonyms. bc_{x,y,z}_max_{field,particle} - The condition for the upper boundary for {fields,particles}. \u0026ldquo;xbc_right_{field,particle}\u0026rdquo;, \u0026ldquo;ybc_up_{field,particle}\u0026rdquo; and \u0026ldquo;zbc_front_{field,particle}\u0026rdquo; are accepted as a synonyms. cpml_thickness - The thickness of the CPML boundary in terms of the number of grid cells. The default value is 6. cpml_kappa_max - A tunable CPML parameter. cpml_a_max - A tunable CPML parameter. cpml_sigma_max - A tunable CPML parameter. There are ten boundary types in EPOCH and each boundary of the domain can have one and only one of these boundaries attached to it. These boundary types are: periodic - A simple periodic boundary condition. Fields and/or particles reaching one edge of the domain are wrapped round to the opposite boundary. If either boundary condition is set to periodic then the boundary condition on the matching boundary at the other side of the box is also assumed periodic. simple_laser - A characteristic based boundary condition to which one or more EM wave sources can be attached. EM waves impinging on a simple_laser boundary are transmitted with as little reflection as possible. Particles are fully transmitted. The field boundary condition works by allowing outflowing characteristics to propagate through the boundary while using the attached lasers to specify the inflowing characteristics. The particles are simply removed from the simulation when they reach the boundary. See laser blocks for details. simple_outflow - A simplified version of simple_laser which has the same properties of transmitting incident waves and particles, but which cannot have EM wave sources attached to it. These boundaries are about 5% more computationally efficient than simple_laser boundaries with no attached sources. This boundary condition again allows outflowing characteristics to flow unchanged, but this time the inflowing characteristics are set to zero. The particles are again simply removed from the simulation when they reach the boundary. reflect - This applies reflecting boundary conditions to particles. When specified for fields, all field components are clamped to zero. conduct - This applies perfectly conducting boundary conditions to the field. When specified for particles, the particles are reflected. open - When applied to fields, EM waves outflowing characteristics propagate through the boundary. Particles are transmitted through the boundary and removed from the system. cpml_laser - See #CPML boundary conditions. cpml_outflow - See #CPML boundary conditions. thermal - See #Thermal boundaries.  NOTE: If simple_laser, simple_outflow, cpml_laser, cpml_outflow or open are specified on one or more boundaries then the code will no longer necessarily conserve mass. Note also that it is possible for the user to specify contradictory, unphysical boundary conditions. It is the users responsibility that these flags are set correctly.\nCPML boundary conditions There are now Convolutional Perfectly Matched Layer boundary conditions in EPOCH. The implementation closely follows that outlined in the book \u0026ldquo;Computational Electrodynamics: The Finite-Difference Time-Domain Method\u0026rdquo; by Taflove and Hagness1. See also Roden and Gedney2.\nCPML boundaries are specified in the input deck by specifying either \u0026ldquo;cpml_outflow\u0026rdquo; or \u0026ldquo;cpml_laser\u0026rdquo; in the boundaries block. \u0026ldquo;cpml_outflow\u0026rdquo; specifies an absorbing boundary condition whereas \u0026ldquo;cpml_laser\u0026rdquo; is used to attach a laser to an otherwise absorbing boundary condition.\nThere are also four configurable parameters:\n cpml_thickness - The thickness of the CPML boundary in terms of the number of grid cells. The default value is 6. cpml_kappa_max, cpml_a_max, cpml_sigma_max - These are tunable parameters which affect the behaviour of the absorbing media. The notation follows that used in the two references quoted above. Note that the \u0026ldquo;cpml_sigma_max\u0026rdquo; parameter is normalised by $\\sigma_{\\rm opt}$ which is taken to be 3.2/dx (see Taflove and Hagness1 for details). These are real valued parameters which take the following default values: cpml_kappa_max=20, cpml_a_max=0.15, cpml_sigma_max=0.7 An example usage is as follows:   begin:boundaries cpml_thickness = 16 cpml_kappa_max = 20 cpml_a_max = 0.2 cpml_sigma_max = 0.7 bc_x_min = cpml_laser bc_x_max = cpml_outflow bc_y_min = cpml_outflow bc_y_max = cpml_outflow end:boundaries  Thermal boundaries Thermal boundary conditions have been added to the \u0026ldquo;boundaries\u0026rdquo; block. These simulate the existence of a \u0026ldquo;thermal bath\u0026rdquo; of particles in the domain adjacent to the boundary. When a particle leaves the simulation it is replace with an incoming particle sampled from a Maxwellian of a temperature corresponding to that of the initial conditions. It is requested using the keyword \u0026ldquo;thermal\u0026rdquo;. For example:\n begin:boundaries bc_x_min = laser bc_x_max = thermal end:boundaries  References   A. Taflove and S. C. Hagness, Computational Electrodynamics: The Finite-Difference Time-Domain Method. Artech House, 2000. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n J. Roden and S. Gedney, \u0026ldquo;Convolution pml (cpml): An efficient fdtd implementation of the cfs-pml for arbitrary media,\u0026rdquo; Microw. Opt. Technol. Lett., 2000. 2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624406887,"objectID":"ee3d5051ae90afd95468545f66312741","permalink":"/documentation/input_deck/input_deck_boundaries.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_boundaries.html","section":"documentation","summary":"This block contains information about the boundary conditions for this run. See EPOCH input deck for more information on the input deck.\nBasics The boundaries block sets the boundary conditions of each boundary of the domain.","tags":null,"title":"boundaries block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the species of particles which are used in the code. Also details of how these are initialised. See EPOCH input deck for more information on the input deck.\nBasics The next section of the input deck describes the particle species used in the code. An example species block for any EPOCH code is given below.\nbegin:species name = Electron charge = -1.0 mass = 1.0 frac = 0.5 # npart = 2000 * 100 number_density = 1.e4 temp = 1e6 temp_x = 0.0 temp_y = temp_x(Electron) number_density_min = 0.1 * den_max number_density = if(abs(x) lt thick, den_max, 0.0) number_density = if((x gt -thick) and (abs(y) gt 2e-6), \\ 0.0, number_density(Carbon)) end:species begin:species name = Carbon charge = 4.0 mass = 1836.0*12 frac = 0.5 number_density = 0.25*number_density(Electron) temp_x = temp_x(Electron) temp_y = temp_x(Electron) dumpmask = full end:species  Each species block accepts the following parameters:\n  name - This specifies the name of the particle species defined in the current block. This name can include any alphanumeric characters in the basic ASCII set. The name is used to identify the species in any consequent input block and is also used for labelling species data in any output dumps. It is a mandatory parameter. **NOTE: IT IS IMPOSSIBLE TO SET TWO SPECIES WITH THE SAME NAME! **\n  charge - This sets the charge of the species in multiples of the electron charge. Negative numbers are used for negatively charged particles. This is a mandatory parameter.\n  mass - This sets the mass of the species in multiples of the electron mass. Cannot be negative. This is a mandatory parameter.\n  npart - This specifies the number of pseudoparticles which should be loaded into the simulation domain for this species block. Using this parameter is the most convenient way of loading particles for simulations which contain multiple species with different number densities. If npart is specified in a species block then any value given for npart in the control block is ignored. npart should not be specified at the same time as frac within a species block.\n  frac - This specifies what fraction of npart (the global number of particles specified in the control block) should be assigned to the species.\n  **NOTE: frac should not be specified at the same time as npart for a given species. **\n npart_per_cell - Integer parameter which specifies the number of particles per cell to use for the initial particle loading. At a later stage this may be extended to allow \u0026ldquo;npart_per_cell\u0026rdquo; to be a spatially varying function.  If per-species weighting is used then the value of \u0026ldquo;npart_per_cell\u0026rdquo; will be the average number of particles per cell. If \u0026ldquo;npart\u0026rdquo; or \u0026ldquo;frac\u0026rdquo; have also been specified for a species, then they will be ignored.\nTo avoid confusion, there is no globally used \u0026ldquo;npart_per_species\u0026rdquo;. If you want to have a single value to change in the input deck then this can be achieved using a constant block.\n dumpmask - Determines which output dumps will include this particle species. The dumpmask has the same semantics as those used by variables in the output block. The actual dumpmask from the output block is applied first and then this one is applied afterwards. For example, if the species block contains \u0026ldquo;dumpmask = full\u0026rdquo; and the output block contains \u0026ldquo;vx = always\u0026rdquo; then the particle velocity will be only be dumped at full dumps for this particle species. The default dumpmask is \u0026ldquo;always\u0026rdquo;. dump - This logical flag is provided for backwards compatibility. If set to \u0026ldquo;F\u0026rdquo; it has the same meaning as \u0026ldquo;dumpmask = never\u0026rdquo;. If set to \u0026ldquo;T\u0026rdquo; it has the same meaning as \u0026ldquo;dumpmask = always\u0026rdquo;. zero_current - Logical flag switching the particle species into zero-current particles. Zero-current particles are enabled if the if the \u0026ldquo;NO_TRACER_PARTICLES\u0026rdquo; precompiler option has not been used and the \u0026ldquo;zero_current\u0026rdquo; flag is set to true for a given species. When set, the species will move correctly for its charge and mass, but contribute no current. This means that these particles are passive elements in the simulation. In all other respects they are designed to behave identically to ordinary particles, so they do take part in collisions by default. This can be prevented using the collision matrices. WARNING: Since the particles effectively have zero weight in terms of their numerical heating properties, they do not always behave in the same way that an ordinary particle with weight would behave and this can sometimes lead to unexpected behaviour. If the purpose is merely to track a subset of a particle species to use as output then a better mechanism to use is \u0026ldquo;persistent subsets\u0026rdquo; (see here). \u0026ldquo;tracer\u0026rdquo; is currently accepted as an alias but this will be removed in version 5.0. \u0026ldquo;zero_current = F\u0026rdquo; is the default value. identify - Used to identify the type of particle. Currently this is used primarily by the QED routines. See here for details. immobile - Logical flag. If this parameter is set to \u0026ldquo;T\u0026rdquo; then the species will be ignored during the particle push. The default value is \u0026ldquo;F\u0026rdquo;. background_species - Logical flag. If set to \u0026ldquo;T\u0026rdquo; the species will be treated as a non evolving continuum background. No particles are loaded. Any particle-like specifications will be ignored. Background species are currently only used by the bremsstrahlung radiation model. See here for details. Default value is \u0026ldquo;F\u0026rdquo;. \u0026ldquo;background\u0026rdquo; is accepted as an alias.  The species blocks are also used for specifying initial conditions for the particle species. The initial conditions in EPOCH can be specified in various ways, but the easiest way is to specify the initial conditions in the input deck file. This allows any initial condition which can be specified everywhere in space by a number density and a drifting Maxwellian distribution function. These are built up using the normal maths expressions, by setting the density and temperature for each species which is then used by the autoloader to actually position the particles.\nThe elements of the species block used for setting initial conditions are:\n number_density - Particle number density in $m^{-3}$. As soon as a number_density= line has been read, the values are calculated for the whole domain and are available for reuse on the right hand side of an expression. This is seen in the above example in the first two lines for the Electron species, where the number density is first set and then corrected. If you wish to specify the number density in parts per cubic metre then you can divide by the \u0026ldquo;cc\u0026rdquo; constant (see here). This parameter is mandatory. \u0026ldquo;density\u0026rdquo; is accepted as an alias. number_density_min - Minimum particle number density in $m^{-3}$. When the number density in a cell falls below number_density_min the autoloader does not load any pseudoparticles into that cell to minimise the number of low weight, unimportant particles. If set to 0 then all cells are loaded with particles. This is the default. \u0026ldquo;density_min\u0026rdquo; is accepted as an alias. number_density_max - Maximum particle number density in $m^{-3}$. When the number density in a cell rises above number_density_max the autoloader clips the number_density to number_density_max allowing easy implementation of exponential rises to plateaus. If it is a negative value then no clipping is performed. This is the default. \u0026ldquo;density_max\u0026rdquo; is accepted as an alias. mass_density - Particle mass density in $kg,m^{-3}$. The same as \u0026ldquo;number_density\u0026rdquo; but multiplied by the particle mass. If you wish to use units of $g,cm^{-3}$ then append the appropriate multiplication factor. For example: \u0026ldquo;mass_density = 2 * 1e3 / cc\u0026rdquo;. temp_{x,y,z} - The temperature in each direction for a thermal distribution in Kelvin. temp - Sets an isotropic temperature distribution in Kelvin. If both temp and a specific temp_x, temp_y, temp_z parameter is specified then the last to appear in the deck has precedence. If neither are given then the species will have a default temperature of zero Kelvin. temp_{x,y,z}_ev, temp_ev - These are the same as the temperature parameters described above except the units are given in electronvolts rather than Kelvin, i.e. using 1ev = 11604.5K . drift_{x,y,z} - Specifies a momentum space offset in $kg\\ ms^{-1}$ to the distribution function for this species. By default, the drift is zero. offset - File offset. See below for details.  Loading data from a file It is also possible to set initial conditions for a particle species using an external file. Instead of specifying the initial conditions mathematically in the input deck, you specify in quotation marks the filename of a simple binary file containing the information required. For more information on what is meant by a \u0026ldquo;simple binary file\u0026rdquo;, see here.\nbegin:species name = Electron number_density = 'Data/ic.dat' offset = 80000 temp_x = 'Data/ic.dat' end:species  The sizes of the variables to be filled do not need to be provided: the code will continue reading until the given variable is filled. Note that ghost or guard cells should not be included in the file as they cannot be set this way.\nAn additional element is also introduced, the offset element. This is the offset in bytes from the start of the file to where the data should be read from. As a given line in the block executes, the file is opened, the file handle is moved to the point specified by the offset parameter, the data is read and the file is then closed. Therefore, unless the offset value is changed between data reading lines the same data will be read into all the variables. The data is read in as soon as a line is executed, and so it is perfectly possible to load data from a file and then modify the data using a mathematical expression. The example block above is for 10,000 values at double precision, i.e. 8-bytes each. The density data is the first 80,000 bytes of \u0026ldquo;ic.dat\u0026rdquo;. Bytes 80,000 to 160,000 are the temp_x data.\nThe file should be a simple binary file consisting of floating point numbers of the same precision as _num in the core EPOCH code. For multidimensional arrays, the data is assumed to be written according to FORTRAN array ordering rules (i.e. column-major order). NOTE: The files that are expected by this block are SIMPLE BINARY files, NOT FORTRAN unformatted files. It is possible to read FORTRAN unformatted files using the offset element, but care must be taken!\nDelta-f parameters The following entries are used for configuring the Delta-f method\n number_density_back drift_{x,y,z}_back temp_{x,y,z}_back temp_{x,y,z}_back_ev temp_back temp_back_ev  These all have the same meanings as the parameters listed above that don\u0026rsquo;t include the \u0026ldquo;_back\u0026rdquo; text, except that they specify the values to use for the background distribution function.\nParticle migration between species It is sometimes useful to separate particle species into separate energy bands and to migrate particles between species when they become more or less energetic. A method to achieve this functionality has been implemented. It is specified using two parameters to the \u0026ldquo;control\u0026rdquo; block:\n use_migration - Logical flag which determines whether or not to use particle migration. The default is \u0026ldquo;F\u0026rdquo;. migration_interval - The number of timesteps between each migration event. The default is 1 (migrate at every timestep). The following parameters are added to the \u0026ldquo;species\u0026rdquo; block: migrate - Logical flag which determines whether or not to consider this species for migration. The default is \u0026ldquo;F\u0026rdquo;. promote_to - The name of the species to promote particles to. demote_to - The name of the species to demote particles to. promote_multiplier - The particle is promoted when its energy is greater than \u0026ldquo;promote_multiplier\u0026rdquo; times the local average. The default value is 1. demote_multiplier - The particle is demoted when its energy is less than \u0026ldquo;demote_multiplier\u0026rdquo; times the local average. The default value is 1. promote_number_density - The particle is only considered for promotion when the local number density is less than \u0026ldquo;promote_number_density\u0026rdquo;. The default value is the largest floating point number. demote_number_density - The particle is only considered for demotion when the local number density is greater than \u0026ldquo;demote_number_density\u0026rdquo;. The default value is 0.  Ionisation EPOCH now includes both field and collisional ionisation, which can be activated by switching on keys in different blocks. Previous versions of EPOCH forced the user to specify ionisation energies for each ion charge state, but since EPOCH 4.19, these are set automatically using look-up tables.\nField and collisional ionisation must be switched on in the control block and collision block respectively, and species which are to be ionised must be specified in their species block. A basic example of using both ionisation mechanisms is given below, where non-relevant lines have been omitted.\nbegin:control use_multi_photon = T use_bsi = F field_ionisation = T end:control begin:collisions use_collisional_ionisation = T ci_n_step = 3 end:collisions begin:species name = Carbon charge = 0 atomic_no = 6 ionise = T ionise_limit = 3 unique_electron_species = T end:species begin:species name = Carbon4 charge = 4 atomic_no = 6 ionise = T ionisation_electron_species = (Electron4, Electron) end:species  A full summary of the keys used in ionisation has been provided below:\n  field_ionisation - Switches on field ionisation.\n  use_collisional_ionisation - Switches on ionisation by collisional electron impact.\n  ci_n_step - Only performs the collisional ionisation calculation once every n steps, where n is set by this parameter. This is done to speed up the code, and the default is 1 (every step). When this is greater than 1, the assumed time-step for the collisional ionisation calculation is n*dt. Note that an ion may only be ionised once per calculation, so if n is too high, the number of ions will be underestimated.\n  atomic_no - Atomic number of the element. When combined with the charge, the code can deduce the element and charge-state of the ion, and may use the appropriate ionisation energy and shell binding energies.\n  ionise - Allows ionisation of this species, and generates additional particle species for each ion charge state.\n  ionise_limit - This limits the number of additional particle species to be generated. In this example, ion macro-particles in the Carbon species can only be ionised 3 times - ionisation of Carbon3 will not be considered.\n  ionisation_electron_species - Name of the electron species to populate with ejected electrons. This can be specified as an array in the event that the user wishes some levels to have a different electron species which can be handy for monitoring ionisation at specific levels. electron and electron_species are accepted as synonyms. Either one species for all ionisation levels, or one species for each level should be specified. In the Carbon4 example, the user may have written ionisation_electron_species = Electron to use the Electron species for all ejected electrons.\n  unique_electron_species - If \u0026ldquo;T\u0026rdquo;, this generates a unique electron species to populate with ejected electrons from each ion charge state. The user must use this, or ionisation_electron_species.\n  Ionised states are created automatically and are named according to the ionising species name with a number appended. For example, with the Carbon species block, the species named \u0026ldquo;Carbon1\u0026rdquo;, \u0026ldquo;Carbon2\u0026rdquo; and \u0026ldquo;Carbon3\u0026rdquo; are automatically created. Note that for pre-ionised species like the Carbon4 block, species would be named \u0026ldquo;Carbon41\u0026rdquo;, \u0026ldquo;Carbon42\u0026rdquo;. These species will also inherit the ``dump'' parameter from their parent species. This behaviour can be overridden by explicitly adding a species block of the same name with a differing dumpmask.\nField ionisation consists of three distinct regimes; multiphoton in which ionisation is best described as absorption of multiple photons, tunnelling in which deformation of the atomic Coulomb potential is the dominant factor, and barrier suppression ionisation in which the electric field is strong enough for an electron to escape classically. It is possible to turn off multiphoton or barrier suppression ionisation through the input deck using the following control block parameters:\n  use_multiphoton - Logical flag which turns on modelling ionisation by multiple photon absorption. This should be set to \u0026ldquo;F\u0026rdquo; if there is no laser attached to a boundary as it relies on laser frequency. The default is \u0026ldquo;T\u0026rdquo;.\n  use_bsi - Logical flag which turns on barrier suppression ionisation correction to the tunnelling ionisation model for high intensity lasers. The default is \u0026ldquo;T\u0026rdquo;.\n  Species Boundary Conditions  bc_x_min - Boundary condition to be applied to this species only on the lower x boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_x_max - Boundary condition to be applied to this species only on the upper x boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_y_min - Boundary condition to be applied to this species only on the lower y boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_y_max - Boundary condition to be applied to this species only on the upper y boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_z_min - Boundary condition to be applied to this species only on the lower z boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. bc_z_max - Boundary condition to be applied to this species only on the upper z boundary. Can be any normal boundary condition apart from periodic. If not specified then the global boundary condition is applied. meet_injectors - Logical flag determining whether the background plasma should be extended to meet the point where particle injectors operate from. This means that plasma is loaded one particle shape function length outside the boundary. This means that it is possible to use an injector to \u0026ldquo;continue\u0026rdquo; an existing drifting plasma. NOT COMPATIBLE WITH PERIODIC BOUNDARY CONDITIONS!  Maxwell Juttner distributions As of version 4.15, EPOCH allows the user to request a Maxwell-Jüttner distribution rather than a Maxwellian distribution when sampling the particle momentum for a species.\nThis feature does not at present work with the delta_f loader and is not available for particle injectors. It does work correctly with the moving window.\n  use_maxwell_juttner - Logical flag determining whether to sample from the Maxwell-Jüttner distribution when loading the particle species. If \u0026ldquo;T\u0026rdquo; then Maxwell-Jüttner is used and if \u0026ldquo;F\u0026rdquo; Maxwellian is used. The default value is \u0026ldquo;F\u0026rdquo;.\n  fractional_tail_cutoff - The sampling is carried out using a rejection method with an arbitrary cut-off. This parameter takes a floating-point argument which specifies the fraction of maximum value at which the sampling should be cut off. Smaller values lead to distortion nearer the peak of the distribution but are faster to sample. Larger values lead to a better approximation of the distribution function but are slower to sample. The default value is 0.0001.\n  If drifts are specified with the Maxwell-Jüttner distribution then the distribution is calculated in the rest frame and then Lorentz transformed to the specified drifting frame.\nArbitrary Distribution functions As of version 4.15, EPOCH also allows the user to request an arbitrary non-Maxwellian distribution function to use when sampling the particle momentum for a species. If combined with a specified drift then the distribution function is calculated first and the drift is applied to the resulting particles by Lorentz transform.\nThis feature does not at present work with the delta_f loader and is not available for particle injectors. It does work correctly with the moving window.\n dist_fn - Specifies the functional form of the distribution function, normalised to have a maximum value of 1. The variables \u0026ldquo;px\u0026rdquo;, \u0026ldquo;py\u0026rdquo; and \u0026ldquo;pz\u0026rdquo; should be used to parameterise the x, y and z components of momentum. This may freely vary in space but temporal variation will be ignored since this is only evaluated at the start of the simulation.   dist_fn_p{x,y,z}_range - Comma separated pair of numbers to specify the range of momentum for p_{x,y,z} in SI units. Should be of the form \u0026ldquo;\u0026lt;lower_range\u0026gt;, \u0026lt;upper_range\u0026gt;\u0026rdquo;  If a range for a momentum direction is not specified then that momentum is assumed to be zero. It is up to the user to ensure that the range is large enough to correctly capture their desired distribution function. Sampling is by a simple rejection sampling and may be much slower than the existing Maxwellian sampler. EPOCH will print a warning if a large number of samples are needed to complete the sampling. If this occurs then you might need to reduce the range of momentum over which sampling is considered.\nIf the \u0026ldquo;dist_fn\u0026rdquo; key is supplied then any supplied temperature keys are ignored. An example of setting up a truncated power law distribution in px would be\nbegin:constant dens = 10 v0 = 0.05 * c vmax = 0.5 * c p0 = v0 * me * (1.0 + 4.0 * x/x_max) pmax = vmax * me alpha = -2.0 end:constant begin:species name = Electron_pl charge = -1 mass = 1.0 frac = 0.5 number_density = dens #Truncated power law distribution in px dist_fn = exp(-p0/px) * (px/p0)^(alpha) dist_fn_px_range = (0, pmax) end:species  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673352059,"objectID":"cd349d1eac12f442231265345663d23c","permalink":"/documentation/input_deck/input_deck_species.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_species.html","section":"documentation","summary":"This block contains information about the species of particles which are used in the code. Also details of how these are initialised. See EPOCH input deck for more information on the input deck.","tags":null,"title":"species block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about laser boundary sources. See EPOCH input deck for more information on the input deck.\nLaser blocks attach an EM wave source to a boundary which is set as simple_laser.\nbegin:laser boundary = x_min id = 1 intensity_w_cm2 = 1.0e15 lambda = 1.06 * micron pol_angle = 0.0 phase = 0.0 t_profile = gauss(time, 40.0e-15, 40.0e-15) t_start = 0.0 t_end = 80.0e-15 end:laser  As already mentioned in the discussion of laser boundaries in the boundaries block, lasers are attached to compatible boundaries here in the initial conditions deck.\n boundary - The boundary on which to attach the laser. In 1D, the directions can be either x_min or x_max. \u0026ldquo;left\u0026rdquo; and \u0026ldquo;right\u0026rdquo; are accepted as a synonyms. In 2D, y_min and y_max may also be specified. These have synonyms of \u0026ldquo;down\u0026rdquo; and \u0026ldquo;up\u0026rdquo;. Finally, 3D adds z_min and z_max with synonyms of \u0026ldquo;back\u0026rdquo; and \u0026ldquo;front\u0026rdquo;. amp - The amplitude of the $E$ field of the laser in $V/m$. intensity - The intensity of the laser in $W/m^2$. There is no need to specify both intensity and amp and the last specified in the block is the value used. It is mandatory to specify at least one. The amplitude of the laser is calculated from intensity using the formula amp = sqrt(2*intensity/c/epsilon0). \u0026ldquo;irradiance\u0026rdquo; is accepted as a synonym. intensity_w_cm2 - This is identical to the intensity parameter described above, except that the units are specified in $W/cm^2$. id - An id code for the laser. Used if you specify the laser time profile in the EPOCH source rather than in the input deck. Does not have to be unique, but all lasers with the same id will have the same time profile. This parameter is optional and is not used under normal conditions. omega - Angular frequency (rad/s not Hz) for the laser. frequency - Ordinary frequency (Hz not rad/s) for the laser. lambda - Wavelength in a vacuum for the laser specified in $m$. If you want to specify in $\\mu m$ then you can multiply by the constant \u0026ldquo;micron\u0026rdquo;. One of lambda or omega (or frequency) is a required parameter. pol_angle - Polarisation angle for the electric field of the laser in radians. This parameter is optional and has a value of zero by default. The angle is measured with respect to the right-hand triad of propagation direction, electric and magnetic fields. Although the 1D code has no $y$ or $z$ spatial axis, the fields still have $y$ and $z$ components. If the laser is on x_min then the default $E$ field is in the $y$-direction and the $B$ field is the $z$-direction. The polarisation angle is measured clockwise about the $x$-axis with zero along the $E_y$ direction. If the laser is on x_max then the angle is anti-clockwise. **Similarly, for propagation directions: **y_min - angle about $y$-axis, zero along $z$-axis **z_min - angle about $z$-axis, zero along $x$-axis **y_max - angle anti-clockwise about $y$-axis, zero along $z$-axis **z_max - angle anti-clockwise about $z$-axis, zero along $x$-axis pol - This is identical to pol_angle with the angle specified in degrees rather than radians. If both are specified then the last one is used. phase - The phase profile of the laser wavefront given in radians. Phase may be a function of both space and time. The laser is driven using ${\\rm{sin}}(\\omega t + \\phi)$ and phase is the $\\phi$ parameter. There is zero phase shift applied by default. profile - The spatial profile of the laser. This should be a spatial function not including any values in the direction normal to the boundary on which the laser is attached, and the expression will be evaluated at the boundary. It may also be time-dependant. The laser field is multiplied by the profile to give its final amplitude so the intention is to use a value between zero and one. By default it is a unit constant and therefore has no affect on the laser amplitude. This parameter is redundant in 1D and is only included for consistency with 2D and 3D versions of the code. t_profile - Used to specify the time profile for the laser amplitude. Like profile the laser field is multiplied by this parameter but it is only a function of time and not space. In a similar manner to profile, it is best to use a value between zero and one. Setting values greater than one is possible but will cause the maximum laser intensity to grow beyond amp. In previous versions of EPOCH, the profile parameter was only a function of space and this parameter was used to impose time-dependance. Since profile can now vary in time, t_profile is no longer needed but it has been kept to facilitate backwards compatibility. It can also make input decks clearer if the time dependance is given separately. The default value of t_profile is just the real constant value of 1.0. t_start - Start time for the laser in seconds. Can be set to the string \u0026ldquo;start\u0026rdquo; to start at the beginning of the simulation. This is the default value. When using this parameter, the laser start is hard. To get a soft start use the t_profile parameter to ramp the laser up to full strength. t_end - End time for the laser in seconds, can be set to the string \u0026ldquo;end\u0026rdquo; to end at the end of the simulation. This is the default value. When using this parameter, the laser end is clipped straight to zero at $t \u0026gt; t_end$. To get a soft end use the t_profile parameter to ramp the laser down to zero. If you add multiple laser blocks to the initial conditions file then the multiple lasers will be additively combined on the boundary.  In theory, any laser time profile required is possible, but the core FDTD solver for the EM fields in EPOCH produces spurious results if sudden changes in the field intensity occur. This is shown below. The pulse shown on the left used a constant t_profile and used t_end to stop the laser after 8fs. Since the stopping time was not an exact multiple of the period, the result was to introduce spurious oscillations behind the pulse. If the laser had a finite phase shift so that the amplitude did not start at zero, a similar effect would be observed on the front of the pulse.\nThe second figure instead used a Gaussian window function with a characteristic width of 8fs as well as using t_end to introduce a hard cutoff. It can clearly be seen that there are no spurious oscillations and the wave packet propagates correctly, showing only some dispersive features.\nThere is no hard and fast rule as to how rapid the rise or fall for a laser can be, and the best advice is to simply test the problem and see whether any problems occur. If they do then there are various solutions. Essentially, the timestep must be reduced to the point where the sharp change in amplitude can be accommodated. The best solution for this is to increase the spatial resolution (with a comparable increase in the number of pseudoparticles), thus causing the timestep to drop via the CFL condition.\nThis is computationally expensive, and so a cheaper option is simply to decrease the input.deck option dt_multiplier. This artificially decreases the timestep below the timestep calculated from the internal stability criteria and allows the resolution of sharp temporal gradients. This is an inferior solution since the FDTD scheme has increased error as the timestep is reduced from that for EM waves. EPOCH includes a high order field solver to attempt to reduce this.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"befe9ca9e484ba712671f4c88b18fad3","permalink":"/documentation/input_deck/input_deck_laser.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_laser.html","section":"documentation","summary":"This block contains information about laser boundary sources. See EPOCH input deck for more information on the input deck.\nLaser blocks attach an EM wave source to a boundary which is set as simple_laser.","tags":null,"title":"laser block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the EM fields specified at the start of the simulation. See EPOCH input deck for more information on the input deck.\nThis block allows you to specify the electric and magnetic fields at any point in the domain. An example block is shown below:\nbegin:fields ex = sin(pi * x / length_x) ey = cos(pi * x / length_x) ez = 0 bx = 1.0 by = -1.0 bz = 0 end:fields  Once again, this is a very simple block needing only limited explanation. All field variables are accessible by name and can be read back using the appropriate commands from the maths parser (see here). The possible parameters are as follows:\n ex,ey,ez - The electric field vectors pointing in all three directions. The default value is zero. bx,by,bz - The magnetic field vectors pointing in all three directions. The default value is zero. offset - File offset. The field values may also be specified using a binary file in a similar way to that used for species variables. See the species block for more details. Any valid maths parser expression can be used to set up the fields, and no check is made to ensure that the $\\nabla.B = 0$ is satisfied.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"948cdf82cd0afd1c327065f74f60337d","permalink":"/documentation/input_deck/input_deck_fields.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_fields.html","section":"documentation","summary":"This block contains information about the EM fields specified at the start of the simulation. See EPOCH input deck for more information on the input deck.\nThis block allows you to specify the electric and magnetic fields at any point in the domain.","tags":null,"title":"fields block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the moving window if the code is used in that fashion. See EPOCH input deck for more information on the input deck.\nEPOCH can include an optional block which causes the simulation domain to operate as a moving window. At present, it is only possible to have the window moving at a speed parallel to the x direction, although the window does not have to start moving at t = 0. When the window moves, the code removes particles from the left hand edge of the domain and introduces new particles at the right hand edge. The new particles are placed by re-evaluating the species density, temperature and drift using the new time and spatial coordinates. The block looks like:\nbegin:window move_window = T window_v_x = 3.0e8 window_start_time = 7.0e-13 bc_x_min_after_move = simple_outflow bc_x_max_after_move = simple_outflow end:window   move_window - Logical flag determining whether or not to move the window. If the window block is absent then this is the same as setting move_window to \u0026ldquo;F\u0026rdquo;. window_v_x - The speed in m/s of the window. window_start_time - The time in seconds at which the window should start moving. window_stop_time - The time in seconds at which the window should stop moving. bc_x_min_after_move - The boundary condition which should apply to the left boundary after the window has started moving. This is to allow the swapping of a laser boundary to a simple outflow boundary. Boundary codes are the same as when just specifying normal boundaries. If a boundary value isn\u0026rsquo;t specified then it is assumed that the boundary isn\u0026rsquo;t changed when the window starts moving. \u0026ldquo;xbc_left_after_move\u0026rdquo; is accepted as a synonym. bc_x_max_after_move - The boundary condition which should apply to the right boundary after the window has started moving. \u0026ldquo;xbc_right_after_move\u0026rdquo; is accepted as a synonym. bc_{y,z}_{min,max}_after_move - \u0026ldquo;y\u0026rdquo; and \u0026ldquo;z\u0026rdquo; versions of the previous two parameters. ybc_down_after_move, ybc_up_after_move, zbc_back_after_move and zbc_front_after_move are accepted as synonyms.  Compatibility Because of how the moving window must work, there are some compatibility issues with certain features. In particular:\n lasers attached to an X boundary which remain in place after the window moves, or attached to Y or Z boundaries:  The laser will behave as though it is attached to the window itself: for Y or Z boundaries with spatial variations this may not give the expected result For X boundaries, the moving emitter will result in a form of numerical Doppler shifting. In addition to this the boundary used to drive the field will shift discontinuously, yielding noisy and erratic changes in the electromagnetic field.   Injectors attached to an X boundary will not work. Those on a Y or Z boundary may appear to work, but the rates will be incorrect. CPML boundary conditions:  in X these cannot work as they rely on time-history which is simply missing. On Y or Z boundaries they will approximately work, but the history will be truncated and so they will generally require more tuning. We can\u0026rsquo;t help with this in general.   Load of particles from file is not supported since it can\u0026rsquo;t be made to work in general.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624406887,"objectID":"6194dda40deb5e969b4a4b0d2aa0c379","permalink":"/documentation/input_deck/input_deck_window.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_window.html","section":"documentation","summary":"This block contains information about the moving window if the code is used in that fashion. See EPOCH input deck for more information on the input deck.\nEPOCH can include an optional block which causes the simulation domain to operate as a moving window.","tags":null,"title":"window block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about when and how to dump output files. See EPOCH input deck for more information on the input deck.\nBasics Output in EPOCH is handled using the custom designed SDF file format (Self Describing Format). A detailed specification of this format is available elsewhere, although this is only of interest to developers wishing to write new libraries. EPOCH comes with readers for ITT IDL, LLNL VisIt, Mathworks MatLab and Python. The IDL reader is also compatible with the open source GDL tool.\nThere are two styles of output block supported by EPOCH. The first style, which will be referred to as the \u0026ldquo;traditional\u0026rdquo; style, is the method that has been supported by EPOCH since its inception. With this method, a single output block governs all the output dumps which are to be performed. There are a few levels of output which give some small amount of flexibility over what gets dumped but these do not allow for a very fine-grained control.\nIn version 4.0 of EPOCH, a new style was introduced in which multiple named output blocks may be specified allowing for much greater flexibility. The existence of a \u0026ldquo;name\u0026rdquo; parameter is what determines that an output block is the new style rather than the traditional style.\nMost of the parameters are shared by both styles. The following sections document the traditional style of output block and any differences between the two styles are described below .\nWhat the code should output and when it should output it is specified in the \u0026ldquo;output\u0026rdquo; block of the input deck. An example output block is shown below:\nbegin:output # If use_offset_grid is true then the code dumps a grid which # displays positions relative to the left hand edge of the window use_offset_grid = F # number of timesteps between output dumps dt_snapshot = 1.0e-14 # Number of dt_snapshot between full dumps full_dump_every = 10 restart_dump_every = -1 force_final_to_be_restartable = T # Properties at particle positions particles = never px = never py = never pz = never vx = never vy = never vz = never charge = never mass = never particle_weight = never # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always jy = always ekbar = always + species mass_density = never + species charge_density = always number_density = always + species temperature = always + species distribution_functions = always particle_probes = never end:output  There are three types of output dump in EPOCH which are used for different purposes. These types are:\n normal - The most frequent type of output dump in EPOCH is a normal dump. full - A full dump is usually written every 10 or so normal dumps. A full dump contains all the data that a normal dump contains and should also contain any information which is needed only infrequently, whether this is the full particle information or a large distribution function. It is possible to turn off full dumps completely. restart - A restart dump is a dump where the code guarantees to write enough data to allow the code to restart from the output. Output dumps are guaranteed to contain all the information in a normal dump and, if they coincide with the timing for a full dump, will also contain the full dump information.  Information will never be written into a file twice, even if two conditions for it being written are satisfied (i.e even if px should be dumped both because it is a full dump and a restart dump, px will only be written once).\nNote that these dump levels only really make sense for the traditional style of output block and are not really required when the new style is used.\nDumpmask When specifying which type of output dump to write a variable to there are eight options which can be specified for each variable and can be combined by addition. Some combinations make no sense but are formally valid. The first four options specify at which output types the variable is to be dumped:\n never - If the variable is not a required restart variable then it will never be written. If it is a required restart variable then it will be written only at restart dumps. full - This variable will be written at full dumps only. always - This variable will be written at full, normal and restart dumps. restart - This variable will be written at restart dumps only. Note that variables required for restarting the code are always written to restart dumps. This flag is to enable the writing of additional variables into such dump files. For grid variables derived from summing over particles (ie. \u0026ldquo;ekbar\u0026rdquo;, \u0026ldquo;mass_density\u0026rdquo;, \u0026ldquo;charge_density\u0026rdquo;, \u0026ldquo;number_density\u0026rdquo;, \u0026ldquo;temperature\u0026rdquo;) the following two parameters also apply. species - The derived variable should be output on a species by species basis. It is combined with a dumpmask code by addition as in: charge_density = always + species . no_sum - The output for this derived variable should not be summed over all species. By default, derived variables are summed over all species. If you don\u0026rsquo;t want to include this sum, you must use the \u0026ldquo;no_sum\u0026rdquo; flag. It is combined with a dumpmask code by addition as in: charge_density = always + species + no_sum . Most grid variables may be averaged over time. A more detailed description of this is given in #Data Averaging. Data averaging is specified using the following dumpmask parameters. average - The output for this variable should be averaged over time. The time span over which the variable will be averaged is controlled using flags described below. snapshot - By default, the \u0026ldquo;average\u0026rdquo; parameter replaces the variable with an averaged version of the data. Adding this flag specifies that the non-averaged variable should also be dumped to file. When applied to a variable, these codes are referred to as a dumpmask.  Directives The first set of options control the type and frequency of output dumps. They are used as follows\n disabled - Logical flag. If this is set to \u0026ldquo;T\u0026rdquo; then the block is ignored and never generates any output. The default value is \u0026ldquo;F\u0026rdquo;. dt_snapshot - Sets the interval between normal output dumps in simulation seconds. Setting zero or negative means that the code will not output based on this condition. The code does NOT guarantee that outputs will be exactly dt_snapshot apart, what is guaranteed is that the next output will be after the first iteration which takes the simulation to a time $\\ge$ dt_snapshot from the last output. As with other variables which specify a unit of time, it can be specified in more convenient unit by using a multiplication factor (see here). For example, \u0026ldquo;dt_snapshot = 5 * femto\u0026rdquo; will set it to be 5 femtoseconds. The default value is a large number which will never trigger an output. nstep_snapshot - Sets the number of timesteps between normal output dumps. Setting zero or negative means that the code will not output based on this condition. If dt_snapshot is also specified then both conditions are considered and output will be generated when either condition is met. The default value is a large integer which will never trigger an output. full_dump_every - The number of normal output dumps between full output dumps. Setting to zero makes every dump a full dump. Setting to a negative number stops the code from producing any full dumps. This is the default. restart_dump_every - The number of normal output dumps between restart dumps. Setting to zero makes every dump a restart dump. Setting to a negative number stops the code from producing any restart dumps. This is the default. force_first_to_be_restartable - Logical flag which determines whether the file written at time zero is a restart dump. The default value is \u0026ldquo;F\u0026rdquo;. force_last_to_be_restartable - Force the code to override other output settings and make the last output dump it writes be a restart dump. Any internal condition which causes the code to terminate will make the code write a restart dump, but code crashes or scheduler terminations will not cause the code to write a restart dump. \u0026ldquo;force_final_to_be_restartable\u0026rdquo; is accepted as a synonym. The default value is \u0026ldquo;T\u0026rdquo;. dump_first - Logical flag which determines whether to write an output file immediately after initialising the simulation. The default is \u0026ldquo;T\u0026rdquo;. dump_last - Logical flag which determines whether to write an output file just before ending the simulation. The default is \u0026ldquo;T\u0026rdquo; if an output block exists in the input deck and \u0026ldquo;F\u0026rdquo; otherwise. \u0026ldquo;dump_final\u0026rdquo; is accepted as a synonym. time_start - Floating point parameter which specifies the simulation time at which to start considering output for the block. Note that if \u0026ldquo;dump_first\u0026rdquo; or \u0026ldquo;dump_last\u0026rdquo; are set to true for this block then dumps will occur at the first or last timestep regardless of the value of the time_start parameter. This also applies to the three following parameters. The default value is 0. time_stop - Floating point parameter which specifies the simulation time at which to stop considering output for the block. The default value is the largest possible float. nstep_start - Integer parameter which specifies the step number at which to start considering output for the block. The default value is 0. nstep_stop - Integer parameter which specifies the step number at which to stop considering output for the block. The default value is the largest possible integer. walltime_start - Floating point parameter which specifies the elapsed walltime in seconds at which to start considering output for the block. Note that if dump_first or dump_last are set to true for this block then dumps will occur at the first or last timestep regardless of the value of the walltime_start parameter. The default value is 0. walltime_stop - Floating point parameter which specifies the elapsed walltime in seconds at which to stop considering output for the block. The default value is the largest possible float. dump_cycle - If this is set to a positive integer then the output file number will be reset to zero after the specified cycle number is reached. eg. if \u0026ldquo;dump_cycle = 2\u0026rdquo; then the sequence of output dumps will be 0000.sdf, 0001.sdf, 0002.sdf, 0000.sdf, 0001.sdf, etc. The default is 0, so dump cycling never occurs. dump_cycle_first_index - If this is set to a positive integer then the value is used as the first index to use when cycling output dumps due to the \u0026ldquo;dump_cycle\u0026rdquo; parameter. For example, if \u0026ldquo;dump_cycle = 2\u0026rdquo; and \u0026ldquo;dump_cycle_first_index = 1\u0026rdquo; then the sequence of output dumps will be 0000.sdf, 0001.sdf, 0002.sdf, 0001.sdf, 0002.sdf, 0001.sdf, etc. The default is 0. dump_source_code - EPOCH has the ability to write its own source code into restart dumps. This is generated at compile time and embedded into the binary and so is guaranteed to match that corresponding to the running code. EPOCH comes with a script called unpack_source_from_restart which can be used to unpack the source code from a restart dump. To use this script, just type unpack_source_from_restart \u0026lt;sdf_filename\u0026gt; at the command-line. If this logical flag is set to false then the feature will be disabled. The default value is \u0026ldquo;T\u0026rdquo;. dump_input_decks - If this logical flag is set to true then a copy of the input decks for the currently running simulation is written into the restart dumps. The default value is \u0026ldquo;T\u0026rdquo;. dt_average - When averaged variables are being output to file, this parameter specifies the simulation time period over which averaging is to occur. \u0026ldquo;averaging_period\u0026rdquo; is accepted as a synonym. nstep_average - When averaged variables are being output to file, this parameter specifies the number of time steps over which averaging is to occur. \u0026ldquo;min_cycles_per_average\u0026rdquo; is accepted as a synonym. If both dt_average and nstep_average are specified, the code will use the one which gives the longest simulation time-span. use_offset_grid - When using moving windows some visualisation programs (notably VisIt) show the motion of the window by moving the visualisation window rather than by changing the x-axis. Setting this option to \u0026ldquo;T\u0026rdquo; causes the code to write another grid which always gives the offset relative to the left hand edge of the window rather than the true origin. Performs no function when not using the moving window. The default value is \u0026ldquo;F\u0026rdquo;. filesystem - String parameter. Some filesystems can be unreliable when performing parallel I/O. Often this is fixable by prefixing the filename with \u0026lsquo;ufs\u0026rsquo; or \u0026lsquo;nfs\u0026rsquo;. This parameter supplies the prefix to be used. The default value is an empty string. file_prefix - Although this parameter is supported by the traditional style of output block, its primary purpose is for use with multiple output blocks so it is documented in . A few additional parameters have been added for use with the new style of output block. These are documented below.  Particle Variables The next set are per particle properties. If you wish to plot these according to their spatial positions, you must include the \u0026ldquo;particle_grid\u0026rdquo; in your output variables. All entries have a default dumpmask of \u0026ldquo;never\u0026rdquo;.\n particle_grid - Requests the output of particle positions. This is a restart variable. No particle variables can be plotted in VisIt unless this is dumped. If any particle variables are written then the \u0026ldquo;particle_grid\u0026rdquo; is automatically written unless \u0026ldquo;particle_grid = never\u0026rdquo; is specified. The synonym \u0026ldquo;particles\u0026rdquo; may also be used. px,py,pz - The dumpmasks for the particle momenta. Restart variable. vx,vy,vz - The dumpmasks for the particle velocities. charge - The dumpmask for the charge of a given particle. This has no effect if the code is not compiled with the flag \u0026ldquo;-DPER_PARTICLE_CHARGE_MASS\u0026rdquo; (see here ). mass - The dumpmask for the mass of a given particles. This has no effect if the code is not compiled with the flag \u0026ldquo;-DPER_PARTICLE_CHARGE_MASS\u0026rdquo; (see here). The synonym \u0026ldquo;rest_mass\u0026rdquo; may also be used. particle_weight - The dumpmask for the weighting function which describes how many real particles each pseudoparticle represents. Restart variable. The synonym \u0026ldquo;weight\u0026rdquo; may also be used. ejected_particles - If requested then all the particles which have left the simulation domain since the last output dump of this type are included in the output. The list of ejected particles is treated as if it were a separate species and the particle variables which get written are requested using the other particle variable flags (ie. \u0026ldquo;particle_grid\u0026rdquo;, etc). Once the data has been written, the ejected particle lists are reset and will accumulate particles until the next requested output dump. particle_energy - The dumpmask for per-particle kinetic energy. relativistic_mass - The dumpmask for per-particle relativistic mass (ie. not rest mass). gamma - The dumpmask for per-particle relativistic gamma (ie. $[1-(v/c)^2]^{-1/2}$). optical_depth - The dumpmask for per-particle optical depth. Restart variable. This option is only supplied for debugging purposes and should not be required by most users. trident_optical_depth - The dumpmask for per-particle optical depth used by the Trident model. Restart variable. This option is only supplied for debugging purposes and should not be required by most users. qed_energy - The dumpmask for per-particle QED-related particle energy. Restart variable. This option is only supplied for debugging purposes and should not be required by most users. work_{x,y,z} - The dumpmask for the work exerted by the fields on each particle during the last time step. The work is divided into its three spatial components. The output is in numbers of $mc^2$ corresponding to the particle\u0026rsquo;s $\\gamma$-factor. Requires compiler flag \u0026ldquo;WORK_DONE_INTEGRATED\u0026rdquo;. work_{x,y,z}_total - Same as above, but the work is integrated over the entire simulation duration. The sum of all three components equals the particle\u0026rsquo;s $\\gamma$-factor. Requires compiler flag \u0026ldquo;WORK_DONE_INTEGRATED\u0026rdquo;. id - Global particle ID. See below for details. Particle IDs are useful if you want to track the progress of each particle throughout the simulation. Since they increase the size of each particle data structure, they are disabled by default and must be enabled using a compiler flag. The \u0026ldquo;PARTICLE_ID\u0026rdquo; flag will use an 8-byte integer to represent the ID and \u0026ldquo;PARTICLE_ID4\u0026rdquo; uses a 4-byte integer. They are written to file using the \u0026ldquo;id\u0026rdquo; flag.  Note: In the current implementation, the particle IDs are passed between processors and written to file using REAL numbers. This means that in double precision the maximum particle ID is $2^{53} \\sim 10^{16}$. This should be ample for the foreseeable future. However, if the code is compiled for single precision then the maximum ID is $2^{24} = 16777216$. Probably not big enough.\nGrid Variables The next set of parameters specify properties which are defined on a regular cartesian mesh. All entries have a default dumpmask of \u0026ldquo;never\u0026rdquo;.\n grid - The dumpmask for the Cartesian grid which defines the locations of the grid variables. No grid variables can be plotted in VisIt unless this variable is output. If any grid variables are written then the \u0026ldquo;grid\u0026rdquo; is automatically written unless \u0026ldquo;grid = never\u0026rdquo; is specified. The synonym \u0026ldquo;field_grid\u0026rdquo; may also be used. ex,ey,ez - The electric field vectors pointing in all three directions. Restart variables. bx,by,bz - The magnetic field vectors pointing in all three directions. Restart variables. In 1D bx is a trivial variable because of the Solenoidal condition. It is included simply for symmetry with higher dimension codes. jx,jy,jz - The current densities pointing in all three directions. Restart variables. Can have species dumpmask.  Derived Variables The final set of parameters specify properties which are not variables used in the code but are derived from them. The first six variables are derived by summing properties of all the particles in each grid cell. The resulting quantities are defined on the regular cartesian mesh used for grid variables. All entries have a default dumpmask of \u0026ldquo;never\u0026rdquo;.\n ekbar - Mean kinetic energy on grid in $J$. Can have species dumpmask. ekflux - Mean kinetic energy flux in each direction on the grid in $W/m^2$. Can have species dumpmask. mass_density - Mass density on grid in $kg/m^3$. Can have species dumpmask. charge_density - Charge density on grid in $C/m^3$. Can have species dumpmask. number_density - Number density on grid in $m^{-3}$. Can have species dumpmask. particles per cell - Number of particles per cell. Can have species dumpmask. The synonym \u0026ldquo;ppc\u0026rdquo; may also be used. average weight - Average of weight of the particles in each cell. Can have species dumpmask. average_p{x,y,z} - Average momentum in each direction of the particles in each cell. Can have species dumpmask. temperature - Isotropic temperature on grid in $K$. Calculated from standard deviation of particle momenta, so in general matches mean kinetic energy only for isotropic plasma with no net drift. The synonym \u0026ldquo;temp\u0026rdquo; may also be used. Can have species dump mask. temperature_{x,y,z} - The temperature in each of the {x,y,z} directions, respectively, in $K$. The synonyms \u0026ldquo;temp_{x,y,z}\u0026rdquo; and \u0026ldquo;t{x,y,z}\u0026rdquo; may also be used. Can have species dumpmask. poynt_flux - Poynting flux in each direction in $W/m^2$.  Other Variables  distribution_functions - Dumpmask for outputting distribution functions specified in the input deck. Each individual distribution function can have its own dumpmask and these will be applied after the value of \u0026ldquo;distribution_functions\u0026rdquo; has been considered. For example, if the output block contains \u0026ldquo;distribution_functions = full\u0026rdquo; and the dist_fn block (see here) contains \u0026ldquo;dumpmask = always\u0026rdquo; then the distribution function will only be output at full dumps. particle_probes - Dumpmask for outputting particle probes specified in the input deck. Each individual particle probe can have its own dumpmask and these will be applied after the value of \u0026ldquo;particle_probes\u0026rdquo; has been considered. For example, if the output block contains \u0026ldquo;particle_probes = always\u0026rdquo; and the dist_fn block contains \u0026ldquo;dumpmask = full\u0026rdquo; then the particle probe will only be output at full dumps. absorption - This is a two-valued output variable. It accepts a dumpmask in the same manner as other output variables. When selected, two numbers will be calculated and written to file:   \u0026ldquo;Absorption/Laser_enTotal\u0026rdquo; - The total amount of energy injected into the simulation by laser boundaries. \u0026ldquo;Absorption/Abs_frac\u0026rdquo; - The fraction of the total laser energy being absorbed by the open boundaries.   total_energy_sum - This is also a two-valued output variable. It accepts a dumpmask in the same manner as other output variables. When selected, the following two numbers will be calculated and written to file:   \u0026ldquo;Total Particle Energy in Simulation (J)\u0026rdquo; \u0026ldquo;Total Field Energy in Simulation (J)\u0026rdquo;  Data Averaging EPOCH can accumulate an average value for field variables to be written to output dumps. These may be requested by using the \u0026ldquo;average\u0026rdquo; keyword when specifying a dump variable. The non-averaged variable will still be written to restart dumps where required for restarting the code but not full or normal dumps. If you also want the non-averaged variable to be written then you can add the \u0026ldquo;snapshot\u0026rdquo; option.\nThe period of time over which averaging occurs can be specified using the \u0026ldquo;dt_average\u0026rdquo; keyword. Alternatively, you may specify the number of cycles over which to perform the averaging using the \u0026ldquo;nstep_average\u0026rdquo; keyword. If both \u0026ldquo;dt_average\u0026rdquo; and \u0026ldquo;nstep_average\u0026rdquo; are specified then the averaging will be performed over the longest of the two intervals.\nNote that previous versions of the code would alter the time step to ensure that there were enough cycles between output dumps to satisfy the \u0026ldquo;nstep_average\u0026rdquo; parameter. However, since it affects the accuracy of the result, this is no longer the case and only a warning message is issued.\nThe following shows an example use of averaging in the output block.\nbegin:output dt_snapshot = 1.0e-15 full_dump_every = 10 dt_average = 1.0e-17 charge_density = always + average + snapshot mass_density = full + average + snapshot ekbar = full + average end:output  With this configuration, \u0026ldquo;charge_density\u0026rdquo; will be written in both normal and averaged form at normal, full and restart dumps. \u0026ldquo;mass_density\u0026rdquo; will be written in both forms at full dumps. Only the average value of \u0026ldquo;ekbar\u0026rdquo; will be written at full dumps.\nOnly field and derived variables can be averaged currently in EPOCH. Particle properties, distribution functions and particle probes cannot currently be averaged.\nSingle-precision output By default, EPOCH is compiled and run using double precision arithmetic. This is the only method which has been fully tested and the method that we recommend to other users of the code. However, this also means that data files can get very large.\nTo avoid this problem, it is possible to run the code in double precision but convert the data to single precision when writing to disk. This is done by adding the \u0026ldquo;single\u0026rdquo; field the the dumpmask of an output variable. It can be specified on a per-variable basis.\nbegin:output dt_snapshot = 8 * femto grid = always ex = always ey = always + single end:output  In this example, the grid variable \u0026ldquo;ex\u0026rdquo; will be written as a double precision array and \u0026ldquo;ey\u0026rdquo; will be converted to single precision.\nDumping variable averages adds an extra field variable for each average requested. These take up memory during runtime but do not influence the simulation behaviour in any way. For this reason, if the average is to be written out in single precision then it may as well be stored in a single precision variable. This behaviour can be requested using the \u0026ldquo;average_single\u0026rdquo; dumpmask flag.\nMultiple output blocks In more recent versions of EPOCH, it is now possible to have multiple \u0026ldquo;output\u0026rdquo; blocks in the input deck, each with their own \u0026ldquo;dt_snapshot\u0026rdquo; or \u0026ldquo;nstep_snapshot\u0026rdquo; and their own set of output variables.\nThe syntax remains the same as the original \u0026ldquo;output\u0026rdquo; block syntax with the addition of \u0026ldquo;name\u0026rdquo; and \u0026ldquo;restartable\u0026rdquo; fields.\nThe \u0026ldquo;name\u0026rdquo; field specifies the file name to use for the output list. Each time EPOCH generates an output dump, it writes an entry into the file \u0026ldquo;\u0026lt;name\u0026gt;.visit\u0026rdquo;. This can be used to find all the output dumps of a specific output block. It is named with a \u0026ldquo;.visit\u0026rdquo; suffix to enable its use as a file grouping list in the VisIt data analysis tool, but it is just a plain text file so it can equally be used by any other program.\nIf two output blocks are written at the same time, the output will be combined into a single file.\nThe \u0026ldquo;restartable\u0026rdquo; field specifies that the output block should generate output dumps containing all the information necessary to restart a simulation.\nThe following parameters are supported by the new style of output block in addition to those for the traditional style:\n name - Identifies the output block with a name which is required when multiple output blocks are used. restartable - Specifies whether or not the output for this block is a restartable dump. dump_at_times - Floating point parameter which specifies a set of simulation times at which to write the current output block. This can only be used with named output blocks. The values are given as a comma separated list. eg. \u0026ldquo;dump_at_times = 0, 0.15, 1.1\u0026rdquo;. The name \u0026ldquo;times_dump\u0026rdquo; is accepted as a synonym. By default the list is empty. dump_at_nsteps - Integer parameter which specifies a set of step numbers at which to write the current output block. This can only be used with named output blocks. The values are given as a comma separated list. eg. \u0026ldquo;dump_at_nsteps = 5, 11, 15\u0026rdquo;. The name \u0026ldquo;nsteps_dump\u0026rdquo; is accepted as a synonym. By default the list is empty. dump_at_walltimes - Floating point parameter which specifies a set of elapsed walltimes at which to write the current output block. This can only be used with named output blocks. The values are given as a comma separated list. eg. \u0026ldquo;dump_at_walltimes = 10, 100.1, 250.5\u0026rdquo;. These times are the total elapsed time in seconds since the start of the simulation. Note that if the simulation has been restarted then the total elapsed time will include the accumulated walltime of all previous runs that were used to produce the restart dump. The name walltimes_dump is accepted as a synonym. By default the list is empty. walltime_interval - Floating point parameter which specifies the interval between output dumps in elapsed walltime seconds. Setting zero or negative means that the code will not output based on this condition. The default value is -1.0. file_prefix - String parameter. It is sometimes useful to distinguish between dumps generated by the different output blocks. This parameter allows the user to supply a file prefix to be prepended to all dumps generated by the current output block. See below for further details. The default value is an empty string. rolling_restart - Logical flag. If set to \u0026ldquo;T\u0026rdquo;, this sets the parameters required for performing rolling restarts on the current block. It is a shorthand for setting the following flags: \u0026ldquo;dump_cycle = 1\u0026rdquo;, \u0026ldquo;restartable = T\u0026rdquo; and \u0026ldquo;file_prefix = roll\u0026rdquo;. With rolling restarts enabled the first file will be named \u0026ldquo;roll0000.sdf\u0026rdquo; and the second will be \u0026ldquo;roll0001.sdf\u0026rdquo;. The third dump will again be named \u0026ldquo;roll0000.sdf\u0026rdquo;, overwriting the first one. In this way, restart dumps can be generated throughout the duration of the simulation whilst limiting the amount of disk space used.  The following parameters cannot be used in conjunction with the new style of output block:\n full_dump_every restart_dump_every force_first_to_be_restartable force_last_to_be_restartable use_offset_grid  The \u0026ldquo;file_prefix\u0026rdquo; parameter warrants some further discussion. This parameter prepends the given prefix to all files generated by the output block in which it is specified. For example, if \u0026ldquo;file_prefix = aa\u0026rdquo; is set then files generated by the output block will be named \u0026ldquo;aa0000.sdf\u0026rdquo;, etc. instead of just \u0026ldquo;0000.sdf\u0026rdquo;.\nThis also allows different variables to different files at the same time step. For example, here are two output blocks which do not use file prefixes:\nbegin:output name = o1 nstep_snapshot = 1 charge_density = always end:output begin:output name = o2 dump_at_nsteps = 10 restartable = T end:output  With this input deck, we want to have the \u0026ldquo;charge_density\u0026rdquo; derived variable at every snapshot and then periodically write a restart dump. The problem is that the dump file \u0026ldquo;0010.sdf\u0026rdquo; contains both the restart information and the \u0026ldquo;charge_density\u0026rdquo; variable. At the end of the run we can\u0026rsquo;t just delete the large restart dumps without losing the smaller variables at that time step.\nWith the new version we would add a prefix to one or both blocks:\nbegin:output name = o1 file_prefix = small nstep_snapshot = 1 charge_density = always end:output begin:output name = o2 nstep_snapshot = 10 restartable = T end:output  Now the \u0026ldquo;charge_density\u0026rdquo; will be written to \u0026ldquo;small0000.sdf\u0026rdquo;, etc. At step 10, two files will be written: \u0026ldquo;small0010.sdf\u0026rdquo; containing just the charge_density and \u0026ldquo;0000.sdf\u0026rdquo; containing all the restart variables.\nNote that some care must be taken, since if the same variable is in the output block for multiple file prefixes then multiple copies will be written to file. This obviously uses more disk space and is more time consuming than necessary.\nIt should also be noted that if multiple output blocks use the same file stem then their output will be combined. eg:\nbegin:output name = o1 file_prefix = a dump_at_nsteps = 2,4 ex = always end:output begin:output name = o2 file_prefix = a dump_at_nsteps = 3,4 ey = always end:output begin:output name = o3 file_prefix = b dump_at_nsteps = 4 ez = always end:output  In this example, at step 2 a0000.sdf contains ex, step 3 a0001.sdf contains ey, step 4 a0002.sdf contains ex, ey and b0000.sdf contains ez.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"f0702d60960854ae14766d0f653d2d33","permalink":"/documentation/input_deck/input_deck_output_block.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_output_block.html","section":"documentation","summary":"This block contains information about when and how to dump output files. See EPOCH input deck for more information on the input deck.\nBasics Output in EPOCH is handled using the custom designed SDF file format (Self Describing Format).","tags":null,"title":"output block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains parameters which should be applied to all output blocks. See EPOCH input deck for more information on the input deck.\nWith the introduction of multiple output blocks, there are now a few parameters that only make sense to be applied globally across all output blocks. To accommodate this, a new block named \u0026ldquo;output_global\u0026rdquo; has been added. Most of the parameters accepted by this block have the same meaning as those in the \u0026ldquo;output\u0026rdquo; block except that they are applied to all \u0026ldquo;output\u0026rdquo; blocks.\nThe parameters that can be specified in the \u0026ldquo;output_global\u0026rdquo; block are as follows:\n force_first_to_be_restartable - Logical flag which determines whether the file written at time zero is a restart dump. The default value is \u0026ldquo;F\u0026rdquo;. force_last_to_be_restartable - Force the code to override other output settings and make the last output dump it writes be a restart dump. Any internal condition which causes the code to terminate will make the code write a restart dump, but code crashes or scheduler terminations will not cause the code to write a restart dump. \u0026ldquo;force_final_to_be_restartable\u0026rdquo; is accepted as a synonym. The default value is \u0026ldquo;T\u0026rdquo;. dump_first - Logical flag which determines whether to write an output file immediately after initialising the simulation. The default is \u0026ldquo;F\u0026rdquo;. dump_last - Logical flag which determines whether to write an output file just before ending the simulation. The default is \u0026ldquo;T\u0026rdquo; if an output block exists in the input deck and \u0026ldquo;F\u0026rdquo; otherwise. \u0026ldquo;dump_final\u0026rdquo; is accepted as a synonym. time_start - Floating point parameter which specifies the simulation time at which to start considering output for all output blocks. Note that if \u0026ldquo;dump_first\u0026rdquo; or \u0026ldquo;dump_last\u0026rdquo; are set to true for any block then dumps will occur at the first or last timestep regardless of the value of this parameter. This also applies to the three following parameters. The default value is 0. time_stop - Floating point parameter which specifies the simulation time at which to stop considering output for all output blocks. The default value is the largest possible float. nstep_start - Integer parameter which specifies the step number at which to start considering output for the block. The default value is 0. nstep_stop - Integer parameter which specifies the step number at which to stop considering output for the block. The default value is the largest possible integer. walltime_start - Floating point parameter which specifies the elapsed walltime in seconds at which to start considering output for all output blocks. Note that if dump_first or dump_last are set to true for any blocks then dumps will occur at the first or last timestep regardless of the value of the walltime_start parameter. The default value is 0. walltime_stop - Floating point parameter which specifies the elapsed walltime in seconds at which to stop considering output all output blocks. The default value is the largest possible float. sdf_buffer_size - Integer parameter. When writing particle data to an SDF file, the data is first transferred into an output buffer. The size of this buffer can have a big impact on the overall speed of writing dump files. This parameter allows the size of the buffer to be specified in bytes. The default value is 67108864 (64 MB). filesystem - String parameter. Some filesystems can be unreliable when performing parallel I/O. Often this is fixable by prefixing the filename with \u0026lsquo;ufs\u0026rsquo; or \u0026lsquo;nfs\u0026rsquo;. This parameter supplies the prefix to be used. The default value is an empty string. use_offset_grid - When using moving windows some visualisation programs (notably VisIt) show the motion of the window by moving the visualisation window rather than by changing the x-axis. Setting this option to \u0026ldquo;T\u0026rdquo; causes the code to write another grid which always gives the offset relative to the left hand edge of the window rather than the true origin. Performs no function when not using the moving window. The default value is \u0026ldquo;F\u0026rdquo;.  dump_first_after_restart - Logical flag to enable a dump to occur immediately after restart. In the past, a dump_first flag in the output block would cause an output dump immediately after restarting. Since this is rarely the desired behaviour, the flag is now ignored when restarting. To force a dump to occur immediately after restart, set dump_first_after_restart = T in the output block. The default value is \u0026ldquo;F\u0026rdquo;.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624406887,"objectID":"cc3c5e8742026f2825fdc30f4e757f53","permalink":"/documentation/input_deck/input_deck_output_global.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_output_global.html","section":"documentation","summary":"This block contains parameters which should be applied to all output blocks. See EPOCH input deck for more information on the input deck.\nWith the introduction of multiple output blocks, there are now a few parameters that only make sense to be applied globally across all output blocks.","tags":null,"title":"output_global block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about distribution functions that should be calculated for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to reconstruct part of the full phase space for one or more particle species. This functionality is provided through a dist_fn block. The distribution function is integrated over all dimensions which are not axes of the distribution function.\nCalculating distribution functions requires some degree of integration of data leading to various possible ways of normalising the resulting distribution function. In EPOCH, distribution functions are normalised so that the value at every point of the distribution function is the number of particles within that cell of the distribution function, ignoring all phase space directions which are not considered as an axis of the distribution function. Summing the distribution function should give the total number of real particles (as opposed to computational pseudoparticles) in the simulation.\nAn example dist_fn block is given below:\nbegin:dist_fn name = x_px ndims = 2 dumpmask = always direction1 = dir_x direction2 = dir_px # Range is ignored for spatial coordinates range1 = (1, 1) range2 = (-50.0e-20, 50.0e-20) # Resolution is ignored for spatial coordinates resolution1 = 1 resolution2 = 5000 restrict_py = (-3.0e-20, 3.0e-20) include_species:Electron include_species:Carbon end:dist_fn   name - The name of the distribution function when it is output. This name is appended with the name of each species for which the data is output and so, for example, when applied to a species named carbon the output is called x_px_Carbon. The Cartesian grid which describes the axes of the distribution function would then be called grid_x_px_Carbon. ndims - The number of dimensions in this phase space reconstruction. Due to difficulties in visualising data in more than three dimensions, this is restricted to being 1, 2 or 3. dumpmask - Determines which output dumps will include this distribution function. The dumpmask has the same semantics as those used by variables in the \u0026ldquo;output\u0026rdquo; block, described here. The dumpmask from \u0026ldquo;distribution_functions\u0026rdquo; in the output block is applied first and then this one is applied afterwards. For example, if the dist_fn block contains \u0026ldquo;dumpmask = full\u0026rdquo; and the output block contains \u0026ldquo;distribution_functions = always\u0026rdquo; then this distribution function will be only be dumped at full dumps. The default dumpmask is \u0026ldquo;always\u0026rdquo;. direction**n** - This is the phase space to sample along axis . This can be any one of: dir_x, dir_y, dir_z, dir_px, dir_py, dir_pz, dir_en, dir_gamma_m1, dir_xy_angle, dir_yz_angle, dir_zx_angle with spatial codes only being available in dimensionalities of the code which have that direction. Therefore dir_z does not exist in EPOCH1D or EPOCH2D and dir_y does not exist in EPOCH1D.  The flags \u0026ldquo;dir_xy_angle\u0026rdquo;, \u0026ldquo;dir_yz_angle\u0026rdquo; and \u0026ldquo;dir_zx_angle\u0026rdquo; calculate the distribution of particle momentum directions in the X-Y, Y-Z and Z-X planes.\n range**n** - The range between which this axis should run. This is in the form of (minimum, maximum). Any particle which exceeds the range is ignored. For momentum directions this parameter is specified in $kg\\ ms^{-1}$. If the range of a momentum direction is set so that the maximum and the minimum are equal then the code will automatically set the range to exactly span the range of particle momenta at the point of writing the dump. resolution**n** - The number of gridpoints in a given direction. This is ignored for spatial dimensions where the resolution is always the same as the resolution of the underlying simulation. include_species - Specifies a species which should be included in the output. This is useful since it is rare that momentum limits are appropriate for both electrons and ions, so usually for a given dist_fn block only electrons or ions are considered. It is possible to have two dist_fn blocks with the same name but different ranges and different include_species settings produce the effect of a single diagnostic for all species in the output file. output_deltaf - If set to \u0026ldquo;T\u0026rdquo;, the particle weights used in calculating the distribution function is adjusted by subtracting the Delta-f distribution function for the particle species. The default value is \u0026ldquo;F\u0026rdquo;. restrict_{x,y,z,px,py,pz} - Restrictions are specified in the same way as ranges, but have a subtly different behaviour. Ranges specify the range of a visible axis on the resulting distribution function, whereas restrictions allow you to specify minimum and maximum values for each spatial and momentum direction and use only particles which fall within this range when calculating the distribution function. Restrictions can be specified even for properties which are not being used as axes. It is possible to set a restriction that is more restrictive than the range applied. This is not trapped as an error and such parts of the distribution function are guaranteed to be empty. The available spatial restrictions depend on the dimensionality of the code. Therefore, attempting to set restrict_z in EPOCH1D will produce a warning. At present, the code to calculate the distribution functions has one limitation: it ignores particle shape functions when calculating properties on the spatial axis, meaning that the result is less smooth than normal properties from the code.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"79a34eda391ba8c8123f1f6a405c86a3","permalink":"/documentation/input_deck/input_deck_dist_fn.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_dist_fn.html","section":"documentation","summary":"This block contains information about distribution functions that should be calculated for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to reconstruct part of the full phase space for one or more particle species.","tags":null,"title":"dist_fn block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about particle probes used for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to consider all the properties of particle which pass through a point/line/plane (depending on dimension) in the simulation. To allow this, it is possible to specify one or more Particle Probe blocks in the input deck. These record copies of all particles which cross a point/line/plane in a given direction which meet minimum and maximum kinetic energy criteria and output the particle properties into the normal output files. Each output file only contains properties for particles which have passed the probe since the previous output, and not all particles which have passed the probe since the start of the simulation.\nParticle probes record the positions, momenta and weight of all particles passing through the plane. If the code is compiled with -DPARTICLE_ID or -DPARTICLE_ID4, the code also outputs the ID of passing particles. If the code is compiled with -DPROBE_TIME, the time at which the particle touches the probe surface is also output.\nTo use particle probes, the code must not have been compiled with the -DNO_PARTICLE_PROBES compiler option. This is a fairly heavyweight diagnostic since each particle position must be tested from within the particle push. The code will run faster if it is not compiled in.\nThe probe is specified in terms of a point in the plane and the normal vector to the plane which is to be monitored. Particles are only recorded if they cross the plane in the direction given by the normal vector. If you want to record particles travelling in both directions then use two particle probes, one with an opposite signed normal vector to the other.\nbegin:probe name = electron_back_probe point = (50.0e-6, -50.0e-6) normal = (1.0, 0.0) ek_min = 0.0 ek_max = -1.0 include_species : s1 dumpmask = always end:probe   name - The name that the probe should have in output dumps. Output variables are then named this as a prefix. For example, the block shown above will result in the name electron_back_probe_px for the x momentum. The particle positions would just be called electron_back_probe. point - An arbitrary point in the plane of the probe. normal - A vector normal to the plane of the probe, in the direction of crossings you wish to monitor. include_species - The species to which this probe should be applied. To probe several species, use several probe blocks in the input deck. \u0026ldquo;probe_species\u0026rdquo; is accepted as a synonym. ek_min - The minimum kinetic energy of particles to store information about. Set to 0 for no minimum kinetic energy. ek_max - The maximum kinetic energy of particles to store information about. Set to -1 for no maximum kinetic energy. dumpmask - The dump code for this particle probe. This is the same as that for the main output controls in input.deck. Note that the code has to store copies of particles which pass through the probe until a dump occurs. This means that the code\u0026rsquo;s memory requirements can increase drastically if this code only dumps probe information infrequently. If this is set to never then the code effectively never uses the probe.  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673360187,"objectID":"db873f83b7b18276527943cb10c2f371","permalink":"/documentation/input_deck/input_deck_probe.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_probe.html","section":"documentation","summary":"This block contains information about particle probes used for output. See EPOCH input deck for more information on the input deck.\nSometimes it is useful to consider all the properties of particle which pass through a point/line/plane (depending on dimension) in the simulation.","tags":null,"title":"probe block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about particle collisions. See EPOCH input deck for more information on the input deck.\nEPOCH has a particle collision routine with scattering algorithms based on the model presented by Sentoku and Kemp1 or the model presented by Pérez et al 2, which in turn was based on the work of Nanbu and Yonemura3. This adds a new output block named \u0026ldquo;collisions\u0026rdquo;, and since version 4.19, there are two possible collision modes: binary and background. Binary collisions pair particles together, and apply scatter to both particles. In the background mode, particle species are split into fast-background pairs, where only particles in the fast species are scattered. Originally, EPOCH could only run in the full binary-collisions mode, which accepts the following keys:\n  use_nanbu - This logical flag determines whether the scattering angle of Pérez/Nanbu will be used. The default is \u0026ldquo;T\u0026rdquo;. If \u0026ldquo;F\u0026rdquo;, the Sentoku-Kemp algorithm will be used.\n  coulomb_log - This may either be set to a real value, specifying the Coulomb logarithm to use when scattering the particles or to the special value \u0026ldquo;auto\u0026rdquo;. If \u0026ldquo;auto\u0026rdquo; is used then the routine will calculate a value based on the local temperature and density of the particle species being scattered, along with the two particle charges. If omitted, the default value is \u0026ldquo;auto\u0026rdquo;.\n  collide - This sets up a symmetric square matrix of size $nspecies \\times nspecies$ containing the collision frequency factors to use between particle species. The element (s1,s2) gives the frequency factor used when colliding species s1 with species s2. If the factor is less than zero, no collisions are performed. If it is equal to one, collisions are performed normally. For any value between zero and one, the collisions are performed using a frequency multiplied by the given factor. If \u0026ldquo;collide\u0026rdquo; has a value of \u0026ldquo;all\u0026rdquo; then all elements of the matrix are set to one. If it has a value of \u0026ldquo;none\u0026rdquo; then all elements are set to minus one. If the syntax \u0026ldquo;species1 species2 value\u0026rdquo; is used, then the (species1,species2) element of the matrix is set to the factor \u0026ldquo;value\u0026rdquo;. This may either be a real number, or the special value \u0026ldquo;on\u0026rdquo; or \u0026ldquo;off\u0026rdquo;. value may also be set to \u0026ldquo;background\u0026rdquo; to specify a fast-background pair (see below). The \u0026ldquo;collide\u0026rdquo; parameter may be used multiple times. The default value is \u0026ldquo;all\u0026rdquo; (ie. all elements of the matrix are set to one, modelling physical collisions).\n  collisional_ionisation - If this logical flag is set to \u0026ldquo;T\u0026rdquo; then the collisional ionisation model is enabled. This process is independent of field_ionisation (see here). However, in order to set up collisional_ionisation you must also specify ionisation energies and electrons in a species block (see here). The default value is \u0026ldquo;F\u0026rdquo;.\n  An example deck using full binary collisions could be set up as follows.\nbegin:collisions use_collisions = T use_nanbu = T coulomb_log = auto collide = all collide = spec1 spec2 off collide = spec2 spec3 0.1 end:collisions  With this block, collisions are turned on, the Nanbu-Pérez scattering algorithm is used and the Coulomb logarithm is automatically calculated. All values of the frequency array are set to one except (spec1,spec2) is set to minus one (and also (spec2,spec1)) and (spec2,spec3) is set to 0.1. Note: only a frequency value of 1 provides a physical scatter.\nBackground collisions The background collisions mode offers a speed-up compared to the binary method when applicable. This mode assumes the particles in one species are considerably faster than the particles in a background species, so the relative velocity between fast and background particles is roughly the fast particle speed. This eliminates the need to pair particles together in a local cell, as in the binary-collision case. However, background particles will not experience scatter in this mode. This mode was originally intended for electron-ion collisions, where both species had temperatures on the order of keV. An example of fast-background collisions is given below:\nbegin:collisions use_collisions = T coulomb_log = 5 collide = none collide = Electron Ion1 background collide = Electron Ion2 background collide = Electron Electron on use_cold_correction = F rel_cutoff = 0.01 back_update_dt = 5.0e-15 end:collisions  The above example deactivates all collisions, then sets up two fast-background pairs, with the Electron providing the fast species in both pairs, and Ion1 and Ion2 taking the background roles. Full binary collisions are used for Electron-Electron collisions, as these do not satisfy the fast-background assumptions. Additional speed-up parameters are used which only apply to background collisions. These are:\n  use_cold_correction - The Nanbu-Pérez collisions model has a low temperature correction factor, given in equation (20) of Pérez2. In some cases, this only affects particles with energy on the order of eV, and may be ignored in hot plasma. If \u0026ldquo;F\u0026rdquo;, this calculation is skipped. The default is \u0026ldquo;T\u0026rdquo;, to perform the full calculation.\n  rel_cutoff - Collisions are calculated in the centre-of-mass frame between colliding fast and background particles. In practice, only the fast particle momentum is transformed. This parameter takes a number between 0 and 1, and if the fractional momentum change between frames is lower than this number, the frame transform is skipped. The default is 0, so frame transforms are always considered.\n  back_update_dt - If the background species number density varies slowly, we do not need to re-calculate each step. This parameter specifies the time-step of recalculation for the background number density, and also the Coulomb logarithm if coulomb_log is set to auto. The default is 0, so background variables are re-calculated each step.\n  References   Y. Sentoku and A. J. Kemp, \u0026ldquo;Numerical methods for particle simulations at extreme densities and temperatures: Weighted particles, relativistic collisions and reduced currents,\u0026rdquo; J. Comput. Phys., 2008. 1\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n F. Pérez et al, \u0026ldquo;Improved modeling of relativistic collisions and collisional ionization in particle-in-cell codes ,\u0026rdquo; Physics of Plasmas, 2012. 2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n K. Nanbu and S. Yonemura, \u0026ldquo;Weighted Particles in Coulomb Collision Simulations Based on the Theory of a Cumulative Scattering Angle,\u0026rdquo; J. Comput. Phys., 1998. 3\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673358746,"objectID":"bf398a887b1c1428719cde66e7fa46b2","permalink":"/documentation/input_deck/input_deck_collisions.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_collisions.html","section":"documentation","summary":"This block contains information about particle collisions. See EPOCH input deck for more information on the input deck.\nEPOCH has a particle collision routine with scattering algorithms based on the model presented by Sentoku and Kemp1 or the model presented by Pérez et al 2, which in turn was based on the work of Nanbu and Yonemura3.","tags":null,"title":"collisions block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about QED pair production. See EPOCH input deck for more information on the input deck.\nEPOCH can model QED pair production, synchrotron emission and radiation reaction as described in Duclous et al1 and Ridgers et al. 2 It is enabled using the compiler flag -DPHOTONS. Additionally, the Trident process is enabled using -DTRIDENT_PHOTONS.\nA new input deck block named \u0026ldquo;qed\u0026rdquo; has been added which accepts the following parameters:\n  use_qed - Logical flag which turns QED on or off. The default is \u0026ldquo;F\u0026rdquo;.\n  qed_start_time - Floating point value specifying the time after which QED effects should be turned on. The default is 0.\n  produce_photons - Logical flag which specifies whether to track the photons generated by synchrotron emission. If this is \u0026ldquo;F\u0026rdquo; then the radiation reaction force is calculated but the properties of the emitted photons are not tracked. The default is \u0026ldquo;F\u0026rdquo;.\n  photon_energy_min - Minimum energy of produced photons. Radiation reaction is calculated for photons of all energies, but photons with energy below this cutoff are not tracked. The default is 0.\n  photon_dynamics - Logical flag which specifies whether to push photons. If \u0026ldquo;F\u0026rdquo; then photons are generated, but their motion through the domain is not simulated and they stay where they were generated. The default is \u0026ldquo;F\u0026rdquo;.\n  produce_pairs - Logical flag which determines whether or not to simulate the process of pair generation from gamma ray photons. Both produce_photons and photon_dynamics must be \u0026ldquo;T\u0026rdquo; for this to work. The default is \u0026ldquo;F\u0026rdquo;.\n  qed_table_location - EPOCH\u0026rsquo;s QED routines use lookup tables to calculate gamma ray emission and pair production. If you want to use tables in a different location from the default, specify the new location using this parameter. The default is \u0026ldquo;src/physics_packages/TABLES\u0026rdquo;.\n  use_radiation_reaction - Logical flag which determines whether or not to calculate the radiation reaction force. If set to \u0026ldquo;F\u0026rdquo; then the force is not calculated. This should nearly always be enabled when using the QED model. It is only provided for testing purposes. The default value is \u0026ldquo;T\u0026rdquo;.\n  QED also requires that the code now know which species are electrons, positrons and photons. The species type is specified using a single \u0026ldquo;identify\u0026rdquo; tag in a species block. To specify an electron the block in the deck would look like\nbegin:species name = electron frac = 0.5 number_density = 7.7e29 identify:electron end:species  Once the identity of a species is set then the code automatically assigns mass and charge states for the species. Possible identities are:\n  electron - A normal electron species. All species of electrons in the simulation must be identified in this way or they will not generate photons.\n  positron - A normal positron species. All species of positron in the simulation must be identified in this way or they will not generate photons.\n  photon - A normal photon species. One species of this type is needed for photon production to work. If multiple species are present then generated photons will appear in the first species of this type.\n  bw_electron - The electron species for pair production by the Breit-Wheeler process. If a species of this type exists then electrons from the pair production module will be created in this species. If no species of this type is specified then pair electrons will be generated in the first electron species.\n  bw_positron - As above but for positrons.\n  trident_electron - The electron species for pair production by the Trident process. If a species of this type exists then electrons from the pair production module will be created in this species. If no species of this type is specified then pair electrons will be generated in the first electron species.\n  trident_positron - As above but for positrons.\n  proton - A normal proton species. This is for convenience only and is not required by the pair production routines. A species should be identified only once, so a \u0026ldquo;bw_electron\u0026rdquo; species does not need to also be identified as an \u0026ldquo;electron\u0026rdquo; species. If the code is running with \u0026ldquo;produce_photons=T\u0026rdquo; then a photon species must be created by the user and identified. If the code is running with \u0026ldquo;produce_pairs=T\u0026rdquo; then the code must specify at least one electron (or bw_electron) species and one positron (or bw_positron) species. These species will usually be defined with zero particles from the start of the simulation and will accumulate particles as the simulation progresses. The code will fail to run if the needed species are not specified.\n  brem_photon - A bremsstrahlung photon species. This is used by the bremsstrahlung radiation model. See the bremsstrahlung page.\n  bh_electron - An electron produced in a Bethe-Heitler pair. See the bremsstrahlung page for more details.\n  bh_positron - A positron produced in a Bethe-Heitler pair. See the bremsstrahlung page for more details.\n  The basic input deck has now been considered fully but it is possible for an end user to add new blocks to the input deck As a result, a version of the code which you have obtained from a source other than the GitHub server may include other input deck blocks. These should be described in additional documentation provided with the version of the code that you have.\nReferences   R. Duclous, J. G. Kirk, and A. R. Bell, \u0026ldquo;Monte carlo calculations of pair production in high-intensity laserplasma interactions,\u0026rdquo; Plasma Phys. Contr. F., vol. 53, no. 1, p. 015009, 2011 1.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n C. P. Ridgers, J. G. Kirk, R. Duclous, T. G. Blackburn, C. S. Brady, K. Bennett, T. D. Arber, A. R. Bell, \u0026ldquo;Modelling gamma-ray photon emission and pair production in high-intensity laser\u0026ndash;matter interactions,\u0026rdquo; J. Comp. Phys., vol. 260, p. 273-285, 2014 2.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673352059,"objectID":"1dcd7aea32db34141ed6c90584a9d8b4","permalink":"/documentation/input_deck/input_deck_qed.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_qed.html","section":"documentation","summary":"This block contains information about QED pair production. See EPOCH input deck for more information on the input deck.\nEPOCH can model QED pair production, synchrotron emission and radiation reaction as described in Duclous et al1 and Ridgers et al.","tags":null,"title":"qed block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains configuration for filters which can be used to modify the data to be output. See EPOCH input deck for more information on the input deck.\nIt is possible to restrict the number of particles written to file according to various criteria. For example, you can now output the momentum of all particles which have a gamma lower than 1.8 or the positions of a randomly chosen subset of a given species.\nA new input deck block named \u0026ldquo;subset\u0026rdquo; is defined which accepts the following parameters:\n name - The name given to this subset. This is used to identify the subset in the output block and is also used when labelling the data in the SDF files. include_species - Add the given particle species to the set of particles that this subset applies to. By default, no particle species are included. dumpmask - The dumpmask to use when considering this subset in an output block. This takes the same form as the output block dumpmask. The default value is \u0026ldquo;always\u0026rdquo;. random_fraction - Select a random percentage of the particle species. This is a real value between zero and one. If 0 is specified, no particles are selected. If 1 is specified, all the particles are selected. If 0.2 is specified, 20% of the particles are selected. {px,py,pz,weight,charge,mass,gamma}_min - Select only the particles with momentum, weight, charge, mass or gamma which is greater than the given value. {px,py,pz,weight,charge,mass,gamma}_max - Select only the particles with momentum, weight, charge, mass or gamma which is less than the given value. {x,y,z}_min - Select only the particles whose position lies above the given value. {x,y,z}_max - Select only the particles whose position lies below the given value. id_min,max - Select only the particles whose \u0026ldquo;id\u0026rdquo; is greater than or less than the given values. The \u0026ldquo;id\u0026rdquo; field is explained below. skip,skip_{x,y,z} - Integer parameter for subsampling output. If set to a positive integer then all grid-based variables using the subset restriction will be reduced when being written to file. This is achieved by skipping by the specified number of cells in each of the specified directions. The \u0026ldquo;skip\u0026rdquo; parameter provides a quick method for setting the same number of cells to skip in all directions. This currently only applies to grid-based variables and is ignored for data averages. The default value is \u0026ldquo;0\u0026rdquo;.  Once a subset has been defined, the subset name can then be used in place of (or in addition to) the dumpmask in an \u0026ldquo;output\u0026rdquo; block (see also here). For example:\nbegin:subset name = background random_fraction = 0.1 include_species:electron include_species:proton end:subset begin:subset name = high_gamma gamma_min = 1.3 include_species:electron end:subset begin:output particles = background + high_gamma + always px = background + high_gamma py = background pz = always end:output  In this example, three \u0026ldquo;px\u0026rdquo; blocks will be written: \u0026ldquo;Particles/background/electron/Px\u0026rdquo;, \u0026ldquo;Particles/background/proton/Px\u0026rdquo; and \u0026ldquo;Particles/high_gamma/electron/Px\u0026rdquo;. The \u0026ldquo;background\u0026rdquo; blocks will contain 10% of the each species, randomly selected. The \u0026ldquo;high_gamma\u0026rdquo; block will contain all the electrons with a gamma greater than 1.3.\nThere will also be \u0026ldquo;Particles/background/electron/Py\u0026rdquo; and \u0026ldquo;Particles/background/proton/Py\u0026rdquo; block containing y-momentum for the same 10% random subset of particles. Finally, the \u0026ldquo;Particles/All/electron/Pz\u0026rdquo; and \u0026ldquo;Particles/All/proton/Pz\u0026rdquo; will contain the z-momentum for all particles.\nThe final selection criteria given in the list above is \u0026ldquo;id_min\u0026rdquo; and \u0026ldquo;id_max\u0026rdquo;. As of EPOCH version 4.0, the code can now assign a unique ID field to every particle in the simulation. This can be useful for tracking specific particles as they move through a simulation. As this field adds extra memory requirements to the particles, it is disabled by default and must be compiled in using the -DPARTICLE_ID compiler flag.\nParticle IDs can be written to file using the \u0026ldquo;id\u0026rdquo; variable name in the \u0026ldquo;output\u0026rdquo; block. Eg.\nbegin:output particles = always id = always end:output  Subsets of fields Subset blocks can be applied to per-species variables such as current and temperature. Only particles within the given momentum ranges and of the selected species are included in the calculations. In addition, subset blocks can now be applied to field or grid variables. This allows you to output spatial sections using the {x,y,z}_max,min restrictions. The output data will be trimmed to the selected ranges and a corresponding restricted grid included in the output. Note that specifying an empty range will lead to output of the entire domain. For example, the following snippet will output an ex_c_centre variable restricted to the centre 1/3rd of the domain with a corresponding grid grid_centre:\nbegin:subset name = centre x_min = x_min + (x_max - x_min) / 3.0 x_max = x_min + 2.0 * (x_max - x_min) / 3.0 end:subset begin:output ... ex = always + centre end:output  Persistent subsets Persistent subsets are subsets that capture a set of particles once, given a specified set of parameters, and then track those particles permanently. Persistent subsets use the same blocks as normal subsets and take the same parameters as normal subsets (except the skip parameters which only apply to fields). Subsets are marked as persistent by setting either\n persist_start_time - Time at which to record the list of particles to be tracked. Throughout the rest of the simulation this recorded list will be used whenever requesting output for this subset. \u0026ldquo;persist_after_time\u0026rdquo; is accepted as an alias. Set to 0 to record from the start of the simulation. persist_start_step - Similar to persist_start_time except this specifies a simulation step number to use instead of time. \u0026ldquo;persist_after_step\u0026rdquo; is accepted as an alias.  If the input deck is edited on restart to add a new persistent subset then it must be added after existing persistent subsets or problems may occur on restart.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"504f427eb73df0c879754da612a3c49f","permalink":"/documentation/input_deck/input_deck_subset.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_subset.html","section":"documentation","summary":"This block contains configuration for filters which can be used to modify the data to be output. See EPOCH input deck for more information on the input deck.\nIt is possible to restrict the number of particles written to file according to various criteria.","tags":null,"title":"subset block","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about user defined constants and expressions. These are designed to simplify the initial condition setup. See EPOCH input deck for more information on the input deck.\nThe constant block type helps to make the input deck more flexible and maintainable. It allows you to define constants and maths parser expressions (see EPOCH maths parser) which can be used by name later in the deck. Constants are simply maths parser expressions which are assigned to a name as shown above. When the name is used on the right hand side of a deck expression it is replaced by the expression it was assigned with. This expression may be a simple numerical constant, a mathematical expression or a function. Constants may contain spatially varying information without having to pre-calculate them at every location in the domain. To those familiar with FORTRAN codes which use statement functions, parameters appearing in the \u0026ldquo;constant\u0026rdquo; block are fairly similar. If a constant name is reused in a constant block then the old constant is deleted and replaced with the new one. This happens without warning.\nbegin:constant lambda = 1.06 * micron omega = 2.0 * pi * c / lambda den_crit = critical(omega) scale = 3.5 * micron den_max = 5.0 * den_crit thick = 300e-9 pplength = 6000e-9 widscale = 5.0e-6 t_wid = (10.0e-6) / c amax = 1.0 wy = 1e-6 y = 0.0 slope = exp(-2.0 * (y/wy)^2) blob = gauss(sqrt(x^2 + y^2), 0.0, 1.0e-6) end:constant  Using constants can be very helpful when dealing with long, complicated expressions since they allow the expression to be broken down into much simpler parts. They can also be used to get around the FORTRAN string length limitation built into many compilers which prevents deck lines being longer then 512 characters long. As a general rule, it is a good idea to break down complicated expressions using constants or by other means, in order to make the deck look more readable. Constants are persistent for the entire runtime of the code, allowing them to be used when specifying time profiles for lasers, and also allowing developers to use maths parser expressions for other internal parts of the code where needed. In the above example, several pre-defined constants have been used (pi and c) and also several functions (critical, exp, gauss and sqrt). These are described here and here.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"840cdf10c04c4cf380220dcab1d5113e","permalink":"/documentation/input_deck/input_deck_constant.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_constant.html","section":"documentation","summary":"This block contains information about user defined constants and expressions. These are designed to simplify the initial condition setup. See EPOCH input deck for more information on the input deck.","tags":null,"title":"constant block","type":"docs"},{"authors":null,"categories":null,"content":"The injector block specifies a particle source to be introduced through a simulation boundary. Each injector block specifies a source of a single species of particle defined by a density, centre of mass drift momentum, temperature and number of simulation particles per cell. Injectors may also be set-up to inject particles with properties and at times read from files created by the user. The current version of the injectors is incompatible with the -DPER_SPECIES_WEIGHT compiler flag, and attempting to use an injector with a version of EPOCH compiled with this flag will fail.\nConcepts EPOCH can inject particles through any of the simulation boundaries. This plasma is either a drifting Maxwellian corresponding to a collisionally thermalized beam or a \u0026ldquo;flux Maxwellian\u0026rdquo; corresponding to a Maxwellian source accelerated by an electrostatic accelerator. It can have any temporal or transverse spatial profile of density, temperature or drift that you wish to specify.\nEPOCH does not automatically make any assumption about the plasma that you wish to inject and does not correct for currents injected into the domain. Current due to an injected beam will be smoothly created as the particles enter the domain. If you wish to inject a neutral beam, you will have to use multiple injectors to inject electrons and ions so as to produce a neutral beam. Great care must be taken when introducing relativistic beams since the current due to a highly relativistic beam will not be the current due to the centre of mass velocity since EPOCH does not use the Maxwell-Jüttner distribution for loading particles.\nThe user may over-ride this behaviour and inject particles with specific momenta, positions, weights and ID values, at specific simulation times. These particle parameters are read from files, and syntax for these is provided here.\nBoundary conditions The injectors only work properly with certain boundary conditions. For most purposes the \u0026ldquo;open\u0026rdquo; boundary condition is the only one that makes sense with injectors since particles are flowing freely through the boundary. Remember that in any version of EPOCH that supports injectors you can also use per species boundary conditions to allow you to have different boundary conditions for injected and bulk particles.\nMoving window Injectors and moving windows can be tricky to work with, so the default behaviour of EPOCH is to stop all injectors when the window starts to move. If you wish to override this behaviour then simply explicitly set t_end in the injector block to a value after the window starts to move. Setting\nt_end = t_end  will cause the injectors to continue running until the end of the simulation even with the moving window. You must take great care when specifying injectors for a moving window because you will likely get gaps or bunches in particles injected through the x boundary and there will probably be some shearing of particles introduced through y and z boundaries. It is in general recommended that you specify a velocity profile for the moving window that stops at times when particles are to be injected and then starts again once the injection is complete.\nKeys   boundary - specifies which boundary to attach the particle source too. Same specification as the laser block, so permitted values are x_min, x_max, y_min, y_max, z_min and z_max\n  species - specifies which species should be injected through the boundary. Just specify the name of the species required.\n  t_start - Time at which to start the injector\n  t_end - Time at which to end the injector\n  npart_per_cell - target pseudo-particle density for the injector.\nAverage number of particles injected will be this value or slightly higher if very few particles are specified\n  number_density - Number density of the particle source in $m^{-3}$. Can be space varying along the boundary to which the injector is attached and time varying\n  number_density_min - Minimum number density in $m^{-3}$ below which pseudo particles are not loaded. Use if the density has a profile to avoid injecting low weight particles in low density regions\n  number_density_max - Maximum particle number density in $m^{-3}$. When the number density in a cell rises above number_density_max the injector clips the density to number_density_max allowing easy implementation of exponential rises to plateaus for time-varying injectors. Note that the number of particles per cell is kept fixed and the number density adjustment is achieved by modifying the particle weight. This flag has no effect for particles with per-species weighting. If the flag has a negative value then no clipping is performed. This is the default.\n  temp_x - Temperature in x direction (K)\n  temp_y - Temperature in y direction (K)\n  temp_z - Temperature in z direction (K)\n  temp - Sets an isotropic temperature distribution in Kelvin. If both temp and a specific temp_x, temp_y, temp_z parameter is specified then the last to appear in the deck has precedence. If neither are given then the injector will have a default temperature of zero Kelvin.\n  temp_{x,y,z}_ev, temp_ev - These are the same as the temperature parameters described above except the units are given in electronvolts rather than Kelvin, i.e. using 1ev = 11604.5K .\n  drift_x - Momentum drift in x direction in $kg.m/s$\n  drift_y - Momentum drift in y direction in $kg.m/s$\n  drift_z - Momentum drift in z direction in $kg.m/s$\n  drift_{x,y,z} - Specifies a momentum space offset in $kg m/s$ to the distribution function for this injector. By default, the drift is zero.\n  use_flux_maxwellian - Logical flag to determine whether to use an accelerated flux Maxwellian rather than a drifting Maxwellian. This calculates the flux due to passing a Maxwellian source into an electrostatic accelerator instead of a drifting Maxwellian. If your particle source is a lab accelerator then you may want to set this to true.\n  Example Deck begin:injector boundary = x_min species = Electron number_density = dens temp_x = temp drift_x = drift_p npart_per_cell = 32 end:injector  Inject particles from file The plasma injectors may be over-written to allow the user to inject macro-particles with specific momenta, positions and weight, at given simulation times on given boundaries. Files containing injected particle properties must be formatted in a particular way. Each variable type (position, momentum, weight, time) must be stored in a separate file. Each line of a given file corresponds to a variable value for one particle, and particles must be arranged in chronological order.\nFor example, a user wants to inject 3 particles of weights 10, 20 and 30, at times 1.0e-15 s, 2.0e-15 s and 3.0e-15 s respectively, into a 1D simulation through the x_min boundary. The file containing injection time data (inject_t.txt) would contain:\n1.0e-15 2.0e-15 3.0e-15  and the weight data file (inject_w.txt) would contain:\n10 20 30  The user could create similar files to describe the $p_x$, $p_y$ and $p_z$ momentum components of each injected particle, where the first value in each file would be assigned to the 1.0e-15 macro-particle. In higher dimensions, injection position on the boundary must also be specified. Particle ID may be given if -DPARTICLE_ID or -DPARTICLE_ID4 are specified.\nThe user may have multiple file-injectors running simultaneously, by defining multiple file-injector blocks. An example block is provided below for a 2D simulation. In this example, all files are present in the same directory as the input deck.\nbegin:injector boundary = x_min species = Electron inject_from_file = T y_data = \u0026quot;inject_y.txt\u0026quot; px_data = \u0026quot;inject_px.txt\u0026quot; py_data = \u0026quot;inject_py.txt\u0026quot; w_data = \u0026quot;inject_w.txt\u0026quot; t_data = \u0026quot;inject_t.txt\u0026quot; end:injector    inject_from_file - If \u0026ldquo;T\u0026rdquo;, the code will ignore the flux-Maxwellian keys, and will instead inject particles based on the {\u0026hellip;}_data keys.\n  {x, y, z}_data - Files containing the positions of injected particles. These are not used in 1D simulations, but must be used in 2D and 3D. In this example, no $x$ file is given, as all particles are injected through x_min.\n  {px, py, pz}_data - Files containing the momenta of injected particles. These are optional parameters - if a momentum component file is missing, this component will be set to zero for all injected particles.\n  w_data - The file containing the weights of all injected particles. This data is mandatory.\n  t_data - The file containing the times each particle passes the boundary. Injected particles will be positioned outside the simulation window, such that they pass the boundary at the time specified in this file. This data is mandatory.\n  id_data - The file containing the ID values assigned to each injected particle. This is optional, and may only be used if the code is compiled with either -DPARTICLE_ID or -DPARTICLE_ID4.\n  Warnings Currently injectors are a beta feature of EPOCH. We believe them to work correctly, but unusual results must be considered suspect. If you get unexpected results, please contact the EPOCH development team.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673352059,"objectID":"ff6d9373653b995c692b37b407217eb8","permalink":"/documentation/input_deck/input_deck_injector.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_injector.html","section":"documentation","summary":"The injector block specifies a particle source to be introduced through a simulation boundary. Each injector block specifies a source of a single species of particle defined by a density, centre of mass drift momentum, temperature and number of simulation particles per cell.","tags":null,"title":"injector block","type":"docs"},{"authors":null,"categories":null,"content":"Antennae allow you to specify currents in the simulation domain that are added to the self consistent currents from the core solver. You can either specify the currents entirely manually or you can specify a frequency and a profile for each current component. You can have as many antennae as you want by specifying multiple antenna blocks.\nExample Deck begin:antenna jx = if (r_xy lt micron, 1.0e-5, 0.0) jy = if (r_xy lt micron, 1.0e-5, 0.0) jz = if (r_xy lt micron, 1.0e-5, 0.0) ranges = ((-micron, micron), (-micron, micron)) omega = 1.0e15 start_time = start stop_time = end end:antenna  Keys  jx - Profile for current in x direction. If you do not specify the omega key then you should include any time dependence manually. If the omega key is specified any time variation in jx will be multiplicatively combined with the sinusoidal variation from omega. Can be time and space varying. jy - Profile for current in y direction. If you do not specify the omega key then you should include any time dependence manually. If the omega key is specified any time variation in jy will be multiplicatively combined with the sinusoidal variation from omega. Can be time and space varying. jz - Profile for current in z direction. If you do not specify the omega key then you should include any time dependence manually. If the omega key is specified any time variation in jz will be multiplicatively combined with the sinusoidal variation from omega. Can be time and space varying. ranges - Array of (min,max) pairs for each dimension of your simulation (1 pair for EPOCH1d, 2 pairs for EPOCH2D and 3 pairs for EPOCH3D) showing the domain over which the antenna should operate. Describes the region of space over which the current from the antenna should be applied. The fields generated by that current will propagate everywhere in the simulation domain. If ranges is not present then the antenna will be applied to the whole domain. Performance of the antenna block will be highest if you set the smallest range possible. omega - Optional frequency for the antenna. If this key is set then the current will vary sinusoidally with the specified frequency. This is faster to run than specifying a sinusoidal profile in the jx, jy or jz keys but performs the same (for a frequency that doesn\u0026rsquo;t change in time, see Time variability section). Can be time varying, but not space varying start_time - Time after which to start applying the antenna currents. Can be \u0026ldquo;start\u0026rdquo; to apply from the start of the simulation. If key is not present antenna runs from the start of the simulation. stop_time - Time after which to cease applying the antenna currents. Can be \u0026ldquo;end\u0026rdquo; to apply until the end of the simulation. If key is not present antenna runs until the end of the simulation.  Time variability When you specify time variation for the jx, jy or jz keys this specifies the instantaneous current to be applied at each moment in time.\nWhen you specify time variation in the omega key this specifies the frequency at this time, but this is applied to the phase state of the antenna as an integral. So the sinusoid that is applied to the current is $\\sin\\Bigl(\\int_0^t\\omega(t')dt'\\Bigr)$. For constant $\\omega$ this reduces to $\\sin(\\omega t)$. This gives the correct behaviour for chirped antennae\nExample deck An example deck for this block can be found in example_decks/antenna.deck. The deck should take 5-20 seconds to run.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624406887,"objectID":"707bde4b84117535d6dc281d83030b06","permalink":"/documentation/input_deck/input_deck_antenna.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_antenna.html","section":"documentation","summary":"Antennae allow you to specify currents in the simulation domain that are added to the self consistent currents from the core solver. You can either specify the currents entirely manually or you can specify a frequency and a profile for each current component.","tags":null,"title":"Input deck antenna","type":"docs"},{"authors":null,"categories":null,"content":"This block contains information about the block used to load particles from file. See EPOCH input deck for more information on the input deck.\nThe particles_from_file block is similar in function to the fields block, it allows the loading of custom particle data from raw binary data files. An example usage of the block is shown below\nbegin:particles_from_file species = \u0026quot;electron\u0026quot; # Load mandatory data for 3D simulation x_data = \u0026quot;xdata.dat\u0026quot; y_data = \u0026quot;ydata.dat\u0026quot; z_data = \u0026quot;ydata.dat\u0026quot; w_data = \u0026quot;ydata.dat\u0026quot; # Load particle ids in 4 byte int format, # ignoring first 8 bytes of file #offset = 8 #id4_data = \u0026quot;iddata.dat\u0026quot; end:particles_from_file  Specifying a particles_from_file block for a species causes EPOCH to load the per-particle data from the specified files. Data files are assumed to be in order such that the first variable in each file will be attributed to one particle, the second variable in each file to a second electron, and so on. A target species to load to, as well as particle position and weight data (unless has been set) must be supplied. With the exception of particle ID, any optional parameters which are left unspecified will be initialised to zero. If the code has been compiled with or then particle IDs may be loaded from a raw binary file of integers of either size 4 or size 8 regardless of the compile time flag choice. If no particle ID data is supplied, IDs will be generated sequentially from 1. All other data should be in the form of floating point numbers of the same precision as in the core code. A particles_from_file block accepts the following parameters:\n  species - Name of the species to which the particles will be loaded. This is a mandatory parameter and the corresponding species block must be defined.\n  {x,y,z}_data - File containing particle position data in $m$. This data must be supplied, up to the dimensionality of the simulation.\n  w_data - File containing pseudoparticle weight, this is the number of real particles the pseudoparticle represents. This data must be supplied.\n  {px,py,pz}_data - File containing particle momentum data in $kg,ms^{-1}$. The default value is zero.\n  id{4,8}_data - File containing particle IDs in either 4 or 8 byte unsigned integer representation.\n  offset - File offset. Number of bytes at the head of the file to be ignored, may be specified multiple times. see for more details of behaviour.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"f32573fb9b55a393445eb0e956ad6d38","permalink":"/documentation/input_deck/input_deck_particle_file.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/input_deck_particle_file.html","section":"documentation","summary":"This block contains information about the block used to load particles from file. See EPOCH input deck for more information on the input deck.\nThe particles_from_file block is similar in function to the fields block, it allows the loading of custom particle data from raw binary data files.","tags":null,"title":"Input deck particle file","type":"docs"},{"authors":null,"categories":null,"content":"There are several input deck blocks which can read conditions directly from a user-specified file. These include the , and . In all such cases, the files specified must be in a simple binary format, often referred to as \u0026ldquo;raw\u0026rdquo; binary files.\nBinary files are machine readable, but not human readable. If you try opening a binary file in a text editor then you will see incomprehensible characters and some text editors might even crash. Most languages can write binary files, see \u0026ldquo;writeu\u0026rdquo; (in IDL/GDL), \u0026ldquo;fwrite\u0026rdquo; in MatLab, the \u0026ldquo;b\u0026rdquo; parameter to \u0026ldquo;open\u0026rdquo; in Python and \u0026ldquo;form=\u0026lsquo;UNFORMATTED\u0026rsquo; \u0026quot; in Fortran, so please see the documentation for those languages. Note that standard unformatted output in Fortran also writes some additional hidden output to the file that alters the offset of the actual binary array data within the file. It is therefore recommended that you always use the \u0026ldquo;access=\u0026lsquo;STREAM\u0026rsquo; \u0026quot; modifier whenever writing such files from Fortran programs.\nFor illustration purposes, here is a simple example of writing a 2D array to file using Fortran:\nPROGRAM output_array INTEGER :: iu, istat INTEGER, PARAMETER :: nx = 10, ny = 20 DOUBLE PRECISION :: array(nx,ny) CHARACTER(LEN=*), PARAMETER :: filename = ’array.dat’ array = 2.0d0 OPEN(newunit=iu, file=filename, status=’NEW’, form=’UNFORMATTED’, \u0026amp;amp; access=’STREAM’, iostat=istat) IF (istat == 0) THEN WRITE(iu) array CLOSE(iu, iostat=istat) ELSE PRINT*, ’ERROR: failed to open file ’, ’“’ // filename // ’”’, \u0026amp;amp; ’ for writing’ END IF END PROGRAM output_array  In this example, there are 200 array elements written to file (10 * 20). Each element is a double-precision number which is 8 bytes. Therefore, the total file size will be 1600 bytes. Note that for Fortran, arrays are indexed using \u0026ldquo;column-major order\u0026rdquo;. This means that in the file, the first array element \u0026ldquo;array(1,1)\u0026rdquo; will be followed by \u0026ldquo;array(2,1)\u0026rdquo; and so on up to \u0026ldquo;array(10,1)\u0026rdquo;. After this, the second index will be incremented and the array element \u0026ldquo;array(1,2)\u0026rdquo; will be output, followed by \u0026ldquo;array(2,2)\u0026rdquo;, etc. In contrast, languages such as C and C++ use row-major order. For these languages the array output is transposed, so the array elements are output in the order: \u0026ldquo;array[0][0], array[0][1], .. array[0][19], array[1][0], ..\u0026rdquo;\nSimple binary files merely contain a long sequence of real numbers and do not contain any information about the shape of the arrays that have been written. This information must be supplied using the input deck. These should correspond to the values of \u0026ldquo;nx\u0026rdquo;, \u0026ldquo;ny\u0026rdquo;, etc. For example, to use the array generated by the Fortran code shown above, the input deck must specify \u0026ldquo;nx = 10\u0026rdquo; and \u0026ldquo;ny = 20\u0026rdquo;.\nIt is possible to write multiple arrays into the same binary file and use the \u0026ldquo;offset\u0026rdquo; comand in the input deck to specify where the next array in the file is to be located. This can be tricky to work with and it is therefore recommended to write each separate array to its own file.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"7d076699feafd5a7475a16628be5614f","permalink":"/documentation/input_deck/binary_files.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/input_deck/binary_files.html","section":"documentation","summary":"There are several input deck blocks which can read conditions directly from a user-specified file. These include the , and . In all such cases, the files specified must be in a simple binary format, often referred to as \u0026ldquo;raw\u0026rdquo; binary files.","tags":null,"title":"Binary files","type":"docs"},{"authors":null,"categories":null,"content":"A discussion of the input deck for EPOCH would not be complete without consideration of the maths parser. The maths parser is the code which reads the input decks. The parser makes it possible that any parameter taking a numerical value (integer or real) can be input as a mathematical expression rather than as a numerical constant. The maths parser is fairly extensive and includes a range of mathematical functions, physical and simulation constants and appropriately prioritised mathematical operators.\nConstants The maths parser in EPOCH has the following constants\n pi - The ratio of the circumference of a circle to its diameter. kb - Boltzmann\u0026rsquo;s constant. me - Mass of an electron. qe - Charge of an electron. c - Speed of light. epsilon0 - Permeability of free space. mu0 - Permittivity of free space. ev - Electronvolt. kev - Kilo-Electronvolt. mev - Mega-Electronvolt. micron - A convenience symbol for specifying wavelength in microns rather than metres. milli - $10^{-3}$ micro - $10^{-6}$ nano - $10^{-9}$ pico - $10^{-12}$ femto - $10^{-15}$ atto - $10^{-18}$ cc - A convenience symbol for converting from cubic metres to cubic centimetres (ie. $10^{-6}$) time - Initial simulation time. x,y,z - Grid coordinates in the x,y,z direction. ix,iy,iz - Grid index in the x,y,z direction. nx,ny,nz - Number of grid points in the x,y,z direction. dx,dy,dz - Grid spacing in the x,y,z direction. {x,y,z}_min - Grid coordinate of the minimum x,y,z boundary. {x,y,z}_max - Grid coordinate of the maximum x,y,z boundary. length_{x,y,z} - The length of the simulation box in the x,y,z direction. nproc_{x,y,z} - The number of processes in the x,y,z directions. nsteps - The number of timesteps requested. t_end - The end time of the simulation. p{x,y,z} - Momentum in the x, y, z directions. Used in specifying arbitrary distribution functions. EPOCH 4.15 or later required  It is also possible for an end user to specify custom constants both within the code and from the input deck. These topics are covered later in this subsection. An example of using a constant would be: length_x = pi\nFunctions The maths parser in EPOCH has the following functions\n abs(a) - Absolute value. floor(a) - Convert real to integer rounding down. ceil(a) - Convert real to integer rounding up. nint(a) - Convert real to integer rounding to nearest integer. sqrt(a) - Square root. sin(a) - Sine. cos(a) - Cosine. tan(a) - Tangent. asin(a) - Arcsine. acos(a) - Arccosine. atan(a) - Arctangent. atan2(Y,X) - Arctangent using the Fortran ATAN2 function. This computes the principal value of the argument function of the complex number $X + i Y$. This function can be used to transform from Cartesian into polar coordinates and allows to determine the angle in the correct quadrant. sinh(a) - Hyperbolic sine. cosh(a) - Hyperbolic cosine. tanh(a) - Hyperbolic tangent. exp(a) - Exponential. loge(a) - Natural logarithm. log10(a) - Base-10 logarithm. log_base(a,b) - Base-b logarithm. gauss($x,x_0,w$) - Calculate a Gaussian profile in variable x centred on $x_0$ with a characteristic width w. $f(x) = \\exp{(-((x-x_0)/w)^2)}$. In this expression the full width at half maximum is given by $fwhm = 2 w \\sqrt{\\ln{2}}$ supergauss($x,x_0,w,n$) - This is identical to \u0026ldquo;gauss\u0026rdquo; except it takes a fourth parameter, n, which is the power to raise the exponential argument to. semigauss($t,A,A_0,w$) - Calculate a semi Gaussian profile in variable $t$ with maximum amplitude $A$, amplitude at $t=0$ $A_0$ and width $w$. The parameter $A_0$ is used to calculate $t_0$, the point at which the Gaussian reaches its maximum value. For $t$ less than $t_0$ the profile is Gaussian and for $t$ greater than $t_0$ it is the constant $A$. $t_0 = w\\sqrt{-\\ln{(A_0/A)}}$f(t) =  \\begin{cases} A \\exp{(-((t-t_0)/w)^2)}, \u0026amp; t \u0026lt; t_0 \\\\ A, \u0026amp; \\mbox{otherwise} \\end{cases}\n interpolate(interp_var,.\u0026hellip;,n_pairs) - Linear interpolation function, explained later. if(a,b,c) - Conditional function. If a != 0 the function returns b, otherwise the function returns c. number_density(a) - Returns the number density for species a. temp_{x,y,z}(a) - Returns temperature in the x, y or z direction for species a. temp(a) - Returns the isotropic temperature for species a. e{x,y,z}(x,y,z) - Returns the x, y or z component of the electric field at the specified location. b{x,y,z}(x,y,z) - Returns the x, y or z component of the magnetic field at the specified location. critical($\\omega$) - Returns the critical density for the given frequency $\\omega$. ie. $n_{crit}(\\omega) = \\omega^2 m_0 \\epsilon_0 / e^2$  It is also possible for an end user to specify custom functions within the code. An example of using a function would be: length_x = exp(pi) The use of most of these functions is fairly simple, but \u0026ldquo;interpolate\u0026rdquo; requires some additional explanation. This function allows a user to specify a set of position,value pairs and have the code linearly interpolate the values between these control points. This function is mainly intended for ease of converting initial conditions from other existing PIC codes, and the same effect can usually be obtained more elegantly using the \u0026ldquo;if\u0026rdquo; command. The structure of the \u0026ldquo;interpolate\u0026rdquo; command is as follows: The first parameter is the variable which is to be used as the axis over which to interpolate the values. This can in general be any valid expression, but will normally just be a coordinate axis. The next 2n entries are the position,value pairs and the final parameter is the number of position,value pairs. The slightly clunky syntax of this command is unfortunately necessary to allow it to work with some fairly fundamental features of the maths parser used in EPOCH.\nOperators The maths parser in EPOCH allows the following operators\n a + b - Addition operator. a - b - Subtraction operator or unary negation operator (auto-detected). a * b - Multiplication operator. a / b - Division operator. a ^ b - Power raise operator. a e b - Power of ten operator (1.0e3 = 1000). a lt b - Less than operator. Returns 1 if a $\u0026lt;$ b, otherwise returns 0. Intended for use with if. a gt b - Greater than operator. Returns 1 if a $\u0026gt;$ b, otherwise returns 0. a eq b - Equality operator. Returns 1 if a == b, otherwise returns 0. a and b - Logical and operator. Returns 1 if a != 0 and b != 0, otherwise returns 0. a or b - Logical or operator. Returns 1 if a != 0 or b != 0, otherwise returns 0.  These follow the usual rules for operator precedence, although it is best to surround more complex expressions in parenthesis if the precedence is important. It is not possible at this time to specify custom operators without major changes to the code. An example of using an operator would be:\nlength_x = 10.0 + 12.0  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624406887,"objectID":"a0e05e75d55e7b546f0c9701cb7b8da6","permalink":"/documentation/code_details/maths_parser.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/maths_parser.html","section":"documentation","summary":"A discussion of the input deck for EPOCH would not be complete without consideration of the maths parser. The maths parser is the code which reads the input decks. The parser makes it possible that any parameter taking a numerical value (integer or real) can be input as a mathematical expression rather than as a numerical constant.","tags":null,"title":"Maths parser","type":"docs"},{"authors":null,"categories":null,"content":"Specifying initial conditions for particles using the input deck If the initial conditions for the plasma you wish to model can be described by a number density and temperature profile on the underlying grid then EPOCH can create an appropriate particle distribution for you. The set of routines which accomplish this task are known as the autoloader. For many users, this functionality is sufficient to make use of the code and there is no need to deal with the internal representation of particles in EPOCH.\nThe autoloader randomly loads particles in space to reproduce the number density profile that was requested. It then sets the momentum components of the particles to approximate a Maxwell-Boltzmann distribution corresponding to the temperature profile. Sometimes this is not the desired behaviour, for example you may wish to model a bump-on-tail velocity distribution. It is currently not possible to specify these initial conditions from the input deck and the particles must be setup by modifying the source code.\nThere are two stages to the particle setup in EPOCH\n auto_load - This routine is called after reading and parsing the input deck. It takes care of allocating particles and setting up their initial positions and momenta using the initial conditions supplied in deck file. It is not necessary to recompile the code, or even have access to the source to change the initial conditions using this method. manual_load - Once particles have been allocated they can have their properties altered in this routine. By default it is an empty routine which does nothing.  Setting autoloader properties from the input deck To illustrate using the autoloader in practice, we present an example for setting up an isolated plasma block in 2D. This would look like:\nbegin:species name = s1 # First set number_density in the range 0 \u0026gt; 1 # Cut down number_density in x direction number_density = if ((x gt -1) and (x lt 1), 1.0, 0.2) # Cut down number_density in y direction number_density = if ((y gt -1) and (y lt 1), number_density(s1), 0.2) # Multiply number_density by real particle number_density number_density = number_density(s1) * 100.0 # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species begin:species # Just copy the number_density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species  An important point to notice is that the two parts of the logical expressions in the input deck are enclosed within their own brackets. This helps to remove some ambiguities in the functioning of the input deck parser. It is hoped that this will soon be fixed, but at present ALWAYS enclose logical expressions in brackets.\nManually overriding particle parameters set by the autoloader Since not all problems in plasma physics can be described in terms of an initial distribution of thermal plasma, it is also possible to manually control properties of each individual pseudoparticle for an initial condition. This takes place in the subroutine manual_load in the file user_interaction/ic_module.f90. Manual loading takes place after all the autoloader phase, to allow manual tweaking of autoloader specified initial conditions.\nEPOCH internal representation of particles Before we can go about manipulating particle properties in manual_load, we first need an overview of how the particles are defined in EPOCH. Inside the code, particles are represented by a Fortran90 TYPE called particle. The current definition of this type (in 1D) is:\nTYPE particle REAL(num), DIMENSION(3) :: part_p REAL(num) :: part_pos #if !defined(PER_SPECIES_WEIGHT) || defined(PHOTONS) REAL(num) :: weight #endif #ifdef DELTAF_METHOD REAL(num) :: pvol #endif #ifdef PER_PARTICLE_CHARGE_MASS REAL(num) :: charge REAL(num) :: mass #endif TYPE(particle), POINTER :: next, prev #ifdef PARTICLE_DEBUG INTEGER :: processor INTEGER :: processor_at_t0 #endif #ifdef PARTICLE_ID4 INTEGER :: id #elif PARTICLE_ID INTEGER(i8) :: id #endif #ifdef COLLISIONS_TEST INTEGER :: coll_count #endif #ifdef WORK_DONE_INTEGRATED REAL(num) :: work_x REAL(num) :: work_y REAL(num) :: work_z REAL(num) :: work_x_total REAL(num) :: work_y_total REAL(num) :: work_z_total #endif #ifdef PHOTONS REAL(num) :: optical_depth REAL(num) :: particle_energy #ifdef TRIDENT_PHOTONS REAL(num) :: optical_depth_tri #endif #endif END TYPE particle  Here, most of the preprocessing directives have been stripped out for clarity. We have left #ifdef PARTICLE_DEBUG as an example. Here, the \u0026ldquo;processor\u0026rdquo; and \u0026ldquo;processor_at_t0\u0026rdquo; variables only exist if the -DPARTICLE_DEBUG define was put in the makefile. If you want to access a property that does not seem to be present, check the preprocessor defines.\nThe \u0026ldquo;particle\u0026rdquo; properties can be explained as follows:\n part_p - The momentum in 3 dimensions for the particle. This is always of size 3. part_pos - The position of the particle in space. This is of the same size as the dimensionality of the code. weight - The weight of this particle. The number of real particles represented by this pseudoparticle. charge - The particle charge. If the code was compiled without per particle charge, then the code uses the charge property from TYPE(particle_species). mass - The particle rest mass. If the code was compiled without per particle mass, then the code uses the mass property from TYPE(particle_species). next, prev - The next and previous particle in the linked list which represents the particles in the current species. This will be explained in more detail later. processor - The rank of the processor which currently holds the particle. processor_at_t0 - The rank of the processor on which the particle started. id - Unique particle ID. coll_count - Used for debugging the collision routines. optical_depth - Optical depth used in the QED routines. particle_energy - Particle energy used in the QED routines. optical_depth_tri - Optical depth for the trident process in the QED routines.  Collections of particles are represented by another Fortran TYPE, called particle_list. This type represents all the properties of a collection of particles and is used behind the scenes to deal with inter-processor communication of particles. The definition of the type is:\nTYPE particle_list TYPE(particle), POINTER :: head TYPE(particle), POINTER :: tail INTEGER(i8) :: count INTEGER :: id_update ! Pointer is safe if the particles in it are all unambiguously linked LOGICAL :: safe ! Does this partlist hold copies of particles rather than originals LOGICAL :: holds_copies TYPE(particle_list), POINTER :: next, prev END TYPE particle_list   head - The first particle in the linked list. tail - The last particle in the linked list. count - The number of particles in the list. Note that this is NOT MPI aware, so reading count only gives you the number of particles on the local processor. safe - Any particle_list which a user should come across will be a safe particle_list. Don\u0026rsquo;t change this property. next, prev - For future expansion it is possible to attach particle_lists together in another linked list. This is not currently used anywhere in the code.  An entire species of particles is represented by another Fortran TYPE, this time called particle_species. This represents all the properties which are common to all particles in a species. The current definition is:\nTYPE particle_species ! Core properties CHARACTER(string_length) :: name TYPE(particle_species), POINTER :: next, prev INTEGER :: id INTEGER :: dumpmask INTEGER :: count_update_step REAL(num) :: charge REAL(num) :: mass REAL(num) :: weight INTEGER(i8) :: count TYPE(particle_list) :: attached_list LOGICAL :: immobile LOGICAL :: fill_ghosts ! Parameters for relativistic and arbitrary particle loader INTEGER :: ic_df_type REAL(num) :: fractional_tail_cutoff TYPE(primitive_stack) :: dist_fn TYPE(primitive_stack) :: dist_fn_range(3) #ifndef NO_TRACER_PARTICLES LOGICAL :: zero_current #endif ! ID code which identifies if a species is of a special type INTEGER :: species_type ! particle cell division INTEGER(i8) :: global_count LOGICAL :: split INTEGER(i8) :: npart_max ! Secondary list TYPE(particle_list), DIMENSION(:), POINTER :: secondary_list ! Injection of particles REAL(num) :: npart_per_cell TYPE(primitive_stack) :: density_function, temperature_function(3) TYPE(primitive_stack) :: drift_function(3) ! Thermal boundaries REAL(num), DIMENSION(:), POINTER :: ext_temp_x_min, ext_temp_x_max ! Species_ionisation LOGICAL :: electron LOGICAL :: ionise INTEGER :: ionise_to_species INTEGER :: release_species INTEGER :: n INTEGER :: l REAL(num) :: ionisation_energy ! Attached probes for this species #ifndef NO_PARTICLE_PROBES TYPE(particle_probe), POINTER :: attached_probes #endif ! Particle migration TYPE(particle_species_migration) :: migrate ! Initial conditions TYPE(initial_condition_block) :: initial_conditions ! Per-species boundary conditions INTEGER, DIMENSION(2*c_ndims) :: bc_particle END TYPE particle_species  This definition is for the 1D version of the code. The only difference for the other two versions is the number of dimensions in the arrays \u0026ldquo;secondary_list\u0026rdquo; and \u0026ldquo;ext_temp_*\u0026rdquo;. There are quite a lot of fields here, so we will just document some of the most important ones.\n name - The name of the particle species, used in the output dumps etc. next, prev - Particle species are also linked together in a linked list. This is used internally by the output dump routines, but should not be used by end users. id - The species number for this species. This is the same number as is used in the input deck to designate the species. dumpmask - Determine when to include this species in output dumps. Note that the flag is ignored for restart dumps. charge - The charge in Coulombs. Even if PER_PARTICLE_CHARGE_MASS is specified, this is still populated from the input deck, and now refers to the reference charge for the species. mass - The mass in kg. weight - The per-species particle weight. count - The global number of particles of this species (NOTE may not be accurate). This will only ever be the number of particles on this processor when running on a single processor. While this property will be accurate when setting up initial conditions, it is only guaranteed to be accurate for the rest of the code if the code is compiled with the correct preprocessor options. attached_list - The list of particles which belong to this species. immobile - If set to .TRUE. then the species is ignored during the particle push. zero_current - If set to .TRUE. then the current is not updated for this particle species.  Setting the particle properties The details of exactly what a linked list means in EPOCH requires a more in-depth study of the source code. For now, all we really need to know is that each species has a list of particles. A pointer to the first particle in the list is contained in species_list(ispecies)%attached_list%head. Once you have a pointer to a particle (eg. current), you advance to the next pointer in the list with current =\u0026gt; current%next. After all the descriptions of the types, actually setting the properties of the particles is fairly simple. The following is an example which positions the particles uniformly in 1D space, but doesn\u0026rsquo;t set any momentum.\nSUBROUTINE manual_load TYPE(particle), POINTER :: current INTEGER :: ispecies REAL(num) :: rpos, dx DO ispecies = 1, n_species current =\u0026gt; species_list(ispecies)%attached_list%head dx = length_x / species_list(ispecies)%attached_list%count rpos = x_min DO WHILE(ASSOCIATED(current)) current%part_pos = rpos current%weight = 1.0_num rpos = rpos + dx current =\u0026gt; current%next ENDDO ENDDO END SUBROUTINE manual_load  This will take the particles which have been placed at random positions by the autoloader and repositions them in a uniform manner. In order to adjust the particle positions, you need to know about the grid used in EPOCH. In this example we only required the length of the domain, \u0026ldquo;length_x\u0026rdquo; and the minimum value of x, \u0026ldquo;x_min\u0026rdquo;. A more exhaustive list is given in the following section. Note that I completely ignored the question of domain decomposition when setting up the particles. The code automatically moves the particles onto the correct processor without user interaction.\nIn the above example, note that particle momentum was not specified and particle weight was set to be a simple constant. Setting particle weight can be very simple if you can get the pseudoparticle distribution to match the real particle distribution, or quite tricky if this isn\u0026rsquo;t possible. The weight of a pseudoparticle is calculated such that the number of pseudoparticles in a cell multiplied by their weights equals the number of physical particles in that cell. This can be quite tricky to get right, so in more complicated cases it is probably better to use the autoloader than to manually set up the number density distribution.\nGrid coordinates used in EPOCH. When setting up initial conditions within the EPOCH source (rather than using the input deck) there are several constants that you may need to use. These constants are:\n nx - Number of gridpoints on the local processor in the x direction. ny - Number of gridpoints on the local processor in the y direction (2D and 3D). nz - Number of gridpoints on the local processor in the z direction (3D). length_{x,y,z} - Length of domain in the x, y, z directions. {x,y,z}_min - Minimum value of x, y, z for the whole domain. {x,y,z}_max - Maximum value of x, y, z for the whole domain. n_species - The number of species in the code.  There are also up to three arrays which are available for use.\n x(-2:nx+3) - Position of a given gridpoint in real units in the x direction. y(-2:ny+3) - Position of a given gridpoint in real units in the y direction (2D and 3D). z(-2:nz+3) - Position of a given gridpoint in read units in the z direction (3D).  Loading a separable non-thermal particle distribution. While the autoloader is capable of dealing with most required initial thermal distributions, you may want to set up non-thermal initial conditions. The code includes a helper function to select a point from an arbitrary distribution function which can be used to deal with most non-thermal distributions. To use the helper function, you need to define two 1D arrays which are the x and y axes for the distribution function. This approach is only possible if the distribution function can be represented as a set of 1D distribution functions in px, py and pz separately. If this is possible then this method is preferred since it is significantly faster than the arbitrary method detailed in the next section. An example of using the helper function is given below.\nSUBROUTINE manual_load TYPE(particle), POINTER :: current INTEGER, PARAMETER :: np_local = 1000 INTEGER :: ispecies, ip REAL(num) :: temperature, stdev2, tail_width, tail_height, tail_drift REAL(num) :: frac, tail_frac, min_p, max_p, dp_local, p2, tail_p2 REAL(num), DIMENSION(np_local) :: p_axis, distfn_axis temperature = 1e4_num tail_width = 0.05_num tail_height = 0.2_num tail_drift = 0.5_num DO ispecies = 1, n_species stdev2 = kb * temperature * species_list(ispecies)%mass frac = 1.0_num / (2.0_num * stdev2) tail_frac = 1.0_num / (2.0_num * stdev2 * tail_width) max_p = 5.0_num * SQRT(stdev2) min_p = -max_p dp_local = (max_p - min_p) / REAL(np_local-1, num) DO ip = 1, np_local p_axis(ip) = min_p + (ip - 1) * dp_local p2 = p_axis(ip)**2 tail_p2 = (p_axis(ip) - tail_drift * max_p)**2 distfn_axis(ip) = EXP(-p2 * frac) \u0026amp;amp; + tail_height * EXP(-tail_p2 * tail_frac) ENDDO current=\u0026gt;species_list(ispecies)%attached_list%head DO WHILE(ASSOCIATED(current)) current%part_p(1) = sample_dist_function(p_axis, distfn_axis) current=\u0026gt;current%next ENDDO ENDDO END SUBROUTINE manual_load  This example will set the particles to have a bump-on-tail velocity distribution, a setup which is not possible to do using only the input deck. It is not necessary to normalise the distribution function, as this is done automatically by the *sample_dist_function* function.\nLasers EPOCH has the ability to add EM wave sources such as lasers at boundaries. To use lasers, set the boundary that you wish to have a laser on to be of type simple_laser and then specify one or more lasers attached to that boundary. Lasers may be specified anywhere initial conditions are specified.\nLaser blocks in multiple dimensions. When running EPOCH in 2D or 3D, the laser can be modified spatially via the profile and phase parameters. These are briefly outlined here but in this section we will describe them in a little more depth.\n  profile - The spatial profile for the laser. This is essentially an array defined along the edge (or surface) that the laser is attached to. It is clear that the spatial profile is only meaningful perpendicular to the laser\u0026rsquo;s direction of travel and so it is just a single constant in 1D. The laser profile is evaluated as an initial condition and so cannot include any temporal information which must be encoded in t_profile. The spatial profile is evaluated at the boundary where the laser is attached and so only spatial information in the plane of the boundary is significant. This is most clearly explained through a couple of examples. In these examples the spatial profile of the laser is set to vary between a flat uniform profile (profile = 1) and a Gaussian profile in y (profile = gauss(y,0,2.5e-6)). The difference between these profiles is obvious but the important point is that a laser travelling parallel to the x-direction has a profile in the y direction. Similarly a laser propagating in the y-direction has a profile in the x direction. In 3D this is extended so that a laser propagating in a specified direction has a profile in both orthogonal directions. So a laser travelling parallel to the x axis in 3D would have a profile in y and z. Since 3D lasers are very similar to 2D lasers, they will not be considered here in greater detail, but in 3D, it is possible to freely specify the laser profile across the entire face where a laser is attached.   phase - Phase shift for the laser in radians. This is a spatial variable which is also defined across the whole of the boundary on which the laser is attached. This allows a user to add a laser travelling at an angle to a boundary as shown in Figure [angle]. The setup for this is not entirely straightforward and requires a little bit of explanation. Figure [wave] illustrates a laser being driven at an angle on the x_min boundary. Different wave fronts cross the $y$-axis at different places and this forms a sinusoidal profile along $y$ that represents the phase. The wavelength of this profile is given by $\\lambda_\\phi = \\lambda / \\sin\\theta$, where $\\lambda$ is the wavelength of the laser and $\\theta$ is the angle of the propagation direction with respect to the $x$-axis. The actual phase to use will be $\\phi(y) = -k_\\phi y = -2\\pi y / \\lambda_\\phi$. It is negative because the phase of the wave is propagating in the positive $y$ direction. It is also necessary to alter the wavelength of the driver since this is given in the direction perpendicular to the boundary. The new wavelength to use will be $\\lambda\\cos\\theta$. Figure [angle] shows the resulting $E_y$ field for a laser driven at an angle of $\\pi / 8$. Note that since the boundary conditions in the code are derived for propagation perpendicular to the boundary, there will be artefacts on the scale of the grid for lasers driven at an angle.\n  Using this technique it is also possible to focus a laser. This is done by using the same technique as above but making the angle of propagation, $\\theta$, a function of $y$ such that the laser is focused to a point along the $x$-axis. A simple example is given here.\nRestarting EPOCH from previous output dumps Another possible way of setting up initial conditions in EPOCH is to load in a previous output dump and use it to specify initial conditions for the code. The effect of this is to restart the code from the state that it was in when the dump was made. To do this, you just set the field \u0026ldquo;restart_snapshot\u0026rdquo; in the control block to the number of the output dump from which you want the code to restart. Because of the way in which the code is written you cannot guarantee that the code will successfully restart from any output dump. To restart properly, the following must have been dumped\n Particle positions. Particle momenta. Particle species. Particle weights. Relevant parts of the electric field (If for example it is known that ez == 0 then it is not needed). Relevant parts of the magnetic field.  It is possible to use the manual particle control part of the initial conditions to make changes to a restarted initial condition after the restart dump is loaded. The output files don\u0026rsquo;t include all of the information needed to restart the code fully since some of this information is contained in the input deck. However, a restart dump also contains a full copy of the input deck used and this can be unpacked before running the code. If specific \u0026ldquo;restart\u0026rdquo; dumps are specified in the input deck, or the \u0026ldquo;force_final_to_be_restartable\u0026rdquo; flag is set then in some cases the output is forced to contain enough information to output all the data. These restart dumps can be very large, and also override the \u0026ldquo;dumpmask\u0026rdquo; parameter specified for a species and output the data for that species anyway.\nParameterising input decks The simplest way to allow someone to use EPOCH as a black box is to give them the input.deck files that control the setup and initial conditions of the code. The input deck is simple enough that a quick read through of the relevant section of the manual should make it fairly easy for a new user to control those features of the code, but the initial conditions can be complex enough to be require significant work on the part of an unfamiliar user to understand. In this case, it can be helpful to use the ability to specify constants in an input deck to parameterise the file. So, to go back to a slight variation on an earlier example:\nbegin:species name = s1 # First set number_density in the range 0-\u0026amp;gt;1 # Cut down number_density in x direction number_density = if ((x gt -1) and (x lt 1), 1.0, 0.2) # Cut down number_density in y direction number_density = if ((y gt -1) and (y lt 1), number_density(s1), 0.2) # Multiply number_density by real particle number density number_density = number_density(s1) * 100.0 # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species begin:species name = s2 # Just copy the number_density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * 100.0 end:species  The particle number density (100.0) is hard coded into the deck file in several places. It would be easier if this was given to a new user as:\nbegin:constant particle_number_density = 100.0 # Particle number density end:constant begin:species name = s1 # First set number_density in the range 0-\u0026amp;gt;1 # Cut down number_density in x direction number_density = if ((x gt -1) and (x lt 1), 1.0, 0.2) # Cut down number_density in y direction number_density = if ((y gt -1) and (y lt 1), number_density(s1), 0.2) # Multiply number_density by real particle number density number_density = number_density(s1) * particle_number_density # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species begin:species name = s2 # Just copy the number density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species  It is also possible to parameterise other elements of initial conditions in a similar fashion. This is generally a good idea, since it makes the initial conditions easier to read an maintain.\nUsing spatially varying functions to further parameterise initial conditions Again, this is just a readability change to the normal input.deck file, but it also makes changing and understanding the initial conditions rather simpler. In this case, entire parts of the initial conditions are moved into a spatially varying constant in order to make changing them at a later date easier. For example:\nbegin:constant particle_number_density = 100.0 # Particle number density profile_x = if((x gt -1) and (x lt 1), 1.0, 0.2) profile_y = if((y gt -1) and (y lt 1), 1.0, 0.2) end:constant begin:species name = s1 # Multiply number_density by real particle number density number_density = particle_number_density * profile_x * profile_y # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species begin:species name = s2 # Just copy the number_density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species  This creates the same output as before. It is now trivial to modify the profiles later. For example:\nbegin:constant particle_number_density = 100.0 # Particle number density profile_x = gauss(x, 0.0, 1.0) profile_y = gauss(y, 0.0, 1.0) end:constant begin:species name = s1 # Multiply number_density by real particle number density number_density = particle_number_density * profile_x * profile_y # Set the temperature to be zero temp_x = 0.0 temp_y = temp_x(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species begin:species name = s2 # Just copy the number density for species s1 number_density = number_density(s1) # Just copy the temperature from species s1 temp_x = temp_x(s1) temp_y = temp_y(s1) # Set the minimum number_density for this species number_density_min = 0.3 * particle_number_density end:species  This changes the code to run with a Gaussian density profile rather then a step function. Again, this can be extended as far as required.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"6e24cc5c6c9e75395221d4d9df35cc7d","permalink":"/documentation/code_details/using_epoch_in_practice.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/using_epoch_in_practice.html","section":"documentation","summary":"Specifying initial conditions for particles using the input deck If the initial conditions for the plasma you wish to model can be described by a number density and temperature profile on the underlying grid then EPOCH can create an appropriate particle distribution for you.","tags":null,"title":"Using EPOCH in practice","type":"docs"},{"authors":null,"categories":null,"content":"To help reduce the impact of numerical noise in certain simulations, the delta-f method may be used in for specified particle species. The delta-f method effectively subtracts a background distribution $f_0$ when calculating currents due to the motion of markers; when the particle distribution function $f$ is close to $f_0$, this substantially reduces the statistical noise in the currents. Only current deposition is implemented differently, and the equations of motion of the markers are not modified in this delta-f approach.\nThe component of the currents associated with the background $f_0$ may be in principle be calculated analytically, but the delta-f implementation in EPOCH assumes (but does not check) that the total background current is zero.\nIn order to use the delta-f method EPOCH must be compiled with the #DELTAF_METHOD precompiler flag enabled. Standard input simulations are not affected by switching on this flag, but the user may then choose to treat certain species in the plasma using the delta-f method. To enable delta-f calculation for a species the background distribution function $f_0$ must be defined in the input block. $f_0$ is specified using variables similar to those used to specify $f$. The current implementation of delta-f allows only a spatially uniform drifting Maxwellian $f_0$, with temperatures $T_x$, $T_y$ and $T_z$ allowed to differ from each other. In 3D, for the case where the temperature in each direction is equal, we have $f_0 = n_0 (2 \\pi T)^{-3/2} \\exp\\left(\\frac{m (\\mathbf{v} - \\mathbf{v_d})^2}{2 k_B T } \\right).$\nThe parameters number_density_back, temp(x,y,z)_back and drift(x,y,z)_back in each species specification in the input deck set $f_0$. number_density_back=0 is the default and is equivalent to not using the delta-f method.\nFor example, the electron species component of an input deck solved using delta-f might be written:\nbegin:species name = electron charge = -1.0 mass = 1.0 frac = 0.3 temp = 1e8 temp_back = 1e8 number_density = 1e20 number_density_back = 1e20 end:species  Additional distribution function diagnostic options are supplied for the Delta-f version. Standard diagnostics work as usual based on the total distribution function $f$ but is is also possible to output the Delta-f component of the distribution functions by adding output_deltaf = T in dist_fn components of the input deck.\nAn example input deck is supplied in the 1D version as twostream_deltaf.deck. This uses the delta-f method to solve the weak-beam two stream instability. The bulk plasma species is solved using the delta-f method, since this evolve very little, and mostly supports the Lagnmuir waves that the weak beam interacts with. The relative change to the beam species is large, and the standard PIC method, rather than delta-f is used to model this species. A comparison of the electric field diagnostics between standard and delta-f simulations shows a substantial decrease in noise.\nFurther details of the method are provided in this pdf.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"db2bac938028317d0a415614391ad965","permalink":"/documentation/code_details/using_delta_f.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/using_delta_f.html","section":"documentation","summary":"To help reduce the impact of numerical noise in certain simulations, the delta-f method may be used in for specified particle species. The delta-f method effectively subtracts a background distribution $f_0$ when calculating currents due to the motion of markers; when the particle distribution function $f$ is close to $f_0$, this substantially reduces the statistical noise in the currents.","tags":null,"title":"Using delta f","type":"docs"},{"authors":null,"categories":null,"content":"Changes between version 3.1 and 4.0 Changes to the Makefile Some changes have been made to the Makefile. These are documented here. The following compile-time defines have been added to the Makefile:\n NO_IO PARTICLE_ID PARTICLE_ID4 COLLISIONS_TEST PHOTONS TRIDENT_PHOTONS PREFETCH  The following compile-time defines have been removed from the Makefile:\n COLLISIONS SPLIT_PARTICLES_AFTER_PUSH PARTICLE_IONISE  Major features and new blocks added to the input deck   CPML boundary conditions  Thermal boundary conditions  Collisions  QED  Subsets  Ionisation  Single-precision output  Multiple output blocks  Particle migration  Additional output block parameters The following parameters have also been added to the \u0026ldquo;output\u0026rdquo; block (see here):\n dump_first dump_last force_first_to_be_restartable ejected_particles absorption id name restartable  Other additions to the input deck   npart_per_cell  dir_{xy,yz,zx}_angle  particle_tstart  identify  Finally, the input deck now has a method for writing continuation lines. If the deck contains a \u0026ldquo;\u0026quot; character then the rest of the line is ignored and the next line becomes a continuation of the current one.\nChanges between version 4.0 and 4.3 Changes to the Makefile Some changes have been made to the Makefile. These are documented here . The following compile-time define has been added to the Makefile:\n MPI_DEBUG  The following compile-time define has been removed from the Makefile:\n FIELD_DEBUG  Additions to the input deck The following parameters have been added to the \u0026ldquo;control\u0026rdquo; block of the input deck:\n nproc{x,y,z} smooth_currents field_ionisation use_exact_restart allow_cpu_reduce check_stop_file_frequency stop_at_walltime stop_at_walltime_file simplify_deck print_constants The \u0026ldquo;restart_snapshot\u0026rdquo; parameter now accepts filenames  The following parameters have been added to the \u0026ldquo;output\u0026rdquo; block of the input deck:\n disabled time_start time_stop nstep_start nstep_stop dump_at_times dump_at_nsteps dump_cycle dump_cycle_first_index filesystem file_prefix rolling_restart particle_energy relativistic_mass gamma total_energy_sum optical_depth qed_energy trident_optical_depth The default value of \u0026ldquo;dump_first\u0026rdquo; is now \u0026ldquo;T\u0026rdquo;  The following parameter has been added to the \u0026ldquo;collisions\u0026rdquo; block of the input deck:\n collisional_ionisation  The following parameter has been added to the \u0026ldquo;qed\u0026rdquo; block of the input deck:\n use_radiation_reaction  The following parameter has been added to the \u0026ldquo;species\u0026rdquo; block of the input deck:\n immobile  The following parameters were changed in the \u0026ldquo;laser\u0026rdquo; block of the input deck:\n The \u0026ldquo;phase\u0026rdquo; parameter can now be time varying The \u0026ldquo;profile\u0026rdquo; parameter can now be time varying  The following parameters have been added to the list of pre-defined constants.\n nproc_{x,y,z} nsteps t_end cc  There has also been a new \u0026ldquo;output_global\u0026rdquo; block added to the input deck.\nChanges in behaviour which are not due to changes in the input deck  The species \u0026ldquo;drift\u0026rdquo; property is now applied to particles whilst the moving window model is active. In previous versions of the code, this property was ignored once the moving window began. Ionisation species now inherit their \u0026ldquo;dumpmask\u0026rdquo;. See here for details. Default values for ignorable directions were added. This change allows submitting 3D or 2D input decks to a 1D version of and 3D input decks to a 2D version of . Any references to y/z will be set equal to zero unless overridden by a deck constant. Other y/z values also assume sensible defaults, eg. 1 grid cell, 1 metre thick, etc. Automatic byte swapping is carried out by the SDF library. The library now checks the endianness of the SDF file and byte-swaps the data if required. \u0026ldquo;qed\u0026rdquo; blocks may now be present even if the code was not compiled using the \u0026ldquo;-DPHOTONS\u0026rdquo; flag. The code will only halt if \u0026ldquo;use_qed=T\u0026rdquo; inside the \u0026ldquo;qed\u0026rdquo; block. The code now checks for the Data directory in a file named \u0026ldquo;USE_DATA_DIRECTORY\u0026rdquo; before prompting at the command-line. This allows the code to be run without waiting for input at the command-line. The field and particle grids are now automatically written to SDF output files if they are needed. The Data directory may now contain a \u0026lsquo;/\u0026rsquo; character.  Changes between version 4.3 and 4.8 Changes to the Makefile Some changes have been made to the Makefile. These are documented here. The following compile-time define has been added to the Makefile:\n PER_SPECIES_WEIGHT NO_TRACER_PARTICLES NO_PARTICLE_PROBES PARSER_CHECKING  The following compile-time define has been removed from the Makefile:\n PER_PARTICLE_WEIGHT TRACER_PARTICLES PARTICLE_PROBES  Additions to the input deck The following parameters have been added to the \u0026ldquo;control\u0026rdquo; block of the input deck:\n allow_missing_restart print_eta_string n_zeros  The following parameters have been added to the \u0026ldquo;output\u0026rdquo; block of the input deck):\n weight (synonym for particle_weight)  The following parameters have been added to the \u0026ldquo;output_global\u0026rdquo; block of the input deck:\n dump_first_after_restart  The following parameters have been added to the \u0026ldquo;subset\u0026rdquo; block of the input deck:\n skip, skip_x,y,z  Changes between version 4.8 and 4.9 New capabilities Version 4.9 adds significant new capabilities as follows:\n delta-f version: particle distributions can be expressed as $f_0 + f_1$ where $f_0$ is a specified background plasma and all simulation particles are used to describe the $f_1$ component, documented in . selectable field solvers: 3 new solvers have been added for fields, fully documented in .  Changes to the Makefile Some changes have been made to the Makefile. These are documented in . The following compile-time define has been added to the Makefile:\n DELTAF_METHOD DELTAF_DEBUG USE_ISATTY  Additions to the input deck The following alterations were made to the input deck:\n ioniz* (with a \u0026ldquo;z\u0026rdquo;) aliases have been added for ionis* keywords. y and z parameters can now appear in the input deck in EPOCH 1D and 2D.  A new deck block has been added. The particles_from_file block allows loading of custom particle data from raw binary data files. See for details. This block accepts the following parameters:\n species {xyz}_data w_data {xyz}_data id{4,8}_data offset  The following parameters have been added to the \u0026ldquo;control\u0026rdquo; block of the input deck (see ):\n maxwell_solver use_current_correction  The following parameters have been added to the \u0026ldquo;species\u0026rdquo; block of the input deck (see ):\n maxwell_solver number_density_back drift_{x,y,z}_back temp_{x,y,z}_back temp_{x,y,z}_back_ev temp_back temp_back_ev  The following parameters have been added to the \u0026ldquo;dist_fn' block of the input deck (see ):\n dir may now take the value mod_p restrict_mod_p  Changes not resulting from changes to the deck  Lasers can be specified with time-varying frequency profile. The existing subset blocks can now be applied to field and derived grid variables. If spatial restrictions are used, subsections will be output, along with a corresponding grid. Note that these are not compatible with the \u0026ldquo;skip\u0026rdquo; parameter to subset blocks. The dist_fn block \u0026ldquo;range\u0026rdquo; keyword is now respected for spatial directions, allowing a spatial subset of the distribution function to be output directly. Some corrections were applied to calculation of thermal boundary conditions for particles. The load balancer may now be disabled by setting a 0 or negative threshold.  Changes between version 4.9 and 4.10 New capabilities Version 4.10 adds the following new capabilities:\n Time varying particle injectors. See here Per-species particle boundaries. You can now specify bc_x_min and bc_x_max to a species block. This overrides the global boundaries for that species. See here Added \u0026ldquo;particles_per_cell\u0026rdquo; output diagnostic. See here  Changes between version 4.10 and 4.11 New capabilities Version 4.11 adds the following new capabilities:\n Added time dependent moving window. No new input deck parameters have been added, but it is now possible to specify \u0026ldquo;window_v_x\u0026rdquo; to be a function that varies in time. See here If \u0026ldquo;print_constants=T\u0026rdquo; in the control block (see here) deck constants are now output to a separate file named \u0026ldquo;const.status\u0026rdquo;. This allows for easier post-processing. Added COMPILER=auto option to automatically detect compiler. See here  The following correction has been made:\n Fractional numbers of particles-per-cell now function as expected when used in conjunction with the moving window.  Changes between version 4.11 and 4.12 New capabilities Version 4.12 adds the following new capabilities:\n Added \u0026ldquo;average_weight\u0026rdquo; output diagnostic. See here Removed the \u0026ldquo;PARTICLE_COUNT_UPDATE\u0026rdquo; Makefile flag and replaced it with a \u0026ldquo;use_particle_count_update\u0026rdquo; parameter in the control block. See here Added \u0026ldquo;use_flux_maxwellian\u0026rdquo; option to the \u0026ldquo;injector\u0026rdquo; block. See here Added \u0026ldquo;lehe_{x,y,z}\u0026rdquo; flags to the \u0026ldquo;maxwell_solver\u0026rdquo; option in the control block. See here Added \u0026ldquo;use_accurate_n_zeros\u0026rdquo; control block parameter. See here Added \u0026ldquo;custom\u0026rdquo; flag to the \u0026ldquo;maxwell_solver\u0026rdquo; option in the control block. See here and here Added the \u0026ldquo;WORK_DONE_INTEGRATED\u0026rdquo; Makefile flag and corresponding dumpmask directives \u0026ldquo;work_{x,y,z}\u0026rdquo; and \u0026ldquo;work_{x,y,z}_total\u0026rdquo;. These add a diagnostic for the work done on a particle by the electric field. See here and here.  Changes between version 4.12 and 4.14 New capabilities Version 4.14 adds the following new capabilities:\n Added the \u0026ldquo;reset_walltime\u0026rdquo; flag to the control block. See here Changed the default value of \u0026ldquo;print_eta_string\u0026rdquo; to \u0026ldquo;T\u0026rdquo; in the control block. Added the ability to request an output dump at run time. See here Added the \u0026ldquo;window_stop_time\u0026rdquo; parameter to the window block. See here Added the \u0026ldquo;atan2\u0026rdquo; function to the maths parser. See here Added \u0026ldquo;dlb_maximum_interval\u0026rdquo; parameter to the control block. See here Added \u0026ldquo;dlb_force_interval\u0026rdquo; parameter to the control block. See here Added \u0026ldquo;balance_first\u0026rdquo; parameter to the control block. See here Added y and z versions of the \u0026ldquo;bc_x_min_after_move\u0026rdquo; and \u0026ldquo;bc_x_max_after_move\u0026rdquo; parameters to the window block. See here Added a \u0026ldquo;dump_at_walltimes\u0026rdquo; parameter to the output block. See here Added \u0026ldquo;walltime_start\u0026rdquo; and \u0026ldquo;walltime_stop\u0026rdquo; parameters to the output block and output_global block. See here and here Added \u0026ldquo;walltime_interval\u0026rdquo; parameter to the output block. See here Added the Higuera-Cary particle push. This can be enabled using the \u0026ldquo;HC_PUSH\u0026rdquo; Makefile flag. See here.  Changes between version 4.14 and 4.15  Added averaging of \u0026ldquo;poynt_flux\u0026rdquo; and \u0026ldquo;ekflux\u0026rdquo; variables. The initial problem setup can now be load-balanced before any particles are loaded. This enables some heavily imbalanced setups to be run that were not previously possible.  Added the \u0026ldquo;use_pre_balance\u0026rdquo; flag to the control block. See here   Allow the load balancer to adjust the processor topology  Added the \u0026ldquo;use_optimal_layout\u0026rdquo; flag to the control block. See here   Added control block option \u0026ldquo;use_more_setup_memory\u0026rdquo; for controlling the way that species are setup. See here Added strided multipass digital current filtering (See here). This adds the following flags to the control block.  smooth_iterations smooth_compensation smooth_strides   Added persistent subsets. See here. This adds the following flags to the subset block  persist_start_time persist_start_step   Added loading of relativistic particle species using the Maxwell-Jüttner distribution. See here. This adds the following flags to the species block  use_maxwell_juttner fractional_tail_cutoff   Added loading of particle species using an arbitrary distribution function for sampling the momentum components. See here. This adds the following flags to the species block  dist_fn dist_fn_p{x,y,z}_range   Added \u0026ldquo;temperature_{x,y,z}\u0026rdquo; derived output variables to the output block. See here  Changes between version 4.15 and 4.16    Added \u0026ldquo;number_density\u0026rdquo; aliases for \u0026ldquo;density\u0026rdquo; in the species and injector blocks (see here and  here).  These aliases include:\n   number_density for density promote_number_density for promote_density demote_number_density for demote_density number_density_min for density_min number_density_max for density_max number_density_back for density_back    Replaced \u0026ldquo;USE_ISATTY\u0026rdquo; Makefile flag with \u0026ldquo;NO_USE_ISATTY\u0026rdquo;. See here.\n  Added \u0026ldquo;NO_MPI3\u0026rdquo; Makefile flag. See here.\n  Added a \u0026ldquo;zero_current\u0026rdquo; alias for \u0026ldquo;tracer\u0026rdquo; in the species blocks. See here. The use of \u0026ldquo;tracer\u0026rdquo; has now been deprecated and will be removed in version 5.0. At that time, the compiler flag will also be renamed.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"7a4fff90d083d4c470fb9cfca820451a","permalink":"/documentation/code_details/previous_versions.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/code_details/previous_versions.html","section":"documentation","summary":"Changes between version 3.1 and 4.0 Changes to the Makefile Some changes have been made to the Makefile. These are documented here. The following compile-time defines have been added to the Makefile:","tags":null,"title":"Previous versions","type":"docs"},{"authors":null,"categories":null,"content":"Using IDL to visualise data The EPOCH distribution comes with procedures for loading and inspecting SDF self-describing data files. The IDL routines are held in the SDF/IDL/ directory. There is also a procedure named Start.pro in each of the epoch\\*d/ directories which is used to set up the IDL environment.\nTo load data into IDL, navigate to one of the base directories (eg. epoch/epoch2d/ where epoch/ is the directory in which you have checked out the git repository) and type the following:\n$\u0026amp;gt; idl Start.pro IDL Version 8.1 (linux x86_64 m64). (c) 2011, ITT Visual Information Solutions Installation number: . +Licensed for use by: STAR404570-5University of Warwick . % Compiled module: TRACKEX_EVENT. % Compiled module: ISOPLOT. % Compiled module: READVAR. % Compiled module: LOADSDFFILE. % Compiled module: SDFHANDLEBLOCK. % Compiled module: SDFGETPLAINMESH. % Compiled module: SDFGETLAGRANMESH. % Compiled module: SDFGETPOINTMESH. % Compiled module: SDFGETPLAINVAR. % Compiled module: SDFGETPOINTVAR. % Compiled module: SDFGETCONSTANT. % Compiled module: SDFCHECKNAME. % Compiled module: INIT_SDFHELP. % Compiled module: GETDATA. % Compiled module: GETSTRUCT. % Compiled module: EXPLORE_DATA. % Compiled module: EXPLORE_STRUCT. % Compiled module: LIST_VARIABLES. % Compiled module: QUICK_VIEW. % Compiled module: GET_WKDIR. % Compiled module: SET_WKDIR. % Compiled module: INIT_STARTPIC. % Compiled module: INIT_WIDGET. % Compiled module: GENERATE_FILENAME. % Compiled module: COUNT_FILES. % Compiled module: LOAD_RAW. % Compiled module: GET_SDF_METATEXT. % Compiled module: VIEWER_EVENT_HANDLER. % Compiled module: EXPLORER_EVENT_HANDLER. % Compiled module: XLOADCT_CALLBACK. % Compiled module: LOAD_DATA. % Compiled module: DRAW_IMAGE. % Compiled module: LOAD_META_AND_POPULATE_SDF. % Compiled module: CLEAR_DRAW_SURFACE. % Compiled module: SDF_EXPLORER. % Compiled module: EXPLORER_LOAD_NEW_FILE. % Compiled module: CREATE_SDF_VISUALIZER. % Compiled module: VIEWER_LOAD_NEW_FILE. % LOADCT: Loading table RED TEMPERATURE IDL\u0026amp;gt;  This starts up the IDL interpreter and loads in all of the libraries for loading and inspecting SDF files.\nWe begin by inspecting SDF file contents and finding out what variables it contains. To do this we execute the list variables procedure call which is provided by the EPOCH IDL library.\nAt each timestep for which EPOCH is instructed to dump a set of variables a new data file is created. These files take the form 0000.sdf. For each new dump the number is incremented. The procedure call accepts up to two arguments. The first argument is mandatory and specifies the number of the SDF file to be read in. This argument can be any integer from 0 to 9999. It is padded with zeros and the suffix \u0026lsquo;.sdf\u0026rsquo; appended to the end to give the name of the data file. eg. 99 ⇒ \u0026lsquo;0099.sdf\u0026rsquo;. The next arguments is optional. The keyword wkdir specifies the directory in which the data files are located. If this argument is omitted then the currently defined global default is used. Initially, this takes the value Data but this can be changed using the set_wkdir procedure and queried using the get_wkdir() function.\nIDL\u0026amp;gt; list_variables,0,\u0026amp;quot;Data\u0026amp;quot; Available elements are 1) EX (ELECTRIC_FIELD) : 2D Plain variable 2) EY (ELECTRIC_FIELD) : 2D Plain variable 3) EZ (ELECTRIC_FIELD) : 2D Plain variable 4) BX (MAGNETIC_FIELD) : 2D Plain variable 5) BY (MAGNETIC_FIELD) : 2D Plain variable 6) BZ (MAGNETIC_FIELD) : 2D Plain variable 7) JX (CURRENT) : 2D Plain variable 8) JY (CURRENT) : 2D Plain variable 9) JZ (CURRENT) : 2D Plain variable 10) WEIGHT_ELECTRON (PARTICLES) : 1D Point variable 11) WEIGHT_PROTON (PARTICLES) : 1D Point variable 12) PX_ELECTRON (PARTICLES) : 1D Point variable 13) PX_PROTON (PARTICLES) : 1D Point variable 14) GRID_ELECTRON (GRID) : 2D Point mesh 15) GRID_PROTON (GRID) : 2D Point mesh 16) EKBAR (DERIVED) : 2D Plain variable 17) EKBAR_ELECTRON (DERIVED) : 2D Plain variable 18) EKBAR_PROTON (DERIVED) : 2D Plain variable 19) CHARGE_DENSITY (DERIVED) : 2D Plain variable 20) NUMBER_DENSITY (DERIVED) : 2D Plain variable 21) NUMBER_DENSITY_ELECTRON (DERIVED) : 2D Plain variable 22) NUMBER_DENSITY_PROTON (DERIVED) : 2D Plain variable 23) GRID (GRID) : 2D Plain mesh 24) GRID_EN_ELECTRON (GRID) : 1D Plain mesh 25) EN_ELECTRON (DIST_FN) : 3D Plain variable 26) GRID_X_EN_ELECTRON (GRID) : 2D Plain mesh 27) X_EN_ELECTRON (DIST_FN) : 3D Plain variable 28) GRID_X_PX_ELECTRON (GRID) : 2D Plain mesh 29) X_PX_ELECTRON (DIST_FN) : 3D Plain variable IDL\u0026amp;gt;  Each variable in the SDF self-describing file format is assigned a name and a class as well as being defined by a given variable type. The \u0026ldquo;list_variables\u0026rdquo; procedure prints out the variable name followed by the variable\u0026rsquo;s class in parenthesis. Following the colon is a description of the variable type.\nTo retrieve the data, you must use the getdata() function call. The function must be passed a snapshot number, either as the first argument or as a keyword parameter \u0026ldquo;snapshot\u0026rdquo;. It also accepts the wkdir as either the second argument or the keyword parameter \u0026ldquo;wkdir\u0026rdquo;. If it is omitted altogether, the current global default is used. Finally, it accepts a list of variables or class of variables to load. Since it is a function, the result must be assigned to a variable. The object returned is an IDL data structure containing a list of named variables.\nTo load either a specific variable or a class of variables, specify the name prefixed by a forward slash. It should be noted here that the IDL scripting language is not case sensitive so $P_x$ can be specified as either \u0026ldquo;/Px\u0026rdquo; or \u0026ldquo;/px\u0026rdquo;.\nWe will now load and inspect the \u0026ldquo;Grid\u0026rdquo; class, this time omitting the optional \u0026ldquo;wkdir\u0026rdquo; parameter. This time we will load from the third dump file generated by the EPOCH run, which is found in the file 0002.sdf since the dump files are numbered starting from zero.\nInspecting Data IDL\u0026amp;gt; gridclass = getdata(1,/grid) IDL\u0026amp;gt; help,gridclass,/structures ** Structure \u0026amp;lt;22806408\u0026amp;gt;, 11 tags, length=536825024, data length=536825016, refs=1: FILENAME STRING 'Data/0001.sdf' TIMESTEP LONG 43 TIME DOUBLE 5.0705572e-15 GRID_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID_PROTON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] X DOUBLE Array[1024] Y DOUBLE Array[512] GRID_EN_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID_X_EN_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] GRID_X_PX_ELECTRON STRUCT -\u0026amp;gt; \u0026amp;lt;Anonymous\u0026amp;gt; Array[1] IDL\u0026amp;gt; help,gridclass.grid,/structures ** Structure \u0026amp;lt;1701168\u0026amp;gt;, 5 tags, length=12376, data length=12376, refs=2: X DOUBLE Array[1025] Y DOUBLE Array[513] LABELS STRING Array[2] UNITS STRING Array[2] NPTS LONG Array[2]  Here we have used IDL\u0026rsquo;s built in \u0026ldquo;help\u0026rdquo; routine and passed the \u0026ldquo;/structures\u0026rdquo; keyword which prints information about a structure\u0026rsquo;s contents rather than just the structure itself.\nSince \u0026ldquo;Grid\u0026rdquo; is a class name, all variables of that class have been loaded into the returned data structure. It is a nested type so many of the variables returned are structures themselves and those variables may contain structures of their own.\nThe \u0026ldquo;Grid\u0026rdquo; variable itself contains x\u0026quot; and \u0026ldquo;y\u0026rdquo; arrays containing the $x$ and $y$ coordinates of the 2D cartesian grid. The other variables in \u0026ldquo;Grid\u0026rdquo; the structure are metadata used to identify the type and properties of the variable. In order to access the \u0026ldquo;Grid\u0026rdquo; variable contained within the \u0026ldquo;gridclass\u0026rdquo; data structure we have used the \u0026ldquo;.\u0026rdquo; operator. In a similar way, we would access the \u0026ldquo;x\u0026rdquo; array contained within the \u0026ldquo;Grid\u0026rdquo; variable using the identifier \u0026ldquo;gridclass.grid.x\u0026rdquo;.\nGetting Help in IDL IDL is a fairly sophisticated scripting environment with a large library of tools for manipulating data. Fortunately, it comes with a fairly comprehensive array of documentation. This can be accessed by typing ? at the IDL prompt.\nIDL\u0026amp;gt; ? % ONLINE_HELP: Starting the online help browser. IDL\u0026amp;gt;  The documentation is divided into books aimed at users or developers and is fully searchable and cross indexed.\nManipulating And Plotting Data Once the data has been loaded from the SDF file we will want to extract the specific data we wish to analyse, perhaps perform some mathematical operations on it and then plot the results.\nTo do this we must learn a few basic essentials about the IDL scripting language. Since we are all familiar with the basic concepts shared by all computer programming languages, I will just provide a brief overview of the essentials and leave other details to the excellent on-line documentation.\nIDL supports multidimensional arrays similar to those found in the FORTRAN programming language. Whole array operations are supported such as \u0026ldquo;5*array\u0026rdquo; to multiply every element of \u0026ldquo;array\u0026rdquo; by 5. Also matrix operations such as addition and multiplication are supported.\nThe preferred method for indexing arrays is to use brackets. It is possible to use parenthesis instead but this usage is deprecated. Column ordering is the same as that used by FORTRAN, so to access the $(i,j,k)$th element of an array you would use \u0026ldquo;array[i,j,k]\u0026rdquo;. IDL arrays also support ranges so \u0026ldquo;array[5:10,3,4]\u0026rdquo; will return a one dimensional array with five elements. \u0026ldquo;array[5:*]\u0026rdquo; specifies elements five to $n$ of an $n$ element array. \u0026ldquo;array[*,3]\u0026rdquo; picks out the third row of an array.\nThere are also a wide range of routines for querying and transforming arrays of data. For example, finding minimum and maximum values, performing FFTs, etc. These details can all be found by searching the on-line documentation.\nFinally, IDL is a full programming language so you can write your own functions and procedures for processing the data to suit your needs.\n1D Plotting in IDL The most commonly performed plot and perhaps the most useful data analysis tool is the 1D plot. In IDL, this is performed by issuing the command plot,x,y where \u0026ldquo;x\u0026rdquo; and \u0026ldquo;y\u0026rdquo; are one dimensional arrays of equal length. For each element \u0026ldquo;x[i]\u0026rdquo; plotted on the $x$-axis the corresponding value \u0026ldquo;y[i]\u0026rdquo; is plotted along the $y$-axis. As a simple example:\nIDL\u0026amp;gt; plot,[1,2,3],[2,2,5]  Gives rise to the following plot:\nAs a more concrete example, we will now take a one-dimensional slice through the 2D array \u0026ldquo;Number Density\u0026rdquo; read in from our SDF data file. In this example we will give the $x$ and $y$ axes labels by passing extra parameters to the \u0026ldquo;plot\u0026rdquo; routine. A full list of parameters can be found in the on-line documentation. In this example we also make use of the \u0026ldquo;$\u0026rdquo; symbol which is IDL\u0026rsquo;s line continuation character.\nIDL\u0026amp;gt; data = getdata(0) IDL\u0026amp;gt; plot,data.x,data.number_density[*,256],xtitle='x', $ IDL\u0026amp;gt; ytitle='number density'  This command generates the following plot:\nPostscript Plots The plots shown so far have just been screen-shots of the interactive IDL plotting window. These are fairly low quality and could included as figures in a paper.\nIn order to generate publication quality plots, we must output to the postscript device. IDL maintains a graphics context which is set using set plot the command. The two most commonly used output devices are \u0026ldquo;x\u0026rdquo; which denotes the X-server and \u0026ldquo;ps\u0026rdquo; which is the postscript device. Once the desired device has been selected, various attributes of its behaviour can be altered using the device procedure. For example, we can set the output file to use for the postscript plot. By default, a file with the name \u0026ldquo;idl.ps\u0026rdquo; is used.\nNote that this file is not fully written until the postscript device is closed using the device,/close command. When we have finished our plot we can resume plotting to screen by setting the device back to \u0026ldquo;x\u0026rdquo;.\nIDL\u0026amp;gt; set_plot,'ps' IDL\u0026amp;gt; device,filename='out.ps' IDL\u0026amp;gt; plot,data.x,data.number_density[*,256],xtitle='x', $ IDL\u0026amp;gt; ytitle='number density',charsize=1.5 IDL\u0026amp;gt; device,/close IDL\u0026amp;gt; set_plot,'x'  This set of commands results in the following plot being written to a file named \u0026ldquo;out.ps\u0026rdquo;.\nBy default, IDL draws its own set of fonts called \u0026ldquo;Hershey vector fonts\u0026rdquo;. Much better looking results can be obtained by using a postscript font instead. These options are passed as parameters to the device procedure. More details can be found in the on-line documentation under \u0026ldquo;Reference Guides $\\Rightarrow$ IDL Reference Guide $\\Rightarrow$ Appendices $\\Rightarrow$ Fonts\u0026rdquo;.\nContour Plots in IDL Whilst 1D plots are excellent tools for quantitive analysis of data, we can often get a better qualitative overview of the data using 2D or 3D plots.\nOne commonly used plot for 2D is the contour plot. The aptly named contour,z,x,y procedure takes a 2D array of data values, \u0026ldquo;z\u0026rdquo;, and plots them against $x$ and $y$ axes which are specified in the 1D \u0026ldquo;x\u0026rdquo; and \u0026ldquo;y\u0026rdquo; arrays. The number of contour lines to plot is specified by the \u0026ldquo;nlevels\u0026rdquo; parameter. If the \u0026ldquo;/fill\u0026rdquo; parameter is used then IDL will fill each contour level with a solid colour rather than just drawing a line at the contour value.\nThe example given below plots a huge number of levels so that a smooth looking plot is produced. \u0026ldquo;xstyle=1\u0026rdquo; requests that the $x$ axes drawn exactly matches the data in the variable rather than just using a nearby rounded value and similarly for \u0026ldquo;ystyle=1\u0026rdquo;.\nIDL\u0026amp;gt; n=100 IDL\u0026amp;gt; levels=max(data.number_density)*findgen(n)/(n-1) IDL\u0026amp;gt; colors=253.*findgen(n)/(n-1)+1 IDL\u0026amp;gt; contour,data.number_density,data.x,data.y,xstyle=1,ystyle=1, $ IDL\u0026amp;gt; levels=levels,/fill,c_colors=colors  Issuing these commands gives us the contour plot shown below. Note that the colour table used is not the default one but has been constructed to be similar to the one used by VisIt.\nShaded Surface Plots in IDL Another method for visualising 2D datasets is to produce a 3D plot in which the data is elevated in the $z$ direction by a height proportional to its value. IDL has two versions of the surface plot. surface produces a wireframe plot and shade surf produces a filled and shaded one. As we can see from the following example, many of IDL\u0026rsquo;s plotting routines accept the same parameters and keywords.\nThe first command shown here, loadct,3, asks IDL to load the third colour table which is\u0026quot;RED_TEMPERATURE\u0026quot;.\nIDL\u0026amp;gt; loadct,3 IDL\u0026amp;gt; shade_surf,data.number_density,data.x,data.y,xstyle=1, $ IDL\u0026amp;gt; ystyle=1,xtitle='x',ytitle='y',ztitle='number density',charsize=3  Interactive Plotting Finally, in recent versions of IDL (not GDL) it is now possible to perform all of these plot types in an interactive graphical user interface. The corresponding procedures are launched with the commands iplot, icontour and isurface.\nIDL\u0026amp;gt; iplot,data.x,data.number_density[*,256]  IDL is an extremely useful tool but it also comes with a fairly hefty price tag. If you are not part of an organisation that will buy it for you then you may wish to look into a free alternative. It is also a proprietary tool and you may not wish to work within the restrictions that this imposes.\nThere are a number of free tools available which offer similar functionality to that of IDL, occasionally producing superior results.\nFor a simple drop-in replacement, the GDL project aims to be fully compatible and works with the existing EPOCH IDL libraries after a couple of small changes. Other tools worth investigating are \u0026quot;yorick\u0026quot; and \u0026quot;python\u0026quot; with the \u0026quot;SciPy\u0026quot; libraries. The python SDF reader documentation will be added soon. At present there is no SDF reader for yorick but one may be developed if there is sufficient demand.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"d20659b75d861bc3da354bc2a944ea6b","permalink":"/documentation/visualising_output/visualising_sdf_files_with_idl_or_gdl.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output/visualising_sdf_files_with_idl_or_gdl.html","section":"documentation","summary":"Using IDL to visualise data The EPOCH distribution comes with procedures for loading and inspecting SDF self-describing data files. The IDL routines are held in the SDF/IDL/ directory. There is also a procedure named Start.","tags":null,"title":"IDL or GDL","type":"docs"},{"authors":null,"categories":null,"content":"Using VisIt to visualise data LLNL VisIt LLNL\u0026rsquo;s VisIt software is a parallel data visualisation package ( LLNL VisIt). EPOCH comes with source code for the plug-in needed to allow VisIt to load the SDF output files which are generated by EPOCH. There are full manuals for VisIt which can be downloaded from the above link so no further details will be given here. To build the plug-in, first ensure that the visit binary is in the $PATH environment variable. Then simply type \u0026ldquo;make visit\u0026rdquo; in one of the epoch{1,2,3}d directories. For more experienced users of VisIt, the xml file which is used to generate the plug-in is supplied in the VisIt subdirectory, called SDF2.xml.\nWhilst IDL is an excellent tool for visualising 1D and 2D datasets, it is extremely poor when it comes to dealing with 3D data. For this purpose, we recommend the use of the \u0026quot;VisIt\u0026quot; visualisation tool.\nThe other great advantage that VisIt has over IDL is the ability to render in parallel, enabling the visualisation of huge datasets which IDL would be incapable of dealing with.\n Initially developed by the Department of Energy (DOE) Advanced Simulation and Computing Initiative (ASCI) Now developed and maintained by the Lawrence Livermore National Laboratory along with a group of external contributors Written in C++ and supports python and Java interfaces Available for UNIX (Irix, Tru64, AIX, Linux, Solaris), Mac OS X (10.3 - Current), and Windows platforms Open source and freely available under the BSD license Plots, operators and database readers are implemented as plugins allowing the VisIt to be dynamically extended at run-time Powerful set of tools for manipulating, analysing and visualising 3D datasets Parallel and distributed architecture for visualising huge data sets  Obtaining And Installing VisIt Both the source code and pre-compiled binaries are available for download from the projects web page which is found at the URL https://wci.llnl.gov/simulation/computer-codes/visit\nThere are full instructions for compiling the project from source code along with build scripts written to help ease the process. However, this is not recommended as it is an extremely large tool and the compilation takes hours to complete. It is usually far easier to download a pre-compiled binary which matches your system architecture.\nHowever, occasionally compilation may be a necessary step. Linux in particular is a moving target and it is not always possible to find a binary which matches the particular combination of libraries installed on your system.\nThe easiest way to install the VisIt tool is to ask the system administrator to do it for you. However, this may not always be the best option. The system in question may be run by someone who is not concerned with your particular software needs or has insufficient skills to deal with the task. In any case, VisIt has a fairly rapid release schedule and you may find that some functionality you need is not present in the version installed on the machine.\nFortunately, for all these scenarios it is usually quite easy to install a copy in your own home directory. Just find a binary on the web page https://wci.llnl.gov/codes/visit/executables.html which closely matches your machine and download it. This can be unpacked into your home directory with the command tar xzf visit2_10_2.linux-x86_64-ubuntu14.tar.gz . The actual name of the file will vary depending on which version you downloaded. This will unpack the VisIt binary into a subdirectory named visit/. Now all that is necessary is to add this to your search path. e.g. export PATH=$HOME/visit/bin:$PATH\nThese instructions illustrate the steps required for installing your own copy of VisIt when you have no other choice. VisIt is an extremely large program, so if a version is already available then it is usually better to use the installed version.\nThe CSC machines at Warwick have a recent version of VisIt installed which is available via the system. To make use of it you must first issue the command module load visit.\nCompiling The Reader Plugin One piece of compilation which is almost always necessary is that of the SDF reader plugin. This is shipped as source code in a subdirectory of the repository. It is located in the SDF/VisIt subdirectory of the main epoch directory. The reader will work for any SDF file generated by any code which uses the SDF I/O routines. You do not need a separate reader for each version of EPOCH.\nTo compile, first navigate to one of the epoch*d directories in your repository. Just type \u0026ldquo;make visit\u0026rdquo; and the build scripts should take care of the rest. The SDF reader plugin will be installed into the $HOME/.visit/linux-intel/plugins/databases/ directory on your system. Note that the linux-intel component will vary depending on your machine operating system and architecture.\nEach time you install a new version of VisIt you must recompile the reader to match the new installation. It will also occasionally be necessary to recompile when changes occur to the SDF data format or the reader plugin itself. The developers will notify users if this is the case, although it does no harm to regularly recompile the reader as a matter of course.\nWe will see later that it is possible to do remote data visualisation with VisIt in which the GUI is launched and interacted with on one machine and the data files are located on a separate machine entirely. In this situation the reader must be installed on the remote machine and must match the setup there. The setup on the local machine is unimportant. In fact it is not even necessary to have the plugin installed on the local machine. This is particularly useful when using a Windows environment to analyse data located on a remote UNIX workstation.\nLoading Data Into VisIt The most straightforward method for loading data into VisIt is to start the application and then browse the filesystem for the dataset you are interested in. This is done by selecting \u0026ldquo;File ⇒ Open file\u0026rdquo; from the VisIt menu bar. A file selection dialogue will appear allowing you to browse directories along with the options to filter the results according to a given regular expression and grouping options. By default, VisIt will attempt to group all files containing the same suffix and some kind of numbering system into a sort of virtual database.\nThe right-hand pane of this window shows a list of selected files which will appear in the main VisIt window when you are finished.\nAn alternative method of specifying the data file to open is to pass a command line option when the tool is launched. An example of this method is visit -o Data/0000.sdf. When the file is specified in this manner the list of files shown in the VisIt window will also include the full list of files in the dataset\u0026rsquo;s subdirectory and all the files in the current working directory. The other SDF files will be grouped together in a virtual database.\nYet another method for selecting the dataset to use is by opening a previously saved session file. We will discuss this further in a later section.\nOnce an SDF file has been successfully loaded the \u0026ldquo;Add\u0026rdquo; menu item will become un-greyed and the cycle numbers for each file in the virtual database will be displayed. If we navigate to one of the plot types we are able to select the variable to plot from a drop-down list.\nContour Plots in VisIt We will now replicate each of the plots which we generated using IDL in earlier sections. For reasons which will soon become clear we begin with the contour plot and move on to the 1D plot in the next section.\nHaving opened the same dataset we were using in the IDL discussion we now select the \u0026ldquo;Add\u0026rdquo; menu item. Notice that many of the plot types listed here are greyed out and cannot be selected. This is because many of the plots are dependent on the type or dimensionality of the variable to be plotted. If our dataset contains no variables which match the required properties for a plot, the plot menu will be disabled.\nFor the current dataset there is no \u0026ldquo;Boundary\u0026rdquo; plot available since this requires multi-material data and none of our variables meet that criteria.\nThe list contains a menu item for a \u0026ldquo;Contour\u0026rdquo; plot. We are not going to select this item since it only generates a contour plot with lines indicating each contour level and not a filled version. Instead we choose \u0026ldquo;Add ⇒ Pseudocolor ⇒ Derived ⇒ Number Density\u0026rdquo; and then hit the \u0026ldquo;Draw\u0026rdquo; button.\nThere are many settings which can alter the visual appearance of plots generated by VisIt. The first point of call is usually to open up the \u0026ldquo;Plot Attributes\u0026rdquo; or \u0026ldquo;Operator Attributes\u0026rdquo; dialogue corresponding to the plot in question. A simpler method for accomplishing this task is to double-click on the plot in the main VisIt menu pane which will launch the corresponding \u0026ldquo;Plot Attributes\u0026rdquo; dialogue.\nIf it is the operator attributes you wish to change, click on the white arrow on the left hand side of the plot in the main VisIt menu pane. This will drop down to reveal a list containing the plot and all operators acting on it. Double-clicking on an operator will launch the corresponding \u0026ldquo;Operator Attributes\u0026rdquo; dialogue.\nAnother important tool for controlling the appearance of plots can be found in \u0026ldquo;Controls ⇒ Annotation\u0026rdquo; from the VisIt menu bar. This allows all of the plot annotations to be modified such as the legend, title, axis labels, etc.\n1D Plotting in VisIt A 1D plot in VisIt is called a \u0026ldquo;Curve\u0026rdquo; plot. We already mentioned that this was greyed out because we have no one dimensional variables in our data file.\nThe solution to this dilemma is the lineout operator which extracts a one dimensional array from a 2D or 3D variable. This operator is selected by pressing the button with red and blue lines located at the top of the plot window.\nOnce the button has been pressed, we can click and drag anywhere in the \u0026ldquo;Pseudocolor\u0026rdquo; plot window. When we release the mouse button a new plot window pops up containing a \u0026ldquo;Curve\u0026rdquo; plot of the data just selected.\nIn order to change the attributes for this plot, we must first select Active window\u0026quot; number 2 in the main VisIt pane.\nShaded Surface Plots in VisIt Again, we will confusingly refuse to pick the obvious plot type for this task. There is \u0026ldquo;Surface\u0026rdquo; plot listed in the menu. However, most of the time the \u0026ldquo;Elevator\u0026rdquo; operator does what we want and also gives us more flexibility.\nThe first step is to do a \u0026ldquo;Pseudocolor\u0026rdquo; plot of \u0026ldquo;Number Density\u0026rdquo; as we did before. Next select the \u0026ldquo;Operator Attributes ⇒ Transforms ⇒ Elevate\u0026rdquo; menu item. In the pop up dialogue click on the \u0026ldquo;Elevation height relative to XY limits?\u0026rdquo; and then \u0026ldquo;Apply\u0026rdquo;. Click \u0026ldquo;Yes\u0026rdquo; when the warning dialogue pops up.\nTo make this plot look similar to the one generated by IDL, we have changed the colour table using \u0026ldquo;Controls ⇒ Color table\u0026rdquo;. We also changed the axis appearance with the annotations menu discussed earlier and changed the height of the elevation using the min and max operator attributes.\nCreating User-Defined Expressions VisIt comes with an extremely powerful method of manipulating data before visualising the results. The basic idea is that an array is transformed by applying a set of mathematical functions on all its elements and then the result is defined as a new variable. Once defined, this variable behaves in exactly the same way as any of the variables read from the data file.\nAs an example, we can combine the three components of electric field to generate a single electric field vector.\nNow when we return to the \u0026ldquo;Add\u0026rdquo; menu we see that the \u0026ldquo;Vector\u0026rdquo; and \u0026ldquo;Streamline\u0026rdquo; and plot types now have an entry for our newly defined vector.\nCreating Movies A compelling visualisation of numerically generated data is often made by combining a series of images into a movie. This can be an invaluable method for illustrating the basic behaviour of a system as it changes over time. Alternatively rotating around a 3D scene can sometimes give a much better idea of the structure in the model being presented. There can also be much to gain by constructing visual fly-throughs of a scene, dynamically slicing through sets of data or combinations of all these techniques.\nVisIt provides several facilities for generating movies from your data. The simplest of these is to select the \u0026ldquo;File ⇒ Save movie\u0026rdquo; menu item. This pops up a movie wizard which will walk you through the process of generating a simple linear movie based on the time-advancing snapshots represented by your virtual database of files. Alternatively you can select one of the pre-defined movie templates which manipulate the currently selected plot and create a movie from that.\nCreating a simple time advancing movie is as simple as walking through the wizard dialogue and selecting from the self-explanatory options presented to you.\nFor many uses, the wizard will give exactly the desired results. However it is occasionally useful to have a little more control over how the movie is created. In such cases it can be useful to specify an image format such as \u0026ldquo;PNG\u0026rdquo; to save to rather than \u0026ldquo;MPEG\u0026rdquo;. VisIt will then generate one image per frame and number them consecutively. At the end of the process the images can be converted into a movie using whatever tool best accomplishes the task.\nAnother useful tip is to select the \u0026ldquo;Later, tell me the command to run\u0026rdquo; radio button. This will output a long command which can run from a UNIX terminal screen. The advantage is that no X session is required so the command can be run in the background. It also becomes a simple task to interrupt the job at any point and resume it from where it left off at a later date. In a similar manner it is easy to resume a job which crashes half way through for any reason.\nMore complex movies can be created by using VisIt\u0026rsquo;s keyframing facility which allows you to change animation attributes such as view or plot attributes as the animation progresses. Further information about this somewhat complex task can be found in the on-line help.\nFinally, you can use VisIt\u0026rsquo;s python scripting interface to programmatically describe the details of each frame as the movie progresses. This approach offers far more flexibility in what can be achieved but is also much more involved and time consuming than the previous two methods. Again, further information on this subject can be found in the on-line help system.\nRemote Visualisation It was mentioned earlier that it is possible to perform remote visualisation using VisIt. This is a process in which the data files being interrogated reside on a different machine to the one on which the VisIt GUI runs and where the results are plotted.\nThis method of working can be extremely useful when the data is generated on a powerful machine located in an external environment such as a large cluster. Another common use is when EPOCH is executed on a UNIX machine and the desktop used for visualisation is running Windows.\nIt is sometimes possible to run a graphical tool on the remote machine and tunnel the X-server session through to the local machine but this can be quite slow and unstable. When connecting to a remote VisIt instance the only data which needs to be sent between machines is the pre-rendered image and a few simple plotting commands. Naturally, this can be a much faster approach.\nAlso, as mentioned before, it is possible to use a machine on which the reader plugin is difficult or impossible to compile for and connect to a machine on which the reader is already installed.\nIn order to use the remote visualisation facility, you must first set up a \u0026ldquo;Host profile\u0026rdquo; for the remote machine using the \u0026ldquo;Options ⇒ Host profiles\u0026rdquo; menu item. The pre-compiled binaries are shipped with a long list of pre-defined host profiles. These are unnecessary for anyone not affiliated and can safely be removed by deleting the directory $HOME/visit/current/.visit (assuming you have unpacked the VisIt tarball into your home directory).\nCreate a new profile by clicking on the \u0026ldquo;New Host\u0026rdquo; button and filling out some of the form fields. The important ones to change are \u0026ldquo;Host nickname\u0026rdquo;, \u0026ldquo;Remote host name\u0026rdquo;, \u0026ldquo;Host name aliases\u0026rdquo; and \u0026ldquo;Username\u0026rdquo;. If the visit binary is not in your default search path on the remote machine then you must specify its location by filling in the \u0026ldquo;Path to VisIt installation\u0026rdquo; field.\nNow click \u0026ldquo;Apply\u0026rdquo; and \u0026ldquo;Dismiss\u0026rdquo; followed by the \u0026ldquo;Options ⇒ Save Settings\u0026rdquo; menu item to ensure that the profile is saved for future sessions.\nData on the remote machine can now be loaded by selecting and picking the desired host profile from the drop down list of \u0026ldquo;Hosts\u0026rdquo;. VisIt will wait for the remote process to launch and then continue with the file selection procedure but now displaying files located on the remote machine rather than the local one. From this point on everything should work as before except you should see the name of the remote machine in the \u0026ldquo;Selected files\u0026rdquo; dialogue.\nParallel Visualisation Parallel visualisation is performed in almost exactly the same manner as remote visualisation. Again, you must create a host profile for the purpose except this time you need to set up a parallel launch profile in the \u0026ldquo;Launch Profiles\u0026rdquo; tab pane. Click the \u0026ldquo;New Profile\u0026rdquo; button, give the profile a name and then set the required options in the \u0026ldquo;Parallel\u0026rdquo; tab on the bottom section of the page. Selecting the \u0026ldquo;Launch parallel engine\u0026rdquo; radio button will allow you to set the various launch options which relate to the cluster on which the job will run.\nThe major difference now is due to the fact that VisIt must be launched by an external job script which fits in with the queueing system used by the parallel machine. Usually you will need to consult with the system administrator of the cluster to confirm which launch method and arguments to use.\nThe details of job launch can be better understood by reading through the \u0026ldquo;User documentation\u0026rdquo; section provided at 1 . Of particular help here is the \u0026ldquo;Getting VisIt to run in parallel\u0026rdquo; section and the \u0026ldquo;How VisIt Launching works\u0026rdquo; entry in the \u0026ldquo;Developer documentation\u0026rdquo; section.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"7d3774268a06227509196710f0882fd9","permalink":"/documentation/visualising_output/visualising_sdf_files_with_llnl_visit.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output/visualising_sdf_files_with_llnl_visit.html","section":"documentation","summary":"Using VisIt to visualise data LLNL VisIt LLNL\u0026rsquo;s VisIt software is a parallel data visualisation package ( LLNL VisIt). EPOCH comes with source code for the plug-in needed to allow VisIt to load the SDF output files which are generated by EPOCH.","tags":null,"title":"LLNL VisIt","type":"docs"},{"authors":null,"categories":null,"content":"Installing the python sdf readers To install the python sdf readers you need to have an installation of python (2 or 3) with the numpy library. The automated plotting library requires the matplotlib library. Both numpy and matplotlib are available through most system package managers or are installable through pip.\nOnce you have a working python install, just go into one of the epoch directories (epoch1d, epoch2d or epoch3d) and type\nmake sdfutils\nThis will build the SDF python library and install the sdf_helper wrapper and utility layer.\nUsing the sdf_helper wrapper layer The low level python SDF library is not user friendly, so a wrapper layer called sdf_helper has been written. This wrapper layer simplifies loading SDF files and provides simple plotting routines using matplotlib.\nImporting sdf_helper Importing sdf_helper is as simple as\nimport sdf_helper  In these examples, the numpy and matplotlib libraries are usually loaded too, and an alias is created for sdf_helper, so the boilerplate code looks like\nimport sdf_helper as sh import numpy as np import matplotlib.pyplot as plt  Loading an sdf file using sdf_helper To load a file, use the getdata function. This function takes either a string which it loads as a filename, so to load the file Data/0010.df you would run\nimport sdf_helper as sh data=sh.getdata('Data/0010.sdf')  or it takes a number which is the dump number, and optionally a second parameter which is the directory name as a string, so you would run\nimport sdf_helper as sh data=sh.getdata(10, 'Data')  Because memory is only allocated when needed in the SDF python reader there is no way of specifying which variables to load using getdata. All variables are available when the file is first loaded, and memory is allocated when the variable is first used.\nListing the available variables in an sdf file To see what variables are available use the list_variables method\nimport sdf_helper as sh data=sh.getdata('Data/0010.sdf') sh.list_variables(data)  This produces an output that looks something like\nCPUs_Current_rank \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [0] CPUs_Original_rank \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [2] Current_Jx \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Charge_Density \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Number_Density \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Number_Density_Left \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Derived_Number_Density_Right \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Electric_Field_Ex \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400] Grid_CPUs_Original_rank \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [3] Grid_CPUs_Original_rank_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [2] Grid_Grid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [401] Grid_Grid_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [400] Grid_x_px_Left \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [400, 200] Grid_x_px_Left_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [399, 199] Grid_x_px_Right \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [400, 200] Grid_x_px_Right_mid \u0026lt;class 'sdf.BlockPlainMesh'\u0026gt; [399, 199] Wall_time \u0026lt;class 'sdf.BlockConstant'\u0026gt; [1] dist_fn_x_px_Left \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400, 200] dist_fn_x_px_Right \u0026lt;class 'sdf.BlockPlainVariable'\u0026gt; [400, 200]  These are the names of the variables in the data structure. This example is taken from the supplied two_stream.deck example in 1D.\nWorking with the data in an SDF file You can access the underlying data using the names obtained from list_variables\nvariable = data.Electric_Field_Ex  This returns an instance of either sdf.BlockPlainVariable or sdf.BlockPointVariable depending on whether you have requested a grid variable (such as Ex, Ey or a distribution function) or a particle variable (such as particle momentum or weight). The raw contents of the variable is a numpy array. It is then available using the data element of these objects.\nimport numpy as np variable = data.Electric_Field_Ex raw = variable.data print(type(raw)) print(np.mean(raw))  produces the output\n\u0026lt;type 'numpy.ndarray'\u0026gt; -1.27980874427008e-06  Plotting using sdf_helper The sdf_helper wrapper script comes with some plotting routines. They are incomplete currently, but aim to provide as close as possible to press ready figures in a single command. You need the matplotlib library to use these routines, and they are only available for 1D and 2D data at present. To plot data, simply provide an sdf.BlockPlainVariable object to the routine plot_auto. An example of plotting a 1D variable, using the two_stream.deck example deck to generate the figures would be\nimport sdf_helper as sh import matplotlib.pyplot as plt plt.ion() data=sh.getdata('Data/0010.sdf') sh.plot_auto(data.Current_Jx)  This will produce a window similar to the image shown here, with slight difference depending on your version of matplotlib and your operating system. The code plt.ion() sets matplotlib to interactive mode, so control will be returned to you as soon as the plot has finished drawing.\n Example 1D plot generated by sdf_helper.plot_auto\nPlotting a 2D function is the same basic idea, and the code\nimport sdf_helper as sh import matplotlib.pyplot as plt plt.ion() data=sh.getdata('Data/0010.sdf') sh.plot_auto(data.dist_fn_x_px_Right, iso=0)  will produce the figure on the right. The procedure for variables from EPOCH2D data is exactly the same.\nChanging colour tables The easiest solution to changing colour tables is to set the global colour table. This is done by\nimport matplotlib.pyplot as plt plt.set_cmap(tablename)  where tablename is a string describing the colour table to be used. The available strings are given here\nSome bugs in matplotlib There are some bugs in matplotlib which can mean that sometimes the 2D images don\u0026rsquo;t render properly. If you get incorrect rendering, please try updating matplotlib to the latest version for your platform. If that doesn\u0026rsquo;t work then pass the parameter compatibility=True to the plot_auto routine. This may make the plot slightly less pretty, but tends to work on more platforms.\nCore Python library The SDF python reader allows you to read any SDF file and access any information within the file. It has very few user friendly features to assist working with the files. Some of the methods listed in the section on sdf_helper (notably list_variables) are not available when using the core library. Loading an sdf file with the core library has the following syntax\nimport sdf data=sdf.read(filename)  where filename is a string containing the name of the file to be loaded. This returns an sdf.BlockList object\nThe sdf.BlockList object The list_variables routine is added by the sdf_helper wrapper, but you can check what elements are in the file by simply typing\ndata.__dict__  Which will produce an output like the following example from EPOCH2D\n{'Header': {'filename': '/Users/phsiav/dev/epoch/epoch2d/Data/0005.sdf', 'file_version': 1, 'file_revision': 4, 'code_name': 'Epoch2d', 'step': 53, 'time': 2.5293132385759517e-14, 'jobid1': 1552896563, 'jobid2': 376, 'code_io_version': 1, 'restart_flag': False, 'other_domains': False, 'station_file': False}, 'Wall_time': \u0026lt;sdf.BlockConstant object at 0x11a012318\u0026gt;, 'Electric_Field_Ex': \u0026lt;sdf.BlockPlainVariable object at 0x11a012220\u0026gt;, 'Electric_Field_Ey': \u0026lt;sdf.BlockPlainVariable object at 0x11a012128\u0026gt;, 'Electric_Field_Ez': \u0026lt;sdf.BlockPlainVariable object at 0x11a012030\u0026gt;, 'Magnetic_Field_Bx': \u0026lt;sdf.BlockPlainVariable object at 0x117b2ceb8\u0026gt;, 'Magnetic_Field_By': \u0026lt;sdf.BlockPlainVariable object at 0x117b2cdc0\u0026gt;, 'Magnetic_Field_Bz': \u0026lt;sdf.BlockPlainVariable object at 0x117b2ccc8\u0026gt;, 'Grid_Grid': \u0026lt;sdf.BlockPlainMesh object at 0x117b2cbd0\u0026gt;, 'Grid_Grid_mid': \u0026lt;sdf.BlockPlainMesh object at 0x117b2cad8\u0026gt;, 'Grid_CPUs_Original_rank': \u0026lt;sdf.BlockPlainMesh object at 0x117b2c9e0\u0026gt;, 'Grid_CPUs_Original_rank_mid': \u0026lt;sdf.BlockPlainMesh object at 0x117b2c8e8\u0026gt;, 'CPUs_Original_rank': \u0026lt;sdf.BlockPlainVariable object at 0x117b2c7f0\u0026gt;, 'CPUs_Current_rank': \u0026lt;sdf.BlockPlainVariable object at 0x11a015128\u0026gt;}\nThe sdf.BlockPlainVariable object These objects represent the variables in the SDF file. It does not fully implement the dict property, so to inspect it\u0026rsquo;s contents you must use\ndir(data.Electric_Field_Ey)  which produces an output like\n['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'blocklist', 'data', 'data_length', 'datatype', 'dims', 'grid', 'grid_id', 'grid_mid', 'id', 'mult', 'name', 'stagger', 'units']\nThe key elements are data which contains the raw data for the variable stored as a numpy array, dims which is an array containing the number of elements in each dimension of the array and grid and grid_mid which refer to sdf.BlockPlainMesh objects that represent the grid axes that the variable is to be plotted against. Grid and grid_mid do similar but different things. Grid is an array of points corresponding to the edges of the computational cells, grid_mid to the midpoints. This means that all of the arrays in grid are one element longer than the arrays in grid_mid. To identify whether to use grid or grid_mid you must compare the sizes of the variable dims array to the sizes of the grid and grid_mid sizes and for each axis use the element of grid or grid_mid that has the same number of elements.\nImportant note! - 2D SDF data is loaded into Python rotated by 90 degrees compared to the original Fortran code that generated it.\nThe sdf.BlockPlainMesh object Once again you have to use the dir command to output the information about an sdf.BlockPlainMesh object, for example in EPOCH\ndir(data.Grid_Grid)  Which produces output like\n['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'blocklist', 'data', 'data_length', 'datatype', 'dims', 'extents', 'geometry', 'id', 'labels', 'mult', 'name', 'units']\nThe important element of this block is data which is a tuple of 1D numpy arrays corresponding to each coordinate axis of the grid.\nPlotting a variable using raw SDF and raw matplotlib  Warning - This is not our recommended suggestion for plotting. We recommend using our helper routines in sdf_helper*  import matplotlib.pyplot as plt import sdf data=sdf.read('Data/0005.sdf') ey = data.Electric_Field_Ey plt.pcolormesh(ey.grid_mid.data[0], ey.grid_mid.data[1], ey.data.T) plt.show()  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"a05a00db2d4350293a64a7343919d8df","permalink":"/documentation/visualising_output/python.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/visualising_output/python.html","section":"documentation","summary":"Installing the python sdf readers To install the python sdf readers you need to have an installation of python (2 or 3) with the numpy library. The automated plotting library requires the matplotlib library.","tags":null,"title":"Python","type":"docs"},{"authors":null,"categories":null,"content":"In this section we outline a few worked examples of setting up problems using the EPOCH input deck.\nElectron two stream instability An obvious simple test problem to do with EPOCH is the electron two stream instability. An example of a nice dramatic two stream instability can be obtained using EPOCH1D by setting the code with the following input deck file:\nbegin:control nx = 400 # Size of domain x_min = 0 x_max = 5.0e5 # Final time of simulation t_end = 1.5e-1 stdout_frequency = 400 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:constant drift_p = 2.5e-24 temp = 273 dens = 10 end:constant begin:species # Rightwards travelling electrons name = Right charge = -1 mass = 1.0 temp = temp drift_x = drift_p number_density = dens npart = 4 * nx end:species begin:species # Leftwards travelling electrons name = Left charge = -1 mass = 1.0 temp = temp drift_x = -drift_p number_density = dens npart = 4 * nx end:species begin:output # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties at particle positions particles = always px = always # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always ekbar = always mass_density = never + species charge_density = always number_density = always + species temperature = always + species end:output  In this example, the constant block sets up constants for the momentum space drift, the temperature and the electron number density. The two species blocks set up the two drifting Maxwellian distributions and the constant density profile. The final output from this simulation is shown in the figure.\nStructured density profile in EPOCH2D A simple but useful example for EPOCH2D is to have a highly structured initial condition to show that this is still easy to implement in EPOCH. A good example initial condition would be:\nbegin:control nx = 500 ny = nx x_min = -10 * micron x_max = -x_min y_min = x_min y_max = x_max nsteps = 0 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic bc_y_min = periodic bc_y_max = periodic end:boundaries begin:constant den_peak = 1.0e19 end:constant begin:species name = Electron number_density = den_peak * (sin(4.0 * pi * x / length_x + pi / 4)) \\ * (sin(8.0 * pi * y / length_y) + 1) number_density_min = 0.1 * den_peak charge = -1.0 mass = 1.0 npart = 20 * nx * ny end:species begin:species name = Proton number_density = number_density(Electron) charge = 1.0 mass = 1836.2 npart = 20 * nx * ny end:species begin:output number_density = always + species end:output  The species block for Electron is specified first, setting up the electron density to be a structured 2D sinusoidal profile. The species block for Proton is then set to match the density of Electron, enforcing charge neutrality. On its own this initial condition does nothing and so only needs to run for 0 timesteps (nsteps = 0 in input.deck). The resulting electron number density should look like the figure.\nA hollow cone in 3D A more useful example of an initial condition is to create a hollow cone. This is easy to do in both 2D and 3D, but is presented here in 3D form.\nbegin:control nx = 250 ny = nx nz = nx x_min = -10 * micron x_max = -x_min y_min = x_min y_max = x_max z_min = x_min z_max = x_max nsteps = 0 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = simple_outflow bc_y_min = periodic bc_y_max = periodic bc_z_min = periodic bc_z_max = periodic end:boundaries begin:output number_density = always + species end:output begin:constant den_cone = 1.0e22 ri = abs(x - 5.0e-6) - 0.5e-6 ro = abs(x - 5.0e-6) + 0.5e-6 xi = 3.0e-6 - 0.5e-6 xo = 3.0e-6 + 0.5e-6 r = sqrt(y^2 + z^2) end:constant begin:species name = proton charge = 1.0 mass = 1836.2 number_density = if((r gt ri) and (r lt ro), den_cone, 0.0) number_density = if((x gt xi) and (x lt xo) and (r lt ri), \\ den_cone, number_density(proton)) number_density = if(x gt xo, 0.0, number_density(proton)) npart = nx * ny * nz end:species begin:species name = electron charge = -1.0 mass = 1.0 number_density = number_density(proton) npart = nx * ny * nz end:species  Cone initial conditions in 3D Cone initial conditions in 2D To convert this to 2D, simply replace the line r = sqrt(y^2+z^2) with the line r = abs(y). The actual work in these initial conditions is done by the three lines inside the block for the Proton species. Each of these lines performs a very specific function:\n Creates the outer cone. Simply tests whether r is within the range of radii which corresponds to the thickness of the cone and if so fills it with the given density. Since the inner radius is x dependent this produces a cone rather than a cylinder. On its own, this line produces a pair of cones joined at the tip. Creates the solid tip of the cone. This line just tests whether the point in space is within the outer radius of the cone and within a given range in x, and fills it with the given density if true. Cuts off all of the cone beyond the solid tip. Simply tests if x is greater than the end of the cone tip and sets the density to zero if so.  This deck produces an initial condition as in the Figures in 3D and 2D respectively.\nFocussing a Gaussian Beam A laser can be driven on the boundary so that it focusses on a given spot. Basic details of how to do this are here. The following deck gives an example for a laser attached to x_min. The important parameters are the waist size (the size of the spot at the focus point) and the distance from the attached boundary to the focus. In this case the waist size is 0.9 micron, and the distance is 15 micron, meaning the focus is at x = + 5 micron.\nbegin:control nx = 500 ny = nx # Final time of simulation t_end = 100 * femto # Size of domain x_min = -10 * micron x_max = -x_min y_min = x_min y_max = x_max stdout_frequency = 10 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = open bc_y_min = periodic bc_y_max = periodic end:boundaries begin:constant lambda0 = 1.0 * micron # These two set the beam focus w_0 = 0.9 * micron # Beam waist size x_spot = 15 * micron # Distance from x_min to spot # These are the parameters calculated for driving the laser # These should not need to be modified x_R = pi * w_0^2 / lambda0 # Rayleigh range RC = x_spot * (1.0 + (x_R/x_spot)^2) # Radius of curvature on x_min w_bnd = w_0 * sqrt( 1.0 + (x_spot/x_R)^2) # Spot size at x_min gouy = atan(x_spot/x_R) # Gouy phase shift at x_min end:constant begin:laser boundary = x_min intensity_w_cm2 = 1.0e15 lambda = lambda0 phase = 2.0 * pi/ lambda0 * y^2 / (2.0 * RC) - gouy profile = gauss(y,0,w_bnd) end:laser begin:output name = normal # Number of timesteps between output dumps dt_snapshot = 25 * femto # Properties on grid grid = always ey = always bz = always end:output  The deck is based on the laser test deck supplied with Epoch, with a modified laser and longer runtime. Other classes of beam (Bessel etc) can be created similarly.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"d3bcb35000c59ee992f06b02811a9323","permalink":"/documentation/examples/basic_examples.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples/basic_examples.html","section":"documentation","summary":"In this section we outline a few worked examples of setting up problems using the EPOCH input deck.\nElectron two stream instability An obvious simple test problem to do with EPOCH is the electron two stream instability.","tags":null,"title":"Basic examples","type":"docs"},{"authors":null,"categories":null,"content":"EPOCH workshop overview The aims of the Workshop are:\n After the workshop you should be able to setup and run EPOCH on a problem of real importance to your research. You should also be in a position to use and understand the manual. You should learn about PIC codes in general. You should understand more about the pitfalls of trying to do LPI studies with PIC. Advice on how to run EPOCH and setup software on your home computers. Give advice to the EPOCH team on new features for the code.  Warwick EPOCH Personnel:\n Tony Arber \u0026ndash; PI on EPOCH project at Warwick. Keith Bennett \u0026ndash; PDRA and senior EPOCH developer. Chris Brady \u0026ndash; Original EPOCH developer and head of RSE at Warwick Heather Ratcliffe - EPOCH user and developer Tom Goffrey \u0026ndash; PDRA and developer on other non-EPOCH codes Alexander Seaton - Final year PhD student with extensive experience of using EPOCH  Resources:\n All machines, and exercises, are linux based. EPOCH is a Fortran90 program which uses MPI for parallelization. You will always need both F90 and MPI to compile and run the code even on one processor. MPI on a Windows computer is not easy. Use linux or a Mac.  Workstation usage You can use the workstations for simple 1D tests and looking at the code.\nUltra-simple getting EPOCH guide! These instructions should work in your host institute if you have git.\n Login to workstation using guest account. Open a terminal. Type the following command at the prompt: git clone --recursive https://github.com/Warwick-Plasma/epoch.git  You will now have a directory called \u0026lsquo;epoch\u0026rsquo;. Inside this directory will be three EPOCH sub-directories epoch1d, epoch2d and epoch3d, an SDF directory and a few other files. Change directory into the epoch1d directory and start working through the \u0026lsquo;Getting Started with EPOCH\u0026rsquo; guide.\nRunning the codes Single core job: \u0026gt; echo Data | mpiexec -n 1 bin/epoch1d Four core parallel job: \u0026gt; echo Data | mpiexec -n 4 bin/epoch2d\nNote: If you don\u0026rsquo;t have git on your home computer you can always download a tar file of epoch when you return to your lab. This you get from the \u0026lsquo;Releases\u0026rsquo; section on the EPOCH GitHub webpage. However I recommend you get, and learn, git and join the 21st century.\nGetting Started with EPOCH Compiling the code The first thing you must do is to compile the code. This is done using the UNIX \u0026ldquo;make\u0026rdquo; command. This command reads a file called Makefile and uses the instructions in this file to generate all the steps required for compiling the code. Most of this is done automatically and the only part which typically needs changing are the instructions for which compiler to use and what compiler flags it accepts. The Makefiles supplied as part of the EPOCH source code contain sections for most commonly used compilers so it is usually unnecessary to actually edit these files. Usually you can compile just by passing the name of the compiler on the command line.\nTo compile the 1D version of the code, first change to the correct directory by typing cd epoch/epoch1d. The compiler used on most desktop machines is gfortran, so you can compile the code by typing make COMPILER=gfortran. Alternatively, if you type make COMPILER=gfortran -j4 then the code will be compiled in parallel using 4 processors. If you wish, you can save yourself a bit of typing by editing your ~/.bashrc file and adding the line export COMPILER=gfortran at the top of the file. Then the command would just be make -j4.\nThe most commonly used compiler on clusters these days is the Intel FORTRAN compiler. You can compile by typing make COMPILER=intel or edit your ~/.bashrc file to add the line export COMPILER=intel at the top.\nYou should rarely need to edit the Makefile more than this. Occasionally, you may need to change fundamental behavior of the code by changing the list of flags in the \u0026ldquo;DEFINES\u0026rdquo; entry. This is documented in the User manual.\nRunning the code Once you have built the version of EPOCH that you want (1D, 2D or 3D) you simply run it by typing ./bin/epoch1d, ./bin/epoch2d, or ./bin/epoch3d. That will then show you the EPOCH splash page, which prints the logo, lists any compile time options that you specified and then asks you to specify the output directory. It will look in this directory for a file with the name \u0026ldquo;input.deck\u0026rdquo; containing the problem setup. Any output performed by the code will also be written into this directory. To work through the examples, you must download an input deck from the section below to the directory you want EPOCH to use and rename the file \u0026ldquo;input.deck\u0026rdquo;. Throughout this guide we will assume that you use the directory named \u0026ldquo;Data\u0026rdquo;.\nGetting the example decks for this workshop The example input decks used in this workshop can be downloaded using the following links. Create a directory \u0026ldquo;~/EXAMPLES\u0026rdquo; to put them in:\ncd . mkdir EXAMPLES  then download the .zip to this folder (either click the link and then copy the file, or right-click and select the save-as option). All decks as a .zip\n 01-1d_laser.deck - A simple laser\n 02-2d_laser.deck - A simple 2d laser\n 03-1d_two_stream.deck - A simple two-stream instability\n 04-1d_two_stream_io.deck - The same two-stream instability with extended output\n 05-2d_moving_window.deck - Simple moving-window problem with density jump and laser\n 06-2d_ramp.deck - Gaussian laser into a density ramp\n 07-1d_heating.deck - Demonstration of numerical heating\nA Basic EM-Field Simulation Our first example problem will be a simple 1D domain with a laser. This should give you a simple introduction to the input deck and visualization of 1D datasets.\nBegin by copying the \u0026ldquo;01-1d_laser.deck\u0026rdquo; file from the EXAMPLES directory into the \u0026ldquo;Data\u0026rdquo; directory using the command: cp ~/EXAMPLES/01-1d_laser.deck Data/input.deck\n Or click to expand and copy this text into a file \"input.deck\" in your Data directory. begin:control nx = 200 # Size of domain x_min = -4 * micron x_max = -x_min # Final time of simulation t_end = 50 * femto #stdout_frequency = 10 end:control begin:boundaries bc_x_min = open #bc_x_min = simple_laser bc_x_max = open end:boundaries #begin:laser # boundary = x_min # intensity_w_cm2 = 1.0e15 # lambda = 1 * micron # phase = pi / 2 # t_profile = gauss(time, 2*micron/c, 1*micron/c) # t_end = 4 * micron / c #end:laser # # #begin:output # dt_snapshot = 1 * micron / c # # # Properties on grid # grid = always # ey = always #end:output   Open the input deck with an editor to view its contents. Eg. \u0026ldquo;gedit Data/input.deck\u0026rdquo;\nThis is the simplest possible input deck. The file is divided into blocks which are surrounded by \u0026ldquo;begin:blocktype\u0026rdquo; and \u0026ldquo;end:blocktype\u0026rdquo; lines. There are currently ten different blocktypes. The most basic input deck requires only two.\nThe first block is the \u0026ldquo;control\u0026rdquo; block. This is used for specifying the domain size and resolution and the length of time to run the simulation. There are also some global simulation parameters that can be specified in this block which will be introduced later. Within the block, each parameter is specified as a \u0026ldquo;name = value\u0026rdquo; pair.\nThe parameters are as follows. \u0026ldquo;nx\u0026rdquo; specifies the number of grid points in the x-direction (since this is a 1D code, the grid is only defined in the x-direction). \u0026ldquo;x_min\u0026rdquo; and \u0026ldquo;x_max\u0026rdquo; give the minimum and maximum grid locations measured in meters. Since most plasma simulations are measured in microns, there is a \u0026ldquo;micron\u0026rdquo; multiplication factor for convenience. There are also multiplication factors for \u0026ldquo;milli\u0026rdquo; through to \u0026ldquo;atto\u0026rdquo;. Finally, the simulation time is specified using \u0026ldquo;t_end\u0026rdquo; measured in seconds.\nThere are also commented lines in the deck. Any text following the \u0026ldquo;#\u0026rdquo; character is ignored. The character may appear anywhere on a line, so in the following example: t_end = 50 #* femto The value of \u0026ldquo;t_end\u0026rdquo; will be set to 50 seconds, since \u0026ldquo;#* femto\u0026rdquo; is ignored.\nThe other required block is the \u0026ldquo;boundaries\u0026rdquo; block. This contains one entry for each boundary, specifying what boundary condition to apply. For the 1D code there are two boundaries: \u0026ldquo;bc_x_min\u0026rdquo; and \u0026ldquo;bc_x_max\u0026rdquo;. The deck currently has both of these set to use open boundary conditions.\nTo run the code type: echo Data | mpiexec -n 4 ./bin/epoch1d\nThis will run epoch1d in parallel using 4 processors. It will use the directory named \u0026ldquo;Data\u0026rdquo; for all its output and will read the file \u0026ldquo;Data/input.deck\u0026rdquo; to obtain the simulation setup.\nThis simulation is rather dull. It is just a grid with zero electromagnetic field and it generates no data files. After running the program, two files are generated in the \u0026ldquo;Data\u0026rdquo; directory. The \u0026ldquo;deck.status\u0026rdquo; file contains the results from the deck parsing routines and is only useful for debugging. The \u0026ldquo;epoch1d.dat\u0026rdquo; file contains a terse one line header with the code name, version information and time the job started followed by a list of output dumps generated during the run.\nStatus information about the running job can be requested by uncommenting the \u0026ldquo;stdout_frequency\u0026rdquo; line in the \u0026ldquo;control\u0026rdquo; block. This is achieved by using a text editor to remove the \u0026ldquo;#\u0026rdquo; character and saving the file.\nAdding a laser We will now edit this input deck to add a laser source to the left hand boundary and dump some output files.\n Open the \u0026ldquo;Data/input.deck\u0026rdquo; file with an editor. Add a \u0026ldquo;#\u0026rdquo; comment character to the beginning of the first \u0026ldquo;bc_x_min\u0026rdquo; line in the \u0026ldquo;boundaries\u0026rdquo; block. Uncomment the line \u0026ldquo;bc_x_min = simple_laser\u0026rdquo; Uncomment the remaining lines in the file.  The change to the \u0026ldquo;boundaries\u0026rdquo; block instructs the code to add a laser source to the left-hand boundary.\nThe Laser Block We then require a new block, named \u0026ldquo;laser\u0026rdquo;, to set up the laser source. The parameters in this block do the following:\n boundary \u0026ndash; Specifies the boundary on which to attach this laser source intensity_w_cm2 \u0026ndash; Specifies the intensity of the laser in Watts / cm^2 lambda \u0026ndash; Gives the wavelength of the laser in meters. We have used the multiplication factor \u0026ldquo;micron\u0026rdquo; for readability phase \u0026ndash; Specifies the phase shift of the laser. t_profile \u0026ndash; This parameter is used to modify the amplitude of the laser over time. It is usually used to ramp a laser up or down gradually. The left-hand side will be a function of time, usually ranging between zero and one. t_end \u0026ndash; The time at which to switch off the laser.  These parameters are mostly self-explanatory. The \u0026ldquo;t_profile\u0026rdquo; parameter is best explained using an example. The figure above shows the result of using a gaussian time profile. The red line shows the value of \u0026ldquo;t_profile\u0026rdquo; over time. This starts at a value close to zero, ramps up to one and then ramps back down to zero. The green line shows the amplitude of the laser when \u0026ldquo;t_profile\u0026rdquo; has not been specified. Note that the function would normally be a sine wave, but this has been shifted by pi/2 because the \u0026ldquo;phase\u0026rdquo; parameter was used. The blue line shows the laser amplitude generated when the \u0026ldquo;t_profile\u0026rdquo; gaussian profile is applied.\nThe Output Block The final addition is the \u0026ldquo;output\u0026rdquo; block. We will cover this in more detail later. For now, it is sufficient to know that this is the block which controls the generation of data output. The parameters used in this case are:\n dt_snapshot \u0026ndash; This specifies the simulation time between each output dump grid \u0026ndash; This controls when to dump the simulation grid. The value of \u0026ldquo;always\u0026rdquo; means that the grid will be output whenever there is a new output dump generated. ey \u0026ndash; The controls when to dump the y-component of the electric field.  Visualising the data Now that we have generated some data we need to plot it. The data is written to a self-describing file format called SDF. This has been developed for use by several codes maintained at the University of Warwick. There are routines for reading the data from within IDL, VisIt, MatLab and Python.\nMore complete documentation on visualisation routines is available here\nLoading the data into IDL/GDL First, we will load the data into IDL/GDL. The desktop machines have GDL installed \u0026ndash; the GNU Data Language, which is a free implementation of IDL. It doesn\u0026rsquo;t have all the feature of IDL but the core routines and syntax are identical. Type gdl Start.pro and GDL will start up and load the SDF reading library. To view the data contained in a file, type list_variables,7,'Data' Here, \u0026ldquo;7\u0026rdquo; is the snapshot number. It can be any number between 0 and 9999. The second parameter specifies the directory which holds the data files. If it is omitted then the directory named \u0026ldquo;Data\u0026rdquo; is used by default.\nTo load the data and assign the result to a structure named \u0026ldquo;data\u0026rdquo;, just issue the following command: data = getstruct(7,/varname) Here, \u0026ldquo;/varname\u0026rdquo; is any of the variables listed by the previous command. This will just read the \u0026ldquo;varname\u0026rdquo; variable into the data structure. However, it is usually easiest just to omit the \u0026ldquo;/varname\u0026rdquo; flag. If it is omitted then the entire contents of the file is read.\nThe \u0026ldquo;getstruct\u0026rdquo; command returns a hierarchical data structure. The contents of this structure can be viewed with the following command: help,data,/struct For the current example the result of this command is the following:\n GDL\u0026gt; help,data,/struct ** Structure \u0026lt;Anonymous\u0026gt;, 8 tags, data length=5552: FILENAME STRING 'Data/0007.sdf' TIMESTEP LONG 185 TIME DOUBLE 2.3449556e-14 HEADER STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] ELAPSED_TIME STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] EY STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] GRID STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] X DOUBLE Array[200]  The first few entries are fairly self-explanatory. The seventh item is a 1D array containing the cell-centred grid positions. The fiftth item is a structure containing a 1D array of Ey at these positions. This structure can be queried in the same way as \u0026ldquo;data\u0026rdquo; :\n GDL\u0026gt; help,data.ey,/struct ** Structure \u0026lt;Anonymous\u0026gt;, 2 tags, data length=1728: METADATA STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] DATA DOUBLE Array[200]  The raw data is contained in the \u0026ldquo;data\u0026rdquo; entry. The sixth entry, \u0026ldquo;GRID\u0026rdquo; is a structure which contains :\nGDL\u0026gt; help,data.grid,/struct ** Structure \u0026lt;Anonymous\u0026gt;, 5 tags, data length=1824: METADATA STRUCT -\u0026gt; \u0026lt;Anonymous\u0026gt; Array[1] X DOUBLE Array[201] LABELS STRING Array[1] UNITS STRING Array[1] NPTS LONG Array[1]  This is the node-centred grid along with its metadata. The cell-centred array shown previously is derived from this. Finally, the HEADER entry contains metadata about the code and runtime information.\nThe above plot can be generated by issuing the following command: plot,data.x,data.ey.data There are more examples on using idl/gdl in the manual.\nLoading the data into Python EPOCH also ships with a module for reading SDF data into python. To build this module, change directory to epoch/epoch1d (or 2d,3d) and type \u0026ldquo;make sdfutils\u0026rdquo;. This will build the python reader and install it locally. It also installs a helper module which adds a few user-friendly routines. To simplify discussion, we will just focus on using this helper routine.\nOpen a python interpreter by typing \u0026ldquo;python\u0026rdquo;, or preferably \u0026ldquo;ipython\u0026rdquo; if you have it installed.\nOn the desktops, the sdf and sdf_helper modules will be imported for you, as sdf and sdf_helper respectively. On other machines, to load the SDF module, type the command:\nimport sdf_helper as sh  You can now load a data file by typing:\ndata = sh.getdata(7)  or\ndata = sdf_helper.getdata(7)  This returns a data structure which can be inspected using\ndata.__dict__  It also imports the contents of data arrays and prints a summary of what has been imported.\nFor example:\nfrom sdf_helper import * data = getdata(7) #\u0026gt;\u0026gt;Reading file Data/0007.sdf t() = time ey(200,) = ey x(201,) = grid xc(200,) = grid_mid  If you have matplotlib installed then you can load the module using\nfrom matplotlib.pyplot import *  Turn on interactive plotting with\nion()  You can now plot the data with the command:\nplot(xc,ey)  The helper module has a \u0026ldquo;plot_auto\u0026rdquo; command which automatically adds axis labels. To use this type:\nplot_auto(data.Electric_Field_Ey)  Loading the data into VisIt EPOCH comes with an SDF reader plugin for the VisIt parallel visualization tool. In order to use it, you must first compile the reader to match the version of VisIt installed on your system. To do this, first ensure that the \u0026ldquo;visit\u0026rdquo; command is in your path. This is the case if typing \u0026ldquo;visit\u0026rdquo; on the command line launches the VisIt application. Once you have this setup, you should be able to type \u0026ldquo;make visit\u0026rdquo; from one of the epoch{1,2,3}d directories. You will need to re-do this each time a new version of VisIt is installed on your system.\nLaunch the VisIt application by typing \u0026ldquo;visit\u0026rdquo; on the command line. A useful shortcut is to type visit -o Data/0000.sdf. This will launch VisIt and open the specified data file on startup. Alternatively, you can browse for the file to open using the \u0026ldquo;Open\u0026rdquo; button. All the SDF files in a directory will be grouped together with a green \u0026ldquo;DB\u0026rdquo; icon and the name \u0026ldquo;*.sdf database\u0026rdquo;.\nYou can then plot a quantity by pressing the \u0026ldquo;Add\u0026rdquo; button, selecting the type of plot and the variable to use for the plot. When the plot has been selected, press the \u0026ldquo;Draw\u0026rdquo; button to render it to screen. The plot above was generated by selecting \u0026ldquo;Add-\u0026gt;Curve-\u0026gt;Electric Field-\u0026gt;Ey\u0026rdquo;. Some of the plot properties were adjusted to make it look nicer.\nMore details on using VisIt are here. We recommend that you learn VisIt \u0026ndash; it\u0026rsquo;s free and powerful.\nLoading data into MatLab The EPOCH distribution also comes with a set of reader routines for the MatLab plotting utility. The routines themselves are contained in the \u0026ldquo;Epoch/Matlab\u0026rdquo; directory. It is first necessary to add this directory to your search path. One simple way of doing this is to use the menu item \u0026ldquo;File-\u0026gt;Set Path\u0026rdquo; and then \u0026ldquo;Add Folder\u0026rdquo; to select the location of the \u0026ldquo;Matlab\u0026rdquo; folder. To make this change permanent you have to use the \u0026ldquo;Save\u0026rdquo; button. Unfortunately, on many systems this will not work as it tries to change global settings which will not be permitted on a multi-user setup. On Unix systems (including OS X), the change can be made permanent by using the \u0026ldquo;$MATLABPATH\u0026rdquo; environment variable. For example in bash this would be \u0026lsquo;export MATLABPATH=\u0026ldquo;Epoch/Matlab\u0026rdquo; ' which you can add to your .bashrc file.\nTo load the data from an SDF file, type the following at the MatLab prompt:\ndata=GetDataSDF('Data/0007.sdf');  The \u0026ldquo;data\u0026rdquo; variable will now contain a data structure similar to that obtained with the IDL reader. You can explore the contents of the structure using MatLab\u0026rsquo;s built-in variable editor. To plot Ey, you can browse to \u0026ldquo;data.Electric_Field.Ey\u0026rdquo;. The structure member \u0026ldquo;data.Electric_Field.Ey.data\u0026rdquo; contains the 1D array with Ey values. Right-clicking on it gives a range of options, including \u0026ldquo;plot\u0026rdquo;. Alternatively, from the command prompt you can type\nx=data.Electric_Field.Ey.grid.x; xc=(x(1:end-1) + x(2:end))/2; plot(xc,data.Electric_Field.Ey.data);  The first two lines set up a cell-centred grid using the node-centred grid data. In the future, this work will be automatically done by the reader.\nA 2D laser Next, we will take a look at the 2-dimensional version of the code.\n Change to the epoch2d directory: cd ~/Epoch/epoch2d Type make -j4 to compile the code. Copy the next example input deck into the Data directory: cp ~/EXAMPLES/02-2d_laser.deck Data/input.deck or save the text below into Data/input.deck Run with echo Data | mpirun -np 4 ./bin/epoch2d   Click to expand begin:control nx = 500 ny = nx # Size of domain x_min = -10 * micron x_max = -x_min y_min = x_min y_max = x_max # Final time of simulation t_end = 50 * femto stdout_frequency = 10 end:control begin:boundaries bc_x_min = simple_laser bc_x_max = open bc_y_min = periodic bc_y_max = periodic end:boundaries begin:constant lambda0 = 1 * micron theta = pi / 8.0 end:constant begin:laser boundary = x_min intensity_w_cm2 = 1.0e15 lambda = lambda0 * cos(theta) profile = gauss(y, 0, 4*micron) #phase = -2.0 * pi * y * tan(theta) / lambda0 #t_profile = gauss(time, 2*micron/c, 1*micron/c) end:laser begin:output dt_snapshot = 1 * micron / c # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always end:output   This deck is very similar to the 1D version that we have just looked at. It contains the necessary modifications for adding a new dimension and some additions to the laser block for driving a laser at an angle.\nThe \u0026ldquo;control\u0026rdquo; block now contains \u0026ldquo;ny\u0026rdquo; which specifies the number of grid points in the y-direction. Notice that we are using the value \u0026ldquo;nx\u0026rdquo; to set \u0026ldquo;ny\u0026rdquo;. As soon as \u0026ldquo;nx\u0026rdquo; has been assigned it becomes available as a constant for use as part of a value. We must also provide the minimum and maximum grid positions in the y-direction using \u0026ldquo;y_min\u0026rdquo;, \u0026ldquo;y_max\u0026rdquo;. Like \u0026ldquo;nx\u0026rdquo;, the values \u0026ldquo;x_min\u0026rdquo; and \u0026ldquo;x_max\u0026rdquo; are available for use once they have been assigned.\nIn the \u0026ldquo;boundaries\u0026rdquo; block we must include boundary conditions for the lower and upper boundaries in the y-direction, \u0026ldquo;bc_y_min\u0026rdquo;, \u0026ldquo;bc_y_max\u0026rdquo;. These have both been set to \u0026ldquo;periodic\u0026rdquo; so that the field at the top of the domain wraps around to the bottom of the domain.\nNext, we introduce a new block type, \u0026ldquo;constant\u0026rdquo;. This block defines named variables which can be arbitrary mathematical expressions. Once defined, these can be used on the left-hand side of name-value pairs in the same way we used \u0026ldquo;nx\u0026rdquo;, \u0026ldquo;x_min\u0026rdquo;, etc. in the \u0026ldquo;control\u0026rdquo; block. This facility can greatly aid the construction and maintenance of complex input decks.\nThe \u0026ldquo;laser\u0026rdquo; block is similar to that given in the 1D version except that there is now a \u0026ldquo;profile\u0026rdquo; parameter. In a similar manner to \u0026ldquo;t_profile\u0026rdquo; this is a function ranging between 0 and 1 which is multiplied by the wave amplitude to give a modified laser profile. The only difference is that this is a function of space rather than time. When applied to a laser attached to \u0026ldquo;x_min\u0026rdquo; or \u0026ldquo;x_max\u0026rdquo; it is a function of Y, defined at all points along the boundary. When the laser is attached to \u0026ldquo;y_min\u0026rdquo; or \u0026ldquo;y_max\u0026rdquo;, it is a function of X.\nFinally, the output block has been modified so that it outputs all electromagnetic field components.\nThe result of plotting \u0026ldquo;Add-\u0026gt;Pseudocolor-\u0026gt;Electric Field-\u0026gt;Ey\u0026rdquo; in VisIt is shown above. The laser block also contains a commented-out \u0026ldquo;phase\u0026rdquo; entry. Unlike in the 1D version seen previously, this is a function of Y, like the \u0026ldquo;profile\u0026rdquo; parameter. Uncommenting this line and re-running the deck will generate a laser driven at an angle to the boundary. The mathematical details explaining why this works are explained in more detail in the User Manual. By making the value of \u0026ldquo;theta\u0026rdquo; a function of Y, it is also possible to produce a focused laser. This is left as an exercise for the reader!\nThe above plot can also be generated using matplotlib using the command plot2d(data.Electric_Field_Ey)\nSpecifying particle species In this example we will finally introduce some particles into the PIC code! The deck is for the 1D version of the code, so change back to the epoch1d directory and copy ~/EXAMPLES/03-1d_two_stream.deck to Data/input.deck (or copy the deck below) and run the code.\n Click to expand begin:control nx = 400 # Size of domain x_min = 0 x_max = 5.0e5 # Final time of simulation t_end = 1.5e-1 stdout_frequency = 400 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:constant drift_p = 2.5e-24 temp = 273 dens = 10 end:constant begin:species # Rightwards travelling electrons name = Right charge = -1 mass = 1.0 temp = temp drift_x = drift_p number_density = dens npart = 4 * nx end:species begin:species # Leftwards travelling electrons name = Left charge = -1 mass = 1.0 temp = temp drift_x = -drift_p number_density = dens npart = 4 * nx end:species begin:output # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties at particle positions particles = always px = always # Properties on grid grid = always ey = always end:output   The control block has one new parameter. \u0026ldquo;npart\u0026rdquo; gives the total number of PIC particles to use in the simulation.\nThe input deck contains a new block type, \u0026ldquo;species\u0026rdquo;, which is used for populating the domain with particles. Every species block must contain a \u0026ldquo;name\u0026rdquo; parameter. This is used to identify the particle species in other sections of the input deck and is also used for naming variables in the output dumps. The next parameter is \u0026ldquo;charge\u0026rdquo; which gives the charge on each particle in terms of elementary charge units. \u0026ldquo;mass\u0026rdquo; is specified in units of electron mass. \u0026ldquo;frac\u0026rdquo; is the fraction of the total number of PIC particles (npart) to assign to this species. Both of the blocks in this deck use \u0026ldquo;frac = 0.5\u0026rdquo;, so there will be 1600 particles of each species. The next parameter, \u0026ldquo;temp\u0026rdquo;, sets the average temperature of the particle species in Kelvin. Alternatively, you can use \u0026ldquo;temp_ev\u0026rdquo; to specify the temperature in electronvolts. Particles are assigned an initial momentum corresponding to a Maxwell-Boltzmann distribution for this temperature. It is defined across the entire problem domain, so in 1D it is a function of X, in 2D a function of X and Y, and in 3D a function of X, Y and Z. \u0026ldquo;number_density\u0026rdquo; sets the number density across the problem domain. The code is set to use per-particle weights in the default Makefile. With this option, the pseudoparticles are distributed evenly across the domain. Then the weight of each pseudoparticle is adjusted so that it matches the number density specified in the \u0026ldquo;number_density\u0026rdquo; parameter. The alternative option is to disable per-particle weighting. In this case, the weight of each pseudoparticle is the same and the particles are placed on the grid so that they match the number density at the start of the simulation. Finally, we have a \u0026ldquo;drift_x\u0026rdquo; parameter. This is also defined across the entire problem domain and is used to give the particles an average momentum drift in the x-direction. There are similar \u0026ldquo;drift_y\u0026rdquo; and \u0026ldquo;drift_z\u0026rdquo; parameters.\nThis deck has been designed to simulate a two-stream instability, so it has two groups of particles which are identical in every respect except that one set is drifting in the opposite direction to the other. In the output block we have added a couple of parameters for outputting particle data. The first parameter, \u0026ldquo;particles\u0026rdquo;, outputs the grid on which the particles are defined. There are two different types of variable in EPOCH: particle variables and grid-based variables. The grid-based variables are like the electromagnetic field components we have seen previously. The domain is divided into a regular Cartesian mesh and the grid-based variables are defined at either a node or cell-centre of each point in this mesh. Particle variables, on the other hand, are associated with each of the pseudoparticles. These PIC particles move independently of the Cartesian mesh and can be located anywhere in the problem domain. The \u0026ldquo;particles\u0026rdquo; parameter requests that the coordinates of each particle are written to file. This information is required in order to plot any of the particle variables. The next parameter is \u0026ldquo;px\u0026rdquo; which writes the momentum of each particle.\nTo plot this using python and matplotlib, type the following:\ndata = getdata(30) plot1d(data.Particles_Px_Left,'r.',ms=2,yscale=1) oplot1d(data.Particles_Px_Right,'b.',ms=2,yscale=1) ylim([-6e-24,6e-24])  To plot with GDL, type the following:\ngdl Start.pro data=getstruct(30) plot,data.grid_right.x,data.px_right.data,psym=3,$ yrange=[-6e-24,6e-24],ystyle=1 oplot,data.grid_left.x,data.px_left.data,psym=3,color=150  Above we have plotted the x-component of particle momentum as a function of x-position at a time when the instability is just starting to form. The \u0026ldquo;psym=3\u0026rdquo; option to the plot routine tells GDL to plot each data point as a dot and not to join the dots up.\nThe Output Block The contents of the output block can be much more complicated than the examples shown so far. Here, we will cover the options in a little more depth.\nEPOCH currently has three different types of output dump. So far, we have only been using the \u0026ldquo;normal\u0026rdquo; dump type. The next type of dump is the \u0026ldquo;full\u0026rdquo; dump. To request this type of dump, you add the parameter \u0026ldquo;full_dump_every\u0026rdquo; which is set to an integer. If this was set equal to \u0026ldquo;10\u0026rdquo; then after every 9 dump files written, the 10th dump would be a \u0026ldquo;full\u0026rdquo; dump. This hierarchy exists so that some variables can be written at frequent intervals whilst large variables such as particle data are written only occasionally. The third dump type is the \u0026ldquo;restart\u0026rdquo; dump. This contains all the variables required in order to restart a simulation, which includes all the field variables along with particle positions, weights and momentum components. In a similar manner to full dumps, the output frequency is specified using the \u0026ldquo;restart_dump_every\u0026rdquo; parameter.\nSo far, we have given all the variable parameters a value of \u0026ldquo;always\u0026rdquo; so that they will always be dumped to file. There are three other values which can be used to specify when a dump will occur. \u0026ldquo;never\u0026rdquo; indicates that a variable should never be dumped to file. This is the default used for all output variables which are not specified in the output block. The value of \u0026ldquo;full\u0026rdquo; indicates that a variable should be written at full dumps. \u0026ldquo;restart\u0026rdquo; means it is written into restart dumps.\nThere are a few output variables which are grid-based quantities derived by summing over properties for all the particles contained within each cell on the mesh. These are \u0026ldquo;ekbar\u0026rdquo;, \u0026ldquo;mass_density\u0026rdquo;, \u0026ldquo;charge_density\u0026rdquo;, \u0026ldquo;number_density\u0026rdquo; and \u0026ldquo;temperature\u0026rdquo;. To find more details about these variables, consult the output block section of the user manual.\nOther Laser-Plasma example decks  Continue the examples\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"1d41a763e549cd5ac4399b5a8e67d90c","permalink":"/documentation/examples/workshop_examples.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples/workshop_examples.html","section":"documentation","summary":"EPOCH workshop overview The aims of the Workshop are:\n After the workshop you should be able to setup and run EPOCH on a problem of real importance to your research.","tags":null,"title":"Workshop examples","type":"docs"},{"authors":null,"categories":null,"content":"Other Laser-Plasma example decks Now that you have a basic understanding of how the input decks work, you should be able to work through the remaining example decks by referring to the User manual for a description of any new parameters used. Several experienced users of the code will be available throughout the duration of the workshop, so if you want help with anything please don\u0026rsquo;t hesitate to ask. The decks are:\n 01-1d_laser.deck Described in notes above (here) 02-2d_laser.deck Described in notes above (here) 03-1d_two_stream.deck Described in notes above (here) 04-1d_two_stream_io.deck This is the same as the previous deck but with the addition of more sophisticated output diagnostics 05-2d_moving_window.deck This deck contains an example of firing a laser into a plasma and then using the moving window facility to track the wave front as it moves beyond the edge of the original domain. 06-2d_ramp.deck This deck contains an example of firing a laser at a plasma with a ramped density profile. 07-1d_heating.deck This deck contains a setup for investigating the anomalous heating of a plasma that occurs for purely resolved systems.  Other things to try  Landau damping predicts collisionless damping of electrostatic waves. Setup a 1D problem with an electrostatic wave and check for a range of wavelengths. Points to note:  Does the answer depend on whether the initial condition is a travelling wave or standing wave? How are these setup? Look for trapping in the Langmuir wave Check the damping rate against published formulae. Try for a range of $k\\lambda_D$ as the most commonly reported formulae assume $kλ_D≪1$ The answer is more accurate, assuming you have enough grid-points and particles to get a good answer, if you ignore the first maxima or two \u0026ndash; why?   A more realistic instability than the two cold beams tested above is the bump-on-tail instability. Setup a 1D bump-on-tail distribution and check that the simple formula for the growth-rates is correctly reproduced. The main problem with the initial conditions is how to setup a suitable initial distribution. Try setting up the initial conditions for a problem of direct relevance to your research. This may be too computationally demanding to run on the workshop computers but it is a good exercise as you can get some help on trickier input decks and diagnostic planning than the simple exercises so far. Check that EPOCH works as expected on your host institution computer. If not we may be able to help before you leave.  Copies of the decks The decks can be downloaded here and viewed or copied from here:\n 04-1d_two_stream_io.deck (click to expand) begin:control nx = 400 # Size of domain x_min = 0 x_max = 5.0e5 # Final time of simulation t_end = 1.5e-1 stdout_frequency = 400 end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:constant drift_p = 2.5e-24 temp = 273 dens = 10 end:constant begin:species # Rightwards travelling electrons name = Right charge = -1 mass = 1.0 temp = temp drift_x = drift_p number_density = dens npart = 4 * nx end:species begin:species # Leftwards travelling electrons name = Left charge = -1 mass = 1.0 temp = temp drift_x = -drift_p number_density = dens npart = 4 * nx end:species begin:output name = normal # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties at particle positions particles = always px = always # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always ekbar = always mass_density = never + species charge_density = always number_density = always + species temperature = always + species distribution_functions = always end:output begin:output name = restart # Number of timesteps between output dumps dt_snapshot = 0.15 restartable = T end:output begin:dist_fn name = x_px ndims = 2 direction1 = dir_x direction2 = dir_px # Range is ignored for spatial coordinates range1 = (1, 1) range2 = (-5e-24, 5e-24) # Resolution is ignored for spatial coordinates resolution1 = 1 resolution2 = 200 include_species:Left include_species:Right end:dist_fn    05-2d_moving_window.deck (click to expand) begin:constant x0 = 20 * micron lambda = 10 * micron t_laser = 120 * femto sigma_t = t_laser / 2 / sqrt(loge(2)) w0_laser = 30 * micron sigma_w0 = w0_laser / 2 / sqrt(loge(2)) den_peak = 5.0e19 * 1.0e6 win_start = 340 * femto end:constant begin:control nx = 1550 / 8 ny = 600 / 8 npart = (60e6) / 8 # Size of domain x_min = 0 x_max = 155 * micron y_min = -30 * micron y_max = -y_min # Final time of simulation t_end = 1600 * femto stdout_frequency = 1 print_eta_string = T end:control begin:boundaries bc_x_min = simple_laser bc_x_max = simple_outflow bc_y_min = simple_outflow bc_y_max = simple_outflow end:boundaries begin:species name = electron charge = -1.0 mass = 1.0 number_density = if((x lt x0), 0.0, den_peak) frac = 0.5 end:species begin:species name = proton charge = 1.0 mass = 1836.2 number_density = number_density(electron) frac = 0.5 end:species begin:output name = normal dt_snapshot = 50 * femto grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always jy = always ekbar = always mass_density = never + species charge_density = always number_density = always + species temperature = always + species end:output begin:output name = large dt_snapshot = 500 * femto particles = always particle_weight = always end:output begin:laser boundary = x_min intensity_w_cm2 = 1.9e18 lambda = lambda t_profile = gauss(time, 2*sigma_t, sigma_t) profile = gauss(y, 0, sigma_w0) end:laser begin:window move_window = T window_v_x = c * 0.87 window_start_time = win_start bc_x_min_after_move = simple_outflow bc_x_max_after_move = simple_outflow end:window    06-2d_ramp.deck (click to expand) begin:constant # Particles per cell part = 32 las_lambda = 1 * micron las_omega = 2.0 * pi * c / las_lambda las_time = 2.0 * pi / las_omega n_crit = critical(las_omega) max_dens = 0.8 * n_crit scale_x = 20 * micron las_scale_y = 8 * micron xmin = -4 * micron # Gaussian Beam stuff w0 = las_scale_y rayleigh_range = pi * w0^2 / las_lambda wz = w0 * sqrt(1 + (x_start / rayleigh_range)^2) radius_of_curvature = x_start * (1.0 + (rayleigh_range / x_start)^2) end:constant begin:control nx = 1024 / 4 ny = 512 / 4 # Final time of simulation t_end = 0.4 * pico # Size of domain x_min = xmin x_end = scale_x + 20 * micron y_min = -20 * micron y_max = -y_min stdout_frequency = 10 end:control begin:laser boundary = x_min intensity_w_cm2 = 1.0e16 omega = las_omega t_profile = if (time lt 2*las_time, gauss(time, 2*las_time, 2*las_time), 1) profile = (1.0 + 0.05 * sin(32.0*pi*y/lengthy)) * gauss(y, 0, las_scale_y) end:laser begin:boundaries bc_x_min = simple_laser bc_x_max = simple_outflow bc_y_min = periodic bc_y_max = periodic end:boundaries begin:species # Electron name = electron charge = -1.0 mass = 1.0 npart = nx * ny * part number_density = max_dens * (exp(x/scale_x) - 1) / (exp(1) - 1) number_density = if(x lt 0, 0.0, number_density(electron)) number_density = if(number_density(electron) gt max_dens, max_dens, \\ number_density(electron)) number_density = if(x gt 75*micron, 0.0, number_density(electron)) #number_density = number_density(electron) \\ * (0.8 + 0.2 * gauss(y, 0, 0.5*las_scale_y)) number_density_min = 0.0001 * n_crit number_density_max = n_crit temp_ev = 10^3 end:species begin:species # Protons name = proton charge = 1.0 mass = 1836.2 npart = nx * ny * part number_density = number_density(electron) number_density_min = 0.0001 * n_crit number_density_max = 1.2 * n_crit temp_ev = 40 end:species begin:output name = normal # Number of timesteps between output dumps dt_snapshot = 5 * femto # Properties at particle positions particles = always px = always particle_weight = always # Properties on grid grid = always ex = always ey = always ez = always bx = always by = always bz = always jx = always jy = always jz = always ekbar = always + species mass_density = never + species charge_density = always # + average + snapshot number_density = always + species temperature = never + species # Extended io distribution_functions = always end:output begin:dist_fn name = en ndims = 1 direction1 = dir_en range1 = (0, 15*kev) resolution1 = 5000 include_species:electron end:dist_fn begin:dist_fn name = x_en ndims = 2 direction1 = dir_x direction2 = dir_en # Range is ignored for spatial coordinates #range1 = (1, 1) range2 = (0, 15*kev) # Resolution is ignored for spatial coordinates #resolution1 = 1 resolution2 = 1500 include_species:electron end:dist_fn begin:dist_fn name = x_px ndims = 2 direction1 = dir_x direction2 = dir_px # Range is ignored for spatial coordinates #range1 = (1, 1) range2 = (-5e-23, 5e-23) # Resolution is ignored for spatial coordinates #resolution1 = 1 resolution2 = 1500 include_species:electron end:dist_fn begin:probe name = electron_probe point = (0.5 * (x_max + x_min), y_min) normal = (1, 0) include_species:electron include_species:proton end:probe    07-1d_heating.deck (click to expand) begin:constant dl = 74.33942 * micron end:constant begin:control nx = 10 # Size of domain x_min = 0 x_max = 14000 * dl # Final time of simulation t_end = 1.5e-2 stdout_frequency = 10000 print_eta_string = T end:control begin:boundaries bc_x_min = periodic bc_x_max = periodic end:boundaries begin:species name = electron charge = -1 mass = 1.0 temp_x_ev = 1 number_density = 1e16 npart = nx * 5 end:species begin:output name = normal # Number of timesteps between output dumps dt_snapshot = 1.5e-3 # Properties on grid grid = always ekbar = always temperature = always end:output begin:output name = large # Number of timesteps between output dumps dt_snapshot = 75e-3 # Properties at particle positions particles = always px = always py = always pz = always end:output   Remote Visualisation with VisIt If the local workstation you are using isn\u0026rsquo;t big enough for your test problems you may also use a your host institutes HPC cluster.\nRemote Visualisation with VisIt Most large simulations are carried out on a remotely located machine. Often this machine is located many miles away, perhaps even in a different country. Viewing data on remote systems can be awkward and poor network speeds can often make it nearly impossible. The VisIt visualisation tool solves this problem by using a client-server model. The program which reads, processes and renders the data is completely separated from the program which displays the results on the screen. It is therefore possible to run VisIt on your local machine and look at data located on a different machine. The method of setting this up varies depending on the configuration of the remote machine so we will not go into details here. However, the desktop machines have been setup to be able to view data located on remote clusters so you can try it out.\nIn the VisIt control window, click the \u0026ldquo;Open\u0026rdquo; button which launches a file browser window. The first entry is called \u0026ldquo;Host\u0026rdquo; and contains a drop-down list of all configure remote machines.\nIf you want to know more about how to set up remote visualisation in VisIt, you can ask one of the Warwick staff members.\nWhen viewing data across a slow network connection, there is one more useful thing to know. VisIt has two methods of drawing plots generated on a remote machine. The first method is to construct the polygons used in drawing the plot on the remote machine and send them across the network. The local machine then turns these into a plot image. This makes manipulating the figure very fast (zooming, rotating, etc), since all the polygons that generate the image are on the local machine. However, if there are a lot of polygons then they can be slow to transfer across the network. They can also use up a lot of memory. For these cases, the alternative is to render the image on the remote machine and just transfer the image across the network. The downside of this approach is that whenever you manipulate the plot, it must be re-drawn on the remote machine and then transferred across the network again. The options controlling this behaviour are to be found under \u0026ldquo;Options-\u0026gt;Rendering\u0026rdquo; in the \u0026ldquo;Advanced\u0026rdquo; tab. The feature is called \u0026ldquo;scalable rendering\u0026rdquo;.\nCollisions in EPOCH EPOCH now contains a collision routine based on the technique outlined in Sentoku \u0026amp; Kemp1\nCollisions are enabled using the output block named collisions which accepts the following three parameters.\n use_collisions \u0026ndash; This is a logical flag which determines whether or not to call the collision routine. If omitted, the default is \u0026ldquo;true\u0026rdquo; if any of the frequency factors are non-zero (see below) and \u0026ldquo;false\u0026rdquo; otherwise.   coulomb_log \u0026ndash; This may either be set to a real value, specifying the Coulomb logarithm to use when scattering the particles or to the special value \u0026ldquo;auto\u0026rdquo;. If \u0026ldquo;auto\u0026rdquo; is used then the routine will calculate a value based on the properties of the two species being scattered. If omitted, the default value is \u0026ldquo;auto\u0026rdquo;.   collide \u0026ndash; This sets up a symmetric square matrix of size nspecies*nspecies containing the collision frequency factors to use between particle species. The element (s1,s2) gives the frequency factor used when colliding species s1 with species s2. If the factor is less than zero, no collisions are performed. If it is equal to one, collisions are performed normally. For any value between zero and one, the collisions are performed using a frequency multiplied by the given factor. If \u0026ldquo;collide\u0026rdquo; has a value of \u0026ldquo;all\u0026rdquo; then all elements of the matrix are set to one. If it has a value of \u0026ldquo;none\u0026rdquo; then all elements are set to minus one. If the syntax \u0026ldquo;species1 species2 \u0026rdquo; is used, then the (species1,species2) element of the matrix is set to the factor \u0026ldquo;\u0026rdquo;. This may either be a real number, or the special value \u0026ldquo;on\u0026rdquo; or \u0026ldquo;off\u0026rdquo;. The \u0026ldquo;collide\u0026rdquo; parameter may be used multiple times. The default value is \u0026ldquo;all\u0026rdquo; (ie. all elements of the matrix are set to one).  For example:\nbegin:collisions use_collisions = T coulomb_log = auto collide = all collide = spec1 spec2 off collide = spec2 spec3 0.1 end:collisions  With this block, collisions are turned on and the Coulomb logarithm is automatically calculated. All values of the frequency array are set to one except (spec1,spec2) is set to minus one (and also (spec2,spec1)) and (spec2,spec3) is set to 0.1\nIonisation in EPOCH EPOCH includes field ionization which can be activated by defining \u0026ldquo;field_ionisation = T\u0026rdquo; in the control block along with ionisation energies and an electron for the ionising species in one of the species blocks. This is done via the species block in the \u0026ldquo;ionisation_energies\u0026rdquo; and \u0026ldquo;electron_species\u0026rdquo; parameter respectively. \u0026ldquo;ionisation_energies\u0026rdquo; should be given as a list in joules, and \u0026ldquo;electron_species\u0026rdquo; should be the name of the species to be used as the electron species. For example, ionising carbon species might appear in the input deck as:\nbegin:species charge = 0.0 mass = 1837.2 name = carbon ionisation_energies = \\ (11.26*ev, 24.38*ev, 47.89*ev, 64.49*ev, 392.1*ev, 490.0*ev) electron_species = electron number_density = den_gas end:species begin:species charge = -1.0 mass = 1.0 name = electron number_density = 0.0 end:species  It is possible to define different electron species for each ionisation level, which is particularly useful in monitoring specific ionisation levels. If we wished to monitor the fourth ionisation level of carbon in the above example, the above example might appear:\nbegin:species charge = 0.0 mass = 1837.2 name = carbon ionisation_energies = \\ (11.26*ev, 24.38*ev, 47.89*ev, 64.49*ev, 392.1*ev, 490.0*ev) electron_species = (electron, electron, electron, fourth, electron, electron) number_density = den_gas end:species begin:species charge = -1.0 mass = 1.0 name = electron number_density = 0.0 end:species begin:species charge = -1.0 mass = 1.0 name = fourth number_density = 0.0 end:species  Field ionisation consists of three distinct regimes; multiphoton in which ionisation is best described as absorption of multiple photons, tunneling in which deformation of the atomic coulomb potential is the dominant factor, and barrier suppression ionisation in which the electric field is strong enough for an electron to escape classically. It is possible to turn off multiphoton or barrier suppression ionisation through the input deck by adding \u0026ldquo;use_multiphoton=F\u0026rdquo; and/or \u0026ldquo;use_bsi=F\u0026rdquo; to the control block.\nQED Effects in EPOCH EPOCH has recently been extended to include some quantum electrodynamic effects that are important for high intensity (\u0026gt;) lasers. The two processes that are included are\n Gamma ray production by QED corrected synchrotron emission (Also called magnetic bremsstrahlung or nonlinear Compton scattering). Electron positron pair production by the Breit-Wheeler process from these gamma ray photons.  For more information on the theory see Duclous et al. 2\nSimulating the QED effects increases EPOCH\u0026rsquo;s memory requirements and so the code has to be compiled with the correct compilation options to turn the module on. To turn the module on, open \u0026ldquo;Makefile\u0026rdquo; in an editor and find the commented out line #DEFINES += $(D)PHOTONS. Uncomment this line, then type \u0026ldquo;make clean\u0026rdquo; and then \u0026ldquo;make\u0026rdquo; (remember to include the COMPILER= if you haven\u0026rsquo;t specified the environment variable) to rebuild the code with QED support.\nOnce the code is built with QED support, actually turning on QED for a specific simulation requires the addition of a new block into the input deck. This block is simply called qed and starts with the usual \u0026ldquo;begin:qed\u0026rdquo; and \u0026ldquo;end:qed\u0026rdquo; markers of the other blocks. The parameters which can go into the block are:\n use_qed - Turns QED on or off. If you don\u0026rsquo;t want QED effects at all then compile the code without the \u0026ldquo;-DPHOTONS\u0026rdquo; lines in the makefile. qed_start_time - Specifies the time after which QED effects should be turned on. For example you can turn off the routines until a laser has crossed the vacuum region in front of the target. produce_photons - Specifies whether you\u0026rsquo;re interested in the photons generated by synchrotron emission. If this is F then the radiation reaction force is calculated but the properties of the emitted photons are not tracked. photon_energy_min - Minimum energy of produced photons. Radiation reaction is calculated for photons of all energies, but photons with energy below this cutoff are not tracked. photon_dynamics - If F then photons are generated, but their motion through the domain is not simulated and they stay where they were generated. Photon motion is often less interesting than photon generation unless you want to simulate pair production. In these cases set this to F. produce_pairs - Whether or not to simulate the process of pair generation from gamma ray photons. Both produce_photons and photon_dynamics must be T for this to work. qed_table_location - EPOCH\u0026rsquo;s QED routines use lookup tables to calculate gamma ray emission and pair production. If you want to use tables in a different location from the default put the location in this parameter.  QED also requires that the code now know which species are electrons, positrons and photons. Rather than try to do this automatically the user has to specify the type of a species. This is done by using a single \u0026ldquo;identify\u0026rdquo; tag in a species block. To specify an electron the block in the deck would look like\nbegin:species name = electron frac = 0.5 number_density = 7.7e29 identify:electron end:species  Once the identity of a species is set then the code automatically assigns mass and charge states for the species. At present, the user cannot override these. Possible identities are\n electron : A normal electron species. All species of electrons in the simulation must be identified in this way or they will not generate photons. positron : A normal positron species. All species of positron in the simulation must be identified in this way or they will not generate photons. photon : A normal photon species. One species of this type is needed for photon production to work. If multiple species are present then generated photons will appear in the first species of this type. bw_electron : The electron species for pair production. If a species of this type exists then electrons from the pair production module will be created in this species. If no species of this type is specified then pair electrons will be generated in the first electron species. bw_positron : The positron species for pair production. If a species of this type exists then positrons from the pair production module will be created in this species. If no species of this type is specified then pair positrons will be generated in the first positron species.  A species should be identified only once, so a \u0026ldquo;bw_electron\u0026rdquo; species does not need to also be identified as an \u0026ldquo;electron\u0026rdquo; species. If the code is running with \u0026ldquo;produce_photons=T\u0026rdquo; then a photon species must be created by user and identified. If the code is running with \u0026ldquo;produce_pairs=T\u0026rdquo; then the code must specify at least one electron (or bw_electron) species and one positron (or bw_positron) species. The code will fail to run if the needed species are not specified.\nOther Useful Info Bug reports, feature requests and questions All questions and requests after the workshop should be posted on the GitHub EPOCH project web page\nThe VisIt programme The VisIt programme is free. It can be downloaded from https://wci.llnl.gov/simulation/computer-codes/visit/ There are many pre-compiled binaries so this ought to be easy. If you have any problems post a question on the GitHub EPOCH project.\nGDL not IDL If you don\u0026rsquo;t have IDL, or don\u0026rsquo;t want to pay for it!, then the free GDL is available from http://gnudatalanguage.sourceforge.net/\nUpdating EPOCH To update to the latest version of EPOCH simple cd into your Epoch directory and enter \u0026lsquo;git pull\u0026rsquo;. This will work fine provided you haven\u0026rsquo;t edited any of the Fortran source code. If you have edited the source code then you need to learn git.\nGetting Old Copies of EPOCH You can also checkout an old version of EPOCH, you may want to get the version used 18 months ago to reproduce some previous simulations exactly for example. In this case it is best to checkout a new branch in the EPOCH repository. If you wanted the version from 10 February 2010 for example you would first enter git log --before=2010-02-11 This will give you the log of commits in reverse order, starting on the 11th of February. Identify the commit you want and copy the commit hash (the long string of numbers and letters following the word \u0026ldquo;commit\u0026rdquo;). To checkout a copy of this version of the code, type git checkout -b old-code  After this your repository will reflect the state of the code at that point in time. To get back to the current version, just type git checkout master\nReferences   Y. Sentoku and A. J. Kemp, \u0026ldquo;Numerical methods for particle simulations at extreme densities and temperatures: Weighted particles, relativistic collisions and reduced currents,\u0026rdquo; J. Comput. Phys., 2008. link\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n R. Duclous, J. G. Kirk, and A. R. Bell, \u0026ldquo;Monte carlo calculations of pair production in high-intensity laser plasma interactions,\u0026rdquo; Plasma Phys. Contr. F., vol. 53, no. 1, p. 015009, 2011 1.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635857383,"objectID":"c445cc87f1f7e004fbe4f077cd397e16","permalink":"/documentation/examples/workshop_examples_continued.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/examples/workshop_examples_continued.html","section":"documentation","summary":"Other Laser-Plasma example decks Now that you have a basic understanding of how the input decks work, you should be able to work through the remaining example decks by referring to the User manual for a description of any new parameters used.","tags":null,"title":"Workshop examples continued","type":"docs"},{"authors":null,"categories":null,"content":"Information about downloading and compiling EPOCH\n","date":1623628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623677148,"objectID":"9a5a2672232f151f25cbfb9f79a507e4","permalink":"/quickstart.html","publishdate":"2021-06-14T00:00:00Z","relpermalink":"/quickstart.html","section":"","summary":"Getting started with EPOCH","tags":null,"title":"Quick start","type":"page"},{"authors":null,"categories":null,"content":"The EPOCH codes are written using MPI for parallelism, but have no other libraries or dependencies. Currently, the codes are written to only require MPI1.2 compatible libraries, although this may change to require full MPI2 compliance in the future. Current versions of both MPICH and OpenMPI implement the MPI2 standard and are known to work with this code. The SCALI MPI implementation is only compliant with the MPI1.2 specification and may loose support soon. There are no plans to write a version of EPOCH which does not require the MPI libraries.\nThe code is supplied with a standard GNU make Makefile, which is also compatible with most other forms of the *make* utility. In theory it is possible to compile the code without a *make* utility, but it is much easier to compile the code using the supplied makefile.\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624401345,"objectID":"bddb619d011ae55fa45467b837a1792a","permalink":"/documentation/basic_usage/libraries.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/documentation/basic_usage/libraries.html","section":"documentation","summary":"The EPOCH codes are written using MPI for parallelism, but have no other libraries or dependencies. Currently, the codes are written to only require MPI1.2 compatible libraries, although this may change to require full MPI2 compliance in the future.","tags":null,"title":"Library requirements for the EPOCH codes","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602943396,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"/contact.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact.html","section":"","summary":"Code licensing","tags":null,"title":"License","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602943396,"objectID":"ec751500388d501a532eaca39aeccb9e","permalink":"/license.html","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/license.html","section":"","summary":"Code licensing","tags":null,"title":"License","type":"widget_page"}]